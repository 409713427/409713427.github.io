{"meta":{"title":"Wst's Blog","subtitle":"后端攻城狮","description":"","author":"ShuaiTongWang","url":"https://409713427.github.io","root":"/"},"pages":[{"title":"404","date":"2021-09-15T13:52:40.000Z","updated":"2021-09-15T13:53:21.500Z","comments":true,"path":"404/index.html","permalink":"https://409713427.github.io/404/index.html","excerpt":"","text":""},{"title":"about","date":"2021-09-15T13:49:50.000Z","updated":"2021-09-15T13:50:10.277Z","comments":true,"path":"about/index.html","permalink":"https://409713427.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-09-15T13:48:30.000Z","updated":"2021-09-15T13:48:52.477Z","comments":true,"path":"categories/index.html","permalink":"https://409713427.github.io/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2021-09-15T13:50:23.000Z","updated":"2021-09-15T13:50:42.853Z","comments":true,"path":"contact/index.html","permalink":"https://409713427.github.io/contact/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-09-15T13:50:55.000Z","updated":"2021-09-15T13:51:17.332Z","comments":true,"path":"friends/index.html","permalink":"https://409713427.github.io/friends/index.html","excerpt":"","text":""},{"title":"导航","date":"2020-05-09T03:19:14.000Z","updated":"2021-09-16T12:57:52.159Z","comments":true,"path":"navigate/index.html","permalink":"https://409713427.github.io/navigate/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-09-15T13:49:06.000Z","updated":"2021-09-15T13:49:32.515Z","comments":true,"path":"tags/index.html","permalink":"https://409713427.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"【Docker】Docker（v20.10.x） 高级篇","slug":"Docker（v20.10.x)/Docker（v20.10.x） 高级篇","date":"2022-07-06T10:39:18.137Z","updated":"2022-07-06T14:38:17.898Z","comments":true,"path":"2022/0706[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0706[object%20Object].html","excerpt":"","text":"第一章：Docker 存储1.1 管理卷 卷出现的目的就是为了保存数据。 docker volume命令可以对 Docker 自己管理的卷（/var/lib/docker/volumes/xx）目录进行操作。 1.1.1 列出所有卷 命令： docker volume ls 示例： docker volume ls 1.1.2 创建卷 命令： docker volume create xxx 示例： docker volume create demo 1.1.3 查询卷详情 命令： docker volume inspect xxx 示例： docker volume inspect demo 1.1.4 删除卷 命令： docker volume rm xxx 示例： docker volume rm demo 1.1.5 移除无用卷 命令： docker volume prune 示例： docker volume prune 1.2 Docker 镜像如何存储？ 查看 Nginx 镜像的分层：docker history nginx 查看 Nginx 镜像如何存储：docker image inspect nginx 其中，GraphDriver 的内容如下： \"GraphDriver\": { \"Data\": { \"LowerDir\": \"/var/lib/docker/overlay2/d444ed42e9cdb93189118904b1fe896a364e9fc97829aa42423accd15becc932/diff:/var/lib/docker/overlay2/311b3d254b54de0a58bcb46726a1a26e009ee2fcb036853cd5c3e976fc7fca52/diff:/var/lib/docker/overlay2/25b50659028f1a9e8109f2cc4a797111ca60196ce5fa61cb8c0ec1ad5513eafc/diff:/var/lib/docker/overlay2/549a1e09e583ad1962dc4fc7279e552f32fa59f0efc3c8f3c5534f45e52fd25b/diff:/var/lib/docker/overlay2/88471fc9dd8656957aae4f68beb6349bec4a29f6eec4ca199aecb89f67a37e93/diff\", \"MergedDir\": \"/var/lib/docker/overlay2/ee25435b99705882168a432aa478a7bd94ace2b0dde052b88bb731b006eab128/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/ee25435b99705882168a432aa478a7bd94ace2b0dde052b88bb731b006eab128/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/ee25435b99705882168a432aa478a7bd94ace2b0dde052b88bb731b006eab128/work\" }, \"Name\": \"overlay2\" }, 其中，LowerDir 是底层目录，包含小型 Linux 和装好的软件： # 用户文件 /var/lib/docker/overlay2/d444ed42e9cdb93189118904b1fe896a364e9fc97829aa42423accd15becc932/diff # 用户文件 /var/lib/docker/overlay2/311b3d254b54de0a58bcb46726a1a26e009ee2fcb036853cd5c3e976fc7fca52/diff # nginx的启动命令 /var/lib/docker/overlay2/25b50659028f1a9e8109f2cc4a797111ca60196ce5fa61cb8c0ec1ad5513eafc/diff # nginx的配置文件在这里 /var/lib/docker/overlay2/549a1e09e583ad1962dc4fc7279e552f32fa59f0efc3c8f3c5534f45e52fd25b/diff # 小型 Linux 文件系统 /var/lib/docker/overlay2/88471fc9dd8656957aae4f68beb6349bec4a29f6eec4ca199aecb89f67a37e93/diff 其中，MergedDir 是合并目录。容器最终的完整工作目录全内容都在合并层；数据卷在容器层产生；所有的增删改都在容器层； 其中，UpperDir：上层目录。 其中，WorkDir：工作目录（临时层），比如：pid 等。 总而言之，Docker 底层的 storage dirver 完成了以上的目录组织结果。 1.3 容器如何挂载1.3.1 概述 Docker 支持三种挂载方式： ① Docker 自动在外部创建文件夹，并自动挂载到容器内部指定的文件夹中（Dockerfile 中的 VOLUME 指令，即/var/lib/docker/volumes/xx/目录）。 ② 自己在外部创建文件夹，手动进行挂载。 ③ 可以将数据挂载到内存中（不使用）。 其中，--mount参数挂载到 Linux 宿主机，但是需要手动挂载（不使用）；-v参数可以实现自动挂载，挂载 Linux 主机或 Docker 自动管理的区域。 1.3.2 volume（卷） 匿名卷（什么也不需要写，也不要加冒号，直接写容器内的目录）： # Docker 将创建出匿名卷，并保存容器 /usr/share/nginx/html 下面的内容 docker run -d -P -v /usr/share/nginx/html nginx 具名卷：docker run -d -P -v nginx:/usr/share/nginx/html nginx 1.3.3 绑定挂载 如果将绑定安装或非空卷安装到存在某些文件或目录的容器中的目录中，则这些文件或目录会被安装遮盖，就像您将文件保存到 Linux 主机上的 /mnt 中一样，然后 将 USB 驱动器安装到 /mnt 中。在卸载 USB 驱动器之前，/mnt 的内容将被 USB 驱动器的内容遮盖。 被遮盖的文件不会被删除或更改，但是在安装绑定安装或卷时将无法访问。 总而言之：外部目录覆盖内部容器目录内容，但不是修改。所以需要谨慎，外部空文件夹挂载方式可能会导致容器内部是空文件夹而导致容器启动失败。docker run -d -P -v /var/nginx/html:/usr/share/nginx/html nginx 1.3.4 总结 当使用 -v 参数的时候，如果是docker run 宿主机绝对路径:Docker容器内部绝对路径的方式，就是挂载，会有空挂载的问题；如果是docker run -v 不以/开头的路径:Docker容器内部绝对路径的方式，就是绑定，Docker 会自动管理，Docker 不会将它当做目录，而是当做卷。 在实际开发中，我们如何使用？ ① 如果是开发测试，用 -v 绝对路径的方式。 ② 如果是生产环境，建议使用具名卷的方式。 ③ 除非特殊如 /var/run/docker.sock 需要挂载主机路径的操作需要使用 -v 绝对路径的方式，否则一般应该使用具名卷的方式。 1.3.5 模拟实际开发 模拟实际开发中使用 Nginx ： docker run -d -P -v nginxhtml:/usr/share/nginx/html -v nginxconf:/etc/nginx nginx 第二章：Dockerfile 解析2.1 Dockerfile 是什么？ Dockerfile 是用来构建 Docker 镜像的文本文件，是有一条条构建镜像所需要的指令和参数所组成的脚本文件，类似于 Linux 中的 Shell 脚本文件。 官网。 2.2 使用 Dockerfile 文件构建镜像的步骤 ① 编写 Dockerfile 文件。 ② 使用 docker build 命令构建镜像。 ③ 使用 docker run 命令根据生成的镜像运行容器。 2.3 Dockerfile 的构建过程2.3.1 Dockerfile 基础知识 ① 每条保留字指令都必须为大写字母且后面要跟随至少一个参数。 ② 指令按照从上到下的顺序依次执行。 ③#表示注释。 ④ 每条指令都会创建一个新的镜像层并对镜像进行提交。 2.3.2 Docker 执行 Dockerfile 的大致流程 ① Docker 从基础镜像上运行一个容器。 ② 执行一条指令并对容器进行修改。 ③ 执行类似 docker commit 的操作提交一个新的镜像层。 ④ Docker 再基于刚才提交的镜像运行一个新的容器。 ⑤ 依次类推，直到 Dockerfile 文件中的所有指令都执行完成。 2.3.3 总结 从应用软件的角度来看，Dockerfile、Docker 镜像和 Docker 容器分别代表软件的三个不同的阶段： Dockerfile 是软件的原材料。 Docker 镜像是软件的交付品。 Docker 容器则可以认为是软件镜像的运行态，即根据镜像运行的容器实例。 Dockerfile 面向开发，Docker 镜像成为交付标准，Docker 容器则涉及部署和运维，三者缺一不可，合力充当了 Docker 体系的基石。 Dockerfile 定义了进程需要的一切东西。Dockerfile 涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程（当应用进程需要和系统服务以及内核进程打交道的时候，还需要考虑如何设计 namespace 的权限控制）等等。 Docker 镜像就是在编写了一个 Dockerfile 文件之后，使用 docker build 命令来产生一个镜像，当运行 Docker 镜像的时候会真正的提供服务。 Docker 容器是直接提供服务的。 2.4 Dockerfile 保留字指令 一般而言，Dockerfile 可以分为四个部分：基础镜像信息、维护者信息、镜像操作指令、启动时执行指令。 指令 说明 FROM 指定基础镜像。 MAINTAINER | 指定维护着信息，已过期，可以使用 LABEL xxx=yyy 来代替。 || RUN | 镜像构建过程中运行的命令。 || CMD | 指定启动容器时默认的命令。 || ENTRYPOINT | 指定镜像的默认入口以及运行命令 。 || EXPOSE | 声明镜像内服务监听的端口，一般而言，此指令只有指导意义，如：SpringBoot 项目的端口是 8080 ，而指定的 EXPOSE 是 8090 ，当然依据 8080 了。 || ENV | 指定环境变量，可以在 docker run 的时候使用 -e 改变。 || ADD | 复制指定的 src 路径下的内容到容器中的 dest 路径下，src 可以为 url 会自动下载，也可以为 tar 文件，会自动解压。 || COPY | 复制本地主机的 src 路径下的内容到镜像中的 dest 路径下，但是不会自动解压等等。 || LABEL | 指定生成镜像的元数据标签信息。 || VOLUME | 创建数据卷挂载点。 || USER | 指定运行容器时的用户名或 UID 。 || WORKDIR | 配置工作目录，为后续的 RUN、CMD、ENTRYPOINT 指令配置工作目录。 || ARG | 指定镜像内使用的参数（如版本号信息等），可以在 docker build 的时候，使用 –build-args 改变。 || OBBUILD | 配置当创建的镜像作为其他镜像的基础镜像是，所指定的创建操作指令。 || STOPSIGNAL | 容器退出的信号值。 || HEALTHCHECK | 健康检查。 || SHELL | 指定使用 shell 时的默认 shell 类型。 | 2.4.1 自定义镜像 要求：CentOS 7 镜像具备 vim 、ifconfig 和 JDK8 的功能。 编写 Dockerfile ，可以使用 VsCode 编辑器，装上 Docker 插件，这样可以校验 Dockerfile 的语法。 ① 编写 Dockerfile ：vim Dockerfile # 基础镜像信息 FROM centos:7.9.2009 # 维护者信息 LABEL xudaxian=123456789@qq.com ENV DEF_PATH=/usr/local WORKDIR $DEF_PATH # 安装 vim 编辑器 RUN yum -y install vim # 安装 ifconfig 命令 RUN yum -y install net-tools # 安装 JDK8 以及 lib 库 RUN yum -y install glibc.i686 RUN mkdir -pv $DEF_PATH/java # 下载 JDK 并解压 RUN curl https://files-cdn.liferay.com/mirrors/download.oracle.com/otn-pub/java/jdk/8u121-b13/jdk-8u121-linux-x64.tar.gz | tar -xzC $DEF_PATH/java # 配置 Java 环境变量 ENV JAVA_HOME=$DEF_PATH/java/jdk1.8.0_121 ENV JRE_HOME=$JAVA_HOME/jre ENV CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH ENV PATH=$JAVA_HOME/bin:$PATH # CMD：启动时执行指令 CMD /bin/bash ② 构建：docker build --no-cache --force-rm -t 镜像名称:TAG . 说明： --no-cache：表示构建的时候不使用之前的缓存。 --force-rm：删除构建过程中的中间容器层。 .：表示构建环境的上下文，通常而言是.，表示以 Dockerfile 所在的目录作为构建的起点。 2.4.2 FROM FROM 指定基础镜像，推荐使用alpine或slim之类的基础小镜像。 scratch镜像是一个空镜像，常常用于多阶段构建。 『问』：如何确定我们需要的基础镜像？ 『答』： ① 如果是 Java 应用，可以选择 Java 基础镜像或 Tomcat 基础镜像。 ② 如果是 JS 模块化应用，可以选择 nodejs 基础镜像。 ③ 每种语言都有自己的服务器或基础环境镜像，如：Python、Golang、Java、PHP 等。2.4.3 LABEL LABEL 用来标注镜像的一些说明信息，常常用来指定维护者的信息。 # 下面的这种格式是可以的 LABEL multi.label1=\"value1\" multi.label2=\"value2\" other=\"value3\" # 下面的这种格式也是可以的 LABEL multi.label1=\"value1\" \\ multi.label2=\"value2\" \\ other=\"value3\" 2.4.4 RUN RUN 指令在当前镜像层顶部的新层执行任何命令，并提交结果，生成新的镜像层。 生成的提交镜像将用于 Dockerfile 中的下一步，分层运行 RUN 指令并生成提交符合 Docker 的核心概念，就像 Git 管理源代码一样。 注意：多个 RUN 指令并没有上下文的关系，换言之，多个 RUN 指令都是在同一个目录操作的。 RUN 有两种格式： # shell 形式，/bin/bash -c 的方式运行，可以破坏 shell 字符串 RUN # exec 的形式 RUN [\"executable\", \"param1\", \"param2\"] 在 RUN 中可以使用\\将一条 RUN 指令继续到下一行。```dockerfileRUN /bin/bash -c ‘source $HOME/.bashrc; echo $HOME’ 等同于RUN /bin/bash -c ‘source $HOME/.bashrc; echo $HOME’ - 示例： ```shell vim Dockerfile # 测试案例 FROM alpine LABEL maintainer=xudaxian ENV msg='hello Docker' RUN echo $msg RUN [\"echo\",\"$msg\"] RUN /bin/sh -c 'echo $msg' RUN [\"/bin/sh\",\"-c\",\"echo $msg\"] CMD sleep 1000 docker build -t test --force-rm --no-cache . 总结： 由于[]不是 shell 形式，所以不能输出变量信息，而是输出$msg。其他任何/bin/sh -c的形式都可以输出变量信息。 shell 是RUN /bin/sh -c &lt;command&gt;的方式，RUN [&quot;/bin/sh&quot;,&quot;-c&quot;,command]的 exec 方式等同于 shell 方式，而RUN [&quot;/bin/sh&quot;,command]的 exec 默认不会进行变量替换。2.4.5 构建期和运行期 构建期是指使用 Dockerfile 构建镜像的整个过程时期，如：docker build 等。 运行期是指使用之前构建的镜像启动容器的过程，如：docker start 、docker run 等。 2.4.6 ARG 语法： ARG name=defaultValue ARG 指令定义了一个变量，用户可以在构建的时候使用--build-arg name=value传递，docker build 命令会将其传递给构建器。 --build-arg指定参数会覆盖 Dockerfile 中指定的同名参数。 如果用户指定了未在 Dockerfile 中定义的构建参数，则构建会输出警告。 ARG 只在构建时期有效，运行时期无效。 不建议使用构建时变量来传递注入 github 密码、用户凭据等机密，因为构建时变量的值可以通过 docker history 来观察到。 ARG 变量定义从 Dockerfile 定义的行开始生效。 使用 ENV 指定定义的环境变量始终会覆盖同名的 ARG 指令。 示例： vim Dockerfile ```shell 选择基础镜像FROM alpine 维护者信息LABEL maintainer=”许大仙” ARG 指令定义了一个变量，用户可以在构建的时候使用 --build-arg name=value 传递，docker build 命令会将其传递给构建器。--build-arg 指定参数会覆盖 Dockerfile 中指定的同名参数。如果用户指定了 未在 Dockerfile 中定义的构建参数 ，则构建会输出 警告 。ARG 只在构建时期有效，运行时期无效。不建议使用构建时变量来传递注入 github 密码、用户凭据等机密，因为构建时变量的值可以通过 docker history 来观察到。ARG 变量定义从 Dockerfile 定义的行开始生效。ARG param=”Hi Docker” 在构建时期会运行的指令（根据 Dockerfile 创建一个镜像的整个过程时期）RUN echo 1111RUN echo ${param} 在运行时候会运行的指令（根据之前创建的镜像启动一个容器，容器启动默认运行的命令）docker start 或 docker runCMD [“/bin/sh”,”-c”,”echo 2222;echo $param”] ```shell docker build -t test01 --force-rm --no-cache . docker build -t test02 --force-rm --no-cache --build-arg param=test . 2.4.7 ENV 语法： ENV name=value ENV 和 ARG 很类似，但是 ENV 在构建期和运行期都有效，并且使用 ENV 指定定义的环境变量始终会覆盖同名的 ARG 指令。 可以使用docker run -e name=value修改 ENV 定义的环境变量。 示例： vim Dockerfile ```dockerfile 选择基础镜像FROM alpine 维护者信息LABEL maintainer=”许大仙” ARG 指令定义了一个变量，用户可以在构建的时候使用 --build-arg name=value 传递，docker build 命令会将其传递给构建器。--build-arg 指定参数会覆盖 Dockerfile 中指定的同名参数。如果用户指定了 未在 Dockerfile 中定义的构建参数 ，则构建会输出 警告 。ARG 只在构建时期有效，运行时期无效。不建议使用构建时变量来传递注入 github 密码、用户凭据等机密，因为构建时变量的值可以通过 docker history 来观察到。ARG 变量定义从 Dockerfile 定义的行开始生效。ARG param=”Hi Docker” ENV 在构建期和运行期都有效，但是只能在运行期进行修改，修改通过 docker run -e name=value 命令。ENV app=taobao 在构建时期会运行的指令（根据 Dockerfile 创建一个镜像的整个过程时期）RUN echo 1111RUN echo ${param}RUN echo ${app} 在运行时候会运行的指令（根据之前创建的镜像启动一个容器，容器启动默认运行的命令）docker start 或 docker runCMD [“/bin/sh”,”-c”,”echo 2222;echo $param;echo app_$app”] ```shell docker build -t test --force-rm --no-cache . docker run -it test 坑：ENV 在构建期就会被解析并持久化，可以通过 docker inspect image 查看。 示例： vim Dockerfile # ENV 的坑 FROM alpine LABEL maintainer=\"许大仙\" ENV msg=\"hello\" ENV msg2=${msg} RUN echo ${msg} RUN echo ${msg2} # 如果运行期修改了 msg=666，那么 msg 和 msg2 的值是 666 和 hello ,因为 ENV 在构建期就会被解析并持久化。 CMD [\"/bin/sh\",\"-c\",\"echo $msg;echo $msg2;\"] docker build -t test --force-rm --no-cache . docker run -it -e msg=666 test 2.4.8 ADD ADD 可以将上下文指定的内容添加（复制）到镜像中，如果是压缩包，ADD 会自动解压；如果是远程 URL ，ADD 会自动下载；但是，ADD 并没有自动下载远程压缩文件并解压的功能。 语法： ADD src dest 注意： src 路径必须在构建的上下文，不能使用../../xxx这种方式，因为 Docker 构建的第一步是将上下文目录（包括子目录）发送给 Docker 的守护进程。 如果 src 是 URL ，并且 dest 不以/结尾，那么就会从 URL 下载文件并将其复制为 dest（名称）。 如果 src 是 URL ，并且 dest 以/结尾，会自动推断出文件的名称（URL 的最后一部分）并保存到 dest（目录）中。 如果 src 是目录，则将复制目录的整个内容，包括文件系统元数据。 示例： vim Dockerfile FROM alpine LABEL maintainer=\"许大仙\" # 如果是远程文件，自动下载 # 如果是压缩文件，自动解压 # 注意：ADD 并没有自动下载远程压缩文件并解压的功能 # 将当前内容复制到 alpine 中 ADD https://download.redis.io/releases/redis-6.2.6.tar.gz /dest # 注意，RUN 指令上下并没有上下文的关系。 RUN ls -l docker build -t test --force-rm --no-cache . 示例：vim Dockerfile FROM alpine LABEL maintainer=\"许大仙\" # 如果是远程文件，自动下载 # 如果是压缩文件，自动解压 # 注意：ADD 并没有自动下载远程压缩文件并解压的功能 ADD https://download.redis.io/releases/redis-6.2.6.tar.gz /dest/ # 注意，RUN 指令上下并没有上下文的关系。 RUN ls -l RUN cd /dest && ls -l docker build -t test --force-rm --no-cache . 示例：wget https://download.redis.io/releases/redis-6.2.6.tar.gz vim Dockerfile FROM alpine LABEL maintainer=\"许大仙\" # 如果是远程文件，自动下载 # 如果是压缩文件，自动解压 # 注意：ADD 并没有自动下载远程压缩文件并解压的功能 ADD redis-6.2.6.tar.gz /dest/ # 注意，RUN 指令上下并没有上下文的关系。 RUN ls -l RUN cd /dest && ls -l docker build -t test --force-rm --no-cache . 2.4.9 COPY 语法： COPY [--chown=:] ... COPY [--chown=:] [\"\",... \"\"] COPY 和 ADD 类似，都有将上下文指定的内容添加（复制）到镜像中的功能，只不过 ADD 的自动下载或解压压缩文件的功能。 --chown功能仅在用于构建 Linux 容器的 Dockerfile 上受支持，而在 Windows 容器上不起作用。 示例：略。 2.4.10 USER 语法： USER [:] USER [:] USER 指令和 WORKDIR 指令类似，都是改变环境状态并影响以后的层，WORKDIR 是改变工作目录，USER 则是改变之后层的执行 RUN 、CMD 、以及 ENTRYPOINT 这类命令的身份。 注意：USER 只是帮助我们切换到指定的用户而已，这个用户必须事先建立好的，否则无法切换。 示例：USER 身份问题 touch a.txt vim Dockerfile FROM alpine LABEL maintainer=\"许大仙\" # 创建用户和组 RUN addgroup -S test && adduser -S test -G test -h /home/test # USER 只是帮准我们切换到指定的用户而已，这个用户必须事先建立好的，否则无法切换。USER 则是改变之后层的执行 RUN、CMD、以及 ENTRYPOINT 这类命令的身份。 USER test:test COPY *.txt /test/ # 注意：一旦声明了 USER 之后，USER 后面的 RUN、CMD、ENTRYPOINT 的身份就是 test ，而 a.txt 是主机生成的，身份是 root ，必然会报错，权限不对。 RUN cd /test && ls -l && echo 1111 > a.txt docker build -t test --force-rm --no-cache . 示例：使用 USER + COPY 解决上面示例的权限等问题touch a.txt vim Dockerfile FROM alpine LABEL maintainer=\"许大仙\" # 创建用户和组 RUN addgroup -S test && adduser -S test -G test -h /home/test # USER 只是帮准我们切换到指定的用户而已，这个用户必须事先建立好的，否则无法切换。USER 则是改变之后层的执行 RUN、CMD、以及 ENTRYPOINT 这类命令的身份。 USER test:test # 通过 COPY 指定的 chown 功能改变复制文件的权限 COPY --chown=test:test *.txt /test/ # 注意：一旦声明了 USER 之后，USER 后面的 RUN、CMD、ENTRYPOINT 的身份就是 test ，而 a.txt 是主机生成的，身份是 root ，但是，因为使用了 COPY --chown=test:test ，所以文件的权限是 test RUN cd /test && ls -l && echo 1111 > a.txt docker build -t test --force-rm --no-cache . 2.4.11 WORKDIR 语法： WORKDIR /a/b/c WORKDIR 指令为 Dockerfile 中跟随它后面的 RUN 、CMD 、ENTRYPOINT、 COPY、ADD 指令设置工作目录。 WORKDIR 指令可在 Dockerfile 中多次使用。 如果提供了相对路径，则它将相对于上一个 WORKDIR 指令的路径，如：```dockerfileWORKDIR /aWORKDIR bWORKDIR cRUN pwd 效果：/a/b/c - WORKDIR 指令也可以用在环境变量上，如： ```dockerfile ENV DIRPATH=/path WORKDIR $DIRPATH/$DIRNAME RUN pwd # 效果：/path/$DIRNAME 示例：touch a.txt vim Dockerfile ```dockerfileFROM alpine RUN pwd &amp;&amp; ls -l WORKDIR /app RUN pwd &amp;&amp; ls -l COPY *.txt . RUN ls -l ```shell docker build -t test --force-rm --no-cache . 2.4.12 VOLUME 语法： #可以是JSON数组 VOLUME [\"/var/log/\"] #可以直接写 VOLUME /var/log #可以空格分割多个 VOLUME /var/log /var/db 注意：用 VOLUME 声明了卷，那么以后对于卷内容的修改会被丢弃，所以，一定要在 volume 声明之前修改内容。 示例： vim Dockerfile FROM alpine # 挂载 容器指定的文件夹，如果不存在，会自动创建。 # 指定了 VOLUME 指令后，即使启动容器的时候没有指定 -v 参数，也会自动进行匿名卷挂载。 VOLUME [ \"/demo\",\"/app\" ] CMD ping www.baidu.com docker build -t test --force-rm --no-cache . 示例：用 VOLUME 声明了卷，那么以后对于卷内容的修改会被丢弃，所以，一定要在 volume 声明之前修改内容 。vim Dockerfile FROM alpine RUN mkdir /demo && mkdir /app RUN echo 111 > /demo/a.txt RUN echo 222 > /app/b.txt # 挂载 容器指定的文件夹，如果不存在，会自动创建。 # 指定了 VOLUME 指令后，即使启动容器的时候没有指定 -v 参数，也会自动进行匿名卷挂载。容器内的 /demo 和 /app ，需要在启动容器的时候，需要使用 -v 参数进行挂载。 # VOLUME 挂载出去的东西，容器改变也不会最终在 docker commit 的时候生效。 # -v 和 VOLUME 挂载出去的目录，主机变，容器里面也会发生变化，但是 # ① docker commit 提交当前容器的所有变化为镜像，就会丢弃。 # ② VOLUME [ \"/demo\",\"/app\" ] 容器会自动挂载，在之后对这些目录所操作的变化，也会丢弃 # ③ 挂载仅仅是为了将外边的数据同步到容器里面 # VOLUME 的最佳实践是写在 CMD 或 ENTRYPOINT 前面 VOLUME [ \"/demo\",\"/app\" ] # 下面的 2 个 RUN 指令没有生效，因为 VOLUME 指定的挂载目录是固化配置，当执行到 VOLUME 的时候就已经写入到容器中了，即使后面容器怎么变，也不会改变。 RUN echo 333 > /demo/a.txt RUN echo 444 > /app/b.txt CMD ping www.baidu.com docker build -t test --force-rm --no-cache . 2.4.13 EXPOSE 语法： EXPOSE [/...] EXPOSE [80,443] EXPOSE 80/tcp EXPOSE 80/udp EXPOSE 指令通知 Docker 容器在运行的时候在指定的网络端口上进行侦听，可以指定端口是侦听 TCP 还是 UDP ，如果没有指定，默认就是 TCP 。 EXPOSE 指令实际上不会发布端口，它充当了构建镜像人员和运行容器人员之间的一种文档，即打算发布那些端口的信息，要在运行容器时映射端口，需要使用docker run -p xxx:xxx或docker run -P的命令。 示例：略。 2.4.14 CMD 和 ENTRYPOINT CMD 的语法： # exec 方式, 首选方式 CMD [\"executable\",\"param1\",\"param2\"] # 为 ENTRYPOINT 提供默认参数 CMD [\"param1\",\"param2\"] # shell 形式 CMD command param1 param2 ENTRYPOINT 的语法： # exec 方式, 首选方式 ENTRYPOINT [\"executable\", \"param1\", \"param2\"] # shell 形式 ENTRYPOINT command param1 param2 注意： ① 如果 Dockerfile 文件中，使用多个 CMD 或 ENTRYPOINT 作为唯一的入口，即写多个 CMD 或 ENTRYPOINT ，则会产生覆盖现象，只有最后一个生效。 ② shell 方式是可以读取环境变量的值的（如：${xxx}），默认情况下，exec 的方式是读取不了环境变量值的，但是 exec 方式的[“/bin/sh”,”-c”,”xxx”]等同于 shell 方式，也是可以读取环境变量值。 ③ 官方推荐使用 RUN 、CMD 以及 ENTRYPOINT 使用 exec 的方式。 ④ 如果既有 CMD 的 exec 方式，又有 ENTRYPOINT 的 exec 方式，那么 CMD 是作为 ENTRYPOINT 的参数的（最佳实践）。 ⑤ 使用docker run -d xxx CMD命令是可以覆盖 Dockerfile 中的 CMD 指令的，不是覆盖 exec 方式数组中的一个，而是全部。 示例：证明注意 ①vim Dockerfile FROM alpine # CMD 和 ENTRYPOINT 作为唯一入口，写多个，只有最后一个生效 CMD ping baidu.com CMD ping bing.com docker build -t test --force-rm --no-cache . # --rm 表示容器退出，自动删除 docker run -it --rm test 示例：证明注意 ①vim Dockerfile FROM alpine # CMD 和 ENTRYPOINT 作为唯一入口，写多个，只有最后一个生效 ENTRYPOINT ping baidu.com ENTRYPOINT ping bing.com docker build -t test --force-rm --no-cache . # --rm 表示容器退出，自动删除 docker run -it --rm test 示例：证明注意 ④vim Dockerfile FROM alpine # java -jar xxx.jar --spring.profile.active=dev --server.port=8888 # CMD [ \"-jar\",\"xxx.jar\",\"--spring.profile.active=dev\",\"--server.port=8888\"] # ENTRYPOINT [ \"java\" ] CMD [\"baidu.com\"] ENTRYPOINT [\"ping\"] docker build -t test --force-rm --no-cache . # --rm 表示容器退出，自动删除 docker run -it --rm test 示例：证明注意 ⑤vim Dockerfile FROM alpine # java -jar xxx.jar --spring.profile.active=dev --server.port=8888 # CMD [ \"-jar\",\"xxx.jar\",\"--spring.profile.active=dev\",\"--server.port=8888\"] # ENTRYPOINT [ \"java\" ] CMD [\"baidu.com\"] ENTRYPOINT [\"ping\"] docker build -t test --force-rm --no-cache . # --rm 表示容器退出，自动删除 docker run -it --rm test bing.com 2.5 虚悬镜像2.5.1 是什么？ 虚悬镜像就是仓库名和标签名都是&lt;none&gt;的镜像，俗称dangling image。 使用 Dockerfile 写一个虚悬镜像：vim Dockerfile FROM ubuntu CMD echo 'action is success' 根据 Dockerfile 构建镜像：docker build . 2.5.2 查看 命令： docker images -f dangling=true 示例： docker images -f dangling=true 2.5.3 删除 命令： docker image prune 示例： docker image prune 2.6 多阶段构建2.6.1 使用 官网。 多阶段构建出现的目的就是为了解决如何让一个镜像变得更小。 示例：常规打包```dockerfile 我们如何打包一个 Java 镜像FROM mavenWORKDIR /appCOPY . .RUN mvn clean packageCOPY /app/target/*.jar /app/app.jarENTRYPOINT java -jar app.jar 这样的镜像有多大？我们最小做到多大？？### 2.6.2 生产示例 - 需求：将 SpringBoot 项目使用多阶段构建打包成 Docker 镜像，并进行启动。 - ① 环境要求： - JDK ：8。 - Maven ：3.5+。 - IDEA：2.22+。 - SpringBoot ：2.5.10。 - ② 新建 SpringBoot 工程： ![](https://cdn.nlark.com/yuque/0/2022/png/513185/1646438677066-070e2328-96c5-4064-9294-9adc9ca64ff2.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_30%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=PAlaD&amp;margin=%5Bobject%20Object%5D&amp;originHeight=963&amp;originWidth=1064&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - ② pom.xml ```xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.10&lt;/version&gt; &lt;/parent&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;groupId&gt;com.github.demo&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;demo&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;${project.artifactId}&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.10&lt;/version&gt; &lt;configuration&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.10.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 为了加速下载需要在 pom 文件中复制如下 --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;!-- snapshots默认是关闭的,需要开启 --&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/project&gt; ③ 启动类：```javapackage com.github.demo; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; /** @author 许大仙 @version 1.0 @since 2022-03-01 11:24:50 /@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }}``` ④ Dockerfile ： # 以下所有前提 保证 Dockerfile 和项目在同一个文件夹 # 第一阶段：环境构建 FROM maven:3.8.4-openjdk-8-slim AS builder WORKDIR /app # 此时有坑，想想 Maven 的标准目录结构 COPY src ./src/ COPY pom.xml . RUN mvn clean package -Dmaven.test.skip=true # 第二阶段，最小运行时环境，只需要 jre；第二阶段并不会有第一阶段哪些没用的层 # jdk springboot-actutor（jdk） FROM openjdk:8u282-slim LABEL maintainer=\"xxxx@qq.com\" # 从上一个阶段复制内容 COPY --from=builder /app/target/*.jar /app.jar # 修改时区 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && echo 'Asia/Shanghai' >/etc/timezone && touch /app.jar # 环境变量 # docker run -e JAVA_OPTS=\"-Xmx512m -Xms64m\" -e PARAMS=\"--spring.profiles.active=dev --server.port=8080\" xxx ENV JAVA_OPTS=\"\" ENV PARAMS=\"\" # 运行 jar 包 ENTRYPOINT [ \"sh\", \"-c\", \"java -Djava.security.egd=file:/dev/./urandom $JAVA_OPTS -jar /app.jar $PARAMS\" ] ⑤ 构建镜像命令： docker build -t test --force-rm --no-cache . ⑥ 启动容器命令： docker run -d -P -e JAVA_OPTS=\"-Xmx512m -Xms64m\" -e PARAMS=\"--spring.profiles.active=dev --server.port=8080\" test 2.7 镜像瘦身 ① 选择最小的基础镜像。 ② 合并 RUN 环节的所有指令，少生成一些镜像层。 ③ RUN 期间可能安装其它程序会生成临时缓存，要自行删除，如： # 开发期间，逐层验证正确的 RUN xxx RUN xxx RUN aaa \\ aaa \\ vvv \\ # 生产环境 RUN apt-get update && apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion \\ && rm -rf /var/lib/apt/lists/* ④ 使用.dockerignore文件，排除上下文中无需参与构建的资源。 ⑤ 合理使用多阶段构建。 ⑥ 合理使用构建缓存加速构建，但是有时也会有坑，开发的时候建议还是docker build -t xxx --no-cache --force-rm .来构建镜像。 第三章：Docker网络3.1 是什么？ Docker 默认启动的时候，会为我们创建三个网络： docker network ls 3.2 常用基本命令 Docker 网络的帮助命令：docker network --help 查看网络：docker network ls 查看网络源数据：docker network inspect xxx 创建网络：docker network create xxx 删除网络：docker network rm xxx 3.3 能干嘛？ ① 容器间的互联、通信以及端口映射。 ② 可以通过服务名直接通信，而不受容器 IP 变化的影响。 3.4 网络模式3.4.1 概述 bridge 模式（默认）： docker run --network bridge xxx host 模式： docker run --network host xxx none 模式： docker run --network none xxx container 模式： docker run --network 容器名称|容器ID xxx 3.4.2 容器实例内默认 IP 生产的规则 Docker 容器内部的 IP 是有可能变化的。 证明： 3.4.3 bridge 模式 Docker 使用 Linux 桥接，在宿主机虚拟一个 Docker 容器网桥( docker0 )，Docker 启动一个容器时会根据 Docker 网桥的网段分配给容器一个 IP 地址，称为 Container-IP ，同时 Docker 网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的 Container-IP 直接通信。 docker run 的时候，没有指定 network 的话默认使用的网桥模式就是 bridge ，使用的就是 docker0 。在宿主机使用 ifconfig 命令就可以看到 docker0 和自己 create 的 network 的 eth0，eth1，eth2……代表网卡一，网卡二，网卡三……，lo 代表127.0.0.1，即 localhost ，inet addr 用来表示网卡的 IP 地址。 网桥 docker0 创建一对对等虚拟设备接口一个叫 veth，另一个叫 eth0 ，成对匹配。 整个宿主机的网桥模式都是 docker0，类似一个交换机有一堆接口，每个接口叫 veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫 veth pair）。 每个容器实例内部也有一块网卡，每个接口叫 eth0 。 docker0 上面的每个 veth 匹配某个容器实例内部的 eth0 ，两两配对，一一匹配。 综上所述，将宿主机上的所有容器都连接到这个内部网络上，两个容器在同一个网络下,会从这个网关下各自拿到分配的 ip ，此时两个容器的网络是互通的。 证明： docker run -d -p 8081:8080 --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --name tomcat82 billygoo/tomcat8-jdk8 3.4.4 host 模式 容器不会获得一个独立的 Network Namespace，而是和宿主机共用一个 NetWork Namespace ，容器将不会虚拟出自己的网卡，而是使用宿主机的 IP 和端口。 证明： docker run -d --network host --name tomcat83 billygoo/tomcat8-jdk8 curl -XGET http://127.0.0.1:8080 3.4.5 none 模式 禁用网络功能，只有 lo 标识(就是 127.0.0.1 表示本地回环)。 证明： docker run -d -p 8084:8080 --network none --name tomcat84 billygoo/tomcat8-jdk8 3.4.6 container 模式 新建的容器和已经存在的一个容器共享一个网络 ip 配置而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。 证明：最佳实践，redis 中没有 ifconfig 等命令，但是 alpine 中有，此时就可以用 alpine 来测试 redis docker run -d -P --name redis redis docker run -it --network container:redis --name alpine alpine /bin/sh 3.4.7 自定义网络 自定义网络默认使用的是桥接网络 bridge 。 自定义网络本身就维护好了主机名和 ip 的对应关系（ip 和域名都能通），常用。 示例： docker network create demo docker run -it --network demo --name alpine1 alpine /bin/sh docker run -it --network demo --name alpine2 alpine /bin/sh 第四章：Docker-compose 容器编排4.1 是什么？ Docker Compose 是 Docker 公司推出的一个工具软件，可以管理多个 Docker 容器组成一个应用。你需要定义一个 YAML 格式的配置文件 docker-compose.yml，写好多个容器之间的调用关系。之后，只要一个命令，就能同时启动/关闭这些容器。 4.2 能干嘛？ Docker 建议我们每一个容器中只运行一个服务，因为 Docker 容器本身占用资源极少，所以最好是将每个服务单独的分割开来但是这样我们又面临了一个问题？ 如果我需要同时部署好多个服务，难道要每个服务单独写 Dockerfile ，然后再去构建镜像、构建容器，太累了，所以 Docker 官方给我们提供了 docker-compose 多服务部署的工具。 例如要实现一个 Web 微服务项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库 mysql 服务容器，redis 服务器，注册中心 eureka ，甚至还包括负载均衡容器等等。 Docker Compose 允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Docker Compose 可以很容易地用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成构建。Docker-Compose 解决了容器与容器之间如何管理编排的问题。 4.3 安装和卸载 安装： # Compose目前已经完全支持Linux、Mac OS和Windows，在我们安装Compose之前，需要先安装Docker。下面我 们以编译好的二进制包方式安装在Linux系统中。 curl -L https://github.com/docker/compose/releases/download/1.29.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose # 国内的地址 curl -L https://get.daocloud.io/docker/compose/releases/download/1.29.2/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose # 设置文件可执行权限 chmod 777 /usr/local/bin/docker-compose # 创建软链接 sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose # 查看版本信息 docker-compose -version 卸载： # 二进制包方式安装的，删除二进制文件即可 rm /usr/local/bin/docker-compose 4.4 Docker Compose 的核心概念 一个文件：docker-compose.yml。 两要素： 服务（service）：一个个应用容器实例，比如订单微服务、库存微服务、mysql 容器、nginx 容器或者 redis 容器。 工程（project）：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。4.5 Docker Compose 的使用步骤 ① 编写 Dockerfile 定义各个微服务应用并构建出对应的镜像文件。 ② 使用 docker-compose.yml 定义一个完整业务单元，安排好整体应用中的各个容器服务。 ③ 最后，执行 docker-compose up 命令来启动并运行整个应用程序，完成一键部署上线。 4.6 DOcker Compose 常用命令 查看帮助： docker-compose -h 启动所有 docker-compose 服务： docker-compose up 启动所有 docker-compose 服务并后台运行： docker-compose up -d 停止并删除容器、网络、卷、镜像： docker-compose down 进入容器实例内部： # 服务id 在 docker-compose.yml 中定义的 docker exec -it 服务id /bin/bash 展示当前 docker-compose 编排过的运行的所有容器： docker-compose ps 展示当前 docker-compose 编排过的容器进程： docker-compose top 查看容器输出日志： docker-compose logs 服务id 检查配置： docker-compose config 检查配置，有问题才有输出： docker-compose config -q 重启服务： docker-compose restart 启动服务： docker-compose start 停止服务： docker-compose stop 常用的命令组合： docker-compose build --force-rm --no-cache &amp;&amp; docker-compose up -d。 … 4.7 Docker Compose 生产示例 需求：使用 Docker Compose 部署项目。 ① 环境要求： JDK ：1.8。 MySQL ：5.7。 IDEA ：2022+。 Maven ：3.5+。 SpringBoot：2.5.10。 Redis：5.0.14。 ② 新建 SpringBoot 工程： ③ pom.xml```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; 4.0.0 org.springframework.boot spring-boot-starter-parent 2.5.10 jar com.github.demo demo 0.0.1 demo demo UTF-8 1.8 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-test test org.springframework.boot spring-boot-starter-data-redis com.alibaba druid-spring-boot-starter 1.2.8 org.projectlombok lombok provided com.baomidou mybatis-plus-boot-starter 3.5.1 mysql mysql-connector-java io.gitee.zero-wsh acTable 2.0.5 org.apache.commons commons-pool2 2.10.0 dev dev 8080 192.168.0.16 3306 root 123456 demo 127.0.0.1 6379 0 test test 8080 192.168.65.100 3306 root 123456 demo 192.168.65.100 6379 0 prod prod 8080 mysql 3306 root 123456 demo redis 6379 0 true ${project.artifactId} org.springframework.boot spring-boot-maven-plugin 2.5.10 ZIP repackage org.apache.maven.plugins maven-compiler-plugin 3.10.0 1.8 1.8 aliyun Nexus Snapshot Repository https://maven.aliyun.com/repository/public default true true aliyun Nexus Snapshot Repository https://maven.aliyun.com/repository/public default true true ``` ④ application.yml```yamlserver: # 服务器配置port: @port@ # 端口servlet: context-path: /apitomcat: uri-encoding: utf-8 threads:max: 800 min-spare: 50 max-http-header-size: 10KB spring: # Spring 配置 profiles: active: @spring.profiles.active@ datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://@mysql.host@:@mysql.port@/@mysql.database@?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true&amp;nullCatalogMeansCurrent=true username: @mysql.username@ password: @mysql.password@ type: com.alibaba.druid.pool.DruidDataSource # 配置数据库连接池的类型 druid: initial-size: 5 # 初始化连接池大小 min-idle: 10 # 最小连接 max-active: 20 # 最大连接 max-wait: 6000 # 配置获取连接等待超时的时间 time-between-eviction-runs-millis: 2000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 min-evictable-idle-time-millis: 600000 # 配置一个连接在池中最小生存的时间，单位是毫秒 max-evictable-idle-time-millis: 900000 # 配置一个连接在池中最大生存的时间，单位是毫秒 validation-query: SELECT 1 # 数据库的最小检测 test-while-idle: true # 检测连接是否可用 test-on-borrow: false # 在获取连接之前是否进行测试 test-on-return: false # 归还连接之前是否进行测试 pool-prepared-statements: false # 不缓存 pstmt max-pool-prepared-statement-per-connection-size: 20 # 配置 pstmt 缓存个数 stat-view-servlet: # 监控界面配置 enabled: true # 启动监控界面 allow: 127.0.0.1 # 白名单 deny: # 黑名单 login-username: admin # 用户名 login-password: 123456 # 密码 url-pattern: /druid/* # 访问路径 web-stat-filter: # WEB 访问监控 enabled: true # 开启 WEB 访问监控 url-pattern: /* # 对所有的路径进行监控 exclusions: “.js,.gif,.jpg,.png,.css,.ico,/druid/“ # 排除一些不必要的url session-stat-enable: true # 开启 session 统计功能，默认为 true session-stat-max-count: 1000 # sessionStatMaxCount 配置，默认为 1000 profile-enable: true # 配置profileEnable能够监控单个url调用的sql列表 filter: # 配置 Filter stat: # 配置状态 enabled: true merge-sql: true # 统计相同的 SQL 命令 log-slow-sql: true # 记录慢 SQL slow-sql-millis: 3000 # 慢 SQL 执行的时间标准 3000 db-type: mysql # 数据库的类型 wall: # 防火墙配置 enabled: true db-type: mysql config: delete-allow: false # 不允许执行删除 update-where-none-check: true multi-statement-allow: true # 允许批处理 slf4j: # 日志配置 enabled: true statement-executable-sql-log-enable: true # 记录执行日志 data-source-log-enabled: true # 开启日志功能 statement-sql-pretty-format: true # 美化 SQL 语句 aop-patterns: com.github.fairy.era. # Spring 监控 AOP 切入点，如x.y.z.service.*,配置多个英文逗号分隔 mvc: throw-exception-if-no-handler-found: true # 发现404 的时候直接抛出异常 format: date: yyyy-MM-dd HH:mm:ss web: resources: add-mappings: false # 关闭默认的静态资源路径映射 jackson: locale: zh_CN date-format: yyyy-MM-dd HH:mm:ss servlet: # 文件上传 multipart: # 单个文件大小 max-file-size: 100MB # 设置总上传的文件大小 max-request-size: 200MB redis: host: @redis.host@ port: @redis.port@ database: @redis.database@ password: @redis.password@ lettuce: pool: max-wait: -1ms min-idle: 0 max-idle: 8 max-active: 8 mybatis-plus: # MyBatis-Plus 配置 global-config: db-config: id-type: assign_id # 主键生成策略 table-underline: true logic-delete-value: 1 # 逻辑已删除值(默认为 1) logic-delete-field: beenDeleted logic-not-delete-value: 0 configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl # 开启日志输出 map-underscore-to-camel-case: true # 开启驼峰功能 zero: # zero 配置 ac-table: model: add_or_update entity-package: com.github.demo.entity - ⑤ 启动类： ```java package com.github.demo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * @author 许大仙 * @version 1.0 * @since 2022-03-01 11:24:50 */ @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } ⑥ 实体类：```javapackage com.github.demo.entity; import com.baomidou.mybatisplus.annotation.TableField;import com.baomidou.mybatisplus.annotation.TableId;import com.baomidou.mybatisplus.annotation.TableName;import io.gitee.zerowsh.actable.annotation.AcColumn;import io.gitee.zerowsh.actable.annotation.AcTable;import lombok.Data; /** (Dept)表实体类 @author 许大仙 @version 1.0 @since 2022-03-03 10:12:47 /@Data@TableName(“dept“)@AcTable(name = “dept“, comment = “部门”)public class Dept { @TableId @AcColumn(name = “id“, comment = “主键”) private String id; @AcColumn(name = “name“, comment = “部门名称”) @TableField(“name“) private String name; @AcColumn(name = “description“, comment = “部门描述”) @TableField(“description“) private String description;}``` ⑦ mapper 接口：```javapackage com.github.demo.mapper; import com.baomidou.mybatisplus.core.mapper.BaseMapper;import com.github.demo.entity.Dept;import org.apache.ibatis.annotations.Mapper; /** (Dept)表数据库访问层 @author 许大仙 @version 1.0 @since 2022-03-03 10:12:49 /@Mapperpublic interface DeptMapper extends BaseMapper { } - ⑧ 业务层接口及实现类： ```java package com.github.demo.service; import com.baomidou.mybatisplus.extension.service.IService; import com.github.demo.entity.Dept; /** * (Dept)表服务接口 * * @author 许大仙 * @version 1.0 * @since 2022-03-03 10:12:46 */ public interface DeptService extends IService&lt;Dept&gt; { } package com.github.demo.service.impl; import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl; import com.github.demo.entity.Dept; import com.github.demo.mapper.DeptMapper; import com.github.demo.service.DeptService; import org.springframework.stereotype.Service; /** * (Dept)表服务实现类 * * @author 许大仙 * @version 1.0 * @since 2022-03-03 10:12:48 */ @Service(\"deptService\") public class DeptServiceImpl extends ServiceImpl&lt;DeptMapper, Dept> implements DeptService { } ⑨ Web 层：```javapackage com.github.demo.web; import com.github.demo.entity.Dept;import com.github.demo.service.DeptService;import lombok.NonNull;import lombok.RequiredArgsConstructor;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController; import java.util.List; /** @author 许大仙 @version 1.0 @since 2022-03-01 13:37:26 /@RestController@RequiredArgsConstructor@RequestMapping(value = “/dept”)public class DeptAction { @NonNull private DeptService deptService; @GetMapping(value = “/list”) public List list() { return deptService.list(); }}``` ⑩ Dockerfile 和 docker-compose.yaml ：# 以下所有前提 保证 Dockerfile 和项目在同一个文件夹 # 第一阶段：环境构建 FROM maven:3.8.4-openjdk-8-slim AS builder WORKDIR /app # 此时有坑，想想 Maven 的标准结构 COPY src ./src COPY pom.xml . ARG profile=dev RUN mvn clean package -Dmaven.test.skip=true -P${profile} # 第二阶段，最小运行时环境，只需要 jre；第二阶段并不会有第一阶段哪些没用的层 # jdk springboot-actutor（jdk） FROM openjdk:8u282-slim LABEL maintainer=\"xxxx@qq.com\" # 从上一个阶段复制内容 COPY --from=builder /app/target/*.jar /app.jar # 修改时区 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && echo 'Asia/Shanghai' >/etc/timezone && touch /app.jar # 环境变量 # docker run -e JAVA_OPTS=\"-Xmx512m -Xms64m\" -e PARAMS=\"--spring.profiles.active=dev --server.port=8080\" xxx ENV JAVA_OPTS=\"\" ENV PARAMS=\"\" # 运行 jar 包 ENTRYPOINT [ \"sh\", \"-c\", \"java -Djava.security.egd=file:/dev/./urandom $JAVA_OPTS -jar /app.jar $PARAMS\" ] ```yamlversion: ‘3.8’ # 指定版本号 services: # 所有需要启动的服务 mysql: # mysql 服务 image: mysql:5.7 container_name: mysql57 environment: - MYSQL_ROOT_PASSWORD=123456 - MYSQL_ROOT_HOST=% - MYSQL_DATABASE=demo - TZ=Asia/Shanghai command: - –default-authentication-plugin=mysql_native_password - –character-set-server=utf8mb4 - –collation-server=utf8mb4_general_ci - –lower_case_table_names=1 volumes: - /var/mysql/conf:/etc/mysql - /var/mysql/logs:/logs - /var/mysql/data:/var/lib/mysql - /etc/localtime:/etc/localtime:ro ports: # 宿主机和容器的端口映射关系 - “33060:3306” # 左边宿主机端口:右边容器端口 networks: # 配置容器连接的网络，引用顶级networks下的条目 - backend restart: always redis: # redis 服务 image: redis:5.0.14-alpine container_name: redis5 command: redis-server –appendonly yes ports: # 宿主机和容器的端口映射关系 - “63790:6379” # 左边宿主机端口:右边容器端口 networks: # 配置容器连接的网络，引用顶级networks下的条目 - backend restart: always demo-back: # 后台服务 build: # 指定根据哪个Dockerfile构建容器 context: ./ dockerfile: Dockerfile args: profile: prod image: demo-back container_name: demo-back # 容器名称，默认为“工程名称_服务条目名称_序号” environment: - TZ=Asia/Shanghai ports: # 宿主机和容器的端口映射关系 - “8080:8080” # 左边宿主机端口:右边容器端口 networks: # 配置容器连接的网络，引用顶级networks下的条目 - frontend - backend restart: always depends_on: - mysql - redis 定义网络，可以多个，如果不声明，默认会创建一个网络名称为“工程名称_default”的bridge网络networks: frontend: # 一个具体网络的条目名称 name: frontend # 网络名称，默认为“工程名称_网络条目名称” driver: bridge # 网络模式，默认为bridge backend: # 一个具体网络的条目名称 name: backend # 网络名称，默认为“工程名称_网络条目名称” driver: bridge # 网络模式，默认为bridge - ⑪ 构建镜像和启动容器命令： ```shell docker-compose build --force-rm --no-cache &amp;&amp; docker-compose up -d 第五章：Docker 轻量级可视化工具 Portainer5.1 什么是 Portainer 官网。 Portainer 社区版 2.0 拥有超过 50 万的普通用户，是功能强大的开源工具集，可让您轻松地在 Docker，Swarm ，Kubernetes 和 Azure ACI 中构建和管理容器。 Portainer 的工作原理是在易于使用的 GUI 后面隐藏使管理容器变得困难的复杂性。通过消除用户使用 CLI，编写 YAML 或理解清单的需求，Portainer 使部署应用程序和解决问题变得如此简单，任何人都可以做到。 5.2 安装 服务端部署： # 访问 9000 端口即可 docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce agent 端部署： docker run -d -p 9001:9001 --name portainer_agent --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent 第六章：Docker 容器监控之 CAdvisor + InfluxDB + Granfana6.1 原生命令查看监控 命令： docker stats 示例： docker stats 通过 docker stats 命令可以很方便的看到当前宿主机上所有容器的 CPU 、 内存以及网络流量等数据，但是，docker stats 统计结果只能是当前宿主机的全部容器，查看的数据是实时的，没有地方存储、没有健康指标过线预警等功能。 6.2 容器监控三剑客 CAdvisor（监控收集）+ InfluxDB（存储数据）+ Granfana（展示图表）。 6.2.1 CAdvisor CAdvisor 是一个容器监控工具，包括容器的内存、CPU、网络 IO 、磁盘 IO 等监控，同时提供一个 WEB 页面用于查看容器的实时运行状态。CAdvisor 默认存储 2 分钟的数据，而且只是针对于单物理机。不过，CAdvisor 提供了很多数据集成接口，支持 InfluxDB 、 Redis 、Kafka 、ElasticSearch 等，可以将监控数据发送给这些数据库存储起来。 CAdvisor 功能主要有两点： 展示 HOST 和 容器两个层次的监控数据。 展示历史变化数据。6.2.2 InfluxDB InfluxDB 是用 Go 语言编写的一个开源分布式时序、事件和指标数据库，无需外部依赖。 InfluxDB 的主要功能： 基于时间序列，支持和时间有关的相关函数（如：最大、最小、求和等）。 可度量性：可以实时对大量数据进行计算。 基于事件：支持任意的事件数据。6.2.3 Granfana Granfana 是一个开源的数据监控分析可视化平台，支持多种数据源配置（支持的数据源包括 InfluxDB 、MySQL、ElasticSearch 等）和丰富的插件以及模板功能，支持图表权限控制和报警。 Granfana 的主要特性： 灵活丰富的图形化选项。 可以混合多种风格。 支持白天和夜间模式。 支持多个数据源。6.3 基于 Docker Compose 容器编排搭建 CIG docker-compose.yml version: '3.8' # 指定版本号 services: influx: image: tutum/influxdb:0.13 ports: - \"8083:8083\" - \"8086:8086\" environment: - PRE_CREATE_DB=cadvisor volumes: - \"/var/influxdb:/var/lib/influxdb\" grafana: image: grafana/grafana ports: - \"3000:3000\" links: - influxdb:influxsrv volumes: - grafana_data:/var/lib/grafana environment: - HTTP_USER=admin - HTTP_PASS=admin - INFLUXDB_HOST=influxsrv - INFLUXDB_PORT=8086 - INFLUXDB_NAME=cadvisor - INFLUXDB_USER=root - INFLUXDB_PASS=root cadvisor: image: google/cadvisor ports: - \"8080:8080\" links: - influxdb:influxsrv hostname: '{{.Node.Hostname}}' command: -logtostderr -docker_only -storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=influxsrv:8086 volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro depends_on: - influx volumes: influx: driver: local grafana: driver: local 启动命令： docker-compose build --force-rm --no-cache && docker-compose up -d","categories":[{"name":"docker","slug":"docker","permalink":"https://409713427.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://409713427.github.io/tags/docker/"}],"author":"wst"},{"title":"【Docker】Docker（v20.10.x） 基础篇","slug":"Docker（v20.10.x)/Docker（v20.10.x） 基础篇","date":"2022-07-06T10:38:35.633Z","updated":"2022-07-06T14:46:24.451Z","comments":true,"path":"2022/0706[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0706[object%20Object].html","excerpt":"","text":"操作系统为 CentOS 7.9 。 第一章：Docker 简介1.1 Docker 是什么？1.1.1 为什么会出现 Docker ？ 如果我们正在开发一个商城系统，使用是一台笔记本电脑，并且本地的开发环境具有特定的配置，然而其他开发人员身处的环境以及配置也各不相同。我们正在开发的应用依赖于我们当前的配置，并且还要依赖于某些配置文件。此外，企业还拥有标准化的测试和生产环境，具有自身的配置和一系列的支持文件，如果我们希望尽可能多的在本地模拟这些环境而不产生重新创建服务器环境的开销，怎么办？ 我们如何确保应用能够在这些环境中运行并通过质量检测？在部署过程中不出现令人头疼的版本、配置问题，也无需重新编写代码和进行故障修复？ 答案就是使用容器。Docker 之所以发展如此迅速，也是因为它给出了一个标准化的解决方案 —- 系统平滑迁移，容器虚拟化技术。 环境配置相当麻烦，换一台机器，就要重新再来一次，费时费力。很多人相当，能不能从根本上解决问题，软件可以带环境安装？ 换言之，安装的时候，将原始的环境一模一样的复制过来。开发人员利用 Docker 可以消除协作编码时 “在我的机器上可以正常工作” 的问题。 之前在服务器配置一个应用的运行环境，需要安装各种软件，就拿电商系统的环境来说，JDK、RabbitMQ、Redis、MySQL 等，安装和配置这些软件有多麻烦不说，它还不能跨平台。假如我们在 Windows 上安装的这些环境，到了 Linux 又需要重新安装。况且就算不跨操作系统，换另一台同样的操作系统的服务器，要移植应用也是非常麻烦。 传统上认为，软件编码开发、测试结束后，所产出的成果就是程序或者能编译执行的二进制字节码等。而为了让这些程序可以顺利的执行，开发团队也需要准备完整的部署文档，以便运维团队得以部署应用系统，开发需要清楚的告诉运维团队，所用的全部配置文件和所有的软件环境。不过，即便如此，依然会发生部署失败的状况。Docker 的出现使得 Docker 得以打破以前的『 程序即应用 』的概念。通过镜像（images）将系统内核除外，运行应用程序所需要的系统环境，由下向上打包，达到应用程序间跨平台间的无缝接轨运作。 1.1.2 Docker 的理念 Docker 是基于 GO 语言实现的云开源项目。 Docker 的主要目标是“Build，Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的姑奶，使得用户的 APP （可以是一个 WEB 应用或者数据库应用等）及其运行环境能够做到一次镜像，处处运行。 Linux 容器技术的出现就解决了这样一个问题，而 Docker 就是在它的基础上发展过来的。将应用打成镜像，通过镜像成为运行在 Docker 容器上面的实例，而 Docker 容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机器就可以一键部署，大大简化了操作流程。 1.1.3 总结 Docker 解决了运行环境和配置问题的软件容器，可以方便做持续集成并有助于整体发布的容器虚拟化技术。 1.2 容器 VS 虚拟机1.2.1 容器发展简史 1.2.2 传统虚拟化技术 虚拟机（Virtual Machine）就是带环境安装的一种解决方案。 它可以在一种操作系统里面运行另一种操作系统，比如在 Windows 10 系统里面运行 Linux 系统 CentOS 7 。应用程序对此毫无感知，因为虚拟机看上去和真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了删除即可，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序、操作系统和硬件三者的逻辑不变。 传统虚拟机技术基于安装在主操作系统上的虚拟机管理系统（如：VirtualBox 和 VMWare 等），可以创建虚拟机（虚拟各种硬件），在虚拟机上安装从操作系统，然后在从操作系统上安装部署各种应用。 虚拟机的缺点： ① 资源占用多。 ② 冗余步骤多。 ③ 启动慢。1.2.3 容器虚拟化技术 由于传统虚拟机的某些缺点，Linux 发展出了另外一种虚拟化技术：Linux 容器（Linux Containers，简称为 LXC）。 Linux 容器是和系统其他部分隔离的一系列进程，从另一个镜像运行，并由该镜像提供支持进程所需的全部文件。容器提供的镜像包含了应用的所有依赖项，因此在从开发到测试再到生产的整个过程中，它都具有可移植性和一致性。 Linux 容器不是模拟一个完整的操作系统而是对进程进行隔离。有了容器，就可以将软件运行的所有资源打包到一个隔离的容器中。容器和虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一的运行。 Docker 容器是在操作系统层面上实现虚拟化，直接复用本地主机上的操作系统，而传统虚拟机则是在硬件层面实现虚拟化。和传统虚拟机相比，Docker 优势体现为启动速度快、占用体积小。 1.2.4 对比 ① 传统的虚拟机是虚拟出一整套硬件后，在其上运行一个完整的操作系统，在该系统上再运行所需要的应用进程。 ② 容器内的应用进程直接运行于宿主机的内核，容器内没有自己的内核也没有直接进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 ③ 每个容器之间互相隔离，每个容器都有自己的文件系统，容器之间的进程不会相互影响，能区分计算资源。 1.3 Docker 能干嘛？1.3.1 技术职称变化 coder。 programmer。 software engineer。 DevOps engineer。 1.3.2 开发运维（DevOps）新一代开发工程师 一次构建，到处运行： 更快速的应用交付和部署：传统的应用开发完成后，需要提供一堆安装程序和配置说明文档，安装部署后需根据配置文档进行繁杂的配置才能正常运行。Docker 化之后只需要交付少量容器镜像文件，在正式生产环境加载镜像并运行即可，应用安装配置在镜像里已经内置好，大大节省部署配置和测试验证时间。 更便捷的升级和扩缩容：随着微服务架构和 Docker 的发展，大量的应用会通过微服务方式架构，应用的开发构建将变成搭乐高积木一样，每个 Docker 容器将变成一块 “积木”，应用的升级将变得非常容易。当现有的容器不足以支撑业务处理时，可通过镜像运行新的容器进行快速扩容，使应用系统的扩容从原先的天级变成分钟级甚至秒级。 更简单的系统运维：应用容器化运行后，生产环境运行的应用可与开发、测试环境的应用高度一致，容器会将应用程序相关的环境和状态完全封装起来，不会因为底层基础架构和操作系统的不一致性给应用带来影响，产生新的 BUG 。当出现程序异常时，也可以通过测试环境的相同容器进行快速定位和修复。 更高效的计算资源利用：Docker 是内核级虚拟化，其不像传统的虚拟化技术一样需要额外的 Hypervisor 支持，所以在一台物理机上可以运行很多个容器实例，可大大提升物理服务器的 CPU 和内存的利用率。 Docker 应用场景：Docker 借鉴了标准集装箱的概念。标准集装箱将货物运往世界各地，Docker 将这个模型运用到自己的设计中，唯一不同的是：集装箱运输货物，而 Docker 运输软件。 1.4 Docker 去哪下？ Docker 官网。 Docker Hub 官网。 第二章：Docker 安装和卸载2.1 前提说明 CentOS 7 安装 Docker： Docker 并非是一个通用的容器工具，它依赖于已经存在并运行的 Linux 内核环境。 Docker 实际上是在已经运行的 Linux 下制造一个隔离的文件环境，因此它执行的效率几乎等同于所部署的 Linux 主机。 因此，Docker 必须部署在 Linux 内核的系统上。如果其他系统想要部署 Docker 就必须要安装一个虚拟的 Linux 环境。 在 Windows 系统上部署 Docker 的方法就是先安装一个虚拟机，并在安装 Linux 系统的虚拟机中运行 Docker（当然，现在 Win 10+ 系统也支持 Docker ，本次不考虑）。 前提条件： 目前，CentOS 仅发行版本中的内核支持 Docker。Docker 运行在 CentOS 7 (64-bit)上，要求系统为 64 位、Linux 系统内核版本为 3.8 以上，这里选用 Centos 7.9 。 查看 CentOS 的版本： cat /etc/redhat-release 查看 Linux 内核：uname -r 2.2 Docker 的基本组成2.2.1 镜像（image） Docker 镜像（image）就是一个只读的模板。镜像可以用来创建 Docker 容器，一个镜像可以创建很多容器。 Docker 镜像相当于一个 root 文件系统。比如：官方镜像中的centos:7就包含了一套完成的 CentOS7 最小系统的 root 文件系统。 Docker 镜像相当于容器的源代码，Docker 镜像文件类似于 Java 的类模板，Docker 容器实例就类似于 Java 中 new 出来的实例对象。 容器和镜像的关系类似于面向对象编程中的对象和类： Docker 面向对象 镜像 类 容器 对象 2.2.2 容器（container） 从面向对象角度：Docker 利用容器（container）独立运行的一个或一组应用，应用程序或服务运行在容器里面，容器就类似于一个虚拟化的运行环境，容器是用镜像创建的运行实例。就像是 Java 中的类和实例对象一样，镜像是静态的定义，容器是镜像运行的实例。容器为镜像提供了一个标准的和隔离的运行环境，它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。 从镜像容器角度：可以将容器看做是一个简易版的 Linux 环境（包括 root 用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 2.2.3 仓库（registry） 仓库（registry）是集中存放镜像文件的场所。 仓库类似于 Maven 仓库，存放各种 jar 包的地方；也类似于 github 仓库，存放各种 git 项目的地方。 Docker 容器提供的官方 registry 被称为 Docker Hub，存放各种镜像模板的地方。 仓库分为公开仓库（public）和私有仓库（private）两种，最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。 国内的公开仓库包括阿里云、网易云等。 2.2.4 总结 Docker 本身是一个容器运行载体或称之为管理引擎。我们将应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就是 image 镜像文件，只有通过这个镜像文件才能生成 Docker 容器实例（类似于 Java 中 new 出来的一个对象）。 image 文件可以看做是容器的模板，Docker 根据 image 文件生成容器的实例，同一个 image 文件，可以生成多个同时运行的容器实例。 2.3 Docker 平台架构 Docker 是一个 C/S 模式的架构，后端是一个松耦合架构，众多模块各司其职。 Docker 运行的基本流程为： ① 用户是使用 Docker Client 和 Docker Daemon 建立通信，并发送请求给后者。 ② Docker Daemon 作为 Docker 架构中的主体部分，首先提供 Docker Server 的功能使其可以接受 Docker Client 的请求。 ③ Docker Engine 执行 Docker 内部的一系列工作，每一项工作都是以 Job 的形式存在的。 ④ Job 的运行过程中，当需要容器镜像时，从 Docker Registry 中下载镜像，并通过镜像管理驱动 Graph driver 将下载的镜像以 Graph 的形式存储。 ⑤ 当需要为 Docker 创建网络环境时，通过网络管理驱动 Network driver 创建并配置 Docker 容器网络环境。 ⑥ 当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 Exec driver 来完成。 ⑦ Libcontainer 是一项独立的容器管理包，Network driver 以及 Exec driver 都是通过 Libcontainer 来实现具体对容器进行的操作。 2.4 Docker 的隔离原理2.4.1 概述 Docker 用 Go 编程语言编写，并利用 Linux 内核的多种功能来交付其功能。 Docker 使用一种称为名称空间的技术来提供容器的隔离工作区。 运行容器时，Docker 会为该容器创建一组名称空间。 这些名称空间提供了一层隔离。 容器的每个方面都在单独的名称空间中运行，并且对其的访问仅限于该名称空间。2.4.2 namespace 6 项隔离 （资源隔离） namespace 系统调用参数 隔离内容 UTS CLONE_NEWUTS 主机和域名。 IPC CLONE_NEWIPC 信号量、消息队列和共享内存。 PID CLONE_NEWPID 进程编号。 Network CLONE_NEWNET 网络设备、网络栈、端口等。 Mount CLONE_NEWNS 挂载点(文件系统)。 User CLONE_NEWUSER 用户和用户组。 2.4.3 cgroups 资源限制 cgroup 提供的主要功能如下： 资源限制：限制任务使用的资源总额，并在超过这个配额时发出提示。 优先级分配：分配CPU时间片数量及磁盘 IO 带宽大小、控制任务运行的优先级。 资源统计：统计系统资源使用量，如 CPU 使用时长、内存用量等。 任务控制：对任务执行挂起、恢复等操作。 cgroup 资源控制系统，每种子系统独立地控制一种资源。功能如下： 子系统 功能 cpu 使用调度程序控制任务对 CPU 的使用。 cpuacct(CPU Accounting) 自动生成 cgroup 中任务对 CPU 资源使用情况的报告。 cpuset 为 cgroup 中的任务分配独立的 CPU (多处理器系统时)和内存。 devices 开启或关闭 cgroup 中任务对设备的访问。 freezer 挂起或恢复 cgroup 中的任务。 memory 设定 cgroup 中任务对内存使用量的限定，并生成这些任务对内存资源使用情况的报告。 perf_event(Linux CPU 性能探测器) 使 cgroup 中的任务可以进行统一的性能测试。 net_cls(Docker 未使用) 通过等级识别符标记网络数据包，从而允许 Linux 流量监控程序(Traffic Controller)识别从具体 cgroup 中生成的数据包。 2.5 Docker 的安装2.5.1 准备工作 操作系统 IP 地址 CentOS 7.9 192.168.65.100 注意：请确保你的 CentOS 7.9 能连上互联网。 2.5.2 关闭防火墙 命令：# 关闭防火墙 systemctl stop firewalld # 禁用防火墙开机自动启动 systemctl disable firewalld 2.5.3 卸载旧版本 命令：sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 2.5.4 yum 安装 gcc 相关 命令：yum -y install gcc yum -y install gcc-c++ 2.5.5 安装所需要的软件包 命令：yum -y install yum-utils 2.5.6 设置 stable 镜像仓库 命令：yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 2.5.7 更新 yum 软件包索引 命令：yum makecache fast 2.5.8 查看存储库中 Docker 的版本 命令：yum list docker-ce --showduplicates | sort -r 2.5.9 安装 Docker 命令：安装指向版本的 Docker，用上面查询的版本号替换 ，如果不指定就安装最新版本的 yum -y install docker-ce-.x86_64 docker-ce-cli-.x86_64 containerd.io 命令：安装最新版本的 Docker yum -y install docker-ce docker-ce-cli containerd.io 注意：本次安装的版本是 3:20.10.9-3.el7 yum -y install docker-ce-3:20.10.9-3.el7.x86_64 docker-ce-cli-3:20.10.9-3.el7.x86_64 containerd.io 2.5.10 启动 Docker 命令：# 启动 Docker systemctl start docker # 开启自动启动 systemctl enable docker 2.5.11 验证 Docker 是否安装成功 命令：docker version 2.5.12 阿里云镜像加速 命令：sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json redis.tar.gz docker import redis.tar.gz xudaxian/redis 3.4 总结 命令 描述 attach 当前 shell 下 attach 连接指定运行镜像。 build 通过 Dockerfile 定制镜像。 commit 提交当前容器为新的镜像。 cp 从容器中拷贝指定文件或者目录到宿主机中。 create 创建一个新的容器，同 run，但不启动容器。 diff 查看 docker 容器变化。 events 从 docker 服务获取容器实时事件。 exec 在已存在的容器上运行命令。 export 导出容器的内容流作为一个 tar 归档文件[对应 import ]。 history 展示一个镜像形成历史。 images 列出系统当前镜像。 import 从tar包中的内容创建一个新的文件系统映像[对应 export ]。 info 显示系统相关信息。 inspect 查看容器详细信息。。 kill kill 指定 docker 容器 load 从一个 tar 包中加载一个镜像[对应 save ]。 login 注册或者登陆一个 docker 源服务器。 logout 从当前 Docker registry 退出。 logs 输出当前容器日志信息。 port 查看映射端口对应的容器内部源端口。 pause 暂停容器。 ps 列出容器列表。 pull 从docker镜像源服务器拉取指定镜像或者库镜像。 push 推送指定镜像或者库镜像至docker源服务器。 restart 重启运行的容器。 rm 移除一个或者多个容器。 rmi | 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除]。 || run | 创建一个新的容器并运行一个命令。 || save | 保存一个镜像为一个 tar 包[对应 load ]。 || search | 在 docker hub 中搜索镜像。 || start | 启动容器。 || stop | 停止容器。 || tag | 给源中镜像打标签。 || top | 查看容器中运行的进程信息。 || unpause | 取消暂停容器。 || version | 查看 docker 版本号。 || wait | 截取容器停止时的退出状态值。 | 第四章：Docker 镜像4.1 概述4.1.1 Docker 镜像是什么？ 镜像是一种轻量级、可执行的独立软件包，它包含运行某个软件所需要的所有内容，我们将应用程序和配置打包好形成一个可交付的运行环境（包括代码、运行时所需要的库、环境变量和配置文件等），这个打包好的运行环境就是 image 镜像文件。 只有通过镜像文件才能生成 Docker 容器实例。 4.1.2 分层的镜像 以拉取 tomcat 镜像为例，我们可以看到 Docker 的镜像好像是一层层的下载。 命令： docker pull tomcat 4.1.3 UnionFS（联合文件系统） 注意：UnionFS 的实现是 aufs 存储驱动，而 aufs 是 Docker 存储驱动的简单实现，如果 Linux 内核是 4.0+ 版本，推荐使用 overlay2 存储驱动，当然我们在安装的时候已经指定了 overlay2 存储驱动。 UnionFS（联合文件系统）：Union 文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（scratch，没有父镜像），可以制作各种具体的应用镜像。 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。 4.1.4 Docker 镜像的加载原理 Docker 的镜像实际上由一层层的文件系统组成，这种层级的文件系统就是 UnionFS 。 bootfs （boot file system）主要包含 bootloader 和 kernel ，bootloader 主要是引导加载 kernel ，Linux 刚启动的时候会加载 bootfs 文件系统，在 Docker 镜像的最底层是引导文件 bootfs。这一层和典型的 Linux/Unix 系统是一样的，包含 bootloader 和 kernel，当 bootloader 加载完成之后整个内核就在内存之中了，此时内存的使用权已经由 bootfs 转交给内核，此时系统也会卸载 bootfs 。 rootfs（root file system），在 bootfs 之上，包含的就是典型 Linux 系统中的 /dev、/proc、/etc 等标准目录和文件。rootfs 就是各种不同操作系统发行版，如：ubuntu、centos 等。 『问』平时我们安装进虚拟机的 CentOS 都是 4G 以上，为什么Docker 才 200+ MB？ 『答』对于一个精简的 OS ，rootfs 可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用的宿主机的 kernel ，自己只需要提供 rootfs 就可以了。由此可见对于不同的 Linux 发行版，bootfs 基本是一致的，rootfs 会有所差别，因为不同的发行版可以共用 bootfs 。 4.1.5 为什么 Docker 镜像要采用这种分层结构？ 镜像分层最大的一个好处就是共享资源，方便复制迁移。 比如：多个镜像都是从相同的 base 镜像构建而来，那么 Docker 只需要在磁盘中保存一份 base 镜像，同时内存中也只是加载一份 base 镜像，就可以为所有容器服务了，而且镜像的每一层都可以被共享。 4.2 Docker 镜像的理解 写时复制，用时分配：Docker 镜像层都是只读的，容器层是可写的。 当容器启动的时候，一个新的可写层被加载到镜像的顶部，这一层通常被称为容器层，容器层之下的都叫做镜像层。 所有对容器的改动，无论添加、删除还是修改文件都只会发生在容器层中，只有容器层是可写的，容器层下面的所有镜像层都是只读的。 4.3 使用 commit 制作镜像 需求：在 ubuntu 镜像（官方镜像）中添加 vim 命令，安装制作为新的镜像。 命令： docker commit -m=\"提交的描述信息\" -a=\"作者\" 容器ID 要创建的目标镜像名:TAG 示例： ① 拉取 ubuntu 镜像到本地： docker pull ubuntu ② 运行 ubuntu 镜像，查看是否携带 vim 命令：docker run -it --name=\"ubuntu\" ubuntu /bin/bash vim a.txt ③ 在连接互联网的情况下，在容器内部安装 vim :# 更新包管理器 apt-get update # 安装 vim 命令 apt-get -y install vim ④ 安装完成后，commit 新的镜像：docker commit -m=\"安装有vim的ubuntu镜像\" -a=\"许大仙\" ubuntu xudaxian/ubuntu ⑤ 启动新的镜像，并进行测试：docker run -it --name=\"xudaxian-ubuntu\" xudaxian/ubuntu /bin/bash vim a.txt 4.4 总结 Docker 中的镜像分层，支持通过扩展现有镜像，创建新的镜像。类似于 Java 中继承一个 Base 基础类，然后自己按需扩展。 新的镜像是从 base 镜像一层一层的叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。 第五章：本地镜像发布到阿里云5.1 本地镜像发布到阿里云流程 5.2 镜像的生成方法 ① 基于当前容器创建镜像，使用 docker commit 命令。 ② 基于 Dockerfile 文件。 5.3 本地镜像推送到阿里云5.3.1 创建仓库镜像 选择控制台，进入容器镜像服务。 选择个人实例： 命名空间： 镜像仓库： 5.3.2 将镜像推送到阿里云： 登录阿里云：docker login --username=**** registry.cn-shanghai.aliyuncs.com 查看镜像，并给镜像打标签：docker tag [ImageId] registry.cn-shanghai.aliyuncs.com/xudaxian/xudaxian-ubuntu:[镜像版本号] 推送镜像：docker push registry.cn-shanghai.aliyuncs.com/xudaxian/xudaxian-ubuntu:1.0 5.4 将阿里云上的镜像下载到本地 删除本地镜像：docker rmi -f registry.cn-shanghai.aliyuncs.com/xudaxian/xudaxian-ubuntu:1.0 下载镜像到本地：docker pull registry.cn-shanghai.aliyuncs.com/xudaxian/xudaxian-ubuntu:1.0 第六章：本地镜像发布到私有库6.1 本地镜像发布到私有库流程 6.2 Docker Registry Docker Registry 是官方提供的工具，可以用于构建私有镜像仓库。 6.3 将本地镜像推送到私有库 下载 Docker Registry 镜像： docker pull registry 运行Docker Registry 私有库 ，相当于本地有个私有的 Docker Hub：docker run -d -p 5000:5000 --name=\"registry\" -v /var/registry/:/tmp/registry --privileged=true registry 注意：默认情况，仓库被创建在容器的 /var/lib/registry 目录下，建议自行用容器卷映射，方便于宿主机联调。 curl 验证私服库上有什么镜像：curl -XGET http://192.168.65.100:5000/v2/_catalog 命令：将镜像打标签 docker tag 镜像:Tag Host:Port/Repository:Tag 示例： docker tag xudaxian/ubuntu 192.168.65.100:5000/xudaxian-ubuntu:1.0 修改配置文件以支持 http ：sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF' { \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"registry-mirrors\": [\"https://du3ia00u.mirror.aliyuncs.com\"], \"live-restore\": true, \"log-driver\":\"json-file\", \"log-opts\": {\"max-size\":\"500m\", \"max-file\":\"3\"}, \"storage-driver\": \"overlay2\", \"insecure-registries\":[\"192.168.65.100:5000\"] } EOF sudo systemctl daemon-reload && sudo systemctl restart docker 将本地镜像推送到私有库：docker push 192.168.65.100:5000/xudaxian-ubuntu:1.0 curl 验证私服库上有什么镜像：curl -XGET http://192.168.65.100:5000/v2/_catalog 拉取本地镜像：docker pull 192.168.65.100:5000/xudaxian-ubuntu:1.0 第七章：Docker 容器数据卷7.1 坑 容器卷记得加入--privileged=true。 Docker 挂载主机目录访问，如果出现 cannot open directory .: Permission denied ，解决方法就是在挂载目录的时候添加--privileged=true参数即可。 因为 CentOS 7 安全模块会之前的系统版本要强，不安全的会先禁止掉，目录挂载默认被认为是不安全的行为。如果我们要开启，一般使用--privileged=true，扩大容器的全局解决挂载目录没有权限的问题，即用了该参数，容器内的 root 就拥有了外部主机的真正的 root 权限；否则，容器内的 root 只是外部主机的一个普通用户。 注意：学习的时候，可以使用该参数，但是如果使用 Dockerfile 来制作镜像的时候，禁止使用 root 用户来制作镜像，推荐使用普通用户制作镜像，防止被黑客攻击。 7.2 Docker 容器数据卷是什么？ 卷就是目录或文件，存在于一个或多个容器中，由 Docker 挂载到容器，但是不属于联合文件系统（UnionFS），因此能够绕过 UnionFS 提供一些用于持续存储或共享数据的特性。 卷的设计目的就是 数据的持久化 ，完全独立于容器的生命周期，因此 Docker 不会在容器删除的时候删除其挂载的容器数据卷。 命令： docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名 总结：将 Docker 容器内的数据保存进宿主机的磁盘中。 7.3 Docker 容器数据卷能干嘛？ 将应用和运行的环境打包成镜像，run 后形成容器实例运行，但是我们希望 数据能够持久化 。Docker 容器产生的数据，如果不使用容器数据源，当容器实例删除之后，容器内的数据自然就丢失了，为了解决这个问题，我们使用了容器的数据卷功能。 7.4 Docker 容器数据卷的特点 ① 数据卷可以在容器之间共享或重用数据。 ② 数据卷中的更改可以实时生效。 ③ 数据卷中的更改不会包含在镜像的更新中。 ④ 数据卷的生命周期一直持续到没有容器使用它为止。 7.5 Docker 容器数据卷案例7.5.1 宿主机和容器之间映射添加容器数据卷 命令： docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名 示例： docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名 查看数据卷是否挂载成功： docker inspect 容器ID|容器名称 示例： docker inspect ubuntu 7.5.2 读写规则映射添加说明 默认情况下，容器内目录是读写（rw），对应的命令为： docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:rw 镜像名 如果想设置容器内目录只能读取，不能写入，可以设为只读（ro），对应的命令为（此时如果宿主机写入内容，可以同步给容器内，容器可以读取数据）： docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:ro 镜像名 7.5.3 容器数据卷的继承和共享 ① 容器 1 完成和宿主机的映射： docker run -it --privileged=true -v /var/tmp:/tmp --name u1 ubuntu ② 容器 2 继承容器 1 的卷规则： docker run -it --privileged=true --volumes-from u1 --name u2 ubuntu 注意：继承的仅仅是容器数据卷的映射规则，容器 1 和 容器 2 之间并没其他什么关系，容器 1 挂了不会影响到 容器 2 。 第八章：Docker 应用常规安装8.1 总体步骤 ① 搜索镜像。 ② 拉取镜像。 ③ 查看镜像。 ④ 启动容器：服务端口映射。 ⑤ 停止容器。 ⑥ 移除容器。 注意：拉取镜像或者使用 Dockerfile 制作镜像的时候，尽量选择镜像带有alpine或slim后缀的，因为这种类型的镜像的体积相对而言比较小，更易于构建和传输。 8.2 安装 MySQL 搜索镜像：docker search mysql 拉取镜像：docker pull mysql:5.7 查看镜像：docker images 启动容器：docker run -d -p 3306:3306 --name mysql5.7 -v /var/mysql5.7/conf:/etc/mysql/conf.d -v /var/mysql5.7/logs:/var/log/mysql -v /var/mysql5.7/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -e TZ=Asia/Shanghai -e MYSQL_DATABASE=ssm --restart=always mysql:5.7 --lower_case_table_names=1 --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --default-authentication-plugin=mysql_native_password 8.3 安装 Tomcat 搜索镜像：docker search tomcat 拉取镜像：docker pull billygoo/tomcat8-jdk8 查看镜像：docker images 启动容器：docker run -d -p 8080:8080 --name tomcat8 billygoo/tomcat8-jdk8 8.4 安装 Redis 搜索镜像：docker search redis 拉取镜像：docker pull redis:6.0.8 查看镜像：docker images 启动容器：docker run -p 6379:6379 --name redis -v /var/redis/data:/data -d redis:6.0.8 redis-server --appendonly yes --requirepass \"123456\" 使用配置文件启动 Redis 容器： vim /var/redis/redis.conf # 更多配置参照 https://raw.githubusercontent.com/redis/redis/6.0/redis.conf port 6379 appendonly yes docker run -p 6379:6379 --name redis -v /var/redis/data:/data -v /var/redis/redis.conf:/etc/redis/redis.conf -d redis:6.0.8 redis-server /etc/redis/redis.conf --appendonly yes 第九章：其他9.1 Docker 中容器的状态 ① Created（新建）。 ② Up（运行中）。 ③ Pause（暂停）。 ④ Exited（退出）。 9.2 docker run 和 docker create 的异同点 同：两个命令都可以创建容器。 异：docker run 创建完容器后会立即启动（常用）；docker create 创建完容器后，需要手动使用 docker start 启动容器。 9.3 Docker 中容器的重启策略 ① no：默认策略，在容器退出时不重启容器。 ② on-failure：在容器非正常退出时（退出状态非0），才会重启容器。 ③ on-failure:3：在容器非正常退出时重启容器，最多重启 3 次。 ④ always：在容器退出时总是重启容器。 ⑤ unless-stopped：在容器退出时总是重启容器，但是不考虑在 Docker 守护进程启动时就已经停止了的容器。","categories":[{"name":"docker","slug":"docker","permalink":"https://409713427.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://409713427.github.io/tags/docker/"}],"author":"wst"},{"title":"【Elasticsearch】1.介绍及安装","slug":"ElasticSearch/1.介绍及安装","date":"2022-04-15T05:35:32.000Z","updated":"2022-07-06T14:46:33.196Z","comments":true,"path":"2022/0415[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0415[object%20Object].html","excerpt":"","text":"全文搜索属于最常见的需求，开源的 Elasticsearch是目前全文搜索引擎的首选，它可以快速地储存、搜索和分析海量数据Elastic的底层是开源库Lucene。但是你没法直接用 Lucene，必须自己写代码去调用它的接口。Elastic是Lucene的封装，提供了REST API的操作接口，开箱即用官方文档 https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html官方中文 https://www.elastic.co/guide/cn/elasticsearch/guide/current/foreword_id.html社区中文 https://es.xiaoleilu.com/index.htmlhttp://doc.codingdict.com/elasticsearch/0/ 基本概念Elasticsearch是一种NoSQL数据库（非关系型数据库），和关系型数据库的基本概念对应如下Elasticsearch``index–&gt;type–&gt;doc–&gt;fieldMySQL 数据库 –&gt; 数据表 –&gt; 行 –&gt; 列 Index（索引）Elastic会索引所有字段，经过处理后写入一个反向索引Inverted Index。查找数据的时候，直接查找该索引，所以Elastic数据管理的顶层单位就叫做索引**Index**它是单个数据库的同义词，每个index（即数据库）的名字必须是小写动词，相当于MySQL的insert名词，相当于MySQL的databaseType（类型）在 Index索引中，可以定义一个或多个类型，类似于MySQL的 Table，每一种类型的数据存放在一起 在Elasticsearch7之后，**Type**类型被移除Elasticsearch 官网提出的近期版本对 type 概念的演变情况如下在 5.X 版本中，一个 index 下可以创建多个 type在 6.X 版本中，一个 index 下只能存在一个 type在 7.X 版本中，直接去除了 type 的概念，就是说 index 不再会有 typeDocument（文档）保存在某个Index索引下，某种Type类型的一个数据，**Document**文档是**JSON**格式的，Document就像是 MySQL中某个Table里面的一行的数据，字段就是Document里的属性 倒排索引Docker安装Elasticsearch Kibana1. 下载镜像文件 docker pull elasticsearch:7.4.2 # 存储和检索数据 docker pull kibana:7.4.2 # 可视化检索数据 2. 配置挂载数据文件夹 mkdir -p /mydata/elasticsearch/config # 创建配置文件目录 mkdir -p /mydata/elasticsearch/data # 创建数据目录 # 将/mydata/elasticsearch/文件夹中文件都可读可写，不配权限，docker中的ES启动不起来 chmod -R 777 /mydata/elasticsearch/ # 配置任意机器可以访问 elasticsearch echo \"http.host: 0.0.0.0\" >/mydata/elasticsearch/config/elasticsearch.yml 3. 启动Elasticsearch命令后面的 \\是换行符，注意前面有空格 docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \\ -e \"discovery.type=single-node\" \\ -e ES_JAVA_OPTS=\"-Xms64m -Xmx512m\" \\ -v /mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ -v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \\ -v /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\ -d elasticsearch:7.4.2 -p 9200:9200 -p 9300:9300向外暴露两个端口，9200用于HTTP REST API请求，9300在分布式集群状态下 ES 之间的通信端口-e &quot;discovery.type=single-node&quot;es 以单节点运行-e ES_JAVA_OPTS=&quot;-Xms64m -Xmx512m&quot;设置启动占用内存，不设置可能会占用当前系统所有内存-v挂载容器中的配置文件、数据文件、插件数据到本机的文件夹访问 IP:9200 看到返回的 json 数据说明启动成功没启动起来使用**docker logs**查看日志，可能是外挂文件的权限不足4. 启动可视化Kibana docker run --name kibana -p 5601:5601 \\ -e ELASTICSEARCH_HOSTS=http://192.168.56.10:9200 \\ -d kibana:7.4.2 kibama的默认参数浏览器输入 http://192.168.56.10:5601/ 测试5. 设置随Docker启动 docker update elasticsearch --restart=always # 设置开机自启 docker update kibana --restart=always # 设置开机自启","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/tags/elasticsearch/"}],"author":"wst"},{"title":"【Elasticsearch】2.使用入门","slug":"ElasticSearch/2.使用入门","date":"2022-04-15T05:35:32.000Z","updated":"2022-07-06T14:46:33.196Z","comments":true,"path":"2022/0415[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0415[object%20Object].html","excerpt":"","text":"Elasticsearch是通过REST API接口来操作数据的，通过几个接口的请求来演示它的使用_cat/_cat/nodes 查看所有节点接口GET [http://192.168.56.10:9200/_cat/nodes](http://192.168.56.10:9200/_cat/nodes)/_cat/health 查看ES健康状况接口GET [http://192.168.56.10:9200/_cat/health](http://192.168.56.10:9200/_cat/health)/_cat/master 查看主节点信息接口：GET [http://192.168.56.10:9200/_cat/master](http://192.168.56.10:9200/_cat/master)/_cat/indicies 查看所有索引等价于 mysql 数据库的 show databases;接口：GET [http://192.168.56.10:9200/_cat/indices](http://192.168.56.10:9200/_cat/indices)查看文档 GET /index/type/id接口GET [http://192.168.56.10:9200/customer/external/1](http://192.168.56.10:9200/customer/external/1) { \"_index\": \"customer\", # 在哪个索引(库) \"_type\": \"external\", # 在哪个类型(表) \"_id\": \"1\", # 文档id(记录) \"_version\": 5, # 版本号 \"_seq_no\": 2, # 并发控制字段，每次更新都会+1，用来做乐观锁 \"_primary_term\": 1, # 同上，主分片重新分配，如重启，就会变化 \"found\": true, \"_source\": { # 数据 \"name\": \"zhangsan\" } } # 乐观锁更新时携带 ?_seq_no=0&amp;_primary_term=1 当携带数据与实际值不匹配时更新失败 索引（保存）或更新一个文档即保存一条数据，保存在哪个索引的哪个类型下，指定用哪个唯一标识PUT 请求接口：PUT [http://192.168.56.10:9200/customer/external/1](http://192.168.56.10:9200/customer/external/1)相同数据再次put，result显示update更新操作，版本号+1POST 请求接口POST [http://192.168.56.10:9200/customer/external/](http://192.168.56.10:9200/customer/external/)POST不带id，会自动创建一个唯一id，所以多次不带id请求都是创建，多次带相同id就是更新**PUT**对比**POST** POST新增，如果不指定id，会自动生成id。指定id就会修改这个数据，并新增版本号 PUT可以新增也可以修改。**PUT**必须指定id，由于PUT需要指定id，我们一般用来做修改操作，不指定id会报错 POST 带 _update接口POST [http://192.168.56.10:9200/customer/external/1/_update](http://192.168.56.10:9200/customer/external/1/_update) 更新数据一定要带上**doc**几种更新文档的区别在上面索引文档即保存文档的时候介绍，还有两种更新文档的方式 当PUT请求必须指定id，且有该id数据存在时，会更新文档并新增版本号 当POST请求带id，与PUT相同，该id数据已经存在时，会更新文档并新增版本号这两种请求类似，即带id，且数据存在，就会执行更新操作POST带_update 请求体的报文格式不同，**_update**方式要修改的数据要包裹在**doc**键下 _update方式不会重复更新，数据与原来一样不会更新，版本号不会改变，另两种方式会重复更新（覆盖原来数据），版本号会改变 这几种方式在更新时都可以增加属性，PUT请求带id更新和POST请求带id更新，会直接覆盖原来的数据，不会在原来的属性里面新增属性 删除文档 &amp; 索引删除文档接口DELETE [http://192.168.56.10:9200/customer/external/1](http://192.168.56.10:9200/customer/external/1) 删除索引接口DELETE [http://192.168.56.10:9200/customer](http://192.168.56.10:9200/customer) 注意：不能删除类型typebulk 批量操作数据语法格式 {action:{metadata}}\\n // 例如index保存记录，update更新 {request body }\\n {action:{metadata}}\\n {request body }\\n 1. 指定索引和类型的批量操作 index表示存储，指定id跟数据 POST /customer/external/_bulk {\"index\":{\"_id\":\"1\"}} {\"name\":\"John Doe\"} {\"index\":{\"_id\":\"2\"}} {\"name\":\"John Doe\"} 在**Kibana**中使用dev-tools测试批量 2. 对所有索引执行批量操作 POST /_bulk {\"delete\":{\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"}} {\"create\":{\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"}} {\"title\":\"my first blog post\"} {\"index\":{\"_index\":\"website\",\"_type\":\"blog\"}} {\"title\":\"my second blog post\"} {\"update\":{\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"}} {\"doc\":{\"title\":\"my updated blog post\"}} 这里的批量操作，当发生某一条执行失败时，其他的数据仍然能够接着执行，也就是说彼此之间是独立的 bulk api以此按顺序执行所有的action（动作）。如果一个单个的动作因任何原因失败，它将继续处理它后面剩余的动作 当bulk api返回时，它将提供每个动作的状态（与发送的顺序相同），可以检查任一指定的动作是否失败了","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/tags/elasticsearch/"}],"author":"wst"},{"title":"【Elasticsearch】3.检索进阶","slug":"ElasticSearch/3.检索进阶","date":"2022-04-15T05:35:32.000Z","updated":"2022-07-06T14:46:33.196Z","comments":true,"path":"2022/0415[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0415[object%20Object].html","excerpt":"","text":"本节参考 官方文档 检索示例导入样本测试数据准备一份顾客银行账户信息的虚构的JSON文档样本 POST bank/account/_bulkhttps://gitee.com/xlh_blog/common_content/blob/master/es%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE.json每个文档都有下列的 schema（模式） { \"account_number\": 1, \"balance\": 39225, \"firstname\": \"Amber\", \"lastname\": \"Duke\", \"age\": 32, \"gender\": \"M\", \"address\": \"880 Holmes Lane\", \"employer\": \"Pyrami\", \"email\": \"amberduke@pyrami.com\", \"city\": \"Brogan\", \"state\": \"IL\" } 检索示例介绍下面的请求都是在Kibana``dev-tools操作 请求方式说明ES支持两种基本方式检索 通过REST request uri发送搜索参数 （uri + 检索参数） GET bank/_search?q=*&amp;sort=account_number:asc # q=* 查询所有 # sort=account_number:asc 按照account_number进行升序排列 通过REST request body来发送它们（uri+ 请求体） GET /bank/_search { \"query\": { \"match_all\": {} }, \"sort\": [ { \"account_number\": \"asc\" } ] } # query 查询条件 # sort 排序条件 **响应结果说明**Elasticsearch 默认会分页返回10条数据，不会一下返回所有数据 响应字段解释 took – 查询需要多长时间，以毫秒为单位 timed_out – 请求是否超时 _shards – 搜索了多少分片，以及多少分片成功、失败或被跳过 max_score – 找到的最相关文档的分数 hits.total.value - 找到了多少个匹配的文档 hits.sort - 文档的排序位置（不按相关性分数排序时） hits._score - 文档的相关性分数（使用 match_all 时不适用）{ \"took\" : 58, # 花费58毫秒 \"timed_out\" : false, # 是否超时 \"_shards\" : { # 集群模式下，每一个分片都进行了哪些操作 \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { # 命中的记录 \"total\" : { \"value\" : 1000, # 检索到的条目 \"relation\" : \"eq\" # 检索的关系 }, \"max_score\" : null, # 最大得分 \"hits\" : [ { \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"0\", \"_score\" : null, \"_source\" : { # 数据的内容 \"account_number\" : 0, \"balance\" : 16623, \"firstname\" : \"Bradshaw\", \"lastname\" : \"Mckenzie\", \"age\" : 29, \"gender\" : \"F\", \"address\" : \"244 Columbus Place\", \"employer\" : \"Euron\", \"email\" : \"bradshawmckenzie@euron.com\", \"city\" : \"Hobucken\", \"state\" : \"CO\" }, \"sort\" : [ 0 ] }, ... ] } } Query DSL本小节参考官方文档 Query DSLElasticsearch提供了一个可以执行查询的JSON风格的DSL（领域对象语言）。这个被称为Query DSL，该查询语言非常全面 1. 基本语法格式一个查询语句的典型结构 QUERY_NAME:{ ARGUMENT:VALUE, ARGUMENT:VALUE,... } 如果针对于某个字段，那么它的结构如下 { QUERY_NAME:{ FIELD_NAME:{ ARGUMENT:VALUE, ARGUMENT:VALUE,... } } } 请求示例 GET bank/_search { \"query\": { \"match_all\": {} }, \"sort\": [ { \"balance\": { \"order\": \"desc\" } } ], \"from\": 0, \"size\": 5, \"_source\": [\"balance\", \"firstname\"] } # match_all 查询类型【代表查询所有的所有】，es中可以在query中组合非常多的查询类型完成复杂查询 # sort 排序，多字段排序，会在前序字段相等时后续字段内部排序，否则以前序为准 # from+size 限定，完成分页功能，从第几条数据开始，每页有多少数据 # _source 指定只查询部分属性 2. 返回部分字段请求示例 GET bank/_search { \"query\": { \"match_all\": {} }, \"from\": 0, \"size\": 5, \"sort\": [ { \"account_number\": { \"order\": \"desc\" } } ], \"_source\": [\"balance\",\"firstname\"] } # _source 指定返回结果中包含的字段名 结果示例 { \"took\" : 372, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 1000, \"relation\" : \"eq\" }, \"max_score\" : null, \"hits\" : [ { \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"248\", \"_score\" : null, \"_source\" : { \"firstname\" : \"West\", \"balance\" : 49989 }, \"sort\" : [ 49989 ] }, { \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"1\", \"_score\" : null, \"_source\" : { \"account_number\" : 1, \"balance\" : 39225, \"firstname\" : \"Amber\", \"lastname\" : \"Duke\", \"age\" : 32, \"gender\" : \"M\", \"address\" : \"880 Holmes Lane\", \"employer\" : \"Pyrami\", \"email\" : \"amberduke@pyrami.com\", \"city\" : \"Brogan\", \"state\" : \"IL\" }, \"sort\" : [ 1 ] }, {...} {...} {...} {...} {...} {...} {...} {...} {...} ] } } 3. match-匹配查询精确查询-基本数据类型（非文本） GET bank/_search { \"query\": { \"match\": { \"account_number\": \"20\" # 20是数字，可以不带引号 } } } # 查找匹配 account_number 为 20 的数据 非文本推荐使用 term 模糊查询-文本字符串match即全文检索，对检索字段进行分词匹配，会按照响应的评分 _score 排序，原理是倒排索引 GET bank/_search { \"query\": { \"match\": { \"address\": \"Kings\" } } } # 查找匹配 address 包含 mill 或 lane 的数据,score 会显示相关性评分 精确匹配-文本字符串每一个文本字段都可以**.keyword** GET bank/_search { \"query\": { \"match\": { \"address.keyword\": \"288 Mill Street\" } } } # 查找 address 为 288 Mill Street 的数据。 # 这里的查找是精确查找，只有完全匹配时才会查找出存在的记录， # 如果想模糊查询应该使用match_phrase 短语匹配 4. match_phrase-短语匹配将需要匹配的值当成一整个单词（不分词）进行检索精确匹配的匹配的只就是address的全部值，match_phrase可以是部分值 GET bank/_search { \"query\": { \"match_phrase\": { \"address\": \"mill lane\" } } } # 这里会检索 address 匹配包含短语 mill lane 的数据 5. multi_math-多字段匹配 GET bank/_search { \"query\": { \"multi_match\": { \"query\": \"mill\", \"fields\": [\"city\", \"address\"] } } } # 检索 city 或 address 匹配包含 mill 的数据，会对查询条件分词 6. bool-复合查询复合语句可以合并，任何其他查询语句，包括符合语句。这也就意味着，复合语句之间可以互相嵌套，可以表达非常复杂的逻辑。 **must**必须满足所列举的所有条件 **must_not**必须不匹配所列举的所有条件 **should**应该满足should所列举的条件，可以不满足，会影响scoreGET bank/_search { \"query\": { \"bool\": { \"must\": [ {\"match\": { \"gender\": \"M\" }}, {\"match\": { \"address\": \"mill\" }} ], \"must_not\": [ {\"match\": { \"age\": \"18\" }} ], \"should\": [ {\"match\": { \"lastname\": \"Wallace\" }} ] } } } # 查询 gender 为 F 且 address 包含 mill 的数据，age不能是28，lastname应该是Wallace 7. filter-结果过滤 在boolean查询中，must, should 和must_not 元素都被称为查询子句 。 文档是否符合每个“must”或“should”子句中的标准，决定了文档的“相关性得分”。 得分越高，文档越符合您的搜索条件。 默认情况下，Elasticsearch 返回根据这些相关性得分排序的文档。“must_not”子句中的条件被视为“过滤器”。 它影响文档是否包含在结果中，但不影响文档的评分方式。还可以显式地指定任意过滤器来包含或排除基于结构化数据的文档。 **filter**对结果进行过滤，且不计算相关性得分 GET bank/_search { \"query\": { \"bool\": { \"must\": [ {\"match\": { \"gender\": \"M\" }}, {\"match\": { \"address\": \"mill\" }} ], \"must_not\": [ {\"match\": { \"age\": \"18\" }} ], \"should\": [ {\"match\": { \"lastname\": \"Wallace\" }} ], \"filter\": {\"range\": { \"age\": { \"gte\": 18, \"lte\": 30 } }} } } } # 增加了过滤，不计入相关性得分 8. term-精确检索 避免使用 term 查询文本字段默认情况下，Elasticsearch 会通过analysis分词将文本字段的值拆分为一部分，这使精确匹配文本字段的值变得困难。 如果要查询文本字段值，请使用 match 查询代替 https://www.elastic.co/guide/en/elasticsearch/reference/7.11/query-dsl-term-query.html文本字段用**match**查询，非文本字段使用**term**检索 GET bank/_search { \"query\": { \"term\": { \"age\": 28 } } } # 查找 age 为 28 的数据 **9. Aggregation-执行聚合**https://www.elastic.co/guide/en/elasticsearch/reference/7.11/search-aggregations.html 聚合提供了从数据中分组和提取数据的能力。最简单的聚合方法大致等于SQL``GROUP BY 和SQL聚合函数。在Elasticsearch中，执行搜索返回hits（命中结果），同时返回聚合结果，有把一个响应中的所有hits（命中结果）分隔开的能力。这是非常强大且有效的，可以执行查询和多个聚合，并且在一次使用中得到各自的（任何一个的）返回结果，使用一次简洁和简化的API来避免网络往返 聚合语法 GET /my-index-000001/_search { \"aggs\":{ \"aggs_name\":{ # 这次聚合的名字，方便展示在结果集中 \"AGG_TYPE\":{ # 聚合的类型(avg,term,terms) } } } } 示例 搜索address中包含mill的所有人的年龄分布以及平均年龄 GET bank/_search { \"query\": { \"match\": { \"address\": \"Mill\" } }, \"aggs\": { \"ageAgg\": { \"terms\": { \"field\": \"age\", \"size\": 10 } }, \"ageAvg\": { \"avg\": { \"field\": \"age\" } }, \"balanceAvg\": { \"avg\": { \"field\": \"balance\" } } }, \"size\": 0 } # \"ageAgg\": { --- 聚合名为 ageAgg # \"terms\": { --- 聚合类型为 term # \"field\": \"age\", --- 聚合字段为 age # \"size\": 10 --- 取聚合后前十个数据 # } # }, # ------------------------ # \"ageAvg\": { --- 聚合名为 ageAvg # \"avg\": { --- 聚合类型为 avg 求平均值 # \"field\": \"age\" --- 聚合字段为 age # } # }, # ------------------------ # \"balanceAvg\": { --- 聚合名为 balanceAvg # \"avg\": { --- 聚合类型为 avg 求平均值 # \"field\": \"balance\" --- 聚合字段为 balance # } # } # ------------------------ # \"size\": 0 --- 不显示命中结果，只看聚合信息 结果 { \"took\" : 10, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 4, \"relation\" : \"eq\" }, \"max_score\" : null, \"hits\" : [ ] }, \"aggregations\" : { \"ageAgg\" : { \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ { \"key\" : 38, \"doc_count\" : 2 }, { \"key\" : 28, \"doc_count\" : 1 }, { \"key\" : 32, \"doc_count\" : 1 } ] }, \"ageAvg\" : { \"value\" : 34.0 }, \"balanceAvg\" : { \"value\" : 25208.0 } } } 按照年龄聚合，并且求这些年龄段的这些人的平均薪资 GET bank/_search { \"query\": { \"match_all\": {} }, \"aggs\": { \"ageAgg\": { \"terms\": { \"field\": \"age\", \"size\": 100 }, \"aggs\": { \"ageAvg\": { \"avg\": { \"field\": \"balance\" } } } } }, \"size\": 0 } 结果 { \"took\" : 12, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 1000, \"relation\" : \"eq\" }, \"max_score\" : null, \"hits\" : [ ] }, \"aggregations\" : { \"ageAgg\" : { \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ { \"key\" : 31, \"doc_count\" : 61, \"ageAvg\" : { \"value\" : 28312.918032786885 } }, { \"key\" : 39, \"doc_count\" : 60, \"ageAvg\" : { \"value\" : 25269.583333333332 } }, ... ] } } } 查出所有年龄分布，并且这些年龄段中M的平均薪资和F的平均薪资以及这个年龄段的总体平均薪资 GET bank/_search { \"query\": { \"match_all\": {} }, \"aggs\": { \"ageAgg\": { \"terms\": { \"field\": \"age\", \"size\": 100 }, \"aggs\": { \"genderAgg\": { \"terms\": { \"field\": \"gender.keyword\" }, \"aggs\": { \"balanceAvg\": { \"avg\": { \"field\": \"balance\" } } } }, \"ageBalanceAvg\": { \"avg\": { \"field\": \"balance\" } } } } }, \"size\": 0 } # \"field\": \"gender.keyword\" gender是txt没法聚合 必须加.keyword精确替代 结果 { \"took\" : 17, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 1000, \"relation\" : \"eq\" }, \"max_score\" : null, \"hits\" : [ ] }, \"aggregations\" : { \"ageAgg\" : { \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ { \"key\" : 31, \"doc_count\" : 61, \"genderAgg\" : { \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ { \"key\" : \"M\", \"doc_count\" : 35, \"balanceAvg\" : { \"value\" : 29565.628571428573 } }, { \"key\" : \"F\", \"doc_count\" : 26, \"balanceAvg\" : { \"value\" : 26626.576923076922 } } ] }, \"ageBalanceAvg\" : { \"value\" : 28312.918032786885 } }, { \"key\" : 39, \"doc_count\" : 60, \"genderAgg\" : { \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ { \"key\" : \"F\", \"doc_count\" : 38, \"balanceAvg\" : { \"value\" : 26348.684210526317 } }, { \"key\" : \"M\", \"doc_count\" : 22, \"balanceAvg\" : { \"value\" : 23405.68181818182 } } ] }, \"ageBalanceAvg\" : { \"value\" : 25269.583333333332 } }, ... ] } } }","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/tags/elasticsearch/"}],"author":"wst"},{"title":"【Elasticsearch】4.Mapping 映射","slug":"ElasticSearch/4.Mapping 映射","date":"2022-04-15T05:35:32.000Z","updated":"2022-07-06T14:46:33.197Z","comments":true,"path":"2022/0415[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0415[object%20Object].html","excerpt":"","text":"https://www.elastic.co/guide/en/elasticsearch/reference/7.11/mapping.html1. Mapping 介绍**Maping**是用来定义一个文档document，以及它所包含的属性field是如何存储和索引的比如，使用maping来定义 哪些字符串属性应该被看做全文本属性full text fields 哪些属性包含数字，日期或地理位置 文档中的所有属性是否都被索引（all 配置） 日期的格式 自定义映射规则来执行动态添加属性 查看mapping信息 **GET bank/_mapping** GET bank/_mapping { \"bank\" : { \"mappings\" : { \"properties\" : { \"account_number\" : { \"type\" : \"long\" }, \"address\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"age\" : { \"type\" : \"long\" }, \"balance\" : { \"type\" : \"long\" }, \"city\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"email\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"employer\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"firstname\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"gender\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"lastname\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"state\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } } } } } } 2. 新版本type移除ElasticSearch7-去掉type概念 关系型数据库中两个数据表示是独立的，即使他们里面有相同名称的列也不影响使用，但ES中不是这样的。elasticsearch是基于Lucene开发的搜索引擎，而ES中不同type下名称相同的filed最终在Lucene中的处理方式是一样的 两个不同type下的两个user_name，在ES同一个索引下其实被认为是同一个filed，你必须在两个不同的type中定义相同的filed映射。否则，不同type中的相同字段名称就会在处理中出现冲突的情况，导致Lucene处理效率下降 去掉type就是为了提高ES处理数据的效率 Elasticsearch 7.x URL中的type参数为可选。比如，索引一个文档不再要求提供文档类型 Elasticsearch 8.x 不再支持URL中的type参数 解决 将索引从多类型迁移到单类型，每种类型文档一个独立索引 将已存在的索引下的类型数据，全部迁移到指定位置即可。详见数据迁移 Elasticsearch 7.x Specifying types in requests is deprecated. For instance, indexing a document no longer requires a document type. The new index APIs are PUT {index}/_doc/{id} in case of explicit ids and POST {index}/_doc for auto-generated ids. Note that in 7.0, _doc is a permanent part of the path, and represents the endpoint name rather than the document type. The include_type_name parameter in the index creation, index template, and mapping APIs will default to false. Setting the parameter at all will result in a deprecation warning. The default mapping type is removed. Elasticsearch 8.x Specifying types in requests is no longer supported. The include_type_name parameter is removed. 3. 属性类型参考：官方属性类型映射操作参考：创建映射操作 1. 创建索引映射创建索引并指定属性的映射规则（相当于新建表并指定字段和字段类型） PUT /my_index { \"mappings\": { \"properties\": { \"age\": {\"type\": \"integer\"}, \"email\": {\"type\": \"keyword\"}, \"name\": {\"type\": \"text\", \"index\": true} } } } 结果 { \"acknowledged\" : true, \"shards_acknowledged\" : true, \"index\" : \"my_index\" } 2. 给已有映射增加字段https://www.elastic.co/guide/en/elasticsearch/reference/7.x/explicit-mapping.html#add-field-mapping PUT /my_index/_mapping { \"properties\": { \"employee-id\": { \"type\": \"keyword\", \"index\": false } } } # \"index\": false，表明新增的字段不被检索。默认是true # https://www.elastic.co/guide/en/elasticsearch/reference/7.x/mapping-index.html 结果 { \"acknowledged\" : true } 3. 查看映射https://www.elastic.co/guide/en/elasticsearch/reference/7.x/explicit-mapping.html#view-mapping GET /my_index/_mapping GET /my_index/_mapping/field/employee-id # 查看某一个字段的映射 结果 { \"my_index\" : { \"mappings\" : { \"properties\" : { \"age\" : { \"type\" : \"integer\" }, \"email\" : { \"type\" : \"keyword\" }, \"employee-id\" : { \"type\" : \"keyword\", \"index\" : false }, \"name\" : { \"type\" : \"text\" } } } } } # index false 表示不能被索引找到 4. 更新映射https://www.elastic.co/guide/en/elasticsearch/reference/7.x/explicit-mapping.html#update-mapping对于已经存在的字段映射，不能更新，更新必须创建新的索引，进行数据迁移5. 数据迁移迁移方式分为两种，一种是7和7之后去掉type的情况，一种是包含type迁移的情况。无type数据迁移 POST reindex [固定写法] { \"source\":{ \"index\":\"twitter\" }, \"dest\":{ \"index\":\"new_twitters\" } } 有type数据迁移 POST reindex [固定写法] { \"source\":{ \"index\":\"twitter\", \"twitter\":\"twitter\" }, \"dest\":{ \"index\":\"new_twitters\" } } 6. 数据迁移实例对于我们的测试数据,是包含type的索引 bank现在我们创建新的索引 **newbank **并修改一些字段的类型来演示当需要更新映射时的数据迁移操作 查看索引 bank 当前字段映射类型 GET /bank/_mapping # 结果 { \"bank\" : { \"mappings\" : { \"properties\" : { \"account_number\" : { \"type\" : \"long\" }, \"address\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"age\" : { \"type\" : \"long\" }, \"balance\" : { \"type\" : \"long\" }, \"city\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"email\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"employer\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"firstname\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"gender\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"lastname\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"state\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } } } } } } 创建新索引 newbank 并修改字段类型 PUT /newbank { \"mappings\": { \"properties\": { \"account_number\": { \"type\": \"long\" }, \"address\": { \"type\": \"text\" }, \"age\": { \"type\": \"integer\" }, \"balance\": { \"type\": \"long\" }, \"city\": { \"type\": \"keyword\" }, \"email\": { \"type\": \"keyword\" }, \"employer\": { \"type\": \"keyword\" }, \"firstname\": { \"type\": \"text\" }, \"gender\": { \"type\": \"keyword\" }, \"lastname\": { \"type\": \"text\", \"fields\": { \"keyword\": { \"type\": \"keyword\", \"ignore_above\": 256 } } }, \"state\": { \"type\": \"keyword\" } } } } 数据迁移 POST _reindex { \"source\": { \"index\": \"bank\", \"type\": \"account\" }, \"dest\": { \"index\": \"newbank\" } } 结果 #! Deprecation: [types removal] Specifying types in reindex requests is deprecated. { \"took\" : 768, \"timed_out\" : false, \"total\" : 1000, \"updated\" : 0, \"created\" : 1000, \"deleted\" : 0, \"batches\" : 1, \"version_conflicts\" : 0, \"noops\" : 0, \"retries\" : { \"bulk\" : 0, \"search\" : 0 }, \"throttled_millis\" : 0, \"requests_per_second\" : -1.0, \"throttled_until_millis\" : 0, \"failures\" : [ ] } 查看迁移后的数据迁移后 type 统一为 _doc 移除 type GET /newbank/_search { \"took\" : 367, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 1000, \"relation\" : \"eq\" }, \"max_score\" : 1.0, \"hits\" : [ { \"_index\" : \"newbank\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"_score\" : 1.0, \"_source\" : { \"account_number\" : 1, \"balance\" : 39225, \"firstname\" : \"Amber\", \"lastname\" : \"Duke\", \"age\" : 32, \"gender\" : \"M\", \"address\" : \"880 Holmes Lane\", \"employer\" : \"Pyrami\", \"email\" : \"amberduke@pyrami.com\", \"city\" : \"Brogan\", \"state\" : \"IL\" } }, ...","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/tags/elasticsearch/"}],"author":"wst"},{"title":"【Elasticsearch】5.分词","slug":"ElasticSearch/5.分词","date":"2022-04-15T05:35:32.000Z","updated":"2022-07-06T14:46:33.197Z","comments":true,"path":"2022/0415[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0415[object%20Object].html","excerpt":"","text":"简介 https://www.elastic.co/guide/en/elasticsearch/reference/7.x/analysis.html 一个**tokenizer**（分词器）接收一个字符流，将之分割为独立的tokens（词元，通常是独立的单词），然后输出tokens流 例如whitespace tokenizer遇到空白字符时分割文本。”Quick brown fox!”分割为**[Quick,brown,fox!]** 该tokenizer（分词器）还负责记录各个terms(词条)的顺序或position位置（用于phrase短语和word proximity词近邻查询），以及term（词条）所代表的原始word（单词）的start（起始）和end（结束）的character offsets（字符串偏移量）（用于高亮显示搜索的内容）。elasticsearch提供了很多内置的分词器，可以用来构建custom analyzers（自定义分词器）POST _analyze { \"analyzer\": \"standard\", \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\" } 默认的分词器一般都是针对于英文，对于中文我们需要安装额外的分词器来进行分词 安装IK分词器1. 下载 事前准备 IK分词器属于 Elasticsearch的插件，所以IK分词器的安装目录是 Elasticsearch的 plugins目录，在我们使用Docker启动Elasticsearch时，已经将该目录挂载到主机的 /mydata/elasticsearch/plugins 目录 IK分词器的版本需要跟Elasticsearch的版本对应，当前选择的版本为 7.4.2，下载地址为Github Release或访问：镜像地址 # 进入挂载的插件目录 /mydata/elasticsearch/plugins cd /mydata/elasticsearch/plugins #修改yum源 # 安装 wget 下载工具 yum install -y wget # 安装unzip yum install -y unzip # 下载对应版本的 IK 分词器（这里是7.4.2） wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.4.2/elasticsearch-analysis-ik-7.4.2.zip 这里已经在挂载的 plugins 目录安装好了 IK分词器。现在我们进入到 es 容器内部检查是否成功安装 # 进入容器内部 docker exec -it elasticsearch /bin/bash # 查看 es 插件目录 ls /usr/share/elasticsearch/plugins # 可以看到 elasticsearch-analysis-ik-7.4.2.zip 所以我们之后只需要在挂载的目录/mydata/elasticsearch/plugins下进行操作即可。2. 解压 # 进入到 es 的插件目录 cd /mydata/elasticsearch/plugins # 解压到 plugins 目录下的 ik 目录 unzip elasticsearch-analysis-ik-7.4.2.zip -d ik # 删除下载的压缩包 rm -f elasticsearch-analysis-ik-7.4.2.zip # 修改文件夹访问权限 chmod -R 777 ik/ 3. 查看安装的ik插件 # 进入 es 容器内部 docker exec -it elasticsearch /bin/bash # 进入 es bin 目录 cd /usr/share/elasticsearch/bin # 执行查看命令 显示 ik elasticsearch-plugin list # 退出容器 exit # 重启 Elasticsearch docker restart elasticsearch 重启遇到错误： Error response from daemon: driver failed programming external connectivity on endpoint elasticsearch (0cf6a38895d321cc793f1f26ebef2335b902328116db2cd01a50601090ff2d07): (iptables failed: iptables –wait -t nat -A DOCKER -p tcp -d 0/0 –dport 9300 -j DNAT –to-destination 172.17.0.6:9300 ! -i docker0: iptables: No chain/target/match by that name. 解决：重启docker systemctl restart docker4. 测试 ik 分词器**GET _analyze** POST _analyze { \"analyzer\": \"ik_max_word\", \"text\": \"尚硅谷电商项目\" } 这里对于默认词库中没有的词，不会有词语的组合，所以我们可以通过配置自定义词库或远程词库来实现对词库的扩展自定义扩展分词库 在nginx中自定义分词文件，通过配置 es 的 ik 配置文件，远程调用nginx中的分词文件，实现自定义扩展词库注：默认nginx请求的是 数据目录的 html 静态目录 1. nginx 中自定义分词文件 vi /mydata/nginx/html/fenci.txt # 输入词元 尚硅谷 乔碧萝 192.168.56.10/es/fenci.txt 2. 给 es 配置自定义词库 # 打开并编辑 ik 插件配置文件 vim /mydata/elasticsearch/plugins/ik/config/IKAnalyzer.cfg.xml 修改为以下内容 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"> &lt;properties> &lt;comment>IK Analyzer 扩展配置&lt;/comment> &lt;!--用户可以在这里配置自己的扩展字典 --> &lt;entry key=\"ext_dict\">&lt;/entry> &lt;!--用户可以在这里配置自己的扩展停止词字典--> &lt;entry key=\"ext_stopwords\">&lt;/entry> &lt;!--用户可以在这里配置远程扩展字典 --> &lt;!-- &lt;entry key=\"remote_ext_dict\">words_location&lt;/entry> --> &lt;entry key=\"remote_ext_dict\">http://192.168.56.10/es/fenci.txt&lt;/entry> &lt;!--用户可以在这里配置远程扩展停止词字典--> &lt;!-- &lt;entry key=\"remote_ext_stopwords\">words_location&lt;/entry> --> &lt;/properties> 3. 重启 elasticsearch 容器 docker restart elasticsearch 4. 测试自定义词库 GET my_index/_analyze { \"analyzer\": \"ik_max_word\", \"text\":\"乔碧萝殿下\" } Docker 安装 Nginx 这里介绍如何使用 docker 安装 nginx，首先我们先启动一个临时的 nginx，将它的配置拷贝到我们将要挂载的本机 nginx 配置目录中，之后再创建一个新的我们要用的 nginx 容器。 1. 创建要挂载的配置目录 mkdir -p /mydata/nginx/conf 2. 启动临时nginx容器 docker run -p 80:80 --name nginx -d nginx:1.10 3. 拷贝出 Nginx 容器的配置 # 将nginx容器中的nginx目录复制到本机的/mydata/nginx/conf目录 docker container cp nginx:/etc/nginx /mydata/nginx/conf # 复制的是nginx目录，将该目录的所有文件移动到 conf 目录 mv /mydata/nginx/conf/nginx/* /mydata/nginx/conf/ # 删除多余的 /mydata/nginx/conf/nginx目录 rm -rf /mydata/nginx/conf/nginx 4. 删除临时nginx容器 # 停止运行 nginx 容器 docker stop nginx # 删除 nginx 容器 docker rm nginx 5. 启动 nginx 容器 docker run -p 80:80 --name nginx \\ -v /mydata/nginx/html:/usr/share/nginx/html \\ -v /mydata/nginx/logs:/var/log/nginx \\ -v /mydata/nginx/conf/:/etc/nginx \\ -d nginx:1.10 6. 设置 nginx 随 Docker 启动 docker update nginx --restart=always 7. 测试 nginx echo 'Hello Nginx' > /mydata/nginx/html/index.html 打开：http://192.168.56.10/ 可以看到下面内容说明安装成功","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/tags/elasticsearch/"}],"author":"wst"},{"title":"【Elasticsearch】6.项目整合","slug":"ElasticSearch/6.项目整合","date":"2022-04-15T05:35:32.000Z","updated":"2022-07-06T14:46:33.238Z","comments":true,"path":"2022/0415[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0415[object%20Object].html","excerpt":"","text":"Elasticsearch-Rest-Client1. 通过 9300: TCP spring-data-elasticsearch:transport-api.jar springboot版本不同，transport-api.jar不同，不能适配ES版本 7.x已经不建议使用，8以后就要废弃 2. 通过 9200: HTTP jestClient 非官方，更新慢 RestTemplate 模拟HTTP请求，ES很多操作需要自己封装，麻烦 HttpClient 同上 **Elasticsearch-Rest-Client**官方RestClient，封装了ES操作，API层次分明，上手简单 最终选择Elasticsearch-Rest-Client``**elasticsearch-rest-high-level-client**https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high.html 创建 Elasticsearch 检索服务模块1. 新建模块2. 检索服务模块 pom.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;parent> &lt;groupId>com.aiguigu.gulimall&lt;/groupId> &lt;artifactId>gulimall-search&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;/parent> &lt;artifactId>mall-search&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;name>mall-search&lt;/name> &lt;description>Elasticsearch 检索服务&lt;/description> &lt;dependencies> &lt;dependency> &lt;groupId>com.atguigu.gulimall&lt;/groupId> &lt;artifactId>gulimall-common&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;exclusions> &lt;exclusion> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;dependency> &lt;groupId>org.elasticsearch.client&lt;/groupId> &lt;artifactId>elasticsearch-rest-high-level-client&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 3. 父 pom 更新依赖检索服务部分不完整 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.aiguigu&lt;/groupId> &lt;artifactId>gulimall&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;packaging>pom&lt;/packaging> &lt;modules> ... &lt;module>mall-search&lt;/module> &lt;/modules> &lt;name>guli-mall&lt;/name> &lt;description>parent&lt;/description> &lt;!-- 这里的属性会被子模块继承 --> &lt;properties> ... &lt;elasticsearch.version>7.4.2&lt;/elasticsearch.version> &lt;/properties> &lt;!-- 子模块继承父模块之后，提供作用：锁定版本 + 子模块不用再写 version --> &lt;dependencyManagement> &lt;dependencies> ... &lt;!-- 重写覆盖 spring-boot-dependencies 中的依赖版本 --> &lt;dependency> &lt;groupId>org.elasticsearch.client&lt;/groupId> &lt;artifactId>elasticsearch-rest-high-level-client&lt;/artifactId> &lt;version>${elasticsearch.version}&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.elasticsearch&lt;/groupId> &lt;artifactId>elasticsearch&lt;/artifactId> &lt;version>${elasticsearch.version}&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.elasticsearch.client&lt;/groupId> &lt;artifactId>elasticsearch-rest-client&lt;/artifactId> &lt;version>${elasticsearch.version}&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;/project> 4. 配置application.yaml spring: application: name: gulimall-search cloud: nacos: discovery: server-addr: 192.168.56.10:8848 5. 主启动类增加注册服务注解 @EnableDiscoveryClient @SpringBootApplication public class MallSearchApplication { public static void main(String[] args) { SpringApplication.run(MallSearchApplication.class, args); } } Elasticsearch 版本不一致问题参考：多模块开发SpringBoot项目自定义第三方依赖版本 问题说明MavenPom文件中没有将spring-boot-starter-parent作为父项目依赖。所以会出现下面的问题 如Springboot版本依赖管理为 2.2.5，对应 es版本为 6.8.6（需要7.4.2） 在父模块中定义7.4.2的版本号 引入 elasticsearch-rest-high-level-client 发现子依赖的elasticsearch版本仍然用 springboot-dependencies中的版本 问题解决如果使用Maven进行一个直接或间接继承spring-boot-dependencies（比如spring-boot-starter-parent）的构建，并想覆盖一个特定的第三方依赖，可以添加合适的元素。浏览spring-boot-dependencies POM可以获取一个全面的属性列表。例如，想要选择一个不同的elasticsearch版本 &lt;properties> &lt;elasticsearch.version>7.4.2&lt;/elasticsearch.version> &lt;/properties> 但是这只在你的Maven项目继承（直接或间接）自spring-boot-dependencies才有用如果使用&lt;scope&gt;import&lt;/scope&gt;，将spring-boot-dependencies添加到自己的dependencyManagement片段，那必须自己重新定义artifact而不是覆盖属性需要在 &lt;dependencyManagement&gt; 下重新定义artifact &lt;dependency> &lt;groupId>org.elasticsearch.client&lt;/groupId> &lt;artifactId>elasticsearch-rest-high-level-client&lt;/artifactId> &lt;version>${elasticsearch.version}&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.elasticsearch&lt;/groupId> &lt;artifactId>elasticsearch&lt;/artifactId> &lt;version>${elasticsearch.version}&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.elasticsearch.client&lt;/groupId> &lt;artifactId>elasticsearch-rest-client&lt;/artifactId> &lt;version>${elasticsearch.version}&lt;/version> &lt;/dependency> 编码测试**具体操作参考：es **操作API1. 编写配置类配置客户端Bean配置请求选项 // 配置请求选项参考： // https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-low-usage-requests.html#java-rest-low-usage-request-options @Configuration public class GulimallElasticSearchConfig { public static final RequestOptions COMMON_OPTIONS; static { RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder(); // builder.addHeader(\"Authorization\", \"Bearer \" + TOKEN); // builder.setHttpAsyncResponseConsumerFactory( // new HttpAsyncResponseConsumerFactory // .HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024)); COMMON_OPTIONS = builder.build(); } @Bean public RestHighLevelClient esRestClient() { return new RestHighLevelClient( RestClient.builder( new HttpHost(\"192.168.163.131\", 9200, \"http\"))); } } 2. 测试配置类依赖注入 // 下面的测试都在本测试类下完成，只标注方法 @SpringBootTest class MallSearchApplicationTests { @Autowired RestHighLevelClient client; @Test void contextLoads() { System.out.println(client); } } 3. 测试存储数据（更新）参考：Index API /** * 测试存储数据到 es * source 方法用于保存数据，数据的格式为键值对形式的类型 * - json 字符串 * - Map * - XContentBuilder * - KV 键值对 * - 实体类对象转json */ @Test void indexData() throws IOException { IndexRequest indexRequest = new IndexRequest(\"users\"); // 参数指定索引 indexRequest.id(\"1\"); // json 字符串，也可创建对象再转为JSON后放入source indexRequest.source(\"{\" + \"\\\"user\\\":\\\"kimchy\\\",\" + \"\\\"postDate\\\":\\\"2013-01-30\\\",\" + \"\\\"message\\\":\\\"trying out Elasticsearch\\\"\" + \"}\", XContentType.JSON); // 指明传入的类型 // KV 键值对 // indexRequest.source(\"username\", \"zhangsan\", \"age\", 12, \"address\", \"sz\"); // 同步执行 IndexResponse index = client.index(indexRequest, GulimallElasticSearchConfig.COMMON_OPTIONS); System.out.println(index) } Kibana检索查看 GET users/_search **4. 测试复杂检索 **参考：Search API检索地址中带有 mill 的人员年龄分布和平均薪资 /** * 检索地址中带有 mill 的人员年龄分布和平均薪资 */ @Test void searchData() throws IOException { // 1. 创建检索请求 SearchRequest searchRequest = new SearchRequest(); // 指定索引 searchRequest.indices(\"bank\"); // 指定 DSL 检索条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 1.1 构建检索条件 address 包含 mill searchSourceBuilder.query(QueryBuilders.matchQuery(\"address\", \"mill\")); // 1.2 按照年龄值分布进行聚合 TermsAggregationBuilder ageAgg = AggregationBuilders.terms(\"ageAgg\").field(\"age\").size(10); searchSourceBuilder.aggregation(ageAgg); // 1.3 计算平均薪资 AvgAggregationBuilder balanceAvg = AggregationBuilders.avg(\"balanceAvg\").field(\"balance\"); searchSourceBuilder.aggregation(balanceAvg); System.out.println(\"检索条件：\" + searchSourceBuilder.toString()); searchRequest.source(searchSourceBuilder); // 2. 执行检索, 获得响应 SearchResponse searchResponse = client.search(searchRequest, GulimallElasticSearchConfig.COMMON_OPTIONS); // 3. 分析结果 // 3.1 获取所有查到的记录 SearchHits hits = searchResponse.getHits(); SearchHit[] searchHits = hits.getHits(); for (SearchHit hit : searchHits) { // 数据字符串 String jsonString = hit.getSourceAsString(); System.out.println(jsonString); // 可以通过 json 转换成实体类对象 Account account = JSON.parseObject(jsonString, Account.class); } // 3.2 获取检索的分析信息(聚合数据等) Aggregations aggregations = searchResponse.getAggregations(); // for (Aggregation aggregation : aggregations.asList()) { // System.out.println(\"当前聚合名：\" + aggregation.getName()); // } Terms ageAgg1 = aggregations.get(\"ageAgg\"); for (Terms.Bucket bucket : ageAgg1.getBuckets()) { String keyAsString = bucket.getKeyAsString(); System.out.println(\"年龄：\" + keyAsString + \" 岁的有 \" + bucket.getDocCount() + \" 人\"); } Avg balanceAvg1 = aggregations.get(\"balanceAvg\"); System.out.println(\"平均薪资: \" + balanceAvg1.getValue()); }","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/tags/elasticsearch/"}],"author":"wst"},{"title":"【RabbitMQ】1.MQ的相关概念","slug":"RabbitMQ/1.MQ的相关概念","date":"2022-03-29T05:35:32.000Z","updated":"2022-07-06T14:46:33.260Z","comments":true,"path":"2022/0329[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0329[object%20Object].html","excerpt":"","text":"一 MQ 的相关概念1 什么是 MQMQ（message queue）本质是个队列，FIFO 先入先出，只不过队列中存放的内容是 message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常见的上下游 “逻辑解耦 + 物理解耦” 的消息通信服务。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不用依赖其他服务。2 为什么要用 MQ 流量消峰 举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。 应用解耦 以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。 异步处理 有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完。 以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅。 使用消息总线，可以很方便解决这个问题， A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样 B 服务也不用做这些操作，A 服务还能及时的得到异步处理成功的消息。 3 MQ 的分类ActiveMQ 优点：单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，较低的概率丢失数据。 缺点：官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。 Kafka 大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafka，这款为大数据而生的消息中间件，以其百万级 TPS 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。目前已经被 LinkedIn，Uber, Twitter, Netflix 等大公司所采纳。 优点：性能卓越，单机写入 TPS 约在百万条 / 秒，最大的优点，就是吞吐量高。时效性 ms 级，可用性非常高，kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用，消费者采用 Pull 方式获取消息，消息有序，通过控制能够保证所有消息被消费且仅被消费一次；有优秀的第三方 Kafka Web 管理界面 Kafka-Manager；在日志领域比较成熟，被多家公司和多个开源项目使用；功能支持：功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用。 缺点：Kafka 单机超过 64 个队列 / 分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；支持消息顺序，但是一台代理宕机后，就会产生消息乱序，社区更新较慢。 RocketMQ RocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一 些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发等场景。 优点：单机吞吐量十万级，可用性非常高，分布式架构，消息可以做到 0 丢失，MQ 功能较为完善，还是分布式的，扩展性好，支持 10 亿级别的消息堆积，不会因为堆积导致性能下降。 缺点：支持的客户端语言不多，目前是 java 及 c++，其中 c++ 不成熟；社区活跃度一般，没有在 MQ 核心中去实现 JMS 等接口，有些系统要迁移需要修改大量代码。 RabbitMQ 2007 年发布，是一个在 AMQP (高级消息队列协议) 基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。 优点：由于 erlang 语言的高并发特性，性能较好；吞吐量到万级，MQ 功能比较完备，健壮、稳定、易用、跨平台、支持多种语言。如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用，社区活跃度高；更新频率相当高。 缺点：商业版需要收费，学习成本较高。 4 MQ 的选择Kafka Kafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。 RocketMQ 天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。 RabbitMQ 结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。 5 RabbitMQ1 RabbitMQ 的概念RabbitMQ 是一个消息中间件，它接受并转发消息。你可以把它当做一个快递站点，当你要发送一个包裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是 一个快递站，一个快递员帮你传递快件。RabbitMQ 与快递站的主要区别在于，它不处理快件而是接收、存储、转发 消息数据2 四大核心概念生产者 产生数据发送消息的程序。交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定。队列队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。3 RabbitMQ 核心部分4 各个名词介绍**Broker**接收和分发消息的应用，RabbitMQ Server 就是 Message Broker**Virtual host** 出于多用户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等 **Connection**publisher／consumer 和 broker 之间的** TCP 连接****Channel** 如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销 **Exchange** message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有：**direct **(point-to-point), **topic **(publish-subscribe) and **fanout **(multicast) **Queue**消息最终被送到这里等待 consumer 取走**Binding** exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据 5 Linux 安装安装 RabbitMQ 本地安装 下载官网下载地址：https://www.rabbitmq.com/download.html这里选择的版本号（注意这两版本要求） - rabbitmq-server-3.8.8-1.el7.noarch.rpm GitHub：https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.8加载下载：https://packagecloud.io/rabbitmq/rabbitmq-server/packages/el/7/rabbitmq-server-3.8.8-1.el7.noarch.rpm - erlang-21.3.8.21-1.el7.x86_64.rpm 官网：https://www.erlang-solutions.com/downloads/加速：https://packagecloud.io/rabbitmq/erlang/packages/el/7/erlang-21.3.8.21-1.el7.x86_64.rpm安装 上传到 /usr/local/software 目录下 (如果没有 software 需要自己创建) rpm -ivh erlang-21.3.8.21-1.el7.x86_64.rpm yum install socat -y rpm -ivh rabbitmq-server-3.8.8-1.el7.noarch.rpm **联网安装 **https://www.rabbitmq.com/documentation.html 启动```shell添加开机启动chkconfig rabbitmq-server on或 sysv-rc-conf rabbitmq-server on 启动服务systemctl start rabbitmq-server 查看服务状态systemctl status rabbitmq-server 开机自启动systemctl enable rabbitmq-server 停止服务systemctl stop rabbitmq-server 重启服务systemctl restart rabbitmq-server 或者/sbin/service rabbitmq-server xxx **Web 管理界面及授权操作** 1. **安装** 默认情况下，是没有安装 web 端的客户端插件，需要安装才可以生效 ```shell /sbin/service rabbitmq-server stop rabbitmq-plugins enable rabbitmq_management 安装完毕以后，重启服务 systemctl restart rabbitmq-server 添加用户访问 http://192.168.199.158:15672/ ，用默认账号 密码 (guest) 登录，出现权限问题。默认情况只能在 localhost 本机下访问，所以需要添加一个远程登录的用户```shell创建账号和密码rabbitmqctl add_user cess 123123 设置用户角色rabbitmqctl set_user_tags cess administrator 为用户添加资源权限 添加配置、写、读权限set_permissions [-p ] rabbitmqctl set_permissions -p “/“ cess “.“ “.“ “.*” 用户级别： 1. **administrator**：可以登录控制台、查看所有信息、可以对 rabbitmq 进行管理。 1. **monitoring**：监控者 登录控制台，查看所有信息。 1. **policymaker**：策略制定者 登录控制台，指定策略。 1. **managment**：普通管理员 登录控制台。 再次登录，用 cess 用户 1. 关闭应用的命令为：rabbitmqctl stop_app 1. 清除的命令为：rabbitmqctl reset 1. 重新启动命令为：rabbitmqctl start_app **docker 安装** 进入docker hub镜像仓库地址[https://hub.docker.com/](https://hub.docker.com/) 下载镜像，带有management版本的（带有web管理后台） ```shell # 下载镜像 sudo docker pull rabbitmq:management RabbitMQ 需要映射的目录 配置文件目录 /etc/rabbitmq /mydata/rabbitmq/conf 数据存储目录 /var/lib/rabbitmq /mydata/rabbitmq/data 日志目录 /var/log/rabbitmq /mydata/rabbitmq/log 创建容器4369 25672 Erlang发现&amp;集群端口5671 5672 AMQP端口15671 web管理后台端口61613 61614 STMP协议端口1883 8883 MQTT协议端口 docker run -d --name rabbitmq -p 5671:5671 -p 5672:5672 -p 15671:15671 \\ -p 4369:4369 -p 25672:25672 --restart=always -v /mydata/rabbitmq/data:/var/lib/rabbitmq \\ -v /mydata/rabbitmq/log:/var/log/rabbitmq \\ -v /mydata/rabbitmq/conf:/etc/rabbitmq \\ -e RABBITMQ_DEFAULT_USER=guest \\ -e RABBITMQ_DEFAULT_PASS=guest rabbitmq:management","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/tags/RabbitMQ/"}],"author":"wst"},{"title":"【RabbitMQ】2.发布确认 持久化 不公平分发 消息应答","slug":"RabbitMQ/2.发布确认 持久化 不公平分发 消息应答","date":"2022-03-29T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0329[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0329[object%20Object].html","excerpt":"","text":"二 Hello world下图中，“P” 是生产者，“ C” 是消费者。中间的框是一个队列 RabbitMQ 代表使用者保留的消息缓冲区连接的时候，需要开启 15672 端口 **依赖 **pom.xml```xml org.apache.maven.plugins maven-compiler-plugin 8 8 &lt;!--rabbitmq 依赖客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--操作文件流的一个依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/dependency&gt; ``` 消息生产者：发送消息```javaimport com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** 生产者：发消息 /public class Producer { //队列名称 private final static String QUEUE_NAME = “hello”; public static void main(String[] args) throws Exception { //创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;192.168.199.158&quot;); factory.setUsername(&quot;cess&quot;); factory.setPassword(&quot;cess&quot;); //channel 实现了自动 close 接口 自动关闭 不需要显示关闭 //创建连接 Connection connection = factory.newConnection(); //获取信道 Channel channel = connection.createChannel(); /* * 生成一个队列 * 1.队列名称 * 2.队列里面的消息是否持久化，默认不持久化（存储在内存中） * 3.该队列是否只供一个消费者进行消费 是否进行共享 true 可以多个消费者消费 * 4.是否自动删除 最后一个消费者断开连接以后 该队列是否自动删除 true 自动删除 * 5.其他参数 */ channel.queueDeclare(QUEUE_NAME, false, false, false, null); /* * 发送一个消息 * 1.发送到那个交换机 * 2.路由的 key 是哪个 * 3.其他的参数信息 * 4.发送消息的消息体 */ String message = &quot;hello world&quot;; channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes()); System.out.println(&quot;消息发送完毕&quot;); }}``` 消息消费者：获取 “生产者” 发出的消息```javaimport com.rabbitmq.client.*; /** 消费者：接收消息 /public class Consumer { private final static String QUEUE_NAME = “hello”; public static void main(String[] args) throws Exception { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;42.192.149.71&quot;); factory.setUsername(&quot;admin&quot;); factory.setPassword(&quot;123456&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); System.out.println(&quot;等待接收消息.........&quot;); //推送的消息如何进行消费的接口回调 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String message = new String(delivery.getBody()); System.out.println(message); }; //取消消费的一个回调接口 如在消费的时候队列被删除掉了 CancelCallback cancelCallback = (consumerTag) -&gt; { System.out.println(&quot;消息消费被中断&quot;); }; /** * 消费者消费消息 - 接受消息 * 1.消费哪个队列 * 2.消费成功之后是否要自动应答 true 代表自动应答 false 手动应答 * 3.消费者成功消费的回调 * 4.消息被取消时的回调 */ channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback); } } **三 Work Queues** Work Queues— 工作队列 (又称任务队列) 的主要思想是避免立即执行资源密集型任务，而不得不等待它完成。我们把任务封装为消息并将其发送到队列，在后台运行的工作进程将弹出任务并最终执行作业。当有多个工作线程时，这些工作线程将一起处理这些任务。 ![](https://cdn.nlark.com/yuque/0/2021/png/1379492/1632811450264-3c426fae-a178-4e27-8585-1e1674c3c770.png#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=NRJxy&amp;margin=%5Bobject%20Object%5D&amp;originHeight=305&amp;originWidth=782&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) **1 轮训分发消息** 在这个案例中我们会启动两个工作线程，一个消息发送线程，我们来看看他们两个工作线程是如何工作的。 1. **抽取工具类** ```java /** * 为连接工厂创建信道的工具类 */ public class RabbitMqUtils { //得到一个连接的 channel public static Channel getChannel() throws Exception { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;192.168.199.158&quot;); factory.setUsername(&quot;cess&quot;); factory.setPassword(&quot;123123&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); return channel; } } 启动两个工作线程来接受消息```java/** 这是一个工作线程，相当于一个消费者 /public class Worker01 { private static final String QUEUE_NAME = “hello”; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); //消息接受 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String receivedMessage = new String(delivery.getBody()); System.out.println(&quot;接收到消息:&quot; + receivedMessage); }; //消息被取消 CancelCallback cancelCallback = (consumerTag) -&gt; { System.out.println(consumerTag + &quot;消费者取消消费接口回调逻辑&quot;); }; System.out.println(&quot;C1 消费者启动等待消费.................. &quot;); channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback); }}```选中 Allow multiple instances 启动后 启动一个发送消息线程 public class Task01 { public static final String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); /* * 生成一个队列 * 1.队列名称 * 2.队列里面的消息是否持久化，默认不持久化（存储在内存中） * 3.该队列是否只供一个消费者进行消费 是否进行共享 true 可以多个消费者消费 * 4.是否自动删除 最后一个消费者端开连接以后 该队列是否自动删除 true 自动删除 * 5.其他参数 */ channel.queueDeclare(QUEUE_NAME, false, false, false, null); Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) { String message = scanner.next(); /* * 发送一个消息 * 1.发送到那个交换机 * 2.路由的 key 是哪个 * 3.其他的参数信息 * 4.发送消息的消息体 */ channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes()); System.out.println(\"消息发送完成：\" + message); } } } 结果展示通过程序执行发现生产者总共发送 4 个消息，消费者 1 和消费者 2 分别分得两个消息，并且是按照有序的一个接收一次消息。 2 消息应答消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成了部分突然它挂掉了，会发生什么情况。RabbitMQ 一旦向消费者传递了一条消息，便立即将该消息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息，以及后续发送给该消费者的消息，因为它无法接收到。为了保证消息在发送过程中不丢失，引入消息应答机制，消息应答就是：消费者在接收到消息并且处理该消息之后，告诉 rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。1 自动应答 消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权衡，因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失了。当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制，有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，使得内存耗尽，最终这些消费者线程被操作系统杀死，所以这种模式仅适用在消费者可以高效并以某种速率能够处理这些消息的情况下使用。 总之，自动应答不靠谱，尽量少用，需要保证高吞吐量和数据传输安全性 2 手动消息应答的方法 **Channel.basicAck()**（用于肯定确认）RabbitMQ已知道该消息成功被处理，可以将其丢弃了。 **Channel.basicNack()**（用于否定确认） **Channel.basicReject()**（用于否定确认）与 **Channel.basicNack()**相比少一个批量处理参数，不处理该消息了直接拒绝，可以将其丢弃了。 3 Multiple 的解释 手动应答的好处是可以批量应答并且减少网络拥堵 。 true 代表批量应答 channel 上未应答的消息：比如说 channel 上有传送 tag 的消息 5、6、7、8， 当前 tag 是 8 那么此时 5-8 的这些还未应答的消息都会被确认收到消息应答。 false 同上面相比只会应答 tag=8 的消息， 5、6、7 这三个消息依然不会被确认收到消息应答（建议false） 如果是SpringBoot中需要配置 # 手动ack消息 spring.rabbitmq.listener.simple.acknowledge-mode=manual 4 消息自动重新入队如果消费者由于某些原因失去连接 (其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确保不会丢失任何消息。5 消息手动应答代码默认消息采用的是自动应答，所以我们要想实现消息消费过程中不丢失，需要把自动应答改为手动应答。消费者在上面代码的基础上增加了以下内容 channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); 消息生产者 /** * 消息生产者,消息在手动应答时是不丢失的，放回队列重新消费 */ public class Task02 { private static final String TASK_QUEUE_NAME = \"ack_queue\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); //声明队列 channel.queueDeclare(TASK_QUEUE_NAME, false, false, false, null); Scanner sc = new Scanner(System.in); System.out.println(\"请输入信息\"); while (sc.hasNext()) { String message = sc.nextLine(); //发布消息 channel.basicPublish(\"\", TASK_QUEUE_NAME, null, message.getBytes(StandardCharsets.UTF_8)); System.out.println(\"生产者发出消息\" + message); } } } **消费者 01 **处理较快，只用1秒 /** * 消费者01 * 手动应答时不丢失 */ public class Work03 { private static final String TASK_QUEUE_NAME = \"ack_queue\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); System.out.println(\"C1 等待接收消息处理时间较 短\"); DeliverCallback deliverCallback = (consumerTag, delivery) -> { String message = new String(delivery.getBody()); SleepUtils.sleep(1); System.out.println(\"接收到消息:\" + message); /** * 1.消息标记 tag * 2.是否批量应答未应答消息 */ channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); }; CancelCallback cancelCallback = (consumerTag) -> { System.out.println(consumerTag + \"消费者取消消费接口回调逻辑\"); }; //采用手动应答 boolean autoAck = false; channel.basicConsume(TASK_QUEUE_NAME, autoAck, deliverCallback, cancelCallback); } } 消费者 02： 把睡眠时间改成 30 秒。正常情况下消息发送方发送两个消息，C1 和 C2 分别接收到消息并进行处理 public class SleepUtils { public static void sleep(int second) { try { Thread.sleep(1000 * second); } catch (InterruptedException e) { Thread.currentThread().interrupt(); } } } 在发送者发送消息 dd，发出消息之后把 C2 消费者停掉，按理说该 C2 来处理该消息，但是由于它处理时间较长，在还未处理完，也就是说 C2 还没有执行 ack 代码的时候，C2 被停掉了，此时会看到消息被 C1 接收到了，说明消息 dd 被重新入队，然后分配给能处理消息的 C1 处理了。*3 RabbitMQ 持久化如果希望即使在RabbitMQ服务重启的情况下，也不会丢失消息，可以*将Queue与Message都设置为可持久化的（durable）**，这样可以保证绝大部分情况下RabbitMQ消息不会丢失。当然还是会有一些小概率事件会导致消息丢失队列持久化之前创建的队列都是非持久化的，rabbitmq 如果重启的话，该队列就会被删除掉，如果要队列实现持久化需要在声明队列的时候把 durable 参数设置为持久化。 /* * 参数 * 1.队列名称 * 2.队列里面的消息是否持久化，默认不持久化（存储在内存中） * 3.该队列是否只供一个消费者进行消费 是否进行共享 true 可以多个消费者消费 * 4.最后一个消费者断开连接以后 该队列是否自动删除 true 自动删除 * 5.其他参数 */ boolean durable = true; // 让队列持久化 channel.queueDeclare(TASK_QUEUE_NAME, durable, false, false, null); //声明队列 注意：如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新创建一个持久化的队列，不然就会出现错误。 以下为控制台中持久化与非持久化队列的 UI 显示区别消息持久化消息实现持久化需要修改消息生产者代码，添加属性MessageProperties.PERSISTENT_TEXT_PLAIN 将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是这里依然存在当消息刚准备存储在磁盘的时候但是还没有存储完，消息还在缓存的一个间隔点。此时并没有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。 public class Task02 { private static final String TASK_QUEUE_NAME = \"ack_queue\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); //声明队列 boolean durable = true; //需要持久化 channel.queueDeclare(TASK_QUEUE_NAME, durable, false, false, null); Scanner sc = new Scanner(System.in); System.out.println(\"请输入信息\"); while (sc.hasNext()) { String message = sc.nextLine(); //发布消息 //设置生产者发送消息为持久化消息（要求保存到磁盘上） channel.basicPublish(\"\", TASK_QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes(StandardCharsets.UTF_8)); System.out.println(\"生产者发出消息\" + message); } } } 4 不公平分发问题在最开始的时候我们学习到RabbitMQ分发消息采用的轮训分发，但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中消费者 1 处理任务的速度非常快，消费者 2 处理速度却很慢，这时还是采用轮训分发的话，就会使得消费者 1很大一部分时间处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下不太好，但是RabbitMQ并不知道这种情况，它依然很公平的进行分发 为了避免这种情况，在消费者中消费之前，可以设置参数 **channel.basicQos(1);** // 设置不公平分发 int prefetchCount = 1; channel.basicQos(prefetchCount); // 通道上允许的未确认消息的最大数量为1 // 采用手动应答 boolean autoAck = false; channel.basicConsume(TASK_QUEUE_NAME, autoAck, deliverCallback, cancelCallback); 意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个任务，然后RabbitMQ就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完 成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加新的worker 或者改变其他存储任务的策略。预取值分发带权的消息分发本身消息就是异步发送的，所以在任何时候，channel上肯定不止一个消息，另外来自消费者的手动确认本质上也是异步的。因此这里就存在一个未确认的消息缓冲区，因此希望开发人员能限制此缓冲区的大小，以避免缓冲区里面无限制的未确认消息问题。这个时候就可以使用**channel.basicQos()**方法设置 “预取计数”值来完成 该值定义通道上允许的未确认消息的最大数量。一旦数量达到配置的数量， RabbitMQ将停止在通道上传递更多消息，除非至少有一个未处理的消息被确认，例如，假设在通道上有未确认的消息 5、6、7，8，并且通道的预取计数设置为 4，此时RabbitMQ将不再该通道传递任何消息，除非至少有一个未应答的消息被 ack。比方说 tag=6 这个消息刚刚被确认 ACK，RabbitMQ将会感知这个情况到并再发送一条消息。消息应答和QoS预取值对用户吞吐量有重大影响通常，增加预取值将提高向消费者传递消息的速度。虽然自动应答传输消息速率是最佳的，但是，在这种情况下已传递但尚未处理的消息的数量也会增加，从而增加了消费者的 RAM 消耗。应该小心使用具有无限预处理的自动确认模式或手动确认模式，消费者消费了大量的消息如果没有确认的话，会导致消费者连接节点的内存消耗变大，所以找到合适的预取值是一个反复试验的过程，不同的负载该值取值也不同，100 到 300 范围内的值通常可提供最佳的吞吐量，并且不会给消费者带来太大的风险。 预取值为 1 是最保守的。当然这将使吞吐量变得很低，特别是消费者连接延迟很严重的情况下，特别是在消费者连接等待时间较长的环境 中。对于大多数应用来说，稍微高一点的值将是最佳的四 发布确认1 发布确认逻辑生产者将信道设置成 **confirm**模式，一旦信道进入 confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的 ID (从 1 开始)，一旦消息被投递到所有匹配的队列之后，**broker**就会发送一个确认给生产者 (包含消息的唯一 ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker回传给生产者的确认消息中delivery-tag域包含了确认消息的序列号，此外broker也可以设置**basic.ack()**的multiple域，表示到这个序列号之前的所有消息都已经得到了处理 confirm模式最大的好处在于它是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ因为自身内部错误导致消息丢失，就会发送一条**nack**消息， 生产者应用程序同样可以在回调方法中处理该 nack消息2 发布确认的策略开启发布确认的方法：发布确认默认是没有开启的，如果要开启，需要调用方法 **confirmSelect()**，每当你要想使用发布确认，都需要在channel上调用该方法。 channel.confirmSelect(); // 开启发布确认 单个确认发布这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它被确认发布，后续的消息才能继续发布，**waitForConfirmsOrDie(long)**这个方法只有在消息被确认的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。 这种确认方式有一个最大的缺点就是：发布速度特别的慢，因为如果没有确认发布的消息就会阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某些应用程序来说这可能已经足够了 // 单个发送 public static void publishMessageIndividually() throws Exception { Channel channel = RabbitMqUtils.getChannel(); // 队列声明 String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, true, false, false, null); // 开启发布确认 channel.confirmSelect(); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) { String message = i + \"\"; channel.basicPublish(\"\", queueName, null, message.getBytes()); // 单个消息马上确认 boolean flag = channel.waitForConfirms(); if (flag) { System.out.println(\"消息发送成功\"); } } long end = System.currentTimeMillis(); System.out.println(\"发布\"+ MESSAGE_COUNT +\"个单独确认消息,耗时\"+ (end-begin) +\"ms\"); } 批量确认发布上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地提高吞吐量，当然这种方式的缺点就是：当发生故障导致发布出现问题时，不知道是哪个消息出问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种方案仍然是同步的，也一样阻塞消息的发布 /** * 批量 */ public static void publishMessageBatch() throws Exception { Channel channel = RabbitMqUtils.getChannel(); //队列声明 String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, true, false, false, null); //开启发布确认 channel.confirmSelect(); //批量确认消息大小 int batchSize = 100; //未确认消息个数 int outstandingMessageCount = 0; long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) { String message = i + \"\"; channel.basicPublish(\"\", queueName, null, message.getBytes()); outstandingMessageCount++; if (outstandingMessageCount == batchSize) { channel.waitForConfirms(); outstandingMessageCount = 0; } } // 为了确保还有剩余没有确认消息 再次确认 if (outstandingMessageCount > 0) { channel.waitForConfirms(); } long end = System.currentTimeMillis(); System.out.println(\"发布\"+ MESSAGE_COUNT +\"个批量确认消息,耗时\"+ (end - begin) +\"ms\"); } 异步确认发布异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说， 它是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功， 下面就让我们来详细讲解异步确认是怎么实现的。如何处理异步未确认消息？最好的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列， 比如说用 ConcurrentLinkedQueue``ConcurrentSkipListMap这个队列在 confirm callbacks 与发布线程之间进行消息的传递 准备消息的监听器，异步监听哪些消息成功了，哪些消息失败了**channel.addConfirmListener(ackCallback, nackCallback)** // 3. 异步批量确认 public static void publishMessageAsync() throws Exception { Channel channel = RabbitMqUtils.getChannel(); String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName, true, false, false, null); // 队列声明 channel.confirmSelect(); // 开启发布确认 /** * 线程安全又去的哈希表，适用于高并发的情况 * 1. 能轻松的将序号与消息关联 * 2. 轻松批量删除条目，只要有序号 * 3. 支持高并发 */ ConcurrentSkipListMap&lt;Long, String> outstandingConfirms = new ConcurrentSkipListMap&lt;>(); // 消息确认成功 回调方法 /** * 1.消息的标识 * 2.是否批量确认s */ ConfirmCallback ackCallback = (deliveryTag, multiple) -> { if (multiple) { // 2. 删除掉已经确认的消息 剩下的就是未确认的消息 ConcurrentNavigableMap&lt;Long, String> confirmed = outstandingConfirms.headMap(deliveryTag); } else { outstandingConfirms.remove(deliveryTag); } System.out.println(\"确认的消息：\" + deliveryTag); }; //消息确认失败 回调方法 ConfirmCallback nackCallback = (deliveryTag, multiple) -> { // 3. 打印一下未确认的消息都有哪些 String message = outstandingConfirms.get(deliveryTag); System.out.println(\"未确认的消息：\" + message + \"，标记tag：\" + deliveryTag); }; // 准备消息的监听器，监听那些消息成功了，那些消息失败了 异步 channel.addConfirmListener(ackCallback, nackCallback); //开始时间 long begin = System.currentTimeMillis(); for (int i = 0; i &lt; MESSAGE_COUNT; i++) { String message = i + \"\"; channel.basicPublish(\"\", queueName, null, message.getBytes()); // 1. 此处记录下所有发送的消息 消息的总和 outstandingConfirms.put(channel.getNextPublishSeqNo(), message); } //结束时间 long end = System.currentTimeMillis(); System.out.println(\"发布\"+ MESSAGE_COUNT +\"个异步确认消息，耗时\"+ (end - begin) +\"ms\"); } 以上 3 种发布确认速度对比 单独发布消息：同步等待确认，简单，但吞吐量非常有限 批量发布消息：批量同步等待确认，简单，合理的吞吐量，一旦出现问题很难推断出是哪条消息出现了问题 异步处理：最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些 public static void main(String[] args) throws Exception { // 1. 单个确认 ConfirmMessage.publishMessageIndividually(); // 发布1000个单独确认消息，耗时765ms // 2. 批量确认 ConfirmMessage.publishMessageBatch(); // 发布1000个批量确认消息，耗时94ms // 3. 异步批量确认 ConfirmMessage.publishMessageAsync(); // 发布1000个异步确认消息，耗时71ms }","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/tags/RabbitMQ/"}],"author":"wst"},{"title":"【RabbitMQ】3.Exchanges","slug":"RabbitMQ/3.Exchanges","date":"2022-03-29T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0329[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0329[object%20Object].html","excerpt":"","text":"五 Exchanges1 Exchanges **1 Exchanges 概念RabbitMQ消息传递模型的核心思想是生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中相反，生产者只能将消息发送到交换机（exchange），交换机工作的内容非常简单，一方面它接收来自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息**，是应该把这些消息放到特定队列，还是说把他们放到许多队列，还是说应该丢弃它们。这就的由交换机的类型来决定2 Exchanges 的类型 直接 (direct) 路由模式 主题 (topic) 主题模式 标题 (headers) 扇出 (fanout) 发布订阅模式 2 临时队列之前的章节使用的是具有特定名称的队列（还记得 hello 和 ack_queue 吗？）。队列的名称至关重要，需要指定消费者去消费哪个队列的消息。每当连接到RabbitMQ时，我们都需要一个全新的空队列，为此可以创建一个具有随机名称的队列，或者能让服务器为我们选择一个随机队列名称那就更好了。其次一旦断开了消费者的连接，队列将被自动删除创建临时队列**String queueName = channel.queueDeclare().getQueue()**创建出来之后长成这样3 绑定 bindings**binding**是exchange和queue之间的桥梁，它告诉我们exchange和哪个队列进行了绑定关系。比如下面这张图就是 X 与 Q1 和 Q2 进行了绑定4 Fanout 发布订阅模式Fanout 介绍**Fanout**这种类型非常简单，将接收到的所有消息广播到它知道的所有队列中**channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT)****channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;)**Fanout 实战Logs 和临时队列的绑定关系如下图为了说明这种模式，构建一个简单的日志系统。它由两个程序组成：第一个程序将发出日志消息，第二个程序是消费者，会启动两个消费者，其中一个消费者接收到消息后把日志存储在磁盘。 **ReceiveLogs01 **将接收到的消息打印在控制台 public class ReceiveLogs01 { private static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); //声明一个交换机 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); //生成一个临时的队列 //队列的名称是随机的 //当消费者断开与队列的连接时 队列自动删除 String queueName = channel.queueDeclare().getQueue(); //把该临时队列绑定我们的 exchange，其中 routingkey(也称之为 binding key)为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, \"\"); System.out.println(\"等待接收消息,把接收到的消息打印在屏幕........... \"); //接收消息 DeliverCallback deliverCallback = (consumerTag, delivery) -> { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\"控制台打印接收到的消息：\" + message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -> {}); } } **ReceiveLogs02 **把消息写出到文件 public class ReceiveLogs02 { private static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); //生成一个临时的队列 //队列的名称是随机的 //当消费者断开与队列的连接时 队列自动删除 String queueName = channel.queueDeclare().getQueue(); //把该临时队列绑定我们的 exchange 其中 routingkey(也称之为 binding key)为空字符串 channel.queueBind(queueName, EXCHANGE_NAME, \"\"); System.out.println(\"等待接收消息,把接收到的消息写到文件........... \"); //接收消息 //接收消息 DeliverCallback deliverCallback = (consumerTag, delivery) -> { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\"02控制台打印接收到的消息：\" + message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -> {}); } } **EmitLog **发送消息给两个消费者接收 public class EmitLog { private static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); /* * 声明一个 exchange * 1.exchange 的名称 * 2.exchange 的类型 */ channel.exchangeDeclare(EXCHANGE_NAME, \"fanout\"); Scanner sc = new Scanner(System.in); System.out.println(\"请输入信息\"); while (sc.hasNext()) { String message = sc.nextLine(); channel.basicPublish(EXCHANGE_NAME, \"\", null, message.getBytes(StandardCharsets.UTF_8)); System.out.println(\"生产者发出消息\" + message); } } } 5 Direct 路由模式在本节将向其中添加一些特别的功能 — 让某个消费者订阅发布的部分消息。例如只把严重错误消息定向存储到日志文件 (以节省磁盘空间)，同时仍然能够在控制台上打印所有日志消息Direct 介绍Fanout这种交换类型缺乏灵活性，它只能进行无意识的广播，在这里将使用**direct**这种类型来进行替换，这种类型的工作方式是，消息只去到它绑定的**routingKey**队列中去上面这张图中，可以看到 X 绑定了两个队列，绑定类型是direct。队列 Q1 绑定键为 orange， 队列 Q2 绑定键有两个：一个绑定键为 black，另一个绑定键为 green。在这种绑定情况下，生产者发布消息到 exchange上，绑定键为orange的消息会被发布到队列 Q1。绑定键为black``green和的消息会被发布到队列 Q2，其他消息类型的消息将被丢弃**channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT)****channel.queueBind(queueName, EXCHANGE_NAME, routingKey)**可绑定多个多重绑定当然如果exchange的绑定类型是direct，**但是它绑定的多个队列的 ****key**如果都相同，这种情况下虽然绑定类型是direct，但是它表现的就和**fanout**类似，就跟广播差不多Direct 实战关系交换机 c1：绑定 console，routingKey为 info、warning c2：绑定 disk，routingKey为 error```javapublic class ReceiveLogsDirect01 {private static final String EXCHANGE_NAME = “direct_logs”; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); //队列声明 String queueName = &quot;console&quot;; channel.queueDeclare(queueName, false, false, false, null); //队列绑定 channel.queueBind(queueName, EXCHANGE_NAME, &quot;info&quot;); channel.queueBind(queueName, EXCHANGE_NAME, &quot;warning&quot;); System.out.println(&quot;等待接收消息...&quot;); //接收消息 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(&quot;01控制台打印接收到的消息：&quot; + message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; {}); } } ```java public class ReceiveLogsDirect02 { private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = &quot;disk&quot;; //队列声明 channel.queueDeclare(queueName, false, false, false, null); //队列绑定 channel.queueBind(queueName, EXCHANGE_NAME, &quot;error&quot;); System.out.println(&quot;等待接收消息...&quot;); //接收消息 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(&quot;02控制台打印接收到的消息：&quot; + message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; {}); } } public class EmitLogDirect { private static final String EXCHANGE_NAME = \"direct_logs\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); // channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); // 创建多个 bindingKey Map&lt;String, String> bindingKeyMap = new HashMap&lt;>(); bindingKeyMap.put(\"info\", \"普通 info 信息\"); bindingKeyMap.put(\"warning\", \"警告 warning 信息\"); bindingKeyMap.put(\"error\", \"错误 error 信息\"); bindingKeyMap.put(\"debug\", \"调试 debug 信息\"); // debug 没有消费者接收此消息 丢失 for (Map.Entry&lt;String, String> bindingKeyEntry : bindingKeyMap.entrySet()) { String bindingKey = bindingKeyEntry.getKey(); String message = bindingKeyEntry.getValue(); channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes(StandardCharsets.UTF_8)); System.out.println(\"生产者发出消息:\" + message); } } } 6 Topics 主题模式Topic 的介绍上一个小节改进了日志记录系统。没有使用只能进行广播的fanout交换机，而是使用了direct交换机，从而实现选择性地接收日志尽管使用direct交换机改进了我们的系统，但是它仍然存在局限性 — 比方说日志类型有 info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候 direct 就办不到了。这时只能使用**topic**类型**channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType**.**TOPIC)****channel.queueBind(queueName, EXCHANGE_NAME, routingKey)**可绑定多个Topic 的要求发送到类型是topic交换机的消息的**routing_key**不能随意写，必须是一个单词列表，以点号分隔开。这些单词可以是任意单词。比如说：”stock.usd.nyse”, “nyse.vmw”, “quick.orange.rabbit”. 这种类型的。当然这个单词列表最多不能超过 255 个字节在这个规则列表中，其中有两个替换符是大家需要注意的 *****可以代替一个单词 **#**可以替代零个或多个单词 Topic 匹配案例 下图绑定关系如下 Q1 –&gt; 绑定的是 中间带 orange 带 3 个单词的字符串 (*.orange.*) Q2 –&gt; 绑定的是 最后一个单词是 rabbit 的 3 个单词 (*.*.rabbit) 第一个单词是 lazy 的多个单词 (lazy.#) 上图是一个队列绑定关系图，我们来看看他们之间数据接收情况是怎么样的 例子 说明 quick.orange.rabbit 被队列 Q1Q2 接收到 lazy.orange.elephant 被队列 Q1Q2 接收到 quick.orange.fox 被队列 Q1 接收到 lazy.brown.fox 被队列 Q2 接收到 lazy.pink.rabbit 虽然满足两个绑定但只被队列 Q2 接收一次 quick.brown.fox 不匹配任何绑定，会被丢弃 quick.orange.male.rabbit 是四个单词不匹配任何绑定会被丢弃 lazy.orange.male.rabbit 是四个单词但匹配 Q2 注意： 当一个队列绑定键是 #，那么这个队列将接收所有数据，就像 fanout 了 如果队列绑定键当中没有 #和 * 出现，那么该队列绑定类型就是 direct 了 Topic 实战 public class ReceiveLogsTopic01 { private static final String EXCHANGE_NAME = \"topic_logs\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); // 声明 Q1 队列与绑定关系 String queueName = \"Q1\"; channel.queueDeclare(queueName, false, false, false, null); // 绑定 channel.queueBind(queueName, EXCHANGE_NAME, \"*.orange.*\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -> { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\"接收队列:\" + queueName + \" 绑定键:\" + delivery.getEnvelope().getRoutingKey() + \",消息:\" + message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -> {}); } } public class ReceiveLogsTopic02 { private static final String EXCHANGE_NAME = \"topic_logs\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); // 声明 Q2 队列与绑定关系 String queueName = \"Q2\"; channel.queueDeclare(queueName, false, false, false, null); // 绑定 channel.queueBind(queueName, EXCHANGE_NAME, \"*.*.rabbit\"); channel.queueBind(queueName, EXCHANGE_NAME, \"lazy.#\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -> { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\"接收队列:\" + queueName + \" 绑定键:\" + delivery.getEnvelope().getRoutingKey() + \",消息:\" + message); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -> {}); } } public class EmitLogTopic { private static final String EXCHANGE_NAME = \"topic_logs\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); // channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); /* * Q1-->绑定的是 * 中间带 orange 带 3 个单词的字符串(*.orange.*) * Q2-->绑定的是 * 最后一个单词是 rabbit 的 3 个单词(*.*.rabbit) * 第一个单词是 lazy 的多个单词(lazy.#) */ Map&lt;String, String> bindingKeyMap = new HashMap&lt;>(); bindingKeyMap.put(\"quick.orange.rabbit\", \"被队列 Q1Q2 接收到\"); bindingKeyMap.put(\"lazy.orange.elephant\", \"被队列 Q1Q2 接收到\"); bindingKeyMap.put(\"quick.orange.fox\", \"被队列 Q1 接收到\"); bindingKeyMap.put(\"lazy.brown.fox\", \"被队列 Q2 接收到\"); bindingKeyMap.put(\"lazy.pink.rabbit\", \"虽然满足两个绑定但只被队列 Q2 接收一次\"); bindingKeyMap.put(\"quick.brown.fox\", \"不匹配任何绑定不会被任何队列接收到会被丢弃\"); bindingKeyMap.put(\"quick.orange.male.rabbit\", \"是四个单词不匹配任何绑定会被丢弃\"); bindingKeyMap.put(\"lazy.orange.male.rabbit\", \"是四个单词但匹配 Q2\"); for (Map.Entry&lt;String, String> bindingKeyEntry : bindingKeyMap.entrySet()) { String bindingKey = bindingKeyEntry.getKey(); String message = bindingKeyEntry.getValue(); channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes(StandardCharsets.UTF_8)); System.out.println(\"生产者发出消息：\" + message); } } } headersheaders匹配AMPQ消息的header而不是路由键，headers交换机与direct交完及完全一致，但性能差很多，几乎用不到","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/tags/RabbitMQ/"}],"author":"wst"},{"title":"【RabbitMQ】4.死信队列 延迟队列","slug":"RabbitMQ/4.死信队列 延迟队列","date":"2022-03-29T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0329[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0329[object%20Object].html","excerpt":"","text":"六 死信队列1 死信的概念死信就是无法被消费的消息，一般来说，producer 将消息投递到broker或者直接到queue里了，consumer 从queue取出消息进行消费，但某些时候由于特定的原因导致**queue**中的某些消息无法被消费，这样的消息如果没有后续的处理，就变成了死信，有死信自然就有死信队列 应用场景：为了保证订单业务的消息数据不丢失，需要使用到RabbitMQ的死信队列机制，当消息消费发生异常时，将消息投入死信队列中。还有比如说：用户在商城下单成功并点击去支付后在指定时间未支付时自动失效2 死信的来源 消息 TTL 过期：TTL 是 Time To Live 的缩写，也就是生存时间 队列达到最大长度：队列满了，无法再添加数据到 mq 中 消息被拒绝：(basic.reject 或 basic.nack) 并且 requeue=false 3 死信实战 Map&lt;String, Object> argument = new HashMap&lt;>(); // 正常队列绑定死信队列信息 argument.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE);// 设置死信交换机 key是固定值 argument.put(\"x-dead-letter-routing-key\", \"lisi\"); // 设置死信routing-key key是固定值 argument.put(\"x-max-length\",6); //设置正常队列的长度限制 argument.put(\"x-dead-message-ttl\", 10000); // 过期时间，也可以在生产者发送消息时指定 // AMQP.BasicProperties properties = // new AMQP.BasicProperties().builder().expiration(\"10000\").build(); channel.queueDeclare(normalQueue, false, false, false, argument); 死信之 TTL 消费者 C1 代码 public class Consumer01 { private static final String NORMAL_EXCHANGE = \"normal_exchange\";// 普通交换机名称 private static final String DEAD_EXCHANGE = \"dead_exchange\"; // 死信交换机名称 public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); // 声明死信和普通交换机 类型为 direct channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); // 正常队列绑定死信队列信息 Map&lt;String, Object> argument = new HashMap&lt;>(); // 正常队列设置死信交换机 参数 key 是固定值 argument.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE); // 正常队列设置死信 routing-key 参数 key 是固定值 argument.put(\"x-dead-letter-routing-key\", \"lisi\"); // 过期时间 ms，也可以在生产者发送消息时指定 // argument.put(\"x-dead-message-ttl\", 10000); // 正常队列 String normalQueue = \"normal-queue\"; channel.queueDeclare(normalQueue, false, false, false, argument); channel.queueBind(normalQueue, NORMAL_EXCHANGE, \"zhangsan\"); // 声明死信队列 String deadQueue = \"dead-queue\"; channel.queueDeclare(deadQueue, false, false, false, null); // 死信队列绑定：队列、交换机、路由键（routingKey） channel.queueBind(deadQueue, DEAD_EXCHANGE, \"lisi\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -> { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\"Consumer01 接收到消息\" + message); }; channel.basicConsume(normalQueue, true, deliverCallback, consumerTag -> {}); } } 生产者代码 public class Producer { private static final String NORMAL_EXCHANGE = \"normal_exchange\"; public static void main(String[] argv) throws Exception { Channel channel = RabbitMqUtils.getChannel(); // channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); // 设置消息的 TTL 时间 10s AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(\"10000\").build(); // 该信息是用作演示队列个数限制 for (int i = 1; i &lt; 11; i++) { String message = \"info\" + i; channel.basicPublish(NORMAL_EXCHANGE, \"zhangsan\", properties, message.getBytes()); System.out.println(\"生产者发送消息:\" + message); } } } 启动 C1 ，之后关闭消费者，模拟其接收不到消息。再启动 Producer 消费者 C2 代码：以上步骤完成后，启动 C2 消费者，它消费死信队列里面的消息 public class Consumer02 { // 死信交换机名称 private static final String DEAD_EXCHANGE = \"dead_exchange\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); String deadQueue = \"dead-queue\"; System.out.println(\"等待接收死信消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -> { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\"Consumer02 接收到消息\" + message); }; channel.basicConsume(deadQueue, true, deliverCallback, consumerTag -> {}); } } 死信之最大长度 消息生产者代码去掉 TTL 属性 C1 消费者修改代码（启动之后关闭该消费者 模拟接收不到消息）注意此时把原先队列删除，因为参数改变了 argument.put(\"x-max-length\",6); //设置正常队列的长度限制，例如发10个，4个则为死信 3C2 消费者代码不变 (启动 C2 消费者) 死信之消息被拒 消息生产者代码同上生产者一致 C1 消费者代码 (启动之后关闭该消费者 模拟其接收不到消息)拒收消息 “info5” ： public class Consumer01 { private static final String NORMAL_EXCHANGE = \"normal_exchange\"; // 普通交换机名称 private static final String DEAD_EXCHANGE = \"dead_exchange\"; // 死信交换机名称 public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); //正常队列绑定死信队列信息 Map&lt;String, Object> argument = new HashMap&lt;>(); argument.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE); // 设置死信交换机 argument.put(\"x-dead-letter-routing-key\", \"lisi\"); // 设置死信 routing-key // argument.put(\"x-dead-message-ttl\", 10000); // 过期时间 // argument.put(\"x-max-length\",6); // 设置正常队列的长度限制 // 正常队列 String normalQueue = \"normal-queue\"; channel.queueDeclare(normalQueue, false, false, false, argument); channel.queueBind(normalQueue, NORMAL_EXCHANGE, \"zhangsan\"); // 声明死信队列 String deadQueue = \"dead-queue\"; channel.queueDeclare(deadQueue, false, false, false, null); //死信队列绑定：队列、交换机、路由键（routingKey） channel.queueBind(deadQueue, DEAD_EXCHANGE, \"lisi\"); System.out.println(\"等待接收消息........... \"); DeliverCallback deliverCallback = (consumerTag, delivery) -> { String message = new String(delivery.getBody(), StandardCharsets.UTF_8); if (\"info5\".equals(message)) { System.out.println(\"Consumer01 拒接消息\" + message); channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false); } else { System.out.println(\"Consumer01 接收到消息\" + message); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); } }; channel.basicConsume(normalQueue, false, deliverCallback, consumerTag -> {}); } } C2 消费者代码不变：启动消费者 1 然后再启动消费者 2 七 延迟队列延迟队列概念延时队列内部是有序的，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列延迟队列使用场景 订单在十分钟之内未支付则自动取消 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒 用户注册成功后，如果三天内没有登陆则进行短信提醒 用户发起退款，如果三天内没有得到处理则通知相关运营人员 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议 这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭。那我们一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？ 如果数据量比较少，确实可以这样做，比如：对于 “如果账单一周内未支付则进行自动结算” 这样的需求， 如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。 但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭 “，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下 RabbitMQ 中的 TTLTTL是RabbitMQ中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒 即一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为“死信”。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用，有两种方式设置 TTL 队列设置**TTL**在创建队列的时候设置队列的**&quot;x-message-ttl&quot;**属性 消息设置**TTL**是针对每条消息设置 TTL 两者的区别 如果设置了队列的TTL属性，一旦消息过期，会被队列马上丢弃（如果配置了死信队列被丢到死信队列） 而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间 另外，还需要注意的一点是，如果不设置TTL，表示消息永远不会过期，如果将TTL设置为 0，表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。 整合 springboot 创建一个空SpringBoot项目 添加依赖```xml org.springframework.boot spring-boot-starter-amqp org.springframework.amqp spring-rabbit-test test io.springfox springfox-swagger2 3.0.0 io.springfox springfox-swagger-ui 3.0.0 ``` 引入amqp场景，RabbitAutoConfiguration就会自动生效，给容器中自动配置了 `**CachingConnectFactory**` `**AmqpAdmin**`进行创建交换机等 `**RabbitTemplate**` `**RabbitMessageTemplate**` `**@EnableRabbit**`开启功能 `**@RabbitListener**`监听消息，必须先开启功能，可以标注在类+方法上 `**@RabbitHandler**`监听消息，只能标注在方法上，跟跟上面搭配可以重载方法，接受不同的对象 配置组件 @Slf4j @RunWith(SpringRunner.class) @SpringBootTest public class GulimallOrderApplicationTests { @Autowired private AmqpAdmin amqpAdmin; /** * 1、如何创建Exchange、Queue、Binding？使用AmqpAdmin进行创建 * 2、如何收发消息 */ @Test public void createExchange() { Exchange directExchange = new DirectExchange(\"hello-java-exchange\", true, false); amqpAdmin.declareExchange(directExchange); log.info(\"Exchange[{}]创建成功：\",\"hello-java-exchange\"); } @Test public void createQueue() { Queue queue = new Queue(\"hello-java-queue\", true, false, false); amqpAdmin.declareQueue(queue); log.info(\"Queue[{}]创建成功：\",\"hello-java-queue\"); } @Test public void createBinding() { Binding binding = new Binding( \"hello-java-queue\", Binding.DestinationType.QUEUE, \"hello-java-exchange\", \"hello.java\", null); amqpAdmin.declareBinding(binding); log.info(\"Binding[{}]创建成功：\",\"hello-java-binding\"); } @Test public void create() { HashMap&lt;String, Object> arguments = new HashMap&lt;>(); arguments.put(\"x-dead-letter-exchange\", \"order-event-exchange\"); arguments.put(\"x-dead-letter-routing-key\", \"order.release.order\"); arguments.put(\"x-message-ttl\", 60000); Queue queue = new Queue(\"order.delay.queue\", true, false, false, arguments); amqpAdmin.declareQueue(queue); log.info(\"Queue[{}]创建成功：\",\"order.delay.queue\"); } } 发送消息 public class RabbitTest { @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMessageTest() { // 创建了一个对象 OrderReturnReasonEntity reasonEntity = new OrderReturnReasonEntity(); reasonEntity.setId(1L); reasonEntity.setCreateTime(new Date()); reasonEntity.setName(\"reason\"); reasonEntity.setStatus(1); reasonEntity.setSort(2); String msg = \"Hello World\"; // 1、发送消息，如果发送的消息是个对象，会使用序列化机制将对象写出去， // 对象必须实现Serializable接口 // 2、再配置类配置消息转换器，可以将发送的消息转为 json rabbitTemplate.convertAndSend(\"hello-java-exchange\", \"hello2.java\", reasonEntity, new CorrelationData(UUID.randomUUID().toString())); log.info(\"消息发送完成:{}\",reasonEntity); } } 接受消息 @RabbitListener(queues = {\"hello-java-queue\"}) @Service(\"orderItemService\") public class OrderItemServiceImpl extends ServiceImpl&lt;OrderItemDao, OrderItemEntity> implements OrderItemService { /** * queues：声明需要监听的队列 * 参数 * 1、Message 原生消息详细信息 * 2、直接写发送的类型（OrderReturnReasonEntity） * 3、Channel 当前传输数据的通道 * 可以很多人来监听Queue，但一条消息只能被一个人消费 */ //@RabbitListener(queues = {\"hello-java-queue\"}) @RabbitHandler public void revieveMessage(Message message, OrderReturnReasonEntity content Channel channel) { // 拿到主体内容 byte[] body = message.getBody(); // 拿到的消息头属性信息 MessageProperties messageProperties = message.getMessageProperties(); System.out.println(\"接受到的消息...内容\" + message + \"===内容：\" + content); } @RabbitHandler public void revieveMessage( OrderEntity content) { // 拿到主体内容 byte[] body = message.getBody(); // 拿到的消息头属性信息 MessageProperties messageProperties = message.getMessageProperties(); System.out.println(\"接受到的消息...内容\" + message + \"===内容：\" + content); } } 修改配置文件 spring.rabbitmq.host=192.168.56.10 spring.rabbitmq.port=5672 spring.rabbitmq.virtual=/ spring.rabbitmq.username=cess spring.rabbitmq.password=cess 添加**Swagger**配置类（是用来自动生成RESTFULL风格API接口文档的） @Configuration @EnableSwagger2 public class SwaggerConfig { @Bean public Docket webApiConfig() { return new Docket(DocumentationType.SWAGGER_2) .groupName(\"webApi\") .apiInfo(webApiInfo()) .select() .build(); } private ApiInfo webApiInfo() { return new ApiInfoBuilder() .title(\"rabbitmq 接口文档\") .description(\"本文档描述了 rabbitmq 微服务接口定义\") .version(\"1.0\") .contact(new Contact(\"cess\", \"http://cess.com\", \"test@qq.com\")) .build(); } } 队列 TTL代码架构图创建两个队列 QA 和 QB，两者队列TTL分别设置为 10S 和 40S，然后在创建一个交换机 X 和死信交换机 Y，它们的类型都是direct，创建一个死信队列 QD，绑定关系如下 配置文件类代码 @Configuration public class TtlQueueConfig { public static final String X_EXCHANGE = \"X\"; // 普通交换机名称 public static final String Y_DEAD_LETTER_EXCHANGE = \"Y\"; // 死信交换机名称 public static final String QUEUE_A = \"QA\"; // 普通队列名称 public static final String QUEUE_B = \"QB\"; // 普通队列名称 public static final String DEAD_LETTER_QUEUE = \"QD\"; // 死信队列名称 // 声明 xExchange @Bean public DirectExchange xExchange() { return new DirectExchange(X_EXCHANGE); } // 声明 yExchange @Bean public DirectExchange yExchange() { return new DirectExchange(Y_DEAD_LETTER_EXCHANGE); } // 声明队列 TTL 10秒 @Bean public Queue queueA() { HashMap&lt;String, Object> arguments = new HashMap&lt;>(3); //声明当前队列绑定的死信交换机 arguments.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE); //声明当前队列的死信路由 key arguments.put(\"x-dead-letter-routing-key\", \"YD\"); //声明队列的 TTL arguments.put(\"x-message-ttl\", 10000); return QueueBuilder.durable(QUEUE_A).withArguments(arguments).build(); } // 声明队列 TTL 40秒 @Bean public Queue queueB() { HashMap&lt;String, Object> arguments = new HashMap&lt;>(3); //声明当前队列绑定的死信交换机 arguments.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE); //声明当前队列的死信路由 key arguments.put(\"x-dead-letter-routing-key\", \"YD\"); //声明队列的 TTL arguments.put(\"x-message-ttl\", 40000); return QueueBuilder.durable(QUEUE_B).withArguments(arguments).build(); } @Bean public Queue queueD() { return QueueBuilder.durable(DEAD_LETTER_QUEUE).build(); } // 声明队列 A 绑定 X 交换机 @Bean public Binding queueABindingX(@Qualifier(\"queueA\") Queue queueA, @Qualifier(\"xExchange\") DirectExchange xExchange) { return BindingBuilder.bind(queueA).to(xExchange).with(\"XA\"); } // 声明队列 B 绑定 X 交换机 @Bean public Binding queueBBindingX(@Qualifier(\"queueB\") Queue queueB, @Qualifier(\"xExchange\") DirectExchange xExchange) { return BindingBuilder.bind(queueB).to(xExchange).with(\"XB\"); } // 声明队列 D 绑定 Y 交换机 @Bean public Binding queueDBindingY(@Qualifier(\"queueD\") Queue queueD, @Qualifier(\"yExchange\") DirectExchange yExchange) { return BindingBuilder.bind(queueD).to(yExchange).with(\"YD\"); } } 消息生产者代码 // 发送延迟消息 @Slf4j @RestController @RequestMapping(\"/ttl\") public class SendMsgController { @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(\"/sendMsg/{message}\") public void sendMessage(@PathVariable String message) { log.info(\"当前时间:{},发送一条信息给两个TTL队列:{}\", new Date().toString(), message); rabbitTemplate.convertAndSend(\"X\", \"XA\", \"消息来自ttl为 10S 的队列: \" + message); rabbitTemplate.convertAndSend(\"X\", \"XB\", \"消息来自ttl为 40S 的队列: \" + message); } } 消息消费者代码 // 队列TTL 消费者 @Slf4j @Component public class DeadLetterConsumer { @RabbitListener(queues = \"QD\") public void reveiveD(Message message, Channel channel) { String msg = new String(message.getBody()); log.info(\"当前时间：{}，收到死信队列的消息：{}\", new Date(), msg); } } 发起一个请求 http://localhost:8080/ttl/sendMsg/嘻嘻嘻第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息， 然后被消费掉，这样一个延时队列就打造完成了 不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S 两个时间选项，如果需要一个小时后处理，那么就需要增加 TTL 为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？延时队列 TTL 优化（有问题）在这里新增了一个队列 QC，绑定关系如下，该队列不设置 TTL 时间配置文件类代码 @Configuration public class TtlQueueConfig { public static final String X_EXCHANGE = \"X\"; // 普通交换机名称 public static final String Y_DEAD_LETTER_EXCHANGE = \"Y\"; //死信交换机 public static final String QUEUE_A = \"QA\"; //普通队列名称 public static final String QUEUE_B = \"QB\"; //普通队列名称 public static final String QUEUE_C = \"QC\"; //普通队列名称 public static final String DEAD_LETTER_QUEUE = \"QD\"; //死信队列名称 // 声明 xExchange @Bean public DirectExchange xExchange() { return new DirectExchange(X_EXCHANGE); } // 声明 yExchange @Bean public DirectExchange yExchange() { return new DirectExchange(Y_DEAD_LETTER_EXCHANGE); } // 声明队列 TTL 10秒 @Bean public Queue queueA() { HashMap&lt;String, Object> arguments = new HashMap&lt;>(3); //声明当前队列绑定的死信交换机 arguments.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE); //声明当前队列的死信路由 key arguments.put(\"x-dead-letter-routing-key\", \"YD\"); //声明队列的 TTL arguments.put(\"x-message-ttl\", 10000); return QueueBuilder.durable(QUEUE_A).withArguments(arguments).build(); } // 声明队列 TTL 40秒 @Bean public Queue queueB() { HashMap&lt;String, Object> arguments = new HashMap&lt;>(3); //声明当前队列绑定的死信交换机 arguments.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE); //声明当前队列的死信路由 key arguments.put(\"x-dead-letter-routing-key\", \"YD\"); //声明队列的 TTL arguments.put(\"x-message-ttl\", 40000); return QueueBuilder.durable(QUEUE_B).withArguments(arguments).build(); } @Bean public Queue queueD() { return QueueBuilder.durable(DEAD_LETTER_QUEUE).build(); } // 声明队列 A 绑定 X 交换机 @Bean public Binding queueABindingX(@Qualifier(\"queueA\") Queue queueA, @Qualifier(\"xExchange\") DirectExchange xExchange) { return BindingBuilder.bind(queueA).to(xExchange).with(\"XA\"); } // 声明队列 B 绑定 X 交换机 @Bean public Binding queueBBindingX(@Qualifier(\"queueB\") Queue queueB, @Qualifier(\"xExchange\") DirectExchange xExchange) { return BindingBuilder.bind(queueB).to(xExchange).with(\"XB\"); } // 声明队列 D 绑定 Y 交换机 @Bean public Binding queueDBindingY(@Qualifier(\"queueD\") Queue queueD, @Qualifier(\"yExchange\") DirectExchange yExchange) { return BindingBuilder.bind(queueD).to(yExchange).with(\"YD\"); } // 声明队列 不设置延迟 @Bean public Queue queueC() { HashMap&lt;String, Object> arguments = new HashMap&lt;>(3); // 声明当前队列绑定的死信交换机 arguments.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE); // 声明当前队列的死信路由 key arguments.put(\"x-dead-letter-routing-key\", \"YD\"); return QueueBuilder.durable(QUEUE_C).withArguments(arguments).build(); } // 声明队列 C 绑定 X 交换机 @Bean public Binding queueCBindingX(@Qualifier(\"queueC\") Queue queueC, @Qualifier(\"xExchange\") DirectExchange xExchange) { return BindingBuilder.bind(queueC).to(xExchange).with(\"XC\"); } } 生产者代码 // 发送延迟消息 @Slf4j @RestController @RequestMapping(\"/ttl\") public class SendMsgController { @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(\"/sendMsg/{message}\") public void sendMessage(@PathVariable String message) { log.info(\"当前时间：{},发送一条信息给两个 TTL 队列:{}\", new Date(), message); rabbitTemplate.convertAndSend(\"X\", \"XA\", \"消息来自ttl为 10S 的队列: \" + message); rabbitTemplate.convertAndSend(\"X\", \"XB\", \"消息来自ttl为 40S 的队列: \" + message); } @GetMapping(\"/sendExpirationMsg/{message}/{ttlTime}\") public void sendMessage(@PathVariable String message, @PathVariable String ttlTime) { log.info(\"当前时间：{},发送一条时长{}毫秒TTL信息给队列QC:{}\", new Date(), ttlTime, message); rabbitTemplate.convertAndSend(\"X\", \"XC\", message, msg->{ msg.getMessageProperties().setExpiration(ttlTime); // 设置发送消息时候的TTL return msg; }); } } 发起请求：http://localhost:8080/ttl/sendExpirationMsg/你好 1/20000http://localhost:8080/ttl/sendExpirationMsg/你好 2/2000如果使用在消息属性上设置**TTL**的方式，消息可能并不会按时 “死亡” 因为**RabbitMQ**只会检查第一个消息是否过期，如果过期则丢到死信队列，** 如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行。**这也就是为什么第二个延时 2 秒却后执行 插件实现延迟队列上文中提到的问题，如果不能实现在消息粒度上的TTL，并使其在设置的TTL时间及时死亡，就无法设计成一个通用的延时队列。接下来就去解决该问题 安装延时队列插件在官网上下载 https://www.rabbitmq.com/community-plugins.html，下载**rabbitmq_delayed_message_exchange**插件，解压放置到RabbitMQ的插件目录。进入RabbitMQ的安装目录下的**plgins**目录，执行下面命令让该插件生效，然后重启RabbitMQ，注意版本对应/usr/lib/rabbitmq/lib/rabbitmq_server-3.9.7/plugins执行**rabbitmq-plugins enable rabbitmq_delayed_message_exchange**代码架构图在这里新增了一个队列delayed.queue,一个自定义交换机 delayed.exchange，绑定关系如下配置文件类代码在我们自定义的交换机中，这是一种新的交换类型，该类型消息支持延迟投递机制 消息传递后并不会立即投递到目标队列中，而是存储在 mnesia(一个分布式数据系统)表中，当达到投递时间时，才投递到目标队列中。 @Configuration public class DelayedQueueConfig { public static final String DELAYED_EXCHANGE_NAME = \"delayed.exchange\"; public static final String DELAYED_QUEUE_NAME = \"delayed.queue\"; public static final String DELAYED_ROUTING_KEY = \"delayed.routingkey\"; //自定义交换机 我们在这里定义的是一个延迟交换机 @Bean public CustomExchange delayedExchange() { Map&lt;String, Object> args = new HashMap&lt;>(); args.put(\"x-delayed-type\", \"direct\"); // 自定义交换机的类型 return new CustomExchange( DELAYED_EXCHANGE_NAME, \"x-delayed-message\", true, false, args); } @Bean public Queue delayedQueue() { return new Queue(DELAYED_QUEUE_NAME); } @Bean public Binding bindingDelayedQueue( @Qualifier(\"delayedQueue\") Queue queue, @Qualifier(\"delayedExchange\") CustomExchange delayedExchange) { return BindingBuilder.bind(queue).to(delayedExchange).with(DELAYED_ROUTING_KEY) .noargs(); } } 消息生产者代码 @GetMapping(\"sendDelayMsg/{message}/{delayTime}\") public void sendMsg(@PathVariable String message, @PathVariable Integer delayTime) { log.info(\"当前时间：{}，发送一条延迟{}毫秒的信息给队列 delayed.queue：{}\", new Date(), delayTime, message); rabbitTemplate.convertAndSend( DelayedQueueConfig.DELAYED_EXCHANGE_NAME, DelayedQueueConfig.DELAYED_ROUTING_KEY, message, correlationData -> { correlationData.getMessageProperties().setDelay(delayTime); return correlationData; }); } 消息消费者代码 @Slf4j @Component public class DelayQueueConsumer { @RabbitListener(queues = DelayedQueueConfig.DELAYED_QUEUE_NAME) public void receiveDelayedQueue(Message message) { String msg = new String(message.getBody()); log.info(\"当前时间：{},收到延时队列的消息：{}\", new Date(), msg); } } 发起请求http://localhost:8080/ttl/sendDelayMsg/come on baby1/20000http://localhost:8080/ttl/sendDelayMsg/come on baby2/2000第二个消息被先消费掉了，符合预期总结延时队列在需要延时处理的场景下非常有用，使用RabbitMQ来实现延时队列可以很好的利用RabbitMQ的特性，如：消息可靠发送、消息可靠投递、死信队列来保障消息至少被消费一次以及未被正确处理的消息不会被丢弃。另外，通过RabbitMQ集群的特性，可以很好的解决单点故障问题，不会因为单个节点挂掉导致延时队列不可用或者消息丢失。当然，延时队列还有很多其它选择，比如利用 Java 的 DelayQueue，利用Redis的 zset，利用 Quartz或者利用 kafka的时间轮，这些方式各有特点，看需要适用的场景","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/tags/RabbitMQ/"}],"author":"wst"},{"title":"【RabbitMQ】6.RabbitMQ集群","slug":"RabbitMQ/6.RabbitMQ集群","date":"2022-03-29T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0329[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0329[object%20Object].html","excerpt":"","text":"十 RabbitMQ 集群1 clustering一句话总结：就是多台MQ同时同时工作使用集群的原因前面介绍了如何安装及运行RabbitMQ服务，不过这些是单机版的，无法满足目前真实应用的要求。搭建一个RabbitMQ集群可以解决单台RabbitMQ服务器遇到内存崩溃、机器掉电或者主板故障的问题，以及满足高吞吐量的需求搭建步骤 修改 3 台机器的主机名称vim /etc/hostname 分别为 node1 node2 node3 分别配置3个节点的 hosts 文件，让各个节点都能互相识别对方 **vim /etc/hosts**192.168.199.158 node1192.168.199.159 node2192.168.199.160 node3 确保各个节点的 cookie 文件使用的是同一个值，在 node1 上执行远程操作命令**scp /var/lib/rabbitmq/.erlang.cookie root@node2:/var/lib/rabbitmq/.erlang.cookie****scp /var/lib/rabbitmq/.erlang.cookie root@node3:/var/lib/rabbitmq/.erlang.cookie** 启动RabbitMQ服务，顺带启动 Erlang 虚拟机和 RbbitMQ 应用服务（在三台节点上分别执行以下命令）**rabbitmq-server -detached** 在节点 2 执行**rabbitmqctl stop_app**(rabbitmqctl stop 会将Erlang 虚拟机关闭，rabbitmqctl stop_app 只关闭 RabbitMQ 服务)**rabbitmqctl reset****rabbitmqctl join_cluster rabbit@node1 ****rabbitmqctl start_app** (只启动应用服务) 在节点 3 执行rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster rabbit@node2rabbitmqctl start_app 集群状态**rabbitmqctl cluster_status** 需要重新设置用户创建账号**rabbitmqctl add_user cess cess**设置用户角色**rabbitmqctl set_user_tags cess administrator**设置用户权限**rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;** 解除集群节点(node2 和 node3 机器分别执行)**rabbitmqctl stop_app****rabbitmqctl reset****rabbitmqctl start_app**查看集群状态**rabbitmqctl cluster_status**，已解除 **rabbitmqctl forget_cluster_node rabbit@node2**(node1 机器上执行) 2 镜像队列一句话总结：将队列镜像到集群中的其他 Broker 节点之上，避免单节点失效使用镜像的原因如果RabbitMQ集群中只有一个Broker节点，那么该节点的失效将导致整体服务的临时性不可用，并且也可能会导致消息的丢失。将所有消息都设置为持久化，并且对应队列的durable属性也设置为true， 但是这样仍然无法避免由于缓存导致的问题：因为消息在发送之后和被写入磁盘井执行刷盘动作之间存在一个短暂却会产生问题的时间窗。通过发布确认机制能够确保客户端知道哪些消息己经存入磁盘， 尽管如此，一般不希望遇到因单点故障导致的服务不可用。引入镜像队列Mirror Queue的机制，可以将队列镜像到集群中的其他 Broker 节点之上，如果集群中的一个节点失效了，队列能自动地切换到镜像中的另一个节点上以保证服务的可用性搭建步骤 启动三台集群节点 随便找一个节点添加 policyadmin — policiespattern 表示队列前缀 在 node1 上创建一个队列发送一条消息，队列存在镜像队列 停掉 node1 之后发现 node2 成为镜像队列 就算整个集群只剩下一台机器了 依然能消费队列里面的消息说明队列里面的消息被镜像队列传递到相应机器里面了 3 Haproxy+Keepalive 实现高可用负载均衡一句话总结，类似Nginx的作用整体架构图Haproxy 实现负载均衡HAProxy 提供高可用性、负载均衡及基于TCPHTTP 应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案，包括 Twitter、Reddit、StackOverflow、GitHub 在内的多家知名互联网公司在使用。HAProxy 实现了一种事件驱动、单一进程模型，此模型支持非常大的井发连接数。扩展 nginx,lvs,haproxy 之间的区别: http://www.ha97.com/5646.html搭建步骤 下载 haproxy(在 node1 和 node2) **yum -y install haprox**y 修改 node1 和 node2 的 haproxy.cfg**vim /etc/haproxy/haproxy.cfg**需要修改红色 IP 为当前机器 IP 在两台节点启动 haproxy**haproxy -f /etc/haproxy/haproxy.cfg ps -ef | grep haproxy** 访问地址http://10.211.55.71:8888/stats Keepalived 实现双机(主备)热备试想如果前面配置的 HAProxy 主机突然宕机或者网卡失效，那么虽然RbbitMQ集群没有任何故障但是对于外界的客户端来说所有的连接都会被断开结果将是灾难性的为了确保负载均衡服务的可靠性同样显得十分重要，这里就要引入**Keepalived**它能够通过自身健康检查、资源接管功能做高可用(双机热备)，实现故障转移搭建步骤 下载 keepalived**yum -y install keepalived** 节点 node1 配置文件**vim /etc/keepalived/keepalived.conf**把资料里的 keepalived.conf 修改后替换 节点 node2 配置文件需要修改global_defs 的 router_id,如:nodeB其次要修改 vrrp_instance_VI 中 state 为”BACKUP”；最后要将priority 设置为小于 100 的值 添加 haproxy_chk.sh(为了防止 HAProxy 服务挂掉之后 Keepalived 还在正常工作而没有切换到 Backup 上，所以这里需要编写一个脚本来检测 HAProxy 务的状态,当 HAProxy 服务挂掉之后该脚本会自动重启HAProxy 的服务，如果不成功则关闭 Keepalived 服务，这样便可以切换到 Backup 继续工作)vim /etc/keepalived/haproxy_chk.sh(可以直接上传文件)修改权限 chmod 777 /etc/keepalived/haproxy_chk.sh 启动 keepalive 命令(node1 和 node2 启动)**systemctl start keepalived** 观察 Keepalived 的日志tail -f /var/log/messages -n 200 观察最新添加的 vipip add show node1 模拟 keepalived 关闭状态**systemctl stop keepalived** 使用 vip 地址来访问rabbitmq集群 4 Federation Exchange 交换机同步使用它的原因 (broker 北京)，(broker 深圳)彼此之间相距甚远，网络延迟是一个不得不面对的问题。有一个在北京的业务(Client 北京) 需要连接(broker 北京)，向其中的交换器 exchangeA 发送消息，此时的网络延迟很小， (Client 北京)可以迅速将消息发送至 exchangeA 中，就算在开启了 publisherconfirm 机制或者事务机制的情况下，也可以迅速收到确认信息。此时又有个在深圳的业务(Client 深圳)需要向 exchangeA 发送消息， 那么(Client 深圳) (broker 北京)之间有很大的网络延迟，(Client 深圳) 将发送消息至 exchangeA 会经历一定的延迟，尤其是在开启了 publisherconfirm 机制或者事务机制的情况下，(Client 深圳) 会等待很长的延迟时间来接收(broker 北京)的确认信息，进而必然造成这条发送线程的性能降低，甚至造成一定程度上的阻塞。将业务(Client 深圳)部署到北京的机房可以解决这个问题，但是如果(Client 深圳)调用的另些服务都部署在深圳，那么又会引发新的时延问题，总不见得将所有业务全部部署在一个机房，那么容灾又何以实现？ 这里使用 Federation 插件就可以很好地解决这个问题. 搭建步骤 需要保证每台节点单独运行 在每台机器上开启 **federation**相关插件 **rabbitmq-plugins enable rabbitmq_federation****rabbitmq-plugins enable rabbitmq_federation_management** 原理图(先运行 consumer 在 node2 创建 fed_exchange) 在 downstream(node2)配置 upstream(node1) 添加 policy 成功的前提 5 Federation Queue 队列同步使用它的原因联邦队列可以在多个 Broker 节点(或者集群)之间为单个队列提供均衡负载的功能。一个联邦队列可以连接一个或者多个上游队列(upstream queue)，并从这些上游队列中获取消息以满足本地消费者消费消息的需求。搭建步骤 原理图 添加 upstream(同上) 添加 policy **6 Shovel 同样是同步**使用它的原因Federation 具备的数据转发功能类似，Shovel 够可靠、持续地从一个 Broker 中的队列(作为源端，即source)拉取数据并转发至另一个 Broker 中的交换器(作为目的端，即 destination)。作为源端的队列和作为目的端的交换器可以同时位于同一个 Broker，也可以位于不同的 Broker 上。Shovel 可以翻译为”铲子”， 是一种比较形象的比喻，这个”铲子”可以将消息从一方”铲子”另一方。Shovel 行为就像优秀的客户端应用程序能够负责连接源和目的地、负责消息的读写及负责连接失败问题的处理。搭建步骤 开启插件(需要的机器都开启) rabbitmq-plugins enable rabbitmq_shovelrabbitmq-plugins enable rabbitmq_shovel_management 原理图(在源头发送的消息直接回进入到目的地队列) 添加 shovel 源和目的地","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/tags/RabbitMQ/"}],"author":"wst"},{"title":"【RabbitMQ】5.发布确认高级 其他知识点","slug":"RabbitMQ/5.发布确认高级 其他知识点","date":"2022-03-29T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0329[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0329[object%20Object].html","excerpt":"","text":"八 发布确认高级1 Springboot 发布确认一句话总结：发布确认的具体实现在生产环境中由于一些不明原因，导致RabbitMQ重启，期间生产者消息投递失败， 导致消息丢失，需要手动处理和恢复。如何才能进行RabbitMQ的消息可靠投递呢？确认机制方案代码架构图在配置文件当中添加 spring.rabbitmq.publisher-confirm-type=correlated **NONE**值是禁用发布确认模式，是默认值 **CORRELATED**值是发布消息成功到交换器后会触发回调方法 **SIMPLE**值经测试有两种效果，其一效果和CORRELATED值一样会触发回调方法，其二在发布消息成功后使用**rabbitTemplate**调用**waitForConfirms**或**waitForConfirmsOrDie**方法等待broker节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 waitForConfirmsOrDie方法如果返回 false 则会关闭channel，则接下来无法发送消息到broker 添加配置类 // 发布确认 @Configuration public class ConfirmConfig { public static final String CONFIRM_EXCHANGE_NAME = \"confirm.exchange\"; public static final String CONFIRM_QUEUE_NAME = \"confirm.queue\"; public static final String ROUTING_KEY = \"key1\"; //声明业务 Exchange @Bean(\"confirmExchange\") public DirectExchange confirmExchange() { return new DirectExchange(CONFIRM_EXCHANGE_NAME); } // 声明确认队列 @Bean(\"confirmQueue\") public Queue confirmQueue() { return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build(); } // 声明确认队列绑定关系 @Bean public Binding queueBindingExchange( @Qualifier(\"confirmQueue\") Queue queue, @Qualifier(\"confirmExchange\") DirectExchange exchange) { return BindingBuilder.bind(queue).to(exchange).with(ROUTING_KEY); } } 消息生产者的回调接口 @PostConstruct@**PostConstruct**注解好多人以为是Spring提供的。其实是Java的注解Java中该注解的说明：@PostConstruct该注解被用来修饰一个非静态的 void 方法。被@PostConstruct修饰的方法会在服务器加载Servlet的时候运行，并且只会被服务器执行一次。@PostConstruct在构造函数之后执行，init 方法之前执行通常会在Spring框架中使用到@PostConstruct注解 该注解的方法在整个Bean初始化中的执行顺序：Constructor(构造方法) -&gt; @Autowired(依赖注入) -&gt; @PostConstruct(注释的方法) @Slf4j @Component public class MyCallBack implements RabbitTemplate.ConfirmCallback { @Autowired private RabbitTemplate rabbitTemplate; //依赖注入 rabbitTemplate 之后再设置它的回调对象 @PostConstruct public void init() { rabbitTemplate.setConfirmCallback(this); } /** * 交换机不管是否收到消息的一个回调方法 * 1 correlationData 消息相关数据 * 2 ack 交换机是否收到消息 true收到 false没收到 * 3 cause 为收到消息的原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) { String id = correlationData != null ? correlationData.getId() : \"\"; if (ack) { log.info(\"交换机已经收到 id 为:{}的消息\", id); } else { //如果发送消息失败，这里可以保存起来以后重新发送 log.info(\"交换机还未收到 id 为:{}消息，原因:{}\", id, cause); } } } 消息生产者 // 开始发消息 测试确认 @RestController @RequestMapping(\"/confirm\") @Slf4j public class ProducerController { @Autowired private RabbitTemplate rabbitTemplate; // 消息回调和退回 @GetMapping(\"sendMessage/{message}\") public void sendMessage(@PathVariable String message) { // 指定消息 id 为 1 CorrelationData correlationData1 = new CorrelationData(\"1\"); rabbitTemplate.convertAndSend(ConfirmConfig.CONFIRM_EXCHANGE_NAME, ConfirmConfig.ROUTING_KEY, message + \"key1\", correlationData1); log.info(ConfirmConfig.ROUTING_KEY + \"发送消息内容:{}\", message + \"key1\"); CorrelationData correlationData2 = new CorrelationData(\"2\"); rabbitTemplate.convertAndSend(ConfirmConfig.CONFIRM_EXCHANGE_NAME, \"key2\" + 2, message + \"key2\", correlationData2); log.info(\"key2\" + \"发送消息内容:{}\", message + \"key2\"); } } 消息消费者```java@Component@Slf4jpublic class ConfirmConsumer { public static final String CONFIRM_QUEUE_NAME = “confirm.queue”; @RabbitListener(queues = CONFIRM_QUEUE_NAME) public void receiveMsg(Message message) { String msg = new String(message.getBody()); log.info(&quot;接受到队列 confirm.queue 消息:{}&quot;, msg); } } 访问 [http://localhost:8080/confirm/sendMessage/%E4%BD%A0%E5%A5%BD](http://localhost:8080/confirm/sendMessage/%E4%BD%A0%E5%A5%BD) **结果分析** ![](https://www.yuque.com/api/filetransfer/images?url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fzhangc233%2Fpic%40master%2Fimg%2Fimage-20210629135636990.png&amp;sign=92c362484368c1373e235674f1b65aeb8edcab839925cc5aef615bbc385a9247#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=Gs1xo&amp;margin=%5Bobject%20Object%5D&amp;originHeight=165&amp;originWidth=844&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) 发送了两条消息，第一条消息的 RoutingKey 为 “key1”，第二条消息的 RoutingKey 为 “key2”，两条消息都成功被交换机接收，也收到了交换机的确认回调，但消费者只收到了一条消息，因为第二条消息的 RoutingKey 与队列的 BindingKey 不一致，也没有其它队列能接收这个消息，所有第二条消息被直接丢弃了。丢弃的消息交换机是不知道的，需要解决告诉生产者消息传送失败** 2 回退消息** **一句话总结：可以设置，当消息传递过程中不可达目的地时，将消息返回给生产者或给与提示** 在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如果发现该消息不可路由，会被直接丢弃，此时生产者是不知道消息被丢弃事件的 如何让无法被路由的消息帮我想办法处理一下？最起码通知我一声，我好自己处理啊。通过设置 **mandatory **参数可以**在当消息传递过程中不可达目的地时将消息返回给生产者** ```properties # 消息退回 spring.rabbitmq.publisher-returns=true Mandatory 参数 rabbitTemplate.setReturnsCallback(myCallBack); @Slf4j @Component public class MyCallBack implements RabbitTemplate.ConfirmCallback, RabbitTemplate.ReturnsCallback { @Autowired private RabbitTemplate rabbitTemplate; //依赖注入 rabbitTemplate 之后再设置它的回调对象 @PostConstruct public void init() { rabbitTemplate.setConfirmCallback(this); rabbitTemplate.setReturnsCallback(this); //🔴 设置回退消息 } /** * 交换机不管是否收到消息的一个回调方法 * 1 correlationData 消息相关数据 * 2 ack 交换机是否收到消息 true收到 false没收到 * 3 cause 为收到消息的原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) { String id = correlationData != null ? correlationData.getId() : \"\"; if (ack) { log.info(\"交换机已经收到 id 为:{}的消息\", id); } else { //如果发送消息失败，这里可以保存起来以后重新发送 log.info(\"交换机还未收到 id 为:{}消息，原因:{}\", id, cause); } } // 在当消息传递过程中不可达目的地时将消息返回给生产者 // 只有不可达目的地的时候 才进行回退 @Override public void returnedMessage(ReturnedMessage returnedMessage) { log.error(\"消息{} 被交换机{}退回了，退回原因：{}，路由Key：{}\", returnedMessage.getMessage(), returnedMessage.getExchange(), returnedMessage.getReplyText(), returnedMessage.getRoutingKey()); } } 3 备份交换机一句话总结：可以设置一个备份交换机，用于接受无法被投送到队列的消息有了 **mandatory **参数和回退消息，可以感知无法投递消息，在生产者的消息无法被投递时发现并处理。但有时候，并不知道该如何处理这些无法路由的消息，最多打个日志，然后触发报警，再来手动处理。而通过日志来处理这些无法路由的消息是很不优雅的做法，特别是当生产者所在的服务有多台机器的时候，手动复制日志会更加麻烦而且容易出错。而且设置 mandatory 参数会增加生产者的复杂性，需要添加处理这些被退回的消息的逻辑。如果既不想丢失消息，又不想增加生产者的复杂性，该怎么做呢？ 在设置死信队列时提到，可以为队列设置死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息。 在RabbitMQ中，有一种备份交换机的机制存在，可以很好的应对这个问题。 备份交换机可以理解为RabbitMQ中交换机的 “备胎”，为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理，通常备份交换机的类型为 **Fanout**，然后在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都进入这个队列了。当然，我们还可以建立一个报警队列，用独立的消费者来进行监测和报警 架构图 // 发布确认 @Configuration public class ConfirmConfig { public static final String CONFIRM_EXCHANGE_NAME = \"confirm.exchange\"; public static final String CONFIRM_QUEUE_NAME = \"confirm.queue\"; public static final String ROUTING_KEY = \"key1\"; public static final String BACKUP_EXCHANGE_NAME = \"backup.exchange\"; public static final String BACKUP_QUEUE_NAME = \"backup.queue\"; public static final String WARNING_QUEUE_NAME = \"warning.queue\"; //声明业务 Exchange @Bean(\"confirmExchange\") public DirectExchange confirmExchange() { return ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME).durable(true) .withArgument(\"alternate-exchange\", BACKUP_EXCHANGE_NAME).build(); // 🔴 } // 声明确认队列 @Bean(\"confirmQueue\") public Queue confirmQueue() { return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build(); } // 声明确认队列绑定关系 @Bean public Binding queueBindingExchange( @Qualifier(\"confirmQueue\") Queue queue, @Qualifier(\"confirmExchange\") DirectExchange exchange) { return BindingBuilder.bind(queue).to(exchange).with(ROUTING_KEY); } //声明备份 Exchange @Bean(\"backupExchange\") public FanoutExchange backupExchange() { return new FanoutExchange(BACKUP_EXCHANGE_NAME); } // 声明备份队列 @Bean(\"backQueue\") public Queue backQueue() { return QueueBuilder.durable(BACKUP_QUEUE_NAME).build(); } // 声明警告队列 @Bean(\"warningQueue\") public Queue warningQueue() { return QueueBuilder.durable(WARNING_QUEUE_NAME).build(); } // 声明备份队列绑定关系 @Bean public Binding backupBinding( @Qualifier(\"backQueue\") Queue queue, @Qualifier(\"backupExchange\") FanoutExchange backupExchange) { return BindingBuilder.bind(queue).to(backupExchange); } // 声明报警队列绑定关系 @Bean public Binding warningBinding( @Qualifier(\"warningQueue\") Queue queue, @Qualifier(\"backupExchange\") FanoutExchange backupExchange) { return BindingBuilder.bind(queue).to(backupExchange); } } @Slf4j @Component public class WarningConsumer { @RabbitListener(queues = ConfirmConfig.WARNING_QUEUE_NAME) public void receiveWarningMsg(Message message) { String msg = new String(message.getBody()); log.error(\"报警发现不可路由消息：{}\", msg); } } :key1发送消息内容:你好key1C.C.S.conToiter.Producercontoe:key2发送消息内容:你好key2C.C.S.controlter.Producercontoe报警发现不可路由消息:你好key2consUmer.WarningConsumerC.C.S接受到队列confirm.queue消息:你好key1ConfirmconsumerC.C.S.consumer交换机已经收到i为:1的消息C.C.s.configMyCattBack交换机已经收到i为:2的消息C.C.S.config.MycaltBackmandatory 参数与备份交换机可以一起使用的时候，如果两者同时开启，消息究竟何去何从？ 谁优先级高，经过上面结果显示答案是备份交换机优先级高九 其他知识点1 幂等性一句话总结：利用全局唯一ID，防范重复消费，利用 redix 的 setnx概念用户对于同一操作发起的一次或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。 举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常， 此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱 了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等 消息重复消费消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断， 故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息 解决思路MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识，比如时间戳或者 UUID ，订单消费者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。 消费端的幂等性保障在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性， 这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。业界主流的幂等性有两种操作 唯一 ID + 指纹码机制，用数据库主键去重 利用 redis 的原子性去实现 唯一 ID + 指纹码机制指纹码：我们的一些规则或者时间戳加别的服务给到的唯一信息码，它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中，优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。 Redis 原子性消费者拿到全局唯一ID，利用 redis执行 setnx命令，返回1就消费，0就丢弃，天然具有幂等性，从而实现不重复消费 2 优先级队列一句话总结：消息可以设置优先级，高的优先被消费使用场景系统中有一个订单催付的场景，客户在天猫下的订单，淘宝会及时将订单推送给商家，如果在用户设定的时间内未付款那么就会给客户推送一条短信提醒，很简单的一个功能对吧 但是，商家肯定是要分大商家和小商家的，比如像苹果、小米这样大商家一年起码能给平台创造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis来存放的定时轮询，大家都知道 redis只能用 List做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ进行改造和优化，如果发现是大客户的订单给一个相对比较高的优先级， 否则就是默认优先级 优先级队列 优先级0-255，越大越优先如何添加？ 控制台页面添加 或者队列中代码添加优先级**&quot;x-max-priority&quot;** Map&lt;String, Object> params = new HashMap(); params.put(\"x-max-priority\", 10); channel.queueDeclare(\"hello\", true, false, false, params); 消息中代码添加优先级AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); 注意事项要让队列实现优先级需要做的事情有如下：队列需要设置为优先级队列，消息需要设置消息的优先级，消费者需要等待消息已经发送到队列中才去消费，因为这样才有机会对消息进行排序 生产者 // 生产者：发消息 public class Producer { //队列名称 private final static String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); /* * 生成一个队列 * 1.队列名称 * 2.队列里面的消息是否持久化，默认不持久化（存储在内存中） * 3.该队列是否只供一个消费者进行消费 是否进行共享 true 可以多个消费者消费 * 4.最后一个消费者端开连接以后 该队列是否自动删除 true 自动删除 * 5.其他参数 */ HashMap&lt;String, Object> argument = new HashMap&lt;>(); // 官方允许0-255，此处设置10，允许优先级范围0-10，不要过大浪费CPU跟内存 argument.put(\"x-max-priority\", 10); channel.queueDeclare(QUEUE_NAME, true, false, false, argument); for (int i = 0; i &lt; 10; i++) { String message = \"info\" + i; if (i == 5) { AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build(); channel.basicPublish(\"\", QUEUE_NAME, properties, message.getBytes()); } else { channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes()); } } System.out.println(\"消息发送完毕\"); } } 消费者 /** * 消费者：接收消息 */ public class Consumer { //队列名称 private final static String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws Exception { Channel channel = RabbitMqUtils.getChannel(); //声明 接受消息 DeliverCallback deliverCallback = (consumerTag, message) -> { System.out.println(new String(message.getBody())); }; //声明 取消消息 CancelCallback cancelCallback = consumerTag ->{ System.out.println(\"消息消费被中断\"); }; /* * 消费者消费消息 * 1.消费哪个队列 * 2.消费成功之后是否要自动应答 true 代表自动应答 false 手动应答 * 3.消费者成功消费的回调 * 4.消息被取消时的回调 */ channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback); } } **3 惰性队列**一句话总结：就是可以设置把消息都放在硬盘中，以减小内存的占用使用场景 RabbitMQ从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当消费者由于各种各样的原因（比如消费者下线、宕机亦或者是由于维护而关闭等）而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了 默认情况下，当生产者将消息发送到RabbitMQ的时候，队列中的消息会尽可能的存储在内存之中， 这样可以更加快速的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份。当RabbitMQ需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。虽然RabbitMQ的开发者们一直在升级相关的算法， 但是效果始终不太理想，尤其是在消息量特别大的时候 两种模式队列具备两种模式：default 和 lazy。默认的为 default 模式，在 3.6.0 之前的版本无需做任何变更。lazy 模式即为惰性队列的模式，可以通过调用 channel.queueDeclare 方法的时候在参数中设置，也可以通过 Policy 的方式设置，如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级。 如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。 在队列声明的时候可以通过 **&quot;x-queue-mode&quot;**参数来设置队列的模式，取值为 default 和 lazy。下面示例中演示了一个惰性队列的声明细节 Map&lt;String, Object> args = new HashMap&lt;String, Object>(); args.put(\"x-queue-mode\", \"lazy\"); channel.queueDeclare(\"myqueue\", false, false, false, args); 内存开销对比在发送 1 百万条消息，每条消息大概占 1KB 的情况下，普通队列占用内存是 1.2GB，而惰性队列仅仅 占用 1.5MB","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/tags/RabbitMQ/"}],"author":"wst"},{"title":"bug/微服务项目报错 Failed to configure a DataSource ‘url‘ attribute is not specified and no embedde","slug":"bug/微服务项目报错 Failed to configure a DataSource ‘url‘ attribute is not specified and no embedde","date":"2022-03-20T11:35:43.858Z","updated":"2022-07-06T13:51:55.133Z","comments":true,"path":"2022/032051148.html","link":"","permalink":"https://409713427.github.io/2022/032051148.html","excerpt":"","text":"微服务项目报错: Failed to configure a DataSource: ‘url‘ attribute is not specified and no embedde项目结构: 在我的项目中api-user-login-8001不需要用放到mybatis-plus ,但是需要依赖beans,beans中导入了mybatis-plus依赖,会存在传递依赖,导致项目报错如下 问题分析及解决方案 问题原因: Mybatis没有找到合适的加载类,其实是spring - datasource - url没有加载成功,分析原因如下所示. 1. DataSourceAutoConfiguration会自动加载. 2. 没有配置spring - datasource - url 属性. 3. spring - datasource - url 配置的地址格式有问题. 4. 配置 spring - datasource - url的文件没有加载. 5. 导入commons没有把不需要的依赖排除掉 网上给出了这几种解决方案.方案一 (解决原因1) 排除此类的autoconfig。启动以后就可以正常运行。 @SpringBootApplication(exclude= {DataSourceAutoConfiguration.class}) 方案二 (解决原因2) 在application.properties/或者application.yml文件中没有添加数据库配置信息. spring: datasource: url: jdbc:mysql://localhost:3306/read_data?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver 方案三 (解决原因3) 在spring xml配置文件中引用了数据库地址 所以需要对:等进行转义处理.但是在application.properties/或者application.yml文件并不需要转义,错误和正确方法写在下面了. //错误示例 spring.datasource.url = jdbc:mysql\\://192.168.0.20\\:1504/f_me?setUnicode=true&amp;characterEncoding=utf8 //正确示例 spring.datasource.url = jdbc:mysql://192.168.0.20:1504/f_me?setUnicode=true&amp;characterEncoding=utf8 方案四 (解决原因4) yml或者properties文件没有被扫描到,需要在pom文件中添加如下.来保证文件都能正常被扫描到并且加载成功. &lt;!-- 如果不添加此节点mybatis的mapper.xml文件都会被漏掉。 --> &lt;resources> &lt;resource> &lt;directory>src/main/java&lt;/directory> &lt;includes> &lt;include>**/*.yml&lt;/include> &lt;include>**/*.properties&lt;/include> &lt;include>**/*.xml&lt;/include> &lt;/includes> &lt;filtering>false&lt;/filtering> &lt;/resource> &lt;resource> &lt;directory>src/main/resources&lt;/directory> &lt;includes> &lt;include>**/*.yml&lt;/include> &lt;include>**/*.properties&lt;/include> &lt;include>**/*.xml&lt;/include> &lt;/includes> &lt;filtering>false&lt;/filtering> &lt;/resource> &lt;/resources> 方案五 (解决原因5) 在导入common依赖时,将不需要并导致无法正常运行的以来排除掉 &lt;dependency> &lt;groupId>org.wst&lt;/groupId> &lt;artifactId>beans&lt;/artifactId> &lt;version>2.0.1&lt;/version> &lt;scope>compile&lt;/scope> &lt;exclusions> &lt;exclusion> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> 说明 我的问题是有原因1或5造成的,没有排除相关依赖或者排除此类的autoconfig,其他方案均未认证其正确性,所以需要自行酌情而定.切勿盲目而为.","categories":[],"tags":[]},{"title":"bug","slug":"bug/maven出现：Failed to execute goal on project ... Could not resolve dependencies for project","date":"2022-03-18T09:04:15.628Z","updated":"2022-03-18T09:20:55.699Z","comments":true,"path":"2022/031855064.html","link":"","permalink":"https://409713427.github.io/2022/031855064.html","excerpt":"","text":"maven出现：Failed to execute goal on project …: Could not resolve dependencies for project …1、我的项目结构是一个父项目，多个子项目目录如下： 2、我这里就举个例子，所以应用的也就是common和order-add这个项目。 3、两个项目都继承父项目 4、在模块中order-add依赖于common，在common中执行完clean和install之后，本地仓库也存在依赖，但是在order-add中进行install就会出现 Failed to execute goal on project ...: Could not resolve dependencies for project ... 这样测错误，最后发现原来是自己没有首先对父项目也就是springcloud-demo1项目进行clean和install ， 5、总结、在父项目下有的子项目在首次运行clean 和install前应该先运行父项目的clean和install","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"SASS用法指南","slug":"预编译css/SASS用法指南","date":"2022-02-24T07:43:40.100Z","updated":"2022-02-24T08:36:01.476Z","comments":true,"path":"2022/022448561.html","link":"","permalink":"https://409713427.github.io/2022/022448561.html","excerpt":"","text":"SASS用法指南一、什么是SASSSASS是一种CSS的开发工具，提供了许多便利的写法，大大节省了设计者的时间，使得CSS的开发，变得简单和可维护。 本文总结了SASS的主要用法。 二、基本用法2.1 变量SASS允许使用变量，所有变量以$开头。 $blue : red; div{ color : $blue; } 如果变量需要镶嵌在字符串值中,就必须写在#{}之中 $side : left; .rounded { border-#{$side}_radius: 5px; } 2.2计算功能SASS允许在代码中使用算数运算: body { margin : (14px/2); top: 50px+100px; right: $var * 10%; } 3.3嵌套SASS允许选择器嵌套. div h1{ color: red; } 可以写成 div{ h1{ color:red; } } 属性也可以嵌套,比如border-color属性,可以写成: p{ border{ color:red; } } 注意,border后面必须加上冒号. 在嵌套的代码块内,可以使用&amp;引用父元素.比如a:hover伪类选择器,可以写成: a{ &amp;:hover{ color:red; } } 2.4注释SASS共有两种注释风格 标准的css注释 /* comment */,会保留到编译后的文件 单行注释 // comment ,只保留在SASS源文件中,编译后被省略. 在/*后面加一个感叹号,表示这是重要注释.即使是压缩模式编译,也会保留这行注释,通常可以用于声明版权信息 /*! 重要注释! */ 三、代码的重用3.1继承SASS允许一个选择器继承另一个选择器,比如: class1 .class1{ border: 1px solid #ddd; } class2要继承class1,就要使用@extend命令 .class{ @extend .class1; font-size:120% } 3.2 MixinMixin是可以重用的代码块 使用@mixin命令,定义一个代码块 @mixin left{ float: left; margin-left: 10px; } 使用 @include命令,调用这个mixin div{ @include left; } mixin的强大之处,在于可以指定参数和缺省值 @mixin left($value: 10px){ float:left; margin-right: $value; } 使用的时候根据需要加入参数: div{ @include left(20px), } 下面是一个mixin的实力,用来生成浏览器前缀 @mixin rounded($vert, $horz, $radius: 10px) { border-#{$vert}-#{$horz}-radius: $radius; -moz-border-radius-#{$vert}#{$horz}: $radius; -webkit-border-#{$vert}-#{$horz}-radius: $radius; } 使用的时候,可以像下面这样调用 #navbar li { @include rounded(top, left); } #footer { @include rounded(top, left, 5px); } 3.3 颜色函数SASS提供了一些内置的颜色函数,以便生成系列颜色 lighten(#cc3, 10%) // #d6d65c darken(#cc3, 10%) // #a3a329 grayscale(#cc3) // #808080 complement(#cc3) // #33c 4.4 插入文件@import命令，用来插入外部文件。 @import \"path/filename.scss\" 如果插入的是.css文件,则等同于css的import命令 @import \"foo.css\" 五、高级用法4.1 条件语句 @if可以用来判断 p{ @if 1+1 == 2 {border: 1px solid;} @if 5&lt;3 { border : 2px dotted; } } 配套的还有@else命令: @if lightness($color) > 30% { background-color: #000; } @else { background-color: #fff; } 4.2 循环语句SASS支持for循环: @for $i from 1 to 10 { .border-#{$i} { border: #{$i}px solid blue; } } 也支持while循环: $i: 6; @while $i > 0 { .item-#{$i} { width: 2em * $i; } $i: $i - 2; } each命令，作用与for类似： @each $member in a, b, c, d { .#{$member} { background-image: url(\"/image/#{$member}.jpg\"); } } 4.3自定义函数SASS允许用户编写自己的函数 @function double($n) { @return $n * 2; } #sidebar { width: double(5px); }","categories":[{"name":"css","slug":"css","permalink":"https://409713427.github.io/categories/css/"}],"tags":[{"name":"css","slug":"css","permalink":"https://409713427.github.io/tags/css/"}],"author":"wst"},{"title":"高级检索,导入/导出EXCEL,mysql查询年度数据","slug":"后端常用功能/智信微应用-环保地图模块开发问题梳理","date":"2022-02-21T02:57:44.391Z","updated":"2022-02-24T09:42:07.970Z","comments":true,"path":"2022/02214512.html","link":"","permalink":"https://409713427.github.io/2022/02214512.html","excerpt":"","text":"智信微应用-环保地图模块开发:这里记录一下之前没写过的功能 高级检索 SearchVO /** * @ProjectName: zx-xinwenmine-security * @Package: com.zgiot.sf.security.vo * @ClassName: SearchVO * @Author: 汪帅瞳 * @Description: 主要用于高级检索 一个searchvo对象就代表一个检索条件 * @Date: 2021/12/22 17:10 * @Version: 2.0 */ @Data @AllArgsConstructor @NoArgsConstructor @ToString public class SearchVO { private String key; //字段名 private String value; //字段值 private boolean like; //模糊或精准 private String equals; //等于或者不等于 private String and; //是与非 private Integer order; //条件顺序 } controller @ApiOperation(\"高级检索\") @PostMapping(\"AdvancedSearch\") public ResponseMessage selectAdvancedRiskInfo(@RequestParam(value = \"pageNum\",defaultValue = \"1\") int pageNum,@RequestParam(value = \"pageSize\",defaultValue = \"10\") int pageSize,@RequestBody List&lt;SearchVO> lists){ System.out.println(lists); lists.sort(Comparator.comparing(SearchVO::getOrder)); System.out.println(lists); IPage&lt;RistDetailAndRistTypeVO> result = riskDetailService.selectAdvancedRiskInfo(pageNum, pageSize, lists); return Result.success(\"200\", \"查询成功\", result); } serviceImpl /** * @Method 高级检索 * @Author wst * @Date 2022/2/23 9:29 */ @Override public IPage&lt;RistDetailAndRistTypeVO> selectAdvancedRiskInfo(int pageNum, int pageSize, List&lt;SearchVO> lists) { String key = \"\"; //字段名 String value = \"\"; //字段值 boolean like; //模糊或精准 boolean equal; //等于或不等于 String and = \"\"; //是与非 or and null/\"\" String pre = \"\"; //存储和上一步的关系 or/and/\"\" String condition = \"\"; //拼接sql语句 保持前后空格 if (riskDetails.size() > 0) { for (int i = 0; i &lt; riskDetails.size(); i++) { SearchVO searchVO = riskDetails.get(i); key = searchVO.getKey(); value = searchVO.getValue(); and = searchVO.getAnd(); like = searchVO.isLike(); equal = searchVO.isEqual(); //拼sql if (\"\".equals(pre)) { //当前是第一个条件 如果下一个条件的字段名与当前要查的相当 并且之间的关系是 or 需要加'(' if (i + 1 &lt; riskDetails.size() &amp;&amp; \"or\".equals(and) &amp;&amp; key.equals(riskDetails.get(i + 1).getKey())) { condition += \" ( \"; } condition += key; if (like) { //模糊 condition += \" like '%\" + value + \"%' \"; } else { //精准 if (equal) { //等于 condition += \" = \"; } else { //不等于 condition += \" != \"; } condition += \" '\" + value + \"' \"; } //如果与下一个条件之间有连接关系 if (!(null == and || and.trim().equals(\"\"))) { condition += \" \" + and + \" \"; pre = and; } } else { // pre里面包含了上一个的关系 if (!(\"or\".equals(pre) &amp;&amp; key.equals(riskDetails.get(i - 1).getKey()))) { if (i + 1 &lt; riskDetails.size() &amp;&amp; \"or\".equals(riskDetails.get(i + 1).getAnd()) &amp;&amp; key.equals(riskDetails.get(i + 1).getKey())) { condition += \" ( \"; } } if (key == null || key.trim().equals(\"\")) { condition += \" 1 = 1 \"; break; } else { condition += key; if (like) { condition += \" like '%\" + value + \"%' \"; } else { if (equal) { condition += \" = \"; } else { condition += \" != \"; } condition += \" '\" + value + \"' \"; } } if (\"or\".equals(pre) &amp;&amp; key.equals(riskDetails.get(i - 1).getKey())) { condition += \")\"; } if (!(null == and || and.trim().equals(\"\"))) { condition += \" \" + and + \" \"; pre = and; } } } } } if(condition.trim().length == 0){ // 没有匹配到条件 默认查询所有 List&lt;RiskDetail> riskDetailList = riskDetailMapper.selectList(null); return riskDetailList; } //数据库操作 List&lt;RiskDetail> riskDetail = riskDetailMapper.selectRiskDetail(condition); return riskDetail; } 导入excel fileUtil package com.zgiot.sf.security.utils; import cn.afterturn.easypoi.excel.ExcelExportUtil; import cn.afterturn.easypoi.excel.entity.ExportParams; import cn.afterturn.easypoi.excel.entity.params.ExcelExportEntity; import com.zgiot.sf.security.entity.RiskType; import org.apache.poi.hssf.usermodel.HSSFWorkbook; import org.apache.poi.ss.usermodel.Cell; import org.apache.poi.ss.usermodel.Row; import org.apache.poi.ss.usermodel.Sheet; import org.apache.poi.ss.usermodel.Workbook; import org.apache.poi.xssf.streaming.SXSSFSheet; import org.apache.poi.xssf.streaming.SXSSFWorkbook; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import javax.servlet.http.HttpServletResponse; import java.io.IOException; import java.io.InputStream; import java.io.OutputStream; import java.io.UnsupportedEncodingException; import java.util.List; import java.util.Map; /** * @ProjectName: zx-xinwenmine-security * @Package: com.zgiot.sf.security.utils * @ClassName: FileUtils * @Author: 40971 * @Description: 用于给一切上传下载文件提供公共方法 * @Date: 2022/2/21 13:24 * @Version: 2.0 */ public class FileUtils { /** * 判断文件格式 * @param inStr * @param fileName * @return * @throws Exception */ public static Workbook getWorkbook(InputStream inStr, String fileName) throws Exception { Workbook workbook = null; if (fileName.endsWith(\"xlsx\")) { workbook = new XSSFWorkbook(inStr); } else if (fileName.endsWith(\"xls\")){ workbook = new HSSFWorkbook(inStr); } else { throw new Exception(\"请上传excel文件！\"); } return workbook; } /** * @Method 导出excel数据 (单模板或带数据) * @Author 40971 * @Param HttpServletResponse response, * @Param String fileName,文件名 * @Param List&lt;String> columnList 首列字段名, * @Param List&lt;Map&lt;String,String>> riskTypes,数据库查询的数据 * @Param String[] mapName数据取出规则 * @Date 2022/2/21 15:39 */ public static void uploadExcel(HttpServletResponse response, String fileName, List&lt;String> columnList,List&lt;Map&lt;String,Object>> riskTypes){ //声明输出流 OutputStream os = null; //设置响应头 setResponseHeader(response,fileName); try { //获取输出流 os = response.getOutputStream(); //内存中保留1000条数据，以免内存溢出，其余写入硬盘 SXSSFWorkbook wb = new SXSSFWorkbook(1000); //获取该工作区的第一个sheet Sheet sheet1 = wb.createSheet(\"sheet1\"); int excelRow = 0; //创建标题行 Row titleRow = sheet1.createRow(excelRow++); for(int i = 0;i&lt;columnList.size();i++){ //创建该行下的每一列，并写入标题数据 Cell cell = titleRow.createCell(i); cell.setCellValue(columnList.get(i)); } //设置内容行 if(riskTypes!=null &amp;&amp; riskTypes.size()>0){ extracted(columnList, riskTypes, sheet1, excelRow); } //将整理好的excel数据写入流中 wb.write(os); } catch (IOException e) { e.printStackTrace(); } finally { try { // 关闭输出流 if (os != null) { os.close(); } } catch (IOException e) { e.printStackTrace(); } } } /** * @Method 设置内容行 * @Author 40971 * @Description * @Param * @Return * @Exception * @Date 2022/2/21 16:12 */ private static void extracted(List&lt;String> columnList, List&lt;Map&lt;String, Object>> riskTypes, Sheet sheet1, int excelRow) { //序号是从1开始的 int count = 1; //外层for循环创建行 for(int i = 0; i&lt; riskTypes.size(); i++){ Row dataRow = sheet1.createRow(excelRow++); //内层for循环创建每行对应的列，并赋值 for(int j = 0; j&lt;= riskTypes.get(0).size(); j++){ Cell cell = dataRow.createCell(j); if(j==0){//第一列是序号列，不是在数据库中读取的数据，因此手动递增赋值 cell.setCellValue(count++); }else{//其余列是数据列，将数据库中读取到的数据依次赋值 //根据标题,取出map中对应的数据 if (null == riskTypes.get(i).get(columnList.get(j))){ continue; }else if (columnList.get(j).contains(\"日期\")){ cell.setCellValue(riskTypes.get(i).get(columnList.get(j)).toString().replaceAll(\"T\", \" \")); }else{ if (!riskTypes.get(i).get(columnList.get(j)).toString().contains(\"null\")) cell.setCellValue(riskTypes.get(i).get(columnList.get(j)).toString()); } } } } } /** * @Method 设置浏览器响应头 * @Author 40971 * @Param HttpServletResponse response, * @Param String fileName 文件名字 * @Date 2022/2/21 15:37 */ private static void setResponseHeader(HttpServletResponse response, String fileName) { try { try { fileName = new String(fileName.getBytes(),\"ISO8859-1\"); } catch (UnsupportedEncodingException e) { e.printStackTrace(); } response.setContentType(\"application/octet-stream;charset=UTF-8\"); response.setHeader(\"Content-Disposition\", \"attachment;filename=\"+ fileName); response.addHeader(\"Pargam\", \"no-cache\"); response.addHeader(\"Cache-Control\", \"no-cache\"); } catch (Exception ex) { ex.printStackTrace(); } } } controller @ApiOperation(\"导入Excel数据\") @PostMapping(\"/importExcel\") public ResponseMessage importExcelVal(@RequestParam(\"file\") MultipartFile file) throws Exception { if (file.isEmpty()) { return Result.error(\"文件不能为空\"); } String result=riskDetailService.importExcelVal(file); if (\"导入成功\".equals(result)) { return Result.success(\"Excel数据读取成功\"); } return Result.error(result); } serviceIpl /** * @Method 导入excel * @Author 409713427 * @Date 2022/2/23 18:14 */ @Override public String importExcelVal(MultipartFile file) { List&lt;RiskDetail> riskDetails = EasyPoiUtil.importExcel(file, 0, 1, RiskDetail.class); // System.out.println(riskDetails); for (RiskDetail riskDetail : riskDetails) { String riskType = riskDetail.getRiskType().getRiskType(); String riskDescribe = riskDetail.getRiskType().getRiskDescribe(); String hazardFactors = riskDetail.getRiskType().getHazardFactors(); QueryWrapper&lt;RiskType> wrapper = new QueryWrapper(); wrapper.eq(\"risk_type\", riskType); wrapper.eq(\"risk_describe\", riskDescribe); wrapper.eq(\"hazard_factors\", hazardFactors); List&lt;RiskType> list = riskTypeService.list(wrapper); if (!(null == list || list.size() ==0)){ riskDetail.setRiskTypeId(list.get(0).getId()); } ZxRole role = zxRoleService.getOne(new QueryWrapper&lt;ZxRole>().eq(\"name\", riskDetail.getRoleId())); riskDetail.setId(UUIDUtil.getUUID()); riskDetail.setRoleId(null == role ? \"\" : role.getId()); } boolean b = riskDetailService.saveBatch(riskDetails); if (b) return \"导入成功\"; else return \"导入失败\"; } 导出Excel controller @ApiOperation(value = \"导出风险辨识清单excel数据\") @GetMapping(value = \"/exportExcelQD\") public void exportCorpLoanDemand(HttpServletResponse response,String condition){ String[] ids = condition.split(\",\"); riskDetailService.exportExcelVal(response,ids); } serviceImpl /** * @Method 导出Excel * @Author 409713427 * @Date 2022/2/23 18:14 */ @Override public void exportExcelVal(HttpServletResponse response, String[] ids) { List&lt;String> titleList = Arrays.asList(\"序号\", \"风险点\", \"风险类型\", \"风险描述\", \"风险等级\", \"风险状态\", \"危害因素\", \"管控措施\", \"负责角色\", \"管控单位及负责人\", \"最高管控单位及负责人\", \"评估日期\", \"解决日期\", \"信息来源\"); List&lt;RiskDetail> riskDetailTypes = null; if (ids == null || ids.length &lt;= 0) { riskDetailTypes = riskDetailMapper.selectList(null); } else { QueryWrapper&lt;RiskDetail> wrapper = new QueryWrapper&lt;>(); wrapper.in(\"id\", ids); riskDetailTypes = riskDetailMapper.selectList(wrapper); } List&lt;Map&lt;String, Object>> dataList = new ArrayList&lt;>(); // 构造数据 for (RiskDetail riskDetail : riskDetailTypes) { Map&lt;String, Object> map = new HashMap&lt;>(); map.put(\"风险点\", riskDetail.getRiskPoint()); RiskType riskType = riskTypeService.selectOneRiskType(riskDetail.getRiskTypeId()); if (null != riskType) { map.put(\"风险类型\", riskType.getRiskType()); } map.put(\"风险类型\", \"\"); map.put(\"风险描述\", riskType.getRiskDescribe()); map.put(\"风险等级\", riskDetail.getRiskLevel()); map.put(\"风险状态\", riskDetail.getIsEnable()); map.put(\"危害因素\", riskType.getHazardFactors()); map.put(\"管控措施\", riskDetail.getControlMeasures()); ZxRole byId = zxRoleService.getById(riskDetail.getRoleId()); if (null != byId) { map.put(\"负责角色\", byId.getName()); } map.put(\"负责角色\", \"\"); map.put(\"管控单位及负责人\", riskDetail.getChargeUser() + \",\" + riskDetail.getCheckUser()); map.put(\"最高管控单位及负责人\", riskDetail.getHighestChargeUser()); map.put(\"评估日期\", riskDetail.getEvaluationTime()); map.put(\"解决日期\", riskDetail.getTargetTime()); map.put(\"信息来源\", riskDetail.getInfoOrigin()); dataList.add(map); } FileUtils.uploadExcel(response, \"风险辨识清单数据.xlsx\", titleList, dataList); } mysql查询年度报表 controller @ApiOperation(\"风险管控年度数据\") @GetMapping(\"/riskannualData\") public ResponseMessage selectriskannualData(@RequestParam(\"year\") String year){ Map&lt;String, Map&lt;String, Integer>> result = riskDetailService.selectriskannualData(year); return new ResponseMessage(\"200\",\"查询成功\",true,result); } serviceImpl /** * @Method 风险管控年度数据 * @Author 409713427 * @Date 2022/2/23 18:14 */ @Override public Map&lt;String,Map&lt;String,Integer>> selectriskannualData(String year) { //存放最后返回的数据容器 Map&lt;月份,Map&lt;总风险/已管控/未管控,数量>> Map&lt;String,Map&lt;String,Integer>> result = new HashMap&lt;>(); //初始化12个月数据 for (int i = 1; i &lt;= 12; i++) { HashMap&lt;String,Integer> temp = new HashMap&lt;>(); temp.put(\"总风险\",0); temp.put(\"已管控\",0); temp.put(\"未管控\",0); result.put(i+\"月\",temp); } //准备循环中需要用的变量 //当前月份 String month; //当前月份的状态 String isCheck; //当前月份未存入的值/当前月份和排查下已经存入的值 Integer num1,num2; //当前月份下的map对象 Map&lt;String, Integer> temp; //当前月管控和未管控的总数量 统计的数量 Integer total1,total2; //去数据库查数据 List&lt;RiskDetailDto> riskDetailDtos = riskDetailMapper.selectRiskAnnualData(year); for (RiskDetailDto riskDetailDto : riskDetailDtos) { /* result.put(临时对象.几月,获取已经存入的value(临时对象.几月).存入(是否管控, 之前的数量+新的数量)); * */ //当前月份 month = riskDetailDto.getMonth(); //当前月份的状态 isCheck = riskDetailDto.getIsCheck(); if (null == month || null == isCheck) continue; //当前月份未存入的值 num1 = Integer.parseInt(riskDetailDto.getNumbers()); //当前月份下的map对象 temp = result.get(month); if (null == temp) continue; //当前月份和排查下已经存入的值 num2 =temp.get(isCheck); if (null == num2) continue; //存入当前月份和状态下 统计的数量 temp.put(isCheck,num1+num2); total1 =temp.get(\"已管控\"); total2 =temp.get(\"未管控\"); temp.put(\"总风险\", total1+total2); //重新存入 result.put(month,temp); } return result; } mapper.xml &lt;select id=\"selectRiskAnnualData\" resultType=\"com.zgiot.sf.security.dto.RiskDetailDto\"> select case(DATE_FORMAT(effect_time,\"%m\")) when '01' then '1月' when '02' then '2月' when '03' then '3月' when '04' then '4月' when '05' then '5月' when '06' then '6月' when '07' then '7月' when '08' then '8月' when '09' then '9月' when '10' then '10月' when '11' then '11月' when '12' then '12月' end as month, count(1) as numbers, is_check as isCheck FROM risk_detail where DATE_FORMAT(effect_time,\"%Y\") = #{year} group by month,is_check &lt;/select> @ApiOperation(value = \"导出风险辨识清单excel数据\") @GetMapping(value = \"/exportExcelQD\") public void exportCorpLoanDemand(HttpServletResponse response,String condition){ String[] ids = condition.split(\",\"); riskDetailService.exportExcelVal(response,ids); } @ApiOperation(\"导入Excel数据\") @PostMapping(\"/importExcel\") public ResponseMessage importExcelVal(@RequestParam(\"file\") MultipartFile file) throws Exception { if (file.isEmpty()) { return Result.error(\"文件不能为空\"); } String result=riskDetailService.importExcelVal(file); if (\"导入成功\".equals(result)) { return Result.success(\"Excel数据读取成功\"); } return Result.error(result); } serviceImpl //高级检索 @Override public List&lt;RiskDetail> selectRiskDetail(List&lt;SearchVO> riskDetails) { }","categories":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"}],"tags":[{"name":"css","slug":"css","permalink":"https://409713427.github.io/tags/css/"}],"author":"wst"},{"title":"【Redis】1.Redis 简介 安装","slug":"Redis/1.Redis 简介 安装","date":"2022-02-14T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0214[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0214[object%20Object].html","excerpt":"","text":"一 NoSQL数据库简介1 技术的分类 解决功能性的问题：Java、Jsp、RDBMS、Tomcat、HTML、Linux、JDBC、SVN 解决扩展性的问题：Struts、Spring、SpringMVC、Hibernate、Mybatis 解决性能的问题：NoSQL、Java线程、Hadoop、Nginx、MQ、ElasticSearch 2 技术发展Web1.0时代 Web1.0的时代，数据访问量很有限，用一夫当关的高性能的单点服务器可以解决大部分问题Web2.0时代随着Web2.0的时代的到来，用户访问量大幅度提升，同时产生了大量的用户数据。加上后来的智能移动设备的普及，所有的互联网平台都面临了巨大的性能挑战。解决CPU及内存压力解决IO压力**3 NoSQL 数据库**NoSQL 数据库概述NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是SQL”，泛指非关系型的数据库。NoSQL 不依赖业务逻辑方式存储，而以简单的key-value模式存储。因此大大的增加了数据库的扩展能力。 不遵循 SQL 标准 不支持 ACID 远超于 SQL 的性能 **NoSQL 适用场景 ** 对数据高并发的读写 海量数据的读写 对数据高可扩展性的 NoSQL 不适用场景 需要事务支持 基于sql的结构化查询存储，处理复杂的关系，需要即席查询 用不着sql的和用了sql也不行的情况，请考虑用NoSql典型数据库Memcache | | ●很早出现的NoSql数据库●数据都在内存中，一般不持久化●支持简单的key-value模式，支持类型单一●一般是作为缓存数据库辅助持久化的数据库 || — | — | Redis | | ●几乎覆盖了Memcached的绝大部分功能●数据都在内存中，支持持久化，主要用作备份恢复●除了支持简单的key-value模式，还支持多种数据结构的存储，比如 list、set、hash、zset、hasn等●一般是作为缓存数据库辅助持久化的数据库 || — | — | MongoDB | | ●高性能、开源、模式自由(schema free)的文档型数据库●数据都在内存中， 如果内存不足，把不常用的数据保存到硬盘●虽然是key-value模式，但是对value（尤其是json）提供了丰富的查询功能●支持二进制数据及大型对象●可以根据数据的特点替代RDBMS ，成为独立的数据库。或者配合RDBMS，存储特定的数据。 || — | — | 3 行式存储数据库（大数据时代）行式数据库列式数据库HbaseHBase是Hadoop项目中的数据库。它用于需要对大量的数据进行随机、实时的读写操作的场景中。HBase的目标就是处理数据量非常庞大的表，可以用普通的计算机处理超过10亿行数据，还可处理有数百万列元素的数据表。Cassandra[kəˈsændrə]Apache Cassandra是一款免费的开源NoSQL数据库，其设计目的在于管理由大量商用服务器构建起来的庞大集群上的**海量数据集(数据量通常达到PB级别)**。在众多显著特性当中，Cassandra最为卓越的长处是对写入及读取操作进行规模调整，而且其不强调主集群的设计思路能够以相对直观的方式简化各集群的创建与扩展流程。 | 计算机存储单位 计算机存储单位一般用B，KB，MB，GB，TB，EB，ZB，YB，BB来表示，它们之间的关系是：位 bit (比特)(Binary Digits)：存放一位二进制数，即 0 或 1，最小的存储单位。字节 byte：8个二进制位为一个字节(B)，最常用的单位。1KB (Kilobyte 千字节)=1024B，1MB (Megabyte 兆字节 简称“兆”)=1024KB，1GB (Gigabyte 吉字节 又称“千兆”)=1024MB，1TB (Trillionbyte 万亿字节 太字节)=1024GB，其中1024=2^10 ( 2 的10次方)，1PB（Petabyte 千万亿字节 拍字节）=1024TB，1EB（Exabyte 百亿亿字节 艾字节）=1024PB，1ZB (Zettabyte 十万亿亿字节 泽字节)= 1024 EB,1YB (Jottabyte 一亿亿亿字节 尧字节)= 1024 ZB,1BB (Brontobyte 一千亿亿亿字节)= 1024 YB.注：“兆”为百万级数量单位。 || — | 图关系型数据库主要应用：社会关系，公共交通网络，地图及网络拓谱(n*(n-1)/2)DB-Engines 数据库排名http://db-engines.com/en/ranking二 Redis概述安装 Redis是一个开源的 **key-value **存储系统 和Memcached类似，它支持存储的value类型相对更多，包括string字符串、list链表、set集合、zsetsorted set – 有序集合和hash哈希类型 这些数据类型都支持 push/pop、add/remove及取交集并集和差集及更丰富的操作，这些操作都是原子性的 在此基础上，Redis支持各种不同方式的排序 与memcached一样，为了保证效率，数据都是缓存在内存中，区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件 并且在此基础上实现了master-slave(主从)同步 1 应用场景配合关系型数据库做高速缓存 分布式架构，做session共享 高频次，热门访问的数据，降低数据库IO 多样的数据结构存储持久化数据2 Redis安装 Redis官方网站 Redis中文官方网站 http://redis.io http://redis.cn/ 安装版本 6.2.1 for Linux（redis-6.2.1.tar.gz） 不用考虑在windows环境下对Redis的支持 安装步骤 准备工作：下载安装最新版的gcc编译器 安装C 语言的编译环境 | CentOSyum install centos-release-scl scl-utils-buildyum install -y devtoolset-8-toolchainscl enable devtoolset-8 bashUbuntuapt-get install gcc（apt-get upgrade gcc） || — | **测试 gcc 版本 ****gcc --version** 下载redis-6.2.1.tar.gz放/opt目录 解压命令：**tar -zxvf redis-6.2.1.tar.gz** 解压完成后进入目录：**cd redis-6.2.1** 在redis-6.2.1目录下再次执行 **make**命令（只是编译好） 如果没有准备好C语言编译环境，make 会报错—Jemalloc/jemalloc.h：没有那个文件 解决方案：运行 **make distclean**在redis-6.2.1目录下再次执行 **make**命令（只是编译好） 跳过make test 继续执行: **make install** 安装目录：/usr/local/bin 查看默认安装目录redis-benchmark：性能测试工具，可以在自己本子运行，看看自己本子性能如何redis-check-aof：修复有问题的aof文件，rdb和aof后面讲redis-check-dump：修复有问题的dump.rdb文件redis-sentinel：Redis集群使用redis-server：Redis服务器启动命令redis-cli：客户端，操作入口 前台启动（不推荐） redis-server前台启动，命令行窗口不能关闭，否则服务器停止 后台启动（推荐） 备份 **redis.conf**复制一份 redis.conf 到其他目录（/etc） cp /opt/redis-3.2.5/redis.conf /etc 后台启动设置**daemonize no**改成 yes修改 redis.conf (128行)文件将里面的daemonize no 改成 yes，让服务在后台启动 Redis启动**redis-server /etc/redis.conf** ps -ef|grep redis 用客户端访问：**redis-cli** 多个端口可以：**redis-cli -p6379** 测试验证： ping Redis关闭单实例关闭：redis-cli shutdown 也可以进入终端后再关闭 shutdown还可以直接杀进程 kill -9 进程号多实例关闭，指定端口关闭：redis-cli -p 6379 shutdown3 Redis介绍相关知识 | 端口6379从何而来Alessia Merz | 默认16个数据库，类似数组下标从0开始，初始默认使用0号库使用命令 **select &lt;dbid&gt;**来切换数据库。如: select 8统一密码管理，所有库同样密码。**dbsize**查看当前数据库的key的数量**flushdb **清空当前库**flushall **通杀全部库 || — | — | Redis是单线程+多路IO复用技术多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池）串行 vs 多线程+锁（memcached） vs 单线程+多路IO复用(Redis)（与Memcache三点不同: 支持多数据类型，支持持久化，单线程+多路IO复用）","categories":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"}],"author":"wst"},{"title":"【Redis】2.Redis 常用五大数据类型","slug":"Redis/2.Redis 常用五大数据类型","date":"2022-02-14T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0214[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0214[object%20Object].html","excerpt":"","text":"哪里去获得redis常见数据类型操作命令http://www.redis.cn/commands.html1 Redis键(key)**keys *** 查看当前库所有key (匹配：keys 1)**exists key** 判断某个key是否存在**type key*** **查看你的key对应的value是什么类型 **del key**** **删除指定的key数据**unlink key** 根据value选择非阻塞删除，仅将keys从keyspace元数据中删除，真正的删除在后续异步操作 **expire key 10** 10秒钟，为给定的key设置过期时间**ttl key** 查看还有多少秒过期，-1表示永不过期，-2表示已过期 **select** 命令切换数据库**dbsize** 查看当前数据库的key的数量**flushdb** 清空当前库**flushall** 通杀全部库2 Redis 字符串(string)简介 string是Redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value string类型是二进制安全的。意味着Redis的string可以包含任何数据。如jpg图片或序列化的对象 string类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M 原子性所谓原子操作是指不会被线程调度机制打断的操作这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程） 在单线程中， 能够在单条指令中完成的操作都可以认为是”原子操作”，因为中断只能发生于指令之间 在多线程中，不能被其它进程（线程）打断的操作就叫原子操作 Redis单命令的原子性主要得益于Redis的单线程案例java中的i++是否是原子操作？不是i=0;两个线程分别对i进行++100次，值是多少？2~200常用命令**set &lt;key&gt; &lt;value&gt;**** 添加或者修改键值对**setnx &lt;key&gt; &lt;value&gt;** 只有在 key 不存在时，设置 key value 的值**setex &lt;key&gt; &lt;过期时间&gt; &lt;value&gt;**设置键值的同时，设置过期时间，单位秒**NX**当数据库中key不存在时，可以将key-value添加数据库**XX**当数据库中key存在时，可以将key-value添加数据库，与NX参数互斥**EX**key的超时秒数**PX**key的超时毫秒数，与EX互斥**get &lt;key&gt;** 查询对应键值**getset &lt;key&gt; &lt;value&gt;** 以新换旧，设置了新值同时获得旧值，没有旧值报错**append &lt;key&gt; &lt;value&gt;** 将给定的 追加到原值的末尾拼成字符串**strlen &lt;key&gt;** ** 获得值的长度 **incr &lt;key&gt;** 将 key 中储存的数字值增1，只能对数字值操作，如果为空，新增值为1**decr &lt;key&gt;**** 将 key 中储存的数字值减1，只能对数字值操作，如果为空，新增值为-1**incrby / decrby &lt;key&gt; &lt;步长&gt;** **将 key 中储存的数字值增减，自定义步长 **mset &lt;key1&gt; &lt;value1&gt; &lt;key2&gt; &lt;value2&gt; ...** 同时设置一个或多个 key-value对**mget &lt;key1&gt; &lt;key2&gt; &lt;key3&gt; ...**** ** 同时获取一个或多个 value**msetnx &lt;key1&gt; &lt;value1&gt; &lt;key2&gt; &lt;value2&gt; ...**同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在才成功，否则都失败，原子性 **getrange &lt;key&gt; &lt;起始位置&gt; &lt;结束位置&gt;**获得值的范围，类似java中的substring，前包，后包**setrange &lt;key&gt; &lt;起始位置&gt; &lt;value&gt;**用覆写所储存的字符串值，从&lt;起始位置&gt;开始(索引从0开始)数据结构string的数据结构为简单动态字符串（Simple Dynamic String,缩写SDS）。是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配如图中所示，内部为当前字符串实际分配的空间 capacity，一般要高于实际字符串长度len当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间需要注意的是字符串最大长度为512M3 Redis 列表(List)简介单键多值Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。常用命令**lpush/rpush &lt;key&gt; &lt;value1&gt; &lt;value2&gt; &lt;value3&gt;...** 从左边/右边插入一个或多个值**lpop/rpop &lt;key&gt;** 从左边/右边弹出一个值。值在键在，值光键亡**rpoplpush &lt;key1&gt; &lt;key2&gt;**** 从列表右边弹出一个值，插到列表左边**lrange &lt;key&gt; &lt;start&gt; &lt;stop&gt;** 按照索引下标读取元素(从左到右) lrange mylist 0 -1 0左边第一个，-1右边第一个，（0 -1表示获取所有）****lindex &lt;key&gt; &lt;index&gt;** 按照索引下标获得元素(从左到右)**llen &lt;key&gt;** 获得列表长度 **linsert &lt;key&gt; before/after &lt;value&gt; &lt;newvalue&gt;**在的后面插入插入值**lrem &lt;key&gt; &lt;n&gt; &lt;value&gt;** 从左边删除n个value(从左到右)**lset &lt;key&gt; &lt;index&gt; &lt;value&gt;**** ** 将列表key下标为index的值替换成value 数据结构List 的数据结构为快速链表 quickList 首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是压缩列表，它将所有的元素紧挨着一起存储，分配的是一块连续的内存 当数据量比较多的时候才会改成quicklist因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。 Redis将链表和 ziplist 结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 4 Redis集合(Set) **简介Redisset对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。Redis 的Set是string类型的无序集合，它底层其实是一个value为null的hash表，所以添加，删除，查找的复杂度都是O(1)**一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变 常用命令**sadd &lt;key&gt; &lt;value1&gt; &lt;value2&gt;...**将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略**smembers &lt;key&gt;**** 取出该集合的所有值**sismember &lt;key&gt; &lt;value&gt;** 判断集合是否为含有该值，有1，没有0**scard &lt;key&gt;** 返回该集合的元素个数**srem &lt;key&gt; &lt;value1&gt; &lt;value2&gt;...** 删除集合中的某个元素**spop &lt;key&gt;** 随机从该集合中吐出一个值**srandmember &lt;key&gt; &lt;n&gt;** 随机从该集合中取出n个值。不会从集合中删除**smove &lt;source&gt; &lt;destination&gt; value** 把集合中一个值从一个集合移动到另一个集合**sinter &lt;key1&gt; &lt;key2&gt;** 返回两个集合的交集元素**sunion &lt;key1&gt; &lt;key2&gt;** 返回两个集合的并集元素**sdiff &lt;key1&gt; &lt;key2&gt;** 返回两个集合的差集元素(key1中的，不包含key2中的)数据结构Set 数据结构是 **dict字典**，字典是用哈希表**实现的Java 中 HashSet 的内部实现使用的是 HashMap，只不过所有的value都指向同一个对象Redis 的 set 结构也是一样，它的内部也使用 hash 结构，所有的value都指向同一个内部值5 Redis 哈希(Hash)简介Redis hash 是一个键值对集合Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象类似 Java 里面的 Map&lt;String, Object&gt; 用户ID为查找的key，存储的value用户对象包含姓名，年龄，生日等信息，如果用普通的key/value结构来存储主要有以下2种存储方式： | 每次修改用户的某个属性需要，先反序列化改好后再序列化回去。开销较大 | 用户ID数据冗余 || — | — | | | 通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题 || — | — | 常用命令**hset &lt;key&gt; &lt;field&gt; &lt;value&gt; &lt;field&gt; &lt;value&gt;**** 给集合中的 键赋值**hget &lt;key1&gt; &lt;field&gt;** 从集合取出 value~~hmset &lt;key1&gt;&lt;field1&gt;&lt;value1&gt;&lt;field2&gt;&lt;value2&gt;...~~~~ ~~批量设置hash的值**hexists &lt;key1&gt; &lt;field&gt;** 查看哈希表 key 中，给定域 field 是否存在**hkeys &lt;key&gt;** 列出该hash集合的所有field**hvals &lt;key&gt;** 列出该hash集合的所有value**hgetall &lt;key&gt;** 获取所有键值**hincrby &lt;key&gt; &lt;field&gt; &lt;increment&gt;** 为哈希表 key 中的域 field 的值加上增量**hsetnx &lt;key&gt; &lt;field&gt; &lt;value&gt;** 将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在 .数据结构Hash类型对应的数据结构是两种：ziplist（压缩列表），hashtable**（哈希表）。当field-value长度较短且个数较少时，使用 ziplist，否则使用 hashtable。 6 Redis有序集合 zset(sorted set) **简介Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合不同之处是有序集合的每个成员都关联了一个评分（score），这个评分被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 **因为元素是有序的，所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素访问有序集合的中间元素也是非常快的，因此你能够使用有序集合作为一个没有重复成员的智能列表常用命令**zadd &lt;key&gt; &lt;score1&gt; &lt;value1&gt; &lt;score2&gt; &lt;value2&gt; …** 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。**zrange &lt;key&gt; &lt;start&gt; &lt;stop&gt; [WITHSCORES]**返回有序集 key 中，在之间的元素，带WITHSCORES，可以让分数一起和值返回到结果集**zrangebyscore key min max [withscores] [limit offset count]**返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。**zrevrangebyscore key max min [withscores] [limit offset count]** 同上，改为从大到小排列**zincrby &lt;key&gt; &lt;increment&gt; &lt;value&gt;** 为元素的score加上增量**zrem &lt;key&gt; &lt;value&gt;**** 删除该集合下，指定值的元素**zcount &lt;key&gt; &lt;min&gt; &lt;max&gt;** 统计该集合，分数区间内的元素个数**zrank &lt;key&gt; &lt;value&gt;** **返回该值在集合中的排名，从0开始。案例：如何利用zset实现一个文章访问量的排行榜？数据结构SortedSet（zset）是Redis 提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map&lt;String, Double&gt;，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。zset底层使用了两个数据结构 hash，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值 跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表 跳跃表（跳表）简介 有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；链表查询需要遍历所有效率低；平衡树或红黑树虽然效率高但结构复杂；Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单。实例 对比有序链表和跳跃表，从链表中查询出51 有序链表 要查找值为51的元素，需要从第一个元素开始依次查找、比较才能找到。共需要6次比较。 跳跃表 从第2层开始，1节点比51节点小，向后比较21节点比51节点小，继续向后比较，后面就是NULL了，所以从21节点向下到第1层在第1层，41节点比51节点小，继续向后，61节点比51节点大，所以从41向下在第0层，51节点为要查找的节点，节点被找到，共查找4次。 从此可以看出跳跃表比有序链表效率要高","categories":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"}],"author":"wst"},{"title":"【Redis】3.Redis 配置文件 发布和订阅","slug":"Redis/3.Redis 配置文件 发布和订阅","date":"2022-02-14T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0214[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0214[object%20Object].html","excerpt":"","text":"四 Redis 配置文件介绍自定义目录：/etc/redis.conf 1 Units单位配置大小单位，开头定义了一些基本的度量单位，只支持bytes，不支持bit大小写不敏感2 INCLUDES包含类似jsp中的**include**，多实例的情况可以把公用的配置文件提取出来3 网络相关配置bind默认情况**bind 127.0.0.1** 只能接受本机的访问请求不写的情况下，无限制接受任何ip地址的访问生产环境肯定要写你应用服务器的地址；服务器是需要远程访问的，所以需要将其注释掉如果开启了**protected-mode** yes，那么在没有设定bind ip且没有设密码的情况下，Redis只允许接受本机的响应，改为**protected-mode no**保存配置，停止服务，重启启动查看进程，不再是本机访Port端口号，默认 **port **6379**tcp-backlog**设置tcp的 backlog，backlog 其实是一个连接队列，backlog队列总和 = 未完成三次握手队列 + 已经完成三次握手队列在高并发环境下你需要一个高 backlog 值来避免慢客户端连接问题注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值（128），所以需要确认增大/proc/sys/net/core/somaxconn和/proc/sys/net/ipv4/tcp_max_syn_backlog（128）两个值来达到想要的效果**timeout**一个空闲的客户端维持多少秒会关闭，0表示关闭该功能，即永不关闭**tcp-keepalive**对访问客户端的一种心跳检测，每个n秒检测一次单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成604 GENERAL通用**daemonize**是否为后台进程，设置为yes守护进程，后台启动**pidfile**存放pid文件的位置，每个实例会产生一个不同的pid文件，保存有进程号**loglevel**指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为notice四个级别根据使用阶段来选择，生产环境选择 notice 或者 warning**logfile**设置日志文件路径**databases 16**设定库的数量 默认16，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id5 SECURITY安全设置密码 **requirepass**访问密码的查看、设置和取消在命令中设置密码，只是临时的。重启redis服务器，密码就还原了。永久设置，需要再配置文件中进行设置。6 LIMITS限制**maxclients** 设置redis同时可以与多少个客户端进行连接 默认情况下为10000个客户端 如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应 **maxmemory** 建议必须设置，否则，将内存占满，造成服务器宕机 设置 redis 可以使用的内存量。一旦到达内存使用上限，redis 将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。 如果redis无法根据移除规则来移除内存中的数据，或者设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。 但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的redis是主redis（说明你的redis有从redis），那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。 **maxmemory-policy** volatile-lru：使用LRU算法移除key，只对设置了过期时间的键；（最近最少使用） allkeys-lru：在所有集合key中，使用LRU算法移除key volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键 allkeys-random：在所有集合key中，移除随机的key volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key noeviction：不进行移除。针对写操作，只是返回错误信息 **maxmemory-samples** 设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU的那个。 一般设置3到7的数字，数值越小样本越不准确，但性能消耗越小 五 Redis 的发布和订阅1 什么是发布和订阅Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。Redis 客户端可以订阅任意数量的频道。2 Redis的发布和订阅 客户端可以订阅频道如下图，一个发布者可以有多个频道 当给这个频道发布消息后，消息就会发送给订阅的客户端 3 发布订阅命令行实现 打开一个客户端订阅channel1**subscribe channel1** 打开另一个客户端，给channel1发布消息hello**publish channel1 hello** 返回的1是订阅者数量 打开第一个客户端可以看到发送的消息 注：发布的消息没有持久化，如果在订阅的客户端收不到hello，只能收到订阅后发布的消息","categories":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"}],"author":"wst"},{"title":"【Redis】6.Redis 事务","slug":"Redis/5.Redis 与 Spring Boot 整合","date":"2022-02-14T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0214[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0214[object%20Object].html","excerpt":"","text":"八 Redis 与 Spring Boot 整合SpringBoot整合Redis非常简单，只需要按如下步骤整合即可整合步骤 在pom.xml文件中引入redis相关依赖 &lt;!-- redis --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> &lt;!-- spring2.X集成 redis所需common-pool2--> &lt;dependency> &lt;groupId>org.apache.commons&lt;/groupId> &lt;artifactId>commons-pool2&lt;/artifactId> &lt;version>2.6.0&lt;/version> &lt;/dependency> application.properties 配置 redis配置| #Redis服务器地址spring.redis.host=192.168.199.200#Redis服务器连接端口spring.redis.port=6379#Redis数据库索引（默认为0）spring.redis.database= 0#连接超时时间（毫秒）spring.redis.timeout=1800000#连接池最大连接数（使用负值表示没有限制）spring.redis.lettuce.pool.max-active=20#最大阻塞等待时间(负数表示没限制)spring.redis.lettuce.pool.max-wait=-1#连接池中的最大空闲连接spring.redis.lettuce.pool.max-idle=5#连接池中的最小空闲连接spring.redis.lettuce.pool.min-idle=0 || — | 添加redis配置类 @EnableCaching @Configuration public class RedisConfig extends CachingConfigurerSupport { @Bean public RedisTemplate&lt;String, Object> redisTemplate(RedisConnectionFactory factory) { RedisTemplate&lt;String, Object> template = new RedisTemplate&lt;>(); RedisSerializer&lt;String> redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setConnectionFactory(factory); // key序列化方式 template.setKeySerializer(redisSerializer); // value序列化 template.setValueSerializer(jackson2JsonRedisSerializer); // value hashmap序列化 template.setHashValueSerializer(jackson2JsonRedisSerializer); return template; } @Bean public CacheManager cacheManager(RedisConnectionFactory factory) { RedisSerializer&lt;String> redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);//解决查询缓存转换异常的问题 ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); // 配置序列化（解决乱码的问题）,过期时间600秒 jackson2JsonRedisSerializer.setObjectMapper(om); RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofSeconds(600)) .serializeKeysWith(RedisSerializationContext.SerializationPair .fromSerializer(redisSerializer)) .serializeValuesWith(RedisSerializationContext.SerializationPair .fromSerializer(jackson2JsonRedisSerializer)) .disableCachingNullValues(); RedisCacheManager cacheManager = RedisCacheManager.builder(factory).cacheDefaults(config).build(); return cacheManager; } } 测试一下RedisTestController中添加测试方法 @RestController @RequestMapping(\"/redisTest\") public class RedisTestController { @Autowired private RedisTemplate redisTemplate; @GetMapping public String testRedis() { // 设置值到redis redisTemplate.opsForValue().set(\"name\",\"lucy\"); // 从redis获取值 String name = (String)redisTemplate.opsForValue().get(\"name\"); return name; } }","categories":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"}],"author":"wst"},{"title":"【Redis】4.Redis 新数据类型 Redis Jedis","slug":"Redis/4.Redis 新数据类型 Redis Jedis","date":"2022-02-14T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0214[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0214[object%20Object].html","excerpt":"","text":"六 Redis 新数据类型1 Bitmaps简介现代计算机用二进制（位）作为信息的基础单位， 1个字节等于8位， 例如”abc”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， “abc”分别对应的ASCII码分别是97、 98、 99， 对应的二进制分别是01100001、01100010、01100011，如下图合理地使用操作位能够有效地提高内存使用率和开发效率，Redis 提供了Bitmaps这个“数据类型”可以实现对位的操作 Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作 Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量 命令 **setbit &lt;key&gt; &lt;offset&gt; &lt;value&gt;** 设置Bitmaps中某个偏移量的值（0或1） *offset:偏移量从0开始实例每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id设置键的第offset个位的值（从0算起） ， 假设现在有20个用户，userid=1， 6， 11， 15， 19的用户对网站进行了访问， 那么当前Bitmaps初始化结果如图unique:users:20200101代表2020-01-01这天的独立访问用户的Bitmaps注很多应用的用户 id 以一个指定数字（例如10000） 开头， 直接将用户id和Bitmaps的偏移量对应势必会造成一定的浪费， 通常的做法是每次做setbit操作时将用户id减去这个指定数字。在第一次初始化Bitmaps时， 假如偏移量非常大， 那么整个初始化过程执行会比较慢， 可能会造成Redis的阻塞 **getbit &lt;key&gt; &lt;offset&gt;** 获取Bitmaps中某个偏移量的值实例 获取id=1、2、8的用户是否在2020-01-01这天访问过， 返回0说明没有访问过注：因为100根本不存在，所以也是返回0 **bitcount &lt;key&gt; [start end]** 统计字符串从 start 字节到 end 字节比特值为1的数量++实例 计算2021-01-01这天的独立访问用户数bit start 和 end 代表起始和结束字节数，下面操作计算用户 id 在第1个字节到第3个字节之间的独立访问用户数， 对应的用户id是11， 15， 19。举例：K1 【01000001 01000000 00000000 00100001】，对应【0，1，2，3】bitcount K1 1 2：统计下标1、2字节组中bit=1的个数，即01000000 00000000–bitcount K1 1 2 –》1bitcount K1 1 3 ：统计下标1、2字节组中bit=1的个数，即01000000 00000000 00100001–》bitcount K1 1 3 –》3bitcount K1 0 -2 ：统计下标0到下标倒数第2，字节组中bit=1的个数，即0100000101000000 00000000–》bitcount K1 0 -2 –》3注意：redis的setbit设置或清除的是bit位置，而bitcount计算的是byte位置。 **bitop and(or/not/xor) &lt;destkey&gt; [key…]**bitop是一个复合操作， 它可以做多个Bitmaps的and（交集） 、 or（并集） 、 not（非） 、 xor（异或） 操作并将结果保存在destkey中。实例 2020-11-04 日访问网站的userid=1,2,5,9。setbit unique:users:20201104 1 1setbit unique:users:20201104 2 1setbit unique:users:20201104 5 1setbit unique:users:20201104 9 12020-11-03 日访问网站的userid=0,1,4,9。setbit unique:users:20201103 0 1setbit unique:users:20201103 1 1setbit unique:users:20201103 4 1setbit unique:users:20201103 9 1计算出两天都访问过网站的用户数量bitop and unique:users:and:20201104_03unique:users:20201103unique:users:20201104计算出任意一天都访问过网站的用户数量（例如月活跃就是类似这种） ， 可以使用or求并集Bitmaps与set对比假设网站有1亿用户， 每天独立访问的用户有5千万， 如果每天用set类型和Bitmaps分别存储活跃用户可以得到表 set和Bitmaps存储一天活跃用户对比 数据类型 每个用户id占用空间 需要存储的用户量 全部内存量 集合类型 64位 50000000 64位*50000000 = 400MB Bitmaps 1位 100000000 1位*100000000 = 12.5MB 很明显， 这种情况下使用Bitmaps能节省很多的内存空间， 尤其是随着时间推移节省的内存还是非常可观的 set和Bitmaps存储独立用户空间对比 数据类型 一天 一个月 一年 集合类型 400MB 12GB 144GB Bitmaps 12.5MB 375MB 4.5GB 但Bitmaps并不是万金油， 假如该网站每天的独立访问用户很少， 例如只有10万（大量的僵尸用户） ， 那么两者的对比如下表所示， 很显然， 这时候使用Bitmaps就不太合适了， 因为基本上大部分位都是0 set和Bitmaps存储一天活跃用户对比（独立用户比较少） 数据类型 每个userid占用空间 需要存储的用户量 全部内存量 集合类型 64位 100000 64位*100000 = 800KB Bitmaps 1位 100000000 1位*100000000 = 12.5MB 2 HyperLogLog简介在工作当中，我们经常会遇到与统计相关的功能需求，比如统计网站PV（PageView页面访问量）,可以使用Redis的 incr、incrby 轻松实现。但像UV（UniqueVisitor，独立访客）、独立IP数、搜索记录数等需要去重和计数的问题如何解决？这种求集合中不重复元素个数的问题称为基数问题 解决基数问题有很多种方案 数据存储在 MySQL 表中，使用 distinct count 计算不重复个数 使用 Redis 提供的 hash、set、bitmaps 等数据结构来处理 以上的方案结果精确，但随着数据不断增加，导致占用空间越来越大，对于非常大的数据集是不切实际的能否能够降低一定的精度来平衡存储空间？Redis推出了 HyperLogLog Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。什么是基数?比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。命令 pfadd**pfadd &lt;key&gt; &lt;element&gt; [element ...]** 添加指定元素到 HyperLogLog 中实例 将所有元素添加到指定HyperLogLog数据结构中。如果执行命令后HLL估计的近似基数发生变化，则返回1，否则返回 pfcount**pfcount &lt;key&gt; [key ...]** 返回统计数量 计算HLL的近似基数，可以计算多个HLL，比如用HLL存储每天的UV，计算一周的UV可以使用7天的UV合并计算即可实例 pfmerge**pfmerge &lt;destkey&gt; &lt;sourcekey&gt; [sourcekey ...]** 将一个或多个HLL合并后的结果存储在另一个HLL中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得实例3 Geospatial简介Redis 3.2 中增加了对 GEO 类型的支持。GEO（Geographic）地理信息的缩写。该类型就是元素的2维坐标，在地图上就是经纬度。redis 基于该类型，提供了经纬度设置、查询、范围查询，距离查询，经纬度 Hash 等常见操作命令 **geoadd &lt;key&gt; &lt;longitude&gt; &lt;latitude&gt; &lt;member&gt; [longitude latitude member...]** 添加地理位置（经度，纬度，名称）实例geoadd china:city 121.47 31.23 shanghaigeoadd china:city 106.50 29.53 chongqing 114.05 22.52 shenzhen 116.38 39.90 beijing两极无法直接添加，一般会下载城市数据，直接通过 Java 程序一次性导入有效的经度从 -180 度到 180 度。有效的纬度从 -85.05112878 度到 85.05112878 度当坐标位置超出指定范围时，该命令将会返回一个错误已经添加的数据，是无法再次往里面添加的 **geopos &lt;key&gt; &lt;member&gt; [member...]** 获得指定地区的坐标值实例 **geodist &lt;key&gt; &lt;member1&gt; &lt;member2&gt; [m|km|ft|mi]**获取两个位置之间的直线距离实例 获取两个位置之间的直线距离 单位m 表示单位为米[默认值]km 表示单位为千米ft 表示单位为英尺mi 表示单位为英里如果用户没有显式地指定单位参数， 那么 GEODIST 默认使用米作为单位 georadius**georadius &lt;key&gt; &lt;longitude&gt; &lt;latitude&gt; radius m|km|ft|mi** 以给定的经纬度为中心，找出某一半径内的元素经度 纬度 距离 单位实例七 Redis Jedis 测试1 Jedis 所需要的jar包 &lt;dependency> &lt;groupId>redis.clients&lt;/groupId> &lt;artifactId>jedis&lt;/artifactId> &lt;version>3.2.0&lt;/version> &lt;/dependency> **2 连接Redis注意事项**禁用Linux的防火墙redis.conf 中注释掉 bind 127.0.0.1 , 设置 protected-mode noLinux(CentOS7)里执行命令** systemctl stop/disable firewalld.service**ubuntu**ufw status **查看防火墙**ufw disable **关闭防火墙**ufw enable **开启防火墙ufw allow 6379 开放6379端口3 Jedis常用操作创建动态的工程创建测试程序 public static void main(String[] args) { // 创建Jedis对象 参数redis主机的ip和port Jedis jedis = new Jedis(\"192.168.199.200\", 6379); String ping = jedis.ping(); System.out.println(ping); } // 操作key string @Test public void test() { Jedis jedis = new Jedis(\"192.168.199.200\", 6379); jedis.set(\"name\", \"lucy\"); String name = jedis.get(\"name\"); System.out.println(name); // 设置多个key-value jedis.mset(\"k1\", \"v1\", \"k2\", \"v2\"); List&lt;String> mget = jedis.mget(\"k1\", \"k2\"); System.out.println(mget); Set&lt;String> keys = jedis.keys(\"*\"); for (String key : keys) { System.out.println(key); } } // 操作list @Test public void demo2() { Jedis jedis = new Jedis(\"192.168.199.200\",6379); jedis.lpush(\"key1\",\"lucy\",\"mary\",\"jack\"); List&lt;String> values = jedis.lrange(\"key1\", 0, -1); System.out.println(values); jedis.close(); } // 操作set @Test public void demo3() { Jedis jedis = new Jedis(\"192.168.199.200\",6379); jedis.sadd(\"names\",\"lucy\", \"mary\"); jedis.sadd(\"names\",\"mary\"); Set&lt;String> names = jedis.smembers(\"names\"); System.out.println(names); jedis.close(); } // 操作hash @Test public void demo4() { Jedis jedis = new Jedis(\"192.168.199.200\",6379); jedis.hset(\"users\",\"age\",\"20\"); String hget = jedis.hget(\"users\", \"age\"); System.out.println(hget); jedis.close(); } // 操作zset @Test public void demo5() { Jedis jedis = new Jedis(\"192.168.199.200\",6379); jedis.zadd(\"china\",100d,\"shanghai\"); Set&lt;String> china = jedis.zrange(\"china\", 0, -1); System.out.println(china); jedis.close(); } 4 Redis Jedis 实例完成一个手机验证码功能 要求 输入手机号，点击发送后随机生成6位数字码，2分钟有效 输入验证码，点击验证，返回成功或失败 每个手机号每天只能输入3次 public class PhoneCode { public static void main(String[] args) { verifyCode(\"13677778888\"); // getRedisCode(\"13677778888\", \"929013\"); } // 1 生成6位数字验证码 public static String getCode() { Random random = new Random(); String code = \"\"; for (int i = 0; i &lt; 6; i++) { code += random.nextInt(10); } return code; } // 2 每个手机每天只能发送三次，验证码放到redis中，设置过期时间120 public static void verifyCode(String phone) { // 连接redis Jedis jedis = new Jedis(\"192.168.199.200\", 6379); // 拼接key // 手机发送次数key String countKey = \"VerifyCode\" + phone + \":count\"; // 验证码key String codeKey = \"VerifyCode\" + phone + \":code\"; // 每个手机每天只能发送三次 String count = jedis.get(countKey); if (count == null) { // 没有发送次数，第一次发送 // 设置发送次数是1 jedis.setex(countKey, 24 * 60 * 60, \"1\"); } else if (Integer.parseInt(count) &lt;= 2) { // 发送次数+1 jedis.incr(countKey); } else { // 发送三次，不能再发送 System.out.println(\"今天发送次数已经超过三次\"); jedis.close(); } // 发送验证码放到redis里面 String vcode = getCode(); jedis.setex(codeKey, 120, vcode); jedis.close(); } // 3 验证码校验 public static void getRedisCode(String phone, String code) { // 连接redis Jedis jedis = new Jedis(\"192.168.199.200\", 6379); // 获取验证码key String codeKey = \"VerifyCode\" + phone + \":code\"; String redisCode = jedis.get(codeKey); // 判断 if (code.equals(redisCode)) { System.out.println(\"成功\"); } else { System.out.println(\"失败\"); } jedis.close(); } }","categories":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"}],"author":"wst"},{"title":"【Redis】6.Redis 事务","slug":"Redis/6.Redis 事务","date":"2022-02-14T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0214[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0214[object%20Object].html","excerpt":"","text":"九 Redis 事务 锁机制 秒杀1 Redis 的事务定义Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。Redis事务的主要作用就是串联多个命令防止别的命令插队2 Multi Exec discard从输入**Multi**命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入**Exec**后，Redis会将之前的命令队列中的命令依次执行，组队的过程中可以通过**discard**来放弃组队。 组队成功，提交成功放弃组队3 事务的错误处理组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚 组队阶段报错，提交失败组队成功，提交有成功有失败情况4 为什么要做成事务想想一个场景：很多人有你的账户，同时去参加双十一抢购 5 事务冲突的问题例子一个请求想给金额减8000一个请求想给金额减5000一个请求想给金额减1000悲观锁 悲观锁（Pessimistic Lock）顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁，读锁，写锁等，都是在做操作之前先上锁 乐观锁 乐观锁（Optimistic Lock）顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis 就是利用这种 check-and-set 机制实现事务的 **watch key [key ...]**在执行multi之前，先执行watch key1 [key2]，可以监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断下图一个执行成功，另一个因为被打断失败**unwatch**取消 WATCH 命令对所有 key 的监视如果在执行 WATCH 命令之后，EXEC命令或 DISCARD命令先被执行了的话，那么就不需要再执行UNWATCHhttp://doc.redisfans.com/transaction/exec.html 6 Redis 事务三特性 单独的隔离操作事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行 **不保证原子性 **事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 十 Redis 事务 秒杀案例1 解决计数器和人员记录的事务操作2 Redis事务–秒杀并发模拟使用工具ab模拟测试CentOS6 默认安装 CentOS7需要手动安装联网：yum install httpd-tools无网络 进入cd /run/media/root/CentOS 7 x86_64/Packages（路径跟centos6不同） 顺序安装apr-1.4.8-3.el7.x86_64.rpmapr-util-1.5.2-6.el7.x86_64.rpmhttpd-tools-2.4.6-67.el7.centos.x86_64.rpm 测试及结果通过ab测试vim postfile 模拟表单提交参数,以&amp;符号结尾;存放当前目录。内容：prodid=0101&amp;ab -n 2000 -c 200 -k -p ~/postfile -T application/x-www-form-urlencoded http://192.168.199.132:8080/Seckill/doseckill超卖 3 超卖问题4 利用乐观锁淘汰用户，解决超卖问题连接超时，通过连接池解决连接池节省每次连接 redis 服务带来的消耗，把连接好的实例反复利用，通过参数管理连接的行为代码见项目中 链接池参数 MaxTotal：控制一个pool可分配多少个jedis实例，通过pool.getResource()来获取；如果赋值为-1，则表示不限制；如果pool已经分配了MaxTotal个jedis实例，则此时pool的状态为exhausted maxIdle：控制一个pool最多有多少个状态为idle(空闲)的jedis实例 MaxWaitMillis：表示当borrow一个jedis实例时，最大的等待毫秒数，如果超过等待时间，则直接抛JedisConnectionException testOnBorrow：获得一个jedis实例的时候是否检查连接可用性（ping()）；如果为true，则得到的jedis实例均是可用的 | //秒杀过程public static boolean doSecKill(String uid, String prodid)throws IOException { // 1 uid和prodid非空判断if (uid == null &#124;&#124; prodid == null) {return false;} // 2 连接redis// Jedis jedis = new Jedis(“192.168.199.200”,6379);// 通过连接池得到jedis对象 JedisPooljedisPoolInstance =JedisPoolUtil.getJedisPoolInstance();Jedis jedis = jedisPoolInstance.getResource(); // 3 拼接key// 3.1 库存keyString kcKey = “sk:” + prodid + “:qt”;// 3.2 秒杀成功用户keyString userKey = “sk:” + prodid + “:user”; // 监视库存jedis.watch(kcKey); // 4 获取库存，如果库存null，秒杀还没有开始String kc = jedis.get(kcKey);if (kc == null) {System.out.println(“秒杀还没有开始，请等待”);jedis.close();return false;} // 5 判断用户是否重复秒杀操作if (jedis.sismember(userKey, uid)) {System.out.println(“已经秒杀成功了，不能重复秒杀”);jedis.close();return false;} // 6 判断如果商品数量，库存数量小于1，秒杀结束if (Integer.parseInt(kc) &lt;= 0) {System.out.println(“秒杀已经结束了”);jedis.close();return false;} // 7 秒杀过程// 使用事务Transaction multi = jedis.multi(); // 组队操作multi.decr(kcKey);multi.sadd(userKey, uid); // 执行List results = multi.exec();if (results == null &#124;&#124; results.size() == 0) {System.out.println(“秒杀失败了！！”); jedis.close();return false;} // 7.1 库存-1// jedis.decr(kcKey);// 7.2 把秒杀成功用户添加清单里面// jedis.sadd(userKey, uid); System.out.println(“秒杀成功！！！！”);jedis.close();return true;} | || — | — | 5 继续增加并发测试继续测试ab -n 2000 -c 200 -k -p postfile -T ‘application/x-www-form-urlencoded’ http://192.168.199.200:8080/seckill/doseckill增加-r参数，-r Don’t exit on socket receive errors.ab -n 2000 -c 100 -r -p postfile -T ‘application/x-www-form-urlencoded’ http://192.168.140.1:8080/seckill/doseckill已经秒光，可是还有库存ab -n 2000 -c 100 -p postfile -T ‘application/x-www-form-urlencoded’ http://192.168.137.1:8080/seckill/doseckill已经秒光，可是还有库存原因，就是乐观锁导致很多请求都失败。先点的没秒到，后点的可能秒到了6 解决库存遗留问题LUA脚本Lua 是一个小巧的脚本语言，Lua脚本可以很容易的被C/C++ 代码调用，也可以反过来调用C/C++的函数，Lua并没有提供强大的库，一个完整的Lua解释器不过200k，所以Lua不适合作为开发独立应用程序的语言，而是作为嵌入式脚本语言。很多应用程序、游戏使用LUA作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。这其中包括魔兽争霸地图、魔兽世界、博德之门、愤怒的小鸟等众多游戏插件或外挂。https://www.w3cschool.cn/lua/LUA脚本在Redis中的优势将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数，提升性能。LUA 脚本是类似 redis 事务，有一定的原子性，不会被其他命令插队，可以完成一些redis事务性的操作。但是注意redis的lua脚本功能，只有在 Redis 2.6 以上的版本才可以使用。利用lua脚本淘汰用户，解决超卖问题。redis 2.6 版本以后，通过lua脚本解决争抢问题，实际上是redis 利用其单线程的特性，用任务队列的方式解决多任务并发问题。7 Redis_事务_秒杀案例_代码项目结构**第一版：简单版 **老师点10次，正常秒杀；同学一起点试一试，秒杀也是正常的；这是因为还达不到并发的效果使用工具ab模拟并发测试，会出现超卖情况。查看库存会出现负数第二版：加事务-乐观锁(解决超卖)，但出现遗留库存和连接超时第三版：连接池解决超时问题，但有剩余第四版：解决库存依赖问题，LUA脚本 local userid=KEYS[1]; local prodid=KEYS[2]; local qtkey=\"sk:\"..prodid..\":qt\"; local usersKey=\"sk:\"..prodid.\":usr'; local userExists=redis.call(\"sismember\",usersKey,userid); if tonumber(userExists)==1 then return 2; end local num= redis.call(\"get\" ,qtkey); if tonumber(num)&lt;=0 then return 0; else redis.call(\"decr\",qtkey); redis.call(\"sadd\",usersKey,userid); end return 1;","categories":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"}],"author":"wst"},{"title":"【Redis】7.Redis 持久化 主从复制","slug":"Redis/7.Redis 持久化 主从复制","date":"2022-02-14T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0214[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0214[object%20Object].html","excerpt":"","text":"十一 Redis 持久化之 RDB官网介绍：http://www.redis.ioRedis 提供了2个不同形式的持久化方式 RDB（Redis DataBase） AOF（Append Of File） 1 RDB（Redis DataBase）在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，恢复时是将快照文件直接读到内存里配置dump.rdb文件 在 redis.conf 中配置文件名称，默认为**dump.rdb**配置位置rdb文件的保存路径，默认为 Redis 启动时命令行所在的目录下 ./也可以修改 dir “/usr/local/bin”如何触发RDB快照，保持策略 配置文件中默认的快照配置**Save**格式：**save 秒钟 写操作次数**RDB是整个内存的压缩过的Snapshot，RDB的数据结构，可以配置复合的快照触发条件默认是1分钟内改了1万次，或5分钟内改了10次，或15分钟内改了1次禁用：不设置save指令，或者给save传入空字符串 命令save VS bgsavesavesave 时只管保存，其它不管，全部阻塞，手动保存，不建议bgsaveRedis会在后台异步进行快照操作， 快照同时还可以响应客户端请求可以通过 **lastsave**命令获取最后一次成功执行快照的时间flushall 命令 执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义**stop-writes-on-bgsave-error** 当Redis无法写入磁盘的话，直接关掉Redis的写操作，推荐 yes**rdbcompression**压缩文件对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能。推荐 yes**rdbchecksum**检查完整性在存储快照后，还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能，推荐 yes备份Redis会单独创建一个子进程（fork）来进行持久化先将数据写入到 一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效 RDB的缺点是最后一次持久化后的数据可能丢失 Fork Fork的作用是复制一个与当前进程一样的进程，新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程 在Linux程序中，fork()会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，Linux中引入了“写时复制技术” 一般情况父进程和子进程会共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程 RDB持久化流程 RDB的备份 先通过 **config get dir**查询rdb文件的目录 将 *.rdb 的文件拷贝到别的地方 RDB的恢复 关闭 Redis 先把备份的文件拷贝到工作目录下 cp dump2.rdb dump.rdb 启动Redis，备份数据会直接加载 优势 适合大规模的数据恢复 对数据完整性和一致性要求不高更适合使用 节省磁盘空间 恢复速度快 劣势 Fork 的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑 虽然 Redis 在 fork 时使用了写时复制技术，但是如果数据庞大时还是比较消耗性能 在备份周期在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢失最后一次快照后的所有修改 如何停止 动态停止RDBredis-cli config set save &quot;&quot;save后给空值，表示禁用保存策略小总结2 AOF（Append Only File）以日志的形式来记录每个写操作（增量保存），将 Redis 执行过的所有写指令记录下来(读操作不记录)， 只许追加文件但不可以改写文件，redis 启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作AOF持久化流程 客户端的请求写命令会被 **append **追加到AOF缓冲区内 AOF缓冲区根据AOF持久化策略 [always, everysec, no] 将操作 **sync **同步到磁盘的AOF文件中 AOF文件大小超过重写策略或手动重写时，会对 AOF文件 **rewrite **重写，压缩AOF文件容量 Redis 服务重启时，会重新 **load **加载 AOF文件中的写操作达到数据恢复的目的 配置AOF开启AOF默认不开启，**appendonly **no，改为 **yes **开启可以在redis.conf中配置文件名称**appendfilename**，默认为 appendonly.aofAOF文件的保存路径，同 RDB 的路径一致**AOF**和**RDB**同时开启，redis听谁的？ AOF 和 RDB 同时开启，系统默认取 **AOF **的数据（数据不会存在丢失）AOF启动/修复/恢复 AOF的备份机制和性能虽然和RDB不同, 但是备份和恢复的操作同RDB一样，都是拷贝备份文件，需要恢复时再拷贝到Redis工作目录下，启动系统即加载 正常恢复 修改默认的appendonly no，改为 yes 将有数据的aof文件复制一份保存到对应目录（查看目录：config get dir） 恢复：重启redis然后重新加载 异常恢复 修改默认的appendonly no，改为yes 如遇到AOF文件损坏，客户端连接会被拒绝，通过/usr/local/bin/redis-check-aof–fix appendonly.aof进行恢复 备份被写坏的AOF文件 恢复：重启redis，然后重新加载 AOF同步频率设置** appendfsync always** 始终同步，每次Redis的写入都会立刻记入日志，性能较差但数据完整性比较好** appendfsync everysec** 每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失** appendfsync no** redis 不主动进行同步，把同步时机交给操作系统Rewrite压缩 是什么AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制, 当AOF文件的大小超过所设定的阈值时，Redis 就会启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集.可以使用命令**bgrewriteaof** 重写原理，如何实现重写AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)redis4.0版本后的重写，是指上就是把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作**no-appendfsync-on-rewrite** 如果 no-appendfsync-on-rewrite=yes，不写入aof文件只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高性能）如果 no-appendfsync-on-rewrite=no, 还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞（数据安全，但是性能降低）触发机制，何时压缩Redis 会记录上次重写时的 AOF 大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发重写虽然可以节约大量磁盘空间，减少恢复时间。但是每次重写还是有一定的负担的，因此设定Redis要满足一定条件才会进行重写**auto-aof-rewrite-percentage**设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发）**auto-aof-rewrite-min-size**设置重写的基准值，最小文件64MB。达到这个值开始重写例如：文件达到70MB开始重写，降到50MB，下次什么时候开始重写？100MB系统载入时或者上次重写完毕时，Redis会记录此时AOF大小，设为base_size,如果Redis的AOF当前大小&gt;= base_size +base_size*100% (默认)且当前大小&gt;=64mb(默认)的情况下，Redis会对AOF进行重写 重写流程 bgrewriteaof 触发重写，判断是否当前有 **bgsave **或 **bgrewriteaof **在运行，如果有，则等待该命令结束后再继续执行 主进程fork出子进程执行重写操作，保证主进程不会阻塞 子进程遍历redis内存中数据到临时文件，客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。 1).子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。2).主进程把aof_rewrite_buf中的数据写入到新的AOF文件 使用新的AOF文件覆盖旧的AOF文件，完成AOF重写 优势 备份机制更稳健，丢失数据概率更低 可读的日志文本，通过操作AOF稳健，可以处理误操作 劣势 比起RDB占用更多的磁盘空间 恢复备份速度要慢 每次读写都同步的话，有一定的性能压力 存在个别Bug，造成恢复不能 小总结3 总结(Which one)用哪个好官方推荐两个都启用如果对数据不敏感，可以选单独用RDB不建议单独用AOF，因为可能会出现 Bug如果只是做纯内存缓存，可以都不用官网建议 RDB 持久化方式能够在指定的时间间隔对你的数据进行快照存储 AOF 持久化方式记录每次对服务器写的操作，当服务器重启的时候，会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾 Redis 还能对 AOF 文件进行后台重写，使得AOF文件的体积不至于过大 只做缓存：如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式 同时开启两种持久化方式 在这种情况下，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整 RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？ 建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)， 快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段 性能建议| 因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则如果使用AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了代价：一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到 **5G **以上默认超过原大小100%大小时重写可以改到适当的数值 || — | 十二 Redis 主从复制1 是什么主机数据更新后根据配置和策略， 自动同步到备机的 master/slaver机制，Master以写为主，Slave以读为主2 能干嘛 读写分离，性能扩展 容灾快速恢复 3 主从复制 创建 /myredis 文件夹，mkdir /myredis 复制 redis.conf 文件到 /myredis 文件夹中，cp /etc/redis.conf /myredis/redis.conf 配置一主两从，需要三个配置文件redis6379.confredis6380.confredis6381.conf 在三个配置文件中写入内容redis.conf 关掉aof（或者换名字） appendonly no，开启守护 daemonize yes新建redis6379.conf，填写以下内容 vim redis6379.conf include /myredis/redis.confpidfile /var/run/redis_6379.pid #Pid文件名字pidfileport 6379 #指定端口portdbfilename dump6379.rdb #dump.rdb名字dbfilename类似方式创建redis6380.conf redis6381.conf 启动三台redis服务器 查看系统进程，看看三台服务器是否启动查看三台主运行情况**info replication**查看主从复制的相关信息 配从(库)不配主(库)**slaveof &lt;ip&gt; &lt;port&gt;**成为某个实例的从服务器在6380和6381上执行 slaveof 127.0.0.1 6379 在主机上写，在从机上可以读取数据在从机上写数据报错 主机挂掉，重启就行，一切如初 从机重启又变为主服务器，需重设：slaveof 127.0.0.1 6379会从主服务器复制所有数据 可以将配置增加到文件中，永久生效 4 复制原理 slave 启动成功连接到 master 后会发送一个 sync 命令 master 接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后（即持久化所有数据 rdb文件），master将传送整个数据文件到slave，以完成一次完全同步 全量复制：而 slave 服务在接收到数据库文件数据，flushall后，将其存盘并加载到内存中 增量复制：master 继续将新的所有收集到的修改命令依次传给slave，完成同步 但是只要是重新连接master，一次完全同步（全量复制）将被自动执行 5 常用3招一主二仆slave1、slave2是从头开始复制还是从切入点开始复制？比如从k4进来，那之前的set的k1 k2 k3是否也可以复制？ 从主服务器复制全部数据从机是否可以写？set可否？ 不能主机shutdown后情况如何？从机是上位还是原地待命？ 原地待命主机又回来了后，主机新增记录，从机还能否顺利复制？ 能其中一台从机down后情况如何？依照原有它能跟上大部队吗？ 从主服务器复制全部数据薪火相传上一个Slave可以是下一个slave的Master，Slave同样可以接收其他 slaves的连接和同步请求，那么该slave作为了链条中下一个的master，可以有效减轻master的写压力，去中心化降低风险用 **slaveof &lt;ip&gt; &lt;port&gt;**中途变更转向会清除之前的数据，重新建立拷贝最新的风险是一旦某个slave宕机，后面的slave都没法备份主机挂了，从机还是从机，无法写数据了反客为主当一个master宕机后，后面的slave可以立刻升为master，其后面的slave不用做任何修改用**slaveof no one**将从机变为主机6 哨兵模式 sentinel反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库使用步骤 调整为一主二仆模式，6379带着6380 6381 自定义的 /myredis 目录下新建**sentinel.conf**文件，名字绝不能错 配置哨兵，填写内容**sentinel monitor mymaster 127.0.0.1 6379 1**其中mymaster为监控对象起的服务器名称， 1 为至少有多少个哨兵同意迁移的数量 启动哨兵/usr/local/bin redis做压测可以用自带的**redis-benchmark**工具执行 **redis-sentinel /myredis/sentinel.conf ** 当主机挂掉，从机选举中产生新的主机(大概10秒左右可以看到哨兵窗口日志，切换了新的主机)哪个从机会被选举为主机呢？根据优先级别：slave-priority 10，已经改名为replica-priority设置从机的优先级，值越小，优先级越高，用于选举主机时使用。默认100 原主机重启后会变为从机复制延时由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重故障恢复优先级在redis.conf中默认：slave-priority 100，值越小优先级越高偏移量是指获得原主机数据最全的每个redis实例启动后都会随机生成一个40位的 runid主从复制 private static JedisSentinelPool jedisSentinelPool=null; public static Jedis getJedisFromSentinel(){ if(jedisSentinelPool==null){ Set&lt;String> sentinelSet=new HashSet&lt;>(); sentinelSet.add(\"192.168.11.103:26379\"); // 哨兵IP 端口号 JedisPoolConfig jedisPoolConfig =new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(10); //最大可用连接数 jedisPoolConfig.setMaxIdle(5); //最大闲置连接数 jedisPoolConfig.setMinIdle(5); //最小闲置连接数 jedisPoolConfig.setBlockWhenExhausted(true); //连接耗尽是否等待 jedisPoolConfig.setMaxWaitMillis(2000); //等待时间 jedisPoolConfig.setTestOnBorrow(true); //取连接的时候进行一下测试 ping pong jedisSentinelPool= new JedisSentinelPool(\"mymaster\", sentinelSet, jedisPoolConfig); return jedisSentinelPool.getResource(); } else { return jedisSentinelPool.getResource(); }","categories":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"}],"author":"wst"},{"title":"【Redis】8.Redis 应用问题解决 新功能","slug":"Redis/8.Redis 应用问题解决 新功能","date":"2022-02-14T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0214[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0214[object%20Object].html","excerpt":"","text":"十四 Redis 应用问题解决1 缓存穿透问题描述key 对应的数据在数据源并不存在，每次针对此 key 的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库 应用服务器压力突然变大 redis 命中率降低 一直查询数据库 原因 redis 到数据库查询不到 出现了很多非正常的url访问 解决方案一个一定不存在缓存及查询不到的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。解决方案： 对空值缓存：如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟 设置可访问的名单（白名单）：使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问 采用布隆过滤器布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量(位图)和一系列随机映射函数（哈希函数）。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难（不存在的一定不存在，存在的可能存在）将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被 这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力 进行实时监控：当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务 2 缓存击穿问题描述key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮 数据库访问压力瞬时增加 redis 正常运行 redis 里面并没有出现大量key过期 redis 某个key过期了，大量访问使用这个key 解决方案 预先设置热门数据：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长 实时调整：现场监控哪些数据热门，实时调整key的过期时长 使用锁 就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db 先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key互斥锁 当操作返回成功时，再进行load db的操作，并回设缓存,最后删除mutex key 当操作返回失败，证明有线程在load db，当前线程睡眠一段时间再重试整个get缓存的方法 3 缓存雪崩问题描述key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，前者则是某一个key 数据库压力变大，服务器崩溃 原因 在极少时间段，查询大量key的集中过期情况 正常访问缓存失效瞬间缓存失效时的雪崩效应对底层系统的冲击非常可怕！解决方案 构建多级缓存架构：nginx缓存 + redis缓存 +其他缓存（ehcache等） 使用锁或队列：用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上，不适用高并发情况 设置过期标志更新缓存：记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。 将缓存失效时间分散开：比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件 4 分布式锁问题描述随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的 Java API 并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！分布式锁主流的实现方案 基于数据库实现分布式锁 基于缓存（Redis等） 基于Zookeeper 每一种分布式锁解决方案都有各自的优缺点 性能：redis最高 可靠性：zookeeper最高 这里，我们就基于redis实现分布式锁使用redis实现分布式锁EX sec：设置键的过期时间为 sec 秒。set key value EX sec 效果等同于 setex key sec valuePX millis：设置键的过期时间为 millis 毫秒。 set key value PX millis 效果等同于 PSETEX key millis valueNX：只在键不存在时，才对键进行设置操作。 set key value NX 效果等同于 setnx key valueXX：只在键已经存在时，才对键进行设置操作 多个客户端同时获取锁（setnx） 获取成功，执行业务逻辑{从db获取数据，放入缓存}，执行完成释放锁（del） 其他客户端等待重试 锁一直没有释放，设置key的过期时间，自动释放上锁之后突然出现异常，无法设置过期时间上锁的同时设置过期时间set users 10 nx ex 12编写代码Redis: set num 0 @GetMapping(\"testLock\") public void testLock() { //1获取锁，setne Boolean lock = redisTemplate.opsForValue().setIfAbsent(\"lock\", \"111\"); //2获取锁成功、查询num的值 if (lock) { Object value = redisTemplate.opsForValue().get(\"num\"); //2.1判断num为空return if (StringUtils.isEmpty(value)) { return; } //2.2有值就转成成int int num = Integer.parseInt(value + \"\"); //2.3把redis的num加1 redisTemplate.opsForValue().set(\"num\", ++num); //2.4释放锁，del redisTemplate.delete(\"lock\"); } else { //3获取锁失败、每隔0.1秒再获取 try { Thread.sleep(100); testLock(); } catch (InterruptedException e) { e.printStackTrace(); } } } 重启，服务集群，通过网关压力测试：ab -n 5000 -c 100 http://192.168.199.132:8080/redisTest/testLock 查看redis中num的值，基本实现 问题：setnx刚好获取到锁，业务逻辑出现异常，导致锁无法释放解决：设置过期时间，自动释放锁优化之设置锁的过期时间设置过期时间有两种方式： 首先想到通过expire设置过期时间（缺乏原子性：如果在setnx和expire之间出现异常，锁也无法释放） 在set时指定过期时间（推荐） 设置过期时间 压力测试肯定也没有问题 问题：可能会释放其他服务器的锁 A B C并发操作 A执行，1上锁，2具体操作，此时服务器卡住，3超时自动释放锁 B抢到执行，1上锁，2具体操作，3途中A服务器恢复过来，进行删除锁操作，B的锁会被释放 解决：setnx获取锁时，设置一个指定的唯一值（例如：uuid）；释放前获取这个值，判断是否自己的锁优化之UUID防误删 @GetMapping(\"testLock\") public void testLock() { // 1 获取锁，setne String uuid = UUID.randomUUID().toString(); Boolean lock = redisTemplate.opsForValue().setIfAbsent(\"lock\",uuid,3,TimeUnit.SECONDS); // 2 获取锁成功、查询num的值 if (lock) { Object value = redisTemplate.opsForValue().get(\"num\"); // 2.1 判断num为空return if (StringUtils.isEmpty(value)) { return; } // 2.2 有值就转成成int int num = Integer.parseInt(value + \"\"); // 2.3 把redis的num加1 redisTemplate.opsForValue().set(\"num\", ++num); // 2.4 释放锁，del String lockuuid = (String) redisTemplate.opsForValue().get(\"lock\"); if (uuid.equals(lockuuid)) { redisTemplate.delete(\"lock\"); } } else { // 3 获取锁失败、每隔0.1秒再获取 try { Thread.sleep(100); testLock(); } catch (InterruptedException e) { e.printStackTrace(); } } } 问题：删除操作缺乏原子性 A B C并发操作 A执行，1上锁，2具体操作，3超时判断uuid一致，正要释放锁的时候，锁已经过期自动删除 B抢到执行，1上锁，2具体操作，3途中A服务器执行删除操作，B的锁会被释放 优化之LUA脚本保证删除的原子性 @GetMapping(\"testLockLua\") public void testLockLua() { // 1 声明一个uuid ,将做为一个value 放入我们的key所对应的值中 String uuid = UUID.randomUUID().toString(); // 2 定义一个锁：lua 脚本可以使用同一把锁，来实现删除！ String skuId = \"25\"; // 访问skuId 为25号的商品 100008348542 String locKey = \"lock:\" + skuId; // 锁住的是每个商品的数据 // 3 获取锁 Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey,uuid,3,TimeUnit.SECONDS); // 如果true if (lock) { // 执行的业务逻辑开始 // 获取缓存中的num 数据 Object value = redisTemplate.opsForValue().get(\"num\"); // 如果是空直接返回 if (StringUtils.isEmpty(value)) { return; } int num = Integer.parseInt(value + \"\"); // 使num 每次+1 放入缓存 redisTemplate.opsForValue().set(\"num\", String.valueOf(++num)); /*使用lua脚本来锁*/ // 定义lua 脚本 String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return \" + \"redis.call('del', KEYS[1]) else return 0 end\"; // 使用redis执行lua执行 DefaultRedisScript&lt;Long> redisScript = new DefaultRedisScript&lt;>(); redisScript.setScriptText(script); // 设置一下返回值类型 为Long // 因为删除判断的时候，返回的0,给其封装为数据类型。如果不封装那么默认返回String 类型， // 那么返回字符串与0 会有发生错误。 redisScript.setResultType(Long.class); // 第一个要是script 脚本 ，第二个需要判断的key，第三个就是key所对应的值。 redisTemplate.execute(redisScript, Arrays.asList(locKey), uuid); } else { // 其他线程等待 try { // 睡眠 Thread.sleep(1000); // 睡醒了之后，调用方法。 testLockLua(); } catch (InterruptedException e) { e.printStackTrace(); } } } Lua 脚本详解：项目中正确使用 // 定义key，key应该是为每个sku定义的，也就是每个sku有一把锁 String locKey =\"lock:\"+skuId; // 锁住的是每个商品的数据 Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey, uuid,3,TimeUnit.SECONDS); 总结 加锁| _// 1. 从redis中获取锁,set k1 v1 px 20000 nx_String uuid = UUID.randomUUID().toString();Boolean lock = this.redisTemplate.opsForValue().setIfAbsent(“lock”, uuid, 2, TimeUnit.SECONDS); || — | 使用lua释放锁| // 2. 释放锁 delString script = “if redis.call(‘get’, KEYS[1]) == ARGV[1] then return redis.call(‘del’, KEYS[1]) else return 0 end”;// 设置lua脚本返回的数据类型DefaultRedisScript redisScript = **new **DefaultRedisScript&lt;&gt;();// 设置lua脚本返回类型为LongredisScript.setResultType(Long.class);redisScript.setScriptText(script); redisTemplate.execute(redisScript, Arrays.asList(“lock”),uuid); || — || | 重试| Thread.sleep(500);testLock(); || — | 为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件 互斥性。在任意时刻，只有一个客户端能持有锁 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了 加锁和解锁必须具有原子性 十五 Redis6.0 新功能1 ACL简介**Redis**``**ACL**是 Access Control List（访问控制列表）的缩写，该功能允许根据可以执行的命令和可以访问的键来限制某些连接。在Redis 5版本之前，Redis 安全规则只有密码控制 还有通过 rename 来调整高危命令比如 flushdb ， KEYS* ， shutdown 等。Redis 6 则提供ACL的功能对用户进行更细粒度的权限控制 接入权限：用户名和密码 可以执行的命令 可以操作的 KEY 参考官网：https://redis.io/topics/acl命令 使用**acl list**命令展现用户权限列表数据说明 使用 **acl cat**命令 查看添加权限指令类别 加参数类型名可以查看类型下具体命令 使用**acl whoami**命令查看当前用户 使用**acl setuser**命令创建和编辑用户ACL ACL规则下面是有效ACL规则的列表。某些规则只是用于激活或删除标志，或对用户ACL执行给定更改的单个单词。其他规则是字符前缀，它们与命令或类别名称、键模式等连接在一起。| ACL规则 | | || — | — | — || 类型 | 参数 | 说明 || 启动和禁用用户 | on | 激活某用户账号 || | off | 禁用某用户账号。注意，已验证的连接仍然可以工作。如果默认用户被标记为off，则新连接将在未进行身份验证的情况下启动，并要求用户使用AUTH选项发送AUTH或HELLO，以便以某种方式进行身份验证。 || 权限的添加删除 | + | 将指令添加到用户可以调用的指令列表中 || | - | 从用户可执行指令列表移除指令 || | +@ | 添加该类别中用户要调用的所有指令，有效类别为@admin、@set、@sortedset…等，通过调用ACL CAT命令查看完整列表。特殊类别@all表示所有命令，包括当前存在于服务器中的命令，以及将来将通过模块加载的命令。 || | -@ | 从用户可调用指令中移除类别 || | allcommands | +@all的别名 || | nocommand | -@all的别名 || 可操作键的添加或删除 | ~ | 添加可作为用户可操作的键的模式。例如~*允许所有的键 | 通过命令创建新用户默认权限acl setuser user1在上面的示例中，我根本没有指定任何规则。如果用户不存在，这将使用just created的默认属性来创建用户。如果用户已经存在，则上面的命令将不执行任何操作。 设置有用户名、密码、ACL权限、并启用的用户 acl setuser user2 on &gt;password ~cached: +get* 2. 切换用户，验证权限 2 IO 多线程简介Redis6 终于支撑多线程了，告别单线程了吗？IO多线程其实指客户端交互部分的网络IO交互处理模块多线程，而非执行命令多线程。Redis6执行命令依然是单线程原理架构Redis 6 加入多线程，但跟 Memcached 这种从 IO处理到数据访问多线程的实现模式有些差异。Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。之所以这么设计是不想因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP 等等的并发问题。整体的设计大体如下另外，多线程IO默认也是不开启的，需要再配置文件中配置**io-threads-do-reads yes** 1153行 开启多线程**io-threads 4**** **设置io线程数量3 工具支持 Cluster之前老版 Redis 想要搭集群需要单独安装 ruby 环境，Redis 5 将 redis-trib.rb 的功能集成到 redis-cli 。另外官方 redis-benchmark 工具开始支持 cluster 模式了，通过多线程的方式对多个分片进行压测4 Redis 新功能持续关注Redis6新功能还有 RESP3新的 Redis 通信协议：优化服务端与客户端之间通信 Client side caching客户端缓存：基于 RESP3 协议实现的客户端缓存功能。为了进一步提升缓存的性能，将客户端经常访问的数据cache到客户端。减少TCP网络交互。 Proxy集群代理模式：Proxy 功能，让 Cluster 拥有像单实例一样的接入方式，降低大家使用cluster的门槛。不过需要注意的是代理不改变 Cluster 的功能限制，不支持的命令还是不会支持，比如跨 slot 的多Key操作。 Modules API Redis 6 中模块 API 开发进展非常大，因为Redis Labs为了开发复杂的功能，从一开始就用上Redis模块。Redis可以变成一个框架，利用Modules来构建不同系统，而不需要从头开始写然后还要BSD许可。Redis一开始就是一个向编写各种系统开放的平台。","categories":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"}],"author":"wst"},{"title":"【springboot】SpringBoot和开发热部署","slug":"spring boot/SpringBoot和开发热部署","date":"2022-01-23T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0123[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0123[object%20Object].html","excerpt":"","text":"SpringBoot Devtools 在项目中引入spring-boot-devtools的Maven坐标：```xml org.springframework.boot spring-boot-devtools true org.springframework.boot spring-boot-maven-plugin true ``` IDEA中需要设置项目自动编译。 使用快捷键ctrl+shift+alt+/，打开Maintenance。 选择Registry，勾选compiler.automake.allow.when.app.running：","categories":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/tags/springboot/"}],"author":"wst"},{"title":"【springboot】整合ElasticSearch(高效检索)","slug":"spring boot/整合ElasticSearch(高效检索)","date":"2022-01-23T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0123[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0123[object%20Object].html","excerpt":"","text":"3、ElasticSearch.pdf 《Spring Data Elasticsearch》Spring Boot整合Elasticsearch的官方文档。 Elasticsearch官网参考文档：https://www.elastic.co/guide/index.html Elasticsearch官方下载地址：https://www.elastic.co/cn/downloads/elasticsearch 1. Springboot 与 Elasticsearch版本对应关系 Spring Data Release Train Spring Data Elasticsearch Elasticsearch Spring Boot 2020.0.0[1] 4.1.x[1] 7.9.3 2.4.x[1] Neumann 4.0.x 7.6.2 2.3.x Moore 3.2.x 6.8.12 2.2.x Lovelace 3.1.x 6.2.2 2.1.x Kay[2] 3.0.x[2] 5.5.0 2.0.x[2] Ingalls[2] 2.1.x[2] 2.4.0 1.5.x[2] 2. 整合步骤创建SpringBoot项目并引入Elasticsearch依赖 引入Spring-Data-Elasticsearch依赖，Spring 团队将Elasticsearch归到“Data”的范畴，所以依赖是以Spring-Data开头。注意版本号一定要与自己在本地安装的ElasticSearch版本保持一致 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-elasticsearch&lt;/artifactId> &lt;/dependency> 基于Java的Elasticsearch配置 新建类 RestClientConfig作为Elasticsearch Rest客户端的配置了类： /** * ElasticSearch 客户端配置 * * @author geng * 2020/12/19 */ @Configuration public class RestClientConfig extends AbstractElasticsearchConfiguration { @Override @Bean public RestHighLevelClient elasticsearchClient() { final ClientConfiguration clientConfiguration = ClientConfiguration.builder() .connectedTo(\"localhost:9200\") .build(); return RestClients.create(clientConfiguration).rest(); } } 3. 测试测试前提是你的ElasticSearch已成功启动 1、创建索引 代码 /** * 创建索引测试 */ @Test void createIndex() throws IOException { //1、构建 创建索引的请求 CreateIndexRequest request = new CreateIndexRequest(\"xk_index\");//索引名 //2、客户端执行请求,获取响应 CreateIndexResponse response = client.indices().create(request, RequestOptions.DEFAULT); //3、打印 System.out.println(\"创建成功，创建的索引名为：\" + response.index()); } 结果 2、获取索引 代码 /** * 获取索引测试 */ @Test void getIndex() throws IOException { //1、构建 获取索引的请求 GetIndexRequest request = new GetIndexRequest(\"xk_index\"); //2、客户端判断该索引是否存在 boolean exists = client.indices().exists(request, RequestOptions.DEFAULT); //3、打印 System.out.println(\"该索引是否存在：\"+exists); } 结果 3、删除索引 代码 /** * 删除索引测试 */ @Test void deleteIndex() throws IOException { //1、构建 删除索引请求 DeleteIndexRequest request = new DeleteIndexRequest(\"xk_index\"); //2、客户段执行删除的请求 AcknowledgedResponse response = client.indices().delete(request, RequestOptions.DEFAULT); //3、打印 System.out.println(\"是否删除成功：\"+response.isAcknowledged()); } 结果 4、创建文档 创建文档就相当于我们所学过的在数据库中添加一条记录，因此，在这里，我们首先新建一个实体类User，一个User对象就相当于一个文档。 @Data @Accessors(chain = true) public class User { private Integer id; private String username; } 然后，在测试类中进行测试，添加文档，代码如下： /** * 创建文档 */ @Test void createDocument() throws IOException { User user = new User().setId(1).setUsername(\"张三\"); //1、构建请求 IndexRequest request = new IndexRequest(\"user_index\"); //2、设置规则 PUT /user_index/user/_doc/1 request.id(\"1\");//设置id request.timeout(TimeValue.timeValueSeconds(1));//设置超时时间 //3、将数据放入到请求中,以JSON的格式存放 request.source(JSONObject.toJSONString(user), XContentType.JSON); //4、客户端发送请求,获取响应结果 IndexResponse response = client.index(request, RequestOptions.DEFAULT); //5、打印 System.out.println(\"响应结果：\"+response.toString()); } 结果 5、获取文档 代码 /** * 获取文档 */ @Test void getDocument() throws IOException { //获取id为1的文档的信息 GetRequest request = new GetRequest(\"user_index\",\"1\"); boolean exists = client.exists(request, RequestOptions.DEFAULT); System.out.println(\"文档是否存在：\"+exists); //如果存在，获取文档信息 if (exists){ GetResponse response = client.get(request, RequestOptions.DEFAULT); System.out.println(\"文档内容为：\"+response.getSourceAsString()); } } 结果 6、更新文档 代码 /** * 更新文档 */ @Test void updateDocument() throws IOException { //更新id为1的文档的信息 UpdateRequest request = new UpdateRequest(\"user_index\", \"1\"); User user = new User().setUsername(\"李四\"); request.doc(JSONObject.toJSONString(user), XContentType.JSON); //客户端执行更新请求 UpdateResponse response = client.update(request, RequestOptions.DEFAULT); System.out.println(\"更新状态：\" +response.status()); } 结果 7、删除文档 代码 /** * 删除文档 */ @Test void deleteDocument() throws IOException { //构建删除请求 DeleteRequest request = new DeleteRequest(\"user_index\", \"1\"); //客户端执行删除请求，并获取响应结果 DeleteResponse response = client.delete(request, RequestOptions.DEFAULT); //打印 System.out.println(\"删除状态：\"+response.status()); } 结果 8、批量插入 代码 /** * 批量插入数据 */ @Test void createBulkDocument() throws IOException { //构建批量插入的请求 BulkRequest request = new BulkRequest(); //设置超时时间 request.timeout(\"10s\"); //设置数据 List&lt;User> list = new ArrayList&lt;>(); list.add(new User().setId(1).setUsername(\"张三\")); list.add(new User().setId(2).setUsername(\"李四\")); list.add(new User().setId(3).setUsername(\"王五\")); list.add(new User().setId(4).setUsername(\"赵六\")); //批量插入请求设置 for (int i = 0; i &lt; list.size(); i++) { request.add( new IndexRequest(\"user_index\")//设置索引 .id(String.valueOf(i+1))//设置文档的id，如果没有指定，会随机生成，自己测试 .source(JSONObject.toJSONString(list.get(i)), XContentType.JSON)//设置要添加的资源，类型为JSON ); } BulkResponse response = client.bulk(request, RequestOptions.DEFAULT); System.out.println(\"批量插入是否失败：\"+response.hasFailures()); } 结果为false，代表没有失败，即插入成功 9、查询 代码 /** * 查询 */ @Test void query() throws IOException { //1、构建搜索请求 SearchRequest request = new SearchRequest(\"user_index\"); //2、设置搜索条件，使用该构建器进行查询 SearchSourceBuilder builder = new SearchSourceBuilder();//生成构建器 //查询条件我们可以用工具类QueryBuilders来构建 //QueryBuilders.termQuery()：精确匹配 //QueryBuilders.matchAllQuery()：全文匹配 //构建精确匹配查询条件 //构建精确匹配查询条件 TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"username.keyword\", \"李四\"); // MatchAllQueryBuilder matchAllQueryBuilder = QueryBuilders.matchAllQuery(); // WildcardQueryBuilder wildcardQueryBuilder = QueryBuilders.wildcardQuery(\"username\", \"张\"); builder.query(termQueryBuilder); //3、将搜索条件放入搜索请求中 request.source(builder); //4、客户端执行搜索请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); //5、打印测试 SearchHit[] hits = response.getHits().getHits(); System.out.println(\"共查询到\"+hits.length+\"条数据\"); System.out.println(\"查询结果：\"); for (int i = 0; i &lt; hits.length; i++) { System.out.println(hits[i].getSourceAsString()); } } 结果","categories":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/tags/springboot/"}],"author":"wst"},{"title":"【springboot】整合MybatisPlus,以及常用配置和插件","slug":"spring boot/整合MybatisPlus,以及常用配置和插件","date":"2022-01-23T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0123[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0123[object%20Object].html","excerpt":"","text":"如需使用Druid连接池,[请点击](https://www.yuque.com/docs/share/15cc1140-5690-4edd-b642-ef72261227b4?# 《整合数据源Druid》 链接有效期至 2022-05-12 16:47:51) 一. SpringBoot与Mybatis-Plus的代码整合&lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-extension&lt;/artifactId> &lt;version>3.4.2&lt;/version> &lt;/dependency> 二. 使用代码生成器生成代码 注入依赖 &lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-generator&lt;/artifactId> &lt;version>3.3.0&lt;/version> &lt;/dependency> &lt;!-- 模板引擎 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-freemarker&lt;/artifactId> &lt;/dependency> 创建代码生成器CodeGenerator (输入表名单个生成) // 演示例子，执行 main 方法控制台输入表名回车自动生成对应项目目录中 public class CodeGenerator { /** * &lt;p> * 读取控制台内容 * &lt;/p> */ public static String scanner(String tip) { Scanner scanner = new Scanner(System.in); StringBuilder help = new StringBuilder(); help.append(\"请输入\" + tip + \"：\"); System.out.println(help.toString()); if (scanner.hasNext()) { String ipt = scanner.next(); if (StringUtils.isNotBlank(ipt)) { return ipt; } } throw new MybatisPlusException(\"请输入正确的\" + tip + \"！\"); } public static void main(String[] args) { // 代码生成器 AutoGenerator mpg = new AutoGenerator(); // 全局配置 GlobalConfig gc = new GlobalConfig(); String projectPath = System.getProperty(\"user.dir\"); gc.setOutputDir(projectPath + \"/src/main/java\"); gc.setAuthor(\"zj\"); gc.setOpen(false); // gc.setSwagger2(true); 实体属性 Swagger2 注解 mpg.setGlobalConfig(gc); // 数据源配置 DataSourceConfig dsc = new DataSourceConfig(); dsc.setUrl(\"jdbc:mysql://localhost:3306/demo?useUnicode=true&amp;useSSL=false&amp;characterEncoding=utf8\"); // dsc.setSchemaName(\"public\"); dsc.setDriverName(\"com.mysql.cj.jdbc.Driver\"); dsc.setUsername(\"root\"); dsc.setPassword(\"123456\"); mpg.setDataSource(dsc); // 包配置 PackageConfig pc = new PackageConfig(); //pc.setModuleName(scanner(\"模块名\")); pc.setParent(\"com.lx.demo\"); mpg.setPackageInfo(pc); // 自定义配置 InjectionConfig cfg = new InjectionConfig() { @Override public void initMap() { // to do nothing } }; // 如果模板引擎是 freemarker String templatePath = \"/templates/mapper.xml.ftl\"; // 如果模板引擎是 velocity // String templatePath = \"/templates/mapper.xml.vm\"; // 自定义输出配置 List&lt;FileOutConfig> focList = new ArrayList&lt;>(); // 自定义配置会被优先输出 focList.add(new FileOutConfig(templatePath) { @Override public String outputFile(TableInfo tableInfo) { // 自定义输出文件名 ， 如果你 Entity 设置了前后缀、此处注意 xml 的名称会跟着发生变化！！ return projectPath + \"/src/main/resources/mapper/\" + pc.getModuleName() + \"/\" + tableInfo.getEntityName() + \"Mapper\" + StringPool.DOT_XML; } }); /* cfg.setFileCreate(new IFileCreate() { @Override public boolean isCreate(ConfigBuilder configBuilder, FileType fileType, String filePath) { // 判断自定义文件夹是否需要创建 checkDir(\"调用默认方法创建的目录，自定义目录用\"); if (fileType == FileType.MAPPER) { // 已经生成 mapper 文件判断存在，不想重新生成返回 false return !new File(filePath).exists(); } // 允许生成模板文件 return true; } }); */ cfg.setFileOutConfigList(focList); mpg.setCfg(cfg); // 配置模板 TemplateConfig templateConfig = new TemplateConfig(); // 配置自定义输出模板 //指定自定义模板路径，注意不要带上.ftl/.vm, 会根据使用的模板引擎自动识别 // templateConfig.setEntity(\"templates/entity2.java\"); // templateConfig.setService(); // templateConfig.setController(); templateConfig.setXml(null); mpg.setTemplate(templateConfig); // 策略配置 StrategyConfig strategy = new StrategyConfig(); strategy.setNaming(NamingStrategy.underline_to_camel); strategy.setColumnNaming(NamingStrategy.underline_to_camel); //strategy.setSuperEntityClass(\"你自己的父类实体,没有就不用设置!\"); strategy.setEntityLombokModel(true); strategy.setRestControllerStyle(true); // 公共父类 //strategy.setSuperControllerClass(\"你自己的父类控制器,没有就不用设置!\"); // 写于父类中的公共字段 //strategy.setSuperEntityColumns(\"id\"); strategy.setInclude(scanner(\"表名，多个英文逗号分割\").split(\",\")); strategy.setControllerMappingHyphenStyle(true); strategy.setTablePrefix(pc.getModuleName() + \"_\"); mpg.setStrategy(strategy); mpg.setTemplateEngine(new FreemarkerTemplateEngine()); mpg.execute(); } } 创建代码生成器CodeGenerator (获取数据库中所有数据表批量生成)```javapackage com.zgiot.zx.production.generator; import com.baomidou.mybatisplus.core.exceptions.MybatisPlusException;import com.baomidou.mybatisplus.core.toolkit.StringPool;import com.baomidou.mybatisplus.core.toolkit.StringUtils;import com.baomidou.mybatisplus.generator.AutoGenerator;import com.baomidou.mybatisplus.generator.InjectionConfig;import com.baomidou.mybatisplus.generator.config.*;import com.baomidou.mybatisplus.generator.config.po.TableInfo;import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy;import com.baomidou.mybatisplus.generator.engine.FreemarkerTemplateEngine; import java.sql.Connection;import java.sql.DriverManager;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.util.ArrayList;import java.util.List;import java.util.Scanner; /** 代码自动生成 / public class CodeGenerator { private static String driverClassName = &quot;com.mysql.jdbc.Driver&quot;; private static String dbUrl = &quot;jdbc:mysql://localhost:3306/schedule_prd?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&quot;; private static String dbUsername = &quot;root&quot;; private static String dbPassword = &quot;123456&quot;; /** * &lt;p&gt; * 读取控制台内容 * &lt;/p&gt; */ public static String scanner(String tip) { Scanner scanner = new Scanner(System.in); StringBuilder help = new StringBuilder(); System.out.println(tip); help.append(&quot;请输入&quot; + tip + &quot;：&quot;); System.out.println(help.toString()); if (scanner.hasNext()) { String ipt = scanner.next(); if (StringUtils.isNotEmpty(ipt)) { return ipt; } } throw new MybatisPlusException(&quot;请输入正确的&quot; + tip + &quot;！&quot;); } /** * 获取某个数据库中的所有表名 * @param dbName * @return * @throws Exception */ private static String[] getTables(String dbName) throws Exception { List&lt;String&gt; tables = new ArrayList&lt;&gt;(); Connection connection = null; PreparedStatement ps = null; ResultSet resultSet = null; try { Class.forName(driverClassName); connection = DriverManager.getConnection(dbUrl,dbUsername,dbPassword); String sql = &quot;select table_name from information_schema.tables where table_schema=?&quot;; ps = connection.prepareStatement(sql); ps.setString(1,dbName); resultSet = ps.executeQuery(); while (resultSet.next()) { tables.add(resultSet.getString(&quot;table_name&quot;)); } String[] result = tables.toArray(new String[tables.size()]); return result; } catch (Exception e) { e.printStackTrace(); } finally { if (resultSet != null) { try { resultSet.close(); } catch (Exception e) { e.printStackTrace(); } } if (ps != null) { try { ps.close(); } catch (Exception e) { e.printStackTrace(); } } if (connection != null) { try { connection.close(); } catch (Exception e) { e.printStackTrace(); } } } throw new Exception(&quot;数据库连接异常！&quot;); } public static void main(String[] args) throws Exception { // 代码生成器 AutoGenerator mpg = new AutoGenerator(); // 全局配置 GlobalConfig gc = new GlobalConfig(); String projectPath = System.getProperty(&quot;user.dir&quot;); gc.setOutputDir(projectPath + &quot;/src/main/java/&quot;); gc.setAuthor(&quot;zhangyanduan&quot;); gc.setOpen(false); mpg.setGlobalConfig(gc); // 数据源配置 DataSourceConfig dsc = new DataSourceConfig(); dsc.setUrl(&quot;jdbc:mysql://localhost:3306/schedule_prd?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&quot;); // dsc.setSchemaName(&quot;public&quot;); dsc.setDriverName(&quot;com.mysql.jdbc.Driver&quot;); dsc.setUsername(&quot;root&quot;); dsc.setPassword(&quot;123456&quot;); mpg.setDataSource(dsc); // 包配置 PackageConfig pc = new PackageConfig(); pc.setModuleName(scanner(&quot;模块名&quot;)); pc.setParent(&quot;com.zgiot.zx&quot;); mpg.setPackageInfo(pc); // 自定义配置 InjectionConfig cfg = new InjectionConfig() { @Override public void initMap() { // to do nothing } }; // 如果模板引擎是 freemarker String templatePath = &quot;/templates/mapper.xml.ftl&quot;; // 如果模板引擎是 velocity // String templatePath = “/templates/mapper.xml.vm”; // 自定义输出配置 List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;(); // 自定义配置会被优先输出 focList.add(new FileOutConfig(templatePath) { @Override public String outputFile(TableInfo tableInfo) { // 自定义输出文件名 System.out.println(projectPath + &quot;\\\\src\\\\main\\\\resources\\\\mapper\\\\&quot; + pc.getModuleName() + &quot;\\\\&quot; + tableInfo.getEntityName() + &quot;Mapper&quot; + StringPool.DOT_XML); return projectPath + &quot;\\\\src\\\\main\\\\resources\\\\mapper\\\\&quot; + pc.getModuleName() + &quot;\\\\&quot; + tableInfo.getEntityName() + &quot;Mapper&quot; + StringPool.DOT_XML; } }); cfg.setFileOutConfigList(focList); mpg.setCfg(cfg); // 配置模板 TemplateConfig templateConfig = new TemplateConfig(); // 配置自定义输出模板 templateConfig.setEntity(null); templateConfig.setService(null); templateConfig.setController(null); templateConfig.setXml(null); mpg.setTemplate(templateConfig); // 策略配置 StrategyConfig strategy = new StrategyConfig(); strategy.setNaming(NamingStrategy.underline_to_camel); strategy.setColumnNaming(NamingStrategy.underline_to_camel); strategy.setEntityLombokModel(true); strategy.setRestControllerStyle(true); // strategy.setInclude(scanner(“表名，多个英文逗号分割”).split(“,”)); strategy.setInclude(getTables(“schedule_prd”)); strategy.setSuperEntityColumns(“id”); strategy.setControllerMappingHyphenStyle(true); strategy.setTablePrefix(“_”); strategy.entityTableFieldAnnotationEnable(true); mpg.setStrategy(strategy); mpg.setTemplateEngine(new FreemarkerTemplateEngine()); mpg.execute(); } } ## 三. 插件配置 ### 分页插件 &gt; 从MyBatis-Plus 3.4.0开始，不再使用旧版本的PaginationInterceptor ，而是使用MybatisPlusInterceptor。 #### 3.4之前的版本 ```java @Configuration @MapperScan(“com.xxx.mapper”) public class MybatisPlusConfig { @Bean public PaginationInterceptor paginationInterceptor() { //3.4版本之前 PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); // 设置请求的页面大于最大页后操作， true调回到首页，false 继续请求 默认false // paginationInterceptor.setOverflow(false); // 设置最大单页限制数量，默认 500 条，-1 不受限制 // paginationInterceptor.setLimit(500); // 开启 count 的 join 优化,只针对部分 left join paginationInterceptor.setCountSqlParser(new JsqlParserCountOptimize(true)); return paginationInterceptor; } } 3.4版本后@Configuration public class MybatisPlusConfig { /* 配置拦截器 3.4版本后 */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));//设置数据类型，还可以添加别的拦截器 return interceptor; } } 防止全表更新与删除插件 在MP中提供了防止全表更新与删除插件。 注意：此插件仅适用于开发环境，不适用于生产环境。 示例： ①配置防止全表更新与删除的插件```javapackage com.example.mp.config; import com.baomidou.mybatisplus.annotation.DbType;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.BlockAttackInnerInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration; /** @author 许大仙 @version 1.0 @since 2021-06-18 22:42 /@Configurationpublic class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); //配置分页插件 PaginationInnerInterceptor paginationInnerInterceptor = new PaginationInnerInterceptor(DbType.MYSQL); interceptor.addInnerInterceptor(paginationInnerInterceptor); //配置防止全表更新与删除的插件 BlockAttackInnerInterceptor blockAttackInnerInterceptor = new BlockAttackInnerInterceptor(); interceptor.addInnerInterceptor(blockAttackInnerInterceptor); return interceptor; } } - ②测试： ```java package com.example.mp; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import com.baomidou.mybatisplus.core.conditions.update.UpdateWrapper; import com.example.mp.domain.User; import com.example.mp.mapper.UserMapper; import org.junit.jupiter.api.Test; import org.mybatis.spring.MyBatisSystemException; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; /** * @author 许大仙 * @version 1.0 * @since 2021-06-18 19:22 */ @SpringBootTest public class TestUpdate { @Autowired private UserMapper userMapper; @Test public void test() { //封装更新字段的对象 User user = new User(); user.setAge(18); try { int result = userMapper.update(user, null); System.out.println(&quot;result = &quot; + result); } catch (MyBatisSystemException e) { e.printStackTrace(); } } } 乐观锁插件主要适用场景意图：当要更新一条记录的时候，希望这条记录没有被别人更新乐观锁实现方式： 取出记录时，获取当前version 更新时，带上这个version 执行更新时， set version = newVersion where version = oldVersion 如果version不对，就更新失败插件配置```javapackage com.example.mp.config; import com.baomidou.mybatisplus.annotation.DbType;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.BlockAttackInnerInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.OptimisticLockerInnerInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration; /** @author 许大仙 @version 1.0 @since 2021-06-18 22:42 /@Configurationpublic class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); //配置分页插件 PaginationInnerInterceptor paginationInnerInterceptor = new PaginationInnerInterceptor(DbType.MYSQL); interceptor.addInnerInterceptor(paginationInnerInterceptor); //乐观锁配置 OptimisticLockerInnerInterceptor optimisticLockerInnerInterceptor = new OptimisticLockerInnerInterceptor(); interceptor.addInnerInterceptor(optimisticLockerInnerInterceptor); //配置防止全表更新与删除的插件 BlockAttackInnerInterceptor blockAttackInnerInterceptor = new BlockAttackInnerInterceptor(); interceptor.addInnerInterceptor(blockAttackInnerInterceptor); return interceptor; } } #### **注解实体字段** 需要为实体字段添加@Version注解。 &gt; 第一步，为表添加`version`字段，并且设置初始值为1： ```sql ALTER TABLE `tb_user` ADD COLUMN `version` int(10) NULL AFTER `email`; UPDATE `tb_user` SET `version`=&#39;1&#39;; 第二步，为User实体对象添加version字段，并且添加@Version注解： package com.example.mp.domain; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableField; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.Version; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import lombok.ToString; import lombok.experimental.Accessors; import java.io.Serializable; /** * @author 许大仙 * @version 1.0 * @since 2021-06-17 21:01 */ @Data @NoArgsConstructor @AllArgsConstructor //@TableName(\"tb_user\") @ToString @Accessors(chain = true) public class User implements Serializable { @TableId(type= IdType.AUTO) private Long id; @TableField(\"user_name\") //解决字段名不一致 private String username; private String password; private String name; private Integer age; private String email; @Version private Integer version; } 测试package com.example.mp; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import com.baomidou.mybatisplus.core.conditions.update.UpdateWrapper; import com.example.mp.domain.User; import com.example.mp.mapper.UserMapper; import org.junit.jupiter.api.Test; import org.mybatis.spring.MyBatisSystemException; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; /** * @author 许大仙 * @version 1.0 * @since 2021-06-18 19:22 */ @SpringBootTest public class TestUpdate { @Autowired private UserMapper userMapper; @Test public void testOptimisticLocker() { //先查询再修改，会触发乐观锁配置，即实体对象中要有version字段值 User user = userMapper.selectById(1); user.setUsername(\"许大仙\"); int result = userMapper.updateById(user); System.out.println(\"result = \" + result); } } 特别说明 支持的数据类型只有:int、Integer、long、Long、Date、Timestamp、LocalDateTime。 整数类型下 newVersion = oldVersion + 1 newVersion 会回写到 entity 中 仅支持 updateById(id) 与 update(entity, wrapper) 方法 在 update(entity, wrapper) 方法下, wrapper 不能复用!!!四. 配置 application.yml 文件基础配置1. 配置日志```yaml#配置日志mybatis-plus:configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #### 2. configLocation( 配置mapper文件位置) - 类型 string - 默认值 null MyBatis 配置文件位置，如果您有单独的 MyBatis 配置，请将其路径配置到 configLocation 中 ```yaml mybatis-plus: mapper-locations: classpath*:mybatis/*.xml 3. typeAliasesPackage(MyBaits 别名包扫描路径) 类型 string 默认值 nullMyBaits 别名包扫描路径，通过该属性可以给包中的类注册别名，注册后在 Mapper 对应的 XML 文件中可以直接使用类名，而不用使用全限定的类名（即 XML 中调用的时候不用包含包名）。 mybatis-plus: type-aliases-package: com.baomidou.mybatisplus.samples.quickstart.entity 4. typeAliasesSuperType 类型 string 默认值 null该配置请和 typeAliasesPackage 一起使用，如果配置了该属性，则仅仅会扫描路径下以该类作为父类的域对象 。 mybatis-plus: type-aliases-package: com.baomidou.mybatisplus.samples.quickstart.entity type-aliases-super-type: java.lang.Object 5. typeHandlersPackage(TypeHandler 扫描路径) 类型 string 默认值 nullTypeHandler 扫描路径，如果配置了该属性，SqlSessionFactoryBean 会把该包下面的类注册为对应的 TypeHandler。 6. typeEnumsPackage(枚举类 扫描路径) 类型 string 默认值 null枚举类 扫描路径，如果配置了该属性，会将路径下的枚举类进行注入，让实体类字段能够简单快捷的使用枚举属性，具体使用请结合 枚举注入 查看。 mybatis-plus: type-enums-package: com.baomidou.mybatisplus.samples.quickstart.enums 7. checkConfigLocation 类型 boolean 默认值 false启动时是否检查 MyBatis XML 文件的存在，默认不检查。 mybatis-plus: check-config-location: false 8. executorType(指定 MyBatis 的执行器) 类型 ExecutorType 默认值 sample通过该属性可指定 MyBatis 的执行器，MyBatis 的执行器总共有三种： ExecutorType.SIMPLE：该执行器类型不做特殊的事情，为每个语句的执行创建一个新的预处理语句（PreparedStatement） ExecutorType.REUSE：该执行器类型会复用预处理语句（PreparedStatement） ExecutorType.BATCH：该执行器类型会批量执行所有的更新语句 mybatis-plus: executor-type: simple 9. configurationProperties(指定外部化 MyBatis Properties 配置) 类型 Properties 默认值 null指定外部化 MyBatis Properties 配置，通过该配置可以抽离配置，实现不同环境的配置部署。 mybatis-plus: configuration-properties: classpath:mybatis/config.properties 进阶配置本部分的配置大都为 MyBatis 原生支持的配置，这意味着您可以通过 MyBatis XML 配置文件的形式进行配置 1. mapUnderscoreToCamelCase(驼峰命名) 类型 boolean 默认值 true 是否开启自动驼峰命名规则（camel case）映射，即从经典数据库列名 A_COLUMN 到经典 Java 属性名 aColumn 的类似映射, 此属性在 mybatis 中原默认值为 false 在 mybatis-plus 中, 此属性也将用于生成最终的 sql 的 select body 符合规则无需使用 @TableField 注解指定数据库字段名. mybatis-plus: configuration: map-underscore-to-camel-case: true 2. aggressiveLazyLoading(懒加载) 类型 boolean 默认值 true当设置为 true 的时候，懒加载的对象可能被任何懒属性全部加载，否则，每个属性都按需加载。需要和 lazyLoadingEnabled 一起使用。 mybatis-plus: configuration: aggressive-lazy-loading: true lazyLoadingEnabled: true 3. autoMappingBehavior(MyBatis 自动映射策略) 类型 AutoMappingBehavior 默认值 partial MyBatis 自动映射策略，通过该配置可指定 MyBatis 是否并且如何来自动映射数据表字段与对象的属性，总共有 3 种可选值： AutoMappingBehavior.NONE：不启用自动映射 AutoMappingBehavior.PARTIAL：只对非嵌套的 resultMap 进行自动映射 AutoMappingBehavior.FULL：对所有的 resultMap 都进行自动映射 mybatis-plus: configuration: auto-mapping-behavior: partial 4. cacheEnabled(二级缓存) 类型：boolean 默认值：true 全局地开启或关闭配置文件中的所有映射器已经配置的任何缓存，默认为 true。 mybatis-plus: configuration: cache-enabled: true 5. callSettersOnNulls 类型：boolean 默认值：false指定当前结果集为null的时候是否调用映射对象Setter（Map 对象时为 put）方法，通常运用于有 Map.keySet() 依赖或 null 值初始化的情况。 通俗的讲，即 MyBatis 在使用 resultMap 来映射查询结果中的列，如果查询结果中包含空值的列，则 MyBatis 在映射的时候，不会映射这个字段，这就导致在调用到该字段的时候由于没有映射，取不到而报空指针异常。 基本类型（int、boolean 等）是不能设置成 null 的。 mybatis-plus: configuration: call-setters-on-nulls: false 6. configurationFactory 类型：Class&lt;?&gt; 默认值：null指定一个提供 Configuration 实例的工厂类。 该工厂生产的实例将用来加载已经被反序列化对象的懒加载属性值，其必须包含一个签名方法static Configuration getConfiguration()。（从 3.2.3 版本开始） mybatis-plus: configuration: configuration-factory: com.xxx.SampleConfigurationFactory 全局策略配置1. refresh(自动刷新 Mapper 对应的 XML 文件) 类型：boolean 默认值：false是否自动刷新 Mapper 对应的 XML 文件，默认不自动刷新。如果配置了该属性，Mapper 对应的 XML 文件会自动刷新，更改 XML 文件后，无需再次重启工程，由此节省大量时间。该配置不建议在生产环境打开！ mybatis-plus: global-config: refresh: true 2. sqlParserCache(是否缓存 Sql 解析) 类型：boolean 默认值：false是否缓存 Sql 解析，默认不缓存。 mybatis-plus: global-config: sql-parser-cache: true 3. sqlSession 类型：SqlSession 默认值：null单例重用 SqlSession。 mybatis-plus: global-config: sql-session: com.xxx.SqlSession 4. sqlSessionFactory 类型：SqlSessionFactory 默认值：null缓存当前 Configuration 的 SqlSessionFactory。 mybatis-plus: global-config: sql-session-factory: com.xxx.SqlSessionFactory DB 策略配置1. capitalMode(是否开启大写命名) 类型：boolean 默认值：false是否开启大写命名，默认不开启。 mybatis-plus: global-config: db-config: capital-mode: false 2. columnLike 类型：boolean 默认值：false是否开启 LIKE 查询，即根据 entity 自动生成的 where 条件中 String 类型字段 是否使用 LIKE，默认不开启。 mybatis-plus: global-config: db-config: column-like: false 3. columnUnderline此属性存在于 2.x 版本上,现同 mapUnderscoreToCamelCase 融合 4. dbType ( 数据库类型 ) 类型：DbType 默认值：OTHER数据库类型,默认值为未知的数据库类型 如果值为OTHER,启动时会根据数据库连接 url 获取数据库类型;如果不是OTHER则不会自动获取数据库类型 mybatis-plus: global-config: db-config: db-type: mysql 5. idType( 全局默认主键类型 ) 类型：IdType 默认值：ID_WORKER全局默认主键类型 mybatis-plus: global-config: db-config: id-type: id_worker 6. logicDeleteValue (逻辑删除) 类型：String 默认值：1逻辑已删除值,(逻辑删除下有效) mybatis-plus: global-config: db-config: logic-delete-field: deleted #全局逻辑删除的实体字段名 logic-delete-value: 1 logic-not-delete-value: 0 7. tablePrefix( 表名前缀 ) 类型：String 默认值：null表名前缀 mybatis-plus: global-config: db-config: table-prefix: xx_ 8. tableUnderline 类型：boolean 默认值：true表名、是否使用下划线命名，默认数据库表使用下划线命名 mybatis-plus: global-config: db-config: table-underline: true 五. 主键自动生成MyBatis-Plus默认实现5种主键生成策略，分别是： AUTO，配合数据库设置自增主键，可以实现主键的自动增长，类型为nmber； INPUT，由用户输入； NONE，不设置，等同于INPUT； ASSIGN_ID，只有当用户未输入时，采用雪花算法生成一个适用于分布式环境的全局唯一主键，类型可以是String和number； ASSIGN_UUID，只有当用户未输入时，生成一个String类型的主键，但不保证全局唯一； 在主键上添加注解 @TableId(type = IdType.AUTO)","categories":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/tags/springboot/"}],"author":"wst"},{"title":"【springboot】整合数据源Druid","slug":"spring boot/整合数据源Druid","date":"2022-01-23T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0123[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0123[object%20Object].html","excerpt":"","text":"1. 引入druid&lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>druid-spring-boot-starter&lt;/artifactId> &lt;version>1.1.23&lt;/version> &lt;/dependency> spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.64.101:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true&amp;nullCatalogMeansCurrent=true driver-class-name: com.mysql.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource # 数据源的其他配置 druid: # 初始化 initial-size: 5 # 最小 min-idle: 5 # 最大 max-active: 20 # 连接等待超时时间 max-wait: 60000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 time-between-eviction-runs-millis: 60000 # 配置一个连接在池中最小生存的时间，单位是毫秒 min-evictable-idle-time-millis: 300000 validation-query: SELECT 1 FROM DUAL test-on-borrow: false test-while-idle: true test-on-return: false # 打开PSCache，并且指定每个连接上PSCache的大小 pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 20 # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙 filters: stat,wall,log4j #合并多个DruidDataSource的监控数据 use-global-data-source-stat: true # 通过connectProperties属性来打开mergeSql功能；慢SQL记录 connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 # 配置DruidStatFilter web-stat-filter: enabled: true url-pattern: \"/*\" exclusions: \"*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*\" # 配置DruidStatViewServlet stat-view-servlet: enabled: true url-pattern: \"/druid/*\" # IP白名单(没有配置或者为空，则允许所有访问) # allow: # IP黑名单 (存在共同时，deny优先于allow) # deny: # 禁用HTML页面上的“Reset All”功能 reset-enable: false # 登录名 login-username: admin # 登录密码 login-password: 123456 或者 server: port: 8888 spring: application: name: springboot-druid datasource: username: root password: 123456 url: jdbc:mysql://localhost:3306/spring-boot-test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=UTC driver-class-name: com.mysql.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource # 数据库连接池类别 druid: initial-size: 5 # 初始化大小 min-idle: 10 # 最小连接数 max-active: 20 # 最大连接数 max-wait: 60000 # 获取连接时的最大等待时间 min-evictable-idle-time-millis: 300000 # 一个连接在池中最小生存的时间，单位是毫秒 time-between-eviction-runs-millis: 60000 # 多久才进行一次检测需要关闭的空闲连接，单位是毫秒 filters: stat,wall # 配置扩展插件：stat-监控统计，log4j-日志，wall-防火墙（防止SQL注入），去掉后，监控界面的sql无法统计 validation-query: SELECT 1 # 检测连接是否有效的 SQL语句，为空时以下三个配置均无效 test-on-borrow: true # 申请连接时执行validationQuery检测连接是否有效，默认true，开启后会降低性能 test-on-return: true # 归还连接时执行validationQuery检测连接是否有效，默认false，开启后会降低性能 test-while-idle: true # 申请连接时如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效，默认false，建议开启，不影响性能 stat-view-servlet: enabled: true # 是否开启 StatViewServlet allow: 127.0.0.1 # 访问监控页面 白名单，默认127.0.0.1 deny: 192.168.56.1 # 访问监控页面 黑名单 login-username: admin # 访问监控页面 登陆账号 login-password: admin # 访问监控页面 登陆密码 filter: stat: enabled: true # 是否开启 FilterStat，默认true log-slow-sql: true # 是否开启 慢SQL 记录，默认false slow-sql-millis: 5000 # 慢 SQL 的标准，默认 3000，单位：毫秒 merge-sql: false # 合并多个连接池的监控数据，默认false 2. 访问druid监控中心启动项目:在浏览器中输入http://IP:端口号/druid/index.html访问监控中心如果有配置登录账号密码，则需要进行登录：定义测试接口查询数据库：监控中心记录访问情况","categories":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/tags/springboot/"}],"author":"wst"},{"title":"【springboot】整合消息队列RabbitMQ","slug":"spring boot/整合消息队列RabbitMQ","date":"2022-01-23T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0123[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0123[object%20Object].html","excerpt":"","text":"6、RabbitMQ.pdf 1. 基于RabbitTemplate的使用首先最重要的是思路：SpringBoot整合RabbitMQ可分为生产者工程与消费者工程分为以下几步 生产者工程 添加RabbitMQ的起步依赖 在application.yml中配置RabbitMQ的信息 创建一个rabbitMQ配置类 创建生产者 消费者工程 添加RabbitMQ的起步依赖 在application.yml中配置RabbitMQ的信息 创建一个rabbitMQ配置类 消费者工程 生产者工程开始 添加RabbitMQ的起步依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-amqp&lt;/artifactId> &lt;/dependency> 在application.yml中配置RabbitMQ的信息 server: port: 8081 spring: application: name: test-rabbitmq-producer rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest virtualHost: / 创建一个rabbitMQ配置类 ，配置Exchange、Queue、及绑定交换机。 本例配置Topic交换机。 package com.example.config; import org.springframework.amqp.core.*; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * @ClassName RabbitmqConfig * @Description TODO * @Author 胡泽 * @Date 2019/12/17 12:35 * @Version 1.0 */ @Configuration public class RabbitmqConfig { public static final String QUEUE_INFORM_EMAIL = \"queue_inform_email\"; public static final String QUEUE_INFORM_SMS = \"queue_inform_sms\"; public static final String EXCHANGE_TOPICS_INFORM=\"exchange_topics_inform\"; public static final String ROUTINGKEY_EMAIL=\"inform.#.email.#\"; public static final String ROUTINGKEY_SMS=\"inform.#.sms.#\"; //声明交换机 @Bean(EXCHANGE_TOPICS_INFORM) public Exchange EXCHANGE_TOPICS_INFORM(){ //durable(true) 持久化，mq重启之后交换机还在 return ExchangeBuilder.topicExchange(EXCHANGE_TOPICS_INFORM).durable(true).build(); } //声明QUEUE_INFORM_EMAIL队列 @Bean(QUEUE_INFORM_EMAIL) public Queue QUEUE_INFORM_EMAIL(){ return new Queue(QUEUE_INFORM_EMAIL); } //声明QUEUE_INFORM_SMS队列 @Bean(QUEUE_INFORM_SMS) public Queue QUEUE_INFORM_SMS(){ return new Queue(QUEUE_INFORM_SMS); } //ROUTINGKEY_EMAIL队列绑定交换机，指定routingKey @Bean public Binding BINDING_QUEUE_INFORM_EMAIL(@Qualifier(QUEUE_INFORM_EMAIL) Queue queue, @Qualifier(EXCHANGE_TOPICS_INFORM) Exchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_EMAIL).noargs(); } //ROUTINGKEY_SMS队列绑定交换机，指定routingKey @Bean public Binding BINDING_ROUTINGKEY_SMS(@Qualifier(QUEUE_INFORM_SMS) Queue queue, @Qualifier(EXCHANGE_TOPICS_INFORM) Exchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_SMS).noargs(); } } 创建生产者 使用RarbbitTemplate发送消息 package com.example; import com.example.config.RabbitmqConfig; import org.junit.jupiter.api.Test; import org.junit.runner.RunWith; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; @SpringBootTest @RunWith(SpringRunner.class) class ProdcerTopicsSpringbootApplicationTests { @Autowired RabbitTemplate rabbitTemplate; @Test public void Producer_topics_springbootTest() { //使用rabbitTemplate发送消息 String message = \"send email message to user\"; /** * 参数： * 1、交换机名称 * 2、routingKey * 3、消息内容 */ rabbitTemplate.convertAndSend(RabbitmqConfig.EXCHANGE_TOPICS_INFORM, \"inform.email\", message); } } 生产者工程结束消费者工程开始 起步依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-amqp&lt;/artifactId> &lt;/dependency> 配置application.yml server: port: 8082 spring: application: name: test-rabbitmq-consumer rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest virtualHost: / 创建一个rabbitMQ配置类```javapackage com.example.config; import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration; /** @ClassName RabbitmqConfig @Description TODO @Author 胡泽 @Date 2019/12/17 12:35 @Version 1.0 /@Configurationpublic class RabbitmqConfig { public static final String QUEUE_INFORM_EMAIL = “queue_inform_email”; public static final String QUEUE_INFORM_SMS = “queue_inform_sms”; public static final String EXCHANGE_TOPICS_INFORM=”exchange_topics_inform”; public static final String ROUTINGKEY_EMAIL=”inform.#.email.#”; public static final String ROUTINGKEY_SMS=”inform.#.sms.#”; //声明交换机 @Bean(EXCHANGE_TOPICS_INFORM) public Exchange EXCHANGE_TOPICS_INFORM(){ //durable(true) 持久化，mq重启之后交换机还在 return ExchangeBuilder.topicExchange(EXCHANGE_TOPICS_INFORM).durable(true).build(); } //声明QUEUE_INFORM_EMAIL队列 @Bean(QUEUE_INFORM_EMAIL) public Queue QUEUE_INFORM_EMAIL(){ return new Queue(QUEUE_INFORM_EMAIL); } //声明QUEUE_INFORM_SMS队列 @Bean(QUEUE_INFORM_SMS) public Queue QUEUE_INFORM_SMS(){ return new Queue(QUEUE_INFORM_SMS); } //ROUTINGKEY_EMAIL队列绑定交换机，指定routingKey @Bean public Binding BINDING_QUEUE_INFORM_EMAIL(@Qualifier(QUEUE_INFORM_EMAIL) Queue queue, @Qualifier(EXCHANGE_TOPICS_INFORM) Exchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_EMAIL).noargs(); } //ROUTINGKEY_SMS队列绑定交换机，指定routingKey @Bean public Binding BINDING_ROUTINGKEY_SMS(@Qualifier(QUEUE_INFORM_SMS) Queue queue, @Qualifier(EXCHANGE_TOPICS_INFORM) Exchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_SMS).noargs(); } } 4. 监听队列，接收消息 ```java package com.example.controller; import com.example.config.RabbitmqConfig; import com.rabbitmq.client.Channel; import com.rabbitmq.client.impl.AMQImpl; import org.springframework.amqp.core.Message; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.boot.autoconfigure.amqp.RabbitProperties; import org.springframework.stereotype.Component; /** * @ClassName ReceiveHandler * @Description TODO * @Author 胡泽 * @Date 2019/12/17 13:02 * @Version 1.0 */ @Component public class ReceiveHandler { //监听email队列 @RabbitListener(queues = {RabbitmqConfig.QUEUE_INFORM_EMAIL}) public void receive_email(Object msg, Message message, Channel channel){ System.out.println(&quot;QUEUE_INFORM_EMAIL msg&quot;+msg); } //监听sms队列 @RabbitListener(queues = {RabbitmqConfig.QUEUE_INFORM_SMS}) public void receive_sms(Object msg, Message message, Channel channel){ System.out.println(&quot;QUEUE_INFORM_SMS msg&quot;+msg); } } 启动生产者：启动成功启动消费者：查看信息 消费者工程结束2. 基于注解的方式使用 **@EnableRabbit **这个注解开启了容器对注册的bean的@RabbitListener检查。 **@RabbitListener ** **@RabbitHandler **与@RabbitListener配合使用 RabbitMQ 可以采用基于注解的方式来创建队列，如下： 手动在 RabbitMQ 管理界面创建 myQueue队列 发送者代码 @Autowired private AmqpTemplate amqpTemplate; public void send(){ String msg = \"mqsender send ...\" + new Date(); amqpTemplate.convertAndSend(\"myQueue\", msg); } 接收者代码 /** * 需要手动在39...50:15672/ 下的RabbitMQ management 界面下创建一个队列 myQueue * @param msg */ @RabbitListener(queues = \"myQueue\") public void receive(String msg){ log.info(\"mqReceive = {}\" , msg ); } 通过注解自动创建 myQueue 队列 发送方程序和上面一样 接收方程序如下：```java/** * @param msg /@RabbitListener(queuesToDeclare = @Queue(“myQueue”))public void receive(String msg){ log.info(“mqReceive = {}” , msg );}``` ** 自动创建，queue 和 exchange 绑定** 发送方程序不变 接收方程序如下// 3. 自动创建，queue 和 exchange 绑定 @RabbitListener(bindings = @QueueBinding( value = @Queue(\"myQueue\"), exchange = @Exchange(\"myExchange\") )) public void receive(String msg){ log.info(\"mqReceive = {}\" , msg ); } ** 实战模拟消息分组** 发送方:```java/** 模拟消息分组 发送方 /public void sendOrder(){ String msg = “mqsender send …” + new Date(); // 参数：交换机，路由key, 消息 amqpTemplate.convertAndSend(“myOrder”,”computer”, msg);}``` 接收方:```java/———– 模拟消息分组 ——————–*// 数码供应商服务 接收消息 消息发到交换机，交换机根据不同的key 发送到不同的队列 /@RabbitListener(bindings = @QueueBinding( exchange = @Exchange(&quot;myOrder&quot;), key = &quot;computer&quot;, value = @Queue(&quot;computerOrder&quot;) ))public void receiveComputer(String msg){ log.info(“ receiveComputer service = {}” , msg );}/** 水果供应商服务 接收消息 /@RabbitListener(bindings = @QueueBinding( value = @Queue(&quot;fruitOrder&quot;), key = &quot;fruit&quot;, exchange = @Exchange(&quot;myOrder&quot;) ))public void receiveFruit(String msg){ log.info(“ receiveFruit service = {}” , msg );}``` 测试用例:```java@Autowiredprivate MQSender sender; @Test public void sendOrderTest() { sender.sendOrder(); }``` 结果： 消息发送到交换机，交换机通过路由key 发送到对应的队列。 因此computerOrder队列得到了消息，进而receiveComputer()接收到了消息。 RabbitMQ超级详解： https://blog.csdn.net/huzecom/article/details/103499692","categories":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/tags/springboot/"}],"author":"wst"},{"title":"【springboot】整合缓存Redis","slug":"spring boot/整合缓存Redis","date":"2022-01-23T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0123[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0123[object%20Object].html","excerpt":"","text":"1、Redis.pdf 1. RedisTemplate/StringRedisTemplate 整合方式 导入redis启动器依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> 在application.yml配置redis数据源```properties经常用到的参数 Redis数据库索引（默认为0）spring.redis.database=0 Redis服务器地址spring.redis.host=localhost Redis服务器连接端口spring.redis.port=6379 Redis服务器连接密码（默认为空）spring.redis.password=123456 连接池最大连接数（使用负值表示没有限制）spring.redis.jedis.pool.max-active=1024 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.jedis.pool.max-wait=10000 连接池中的最大空闲连接spring.redis.jedis.pool.max-idle=200 连接池中的最小空闲连接spring.redis.jedis.pool.min-idle=0 连接超时时间（毫秒）spring.redis.timeout=10000 这个和下文对应redis.host=localhostredis.port=6379#连接超时时间redis.timeout=3redis.password=123456#连接池配置#最大连接数redis.poolMaxTotal=10#最大空闲连接数redis.poolMaxIdle=10#最大等待连接数redis.poolMaxWait=3 - 在service中注入StringRedisTemplate或者RedisTemplate ![](https://cdn.nlark.com/yuque/0/2022/png/26718429/1652068476153-f214b066-e120-415a-bd88-1a1cd1dc6bd6.png#clientId=uf68b53fa-f840-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u36345289&amp;margin=%5Bobject%20Object%5D&amp;originHeight=311&amp;originWidth=853&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue3a9fd3c-c572-4f6e-832a-bb33296f461&amp;title=) 首先如下图所示**StringRedisTemplate继承了RedisTemplate,所以两者对Redis的操作方法具有相同之处** ![](https://cdn.nlark.com/yuque/0/2022/png/26718429/1652068502974-ad0a1017-43e8-4299-a8ea-efa01990495a.png#clientId=uf68b53fa-f840-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u695a8fe7&amp;margin=%5Bobject%20Object%5D&amp;originHeight=268&amp;originWidth=865&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue84cac66-6ae6-4e65-bc93-4a903be4f4f&amp;title=) ## 1.1 StringRedisTemplate与RedisTemplate的区别 - 两者的数据是**不共通**的；也就是说StringRedisTemplate只能管理StringRedisTemplate里面的数据，RedisTemplate只能管理RedisTemplate中的数据。 - 其实他们两者之间的区别主要在于他们使用的序列化类: - RedisTemplate使用的是JdkSerializationRedisSerializer 存入数据会将数据先序列化成字节数组然后在存入Redis数据库。 - StringRedisTemplate使用的是StringRedisSerializer - 使用时注意事项： - 当你的redis数据库里面本来存的是字符串数据或者你要存取的数据就是字符串类型数据的时候，那么你就使用StringRedisTemplate即可。 - 但是如果你的数据是复杂的对象类型，而取出的时候又不想做任何的数据转换，直接从Redis里面取出一个对象，那么使用RedisTemplate是更好的选择。 - RedisTemplate使用时常见问题： - redisTemplate 中存取数据都是字节数组。当redis中存入的数据是可读形式而非字节数组时，使用redisTemplate取值的时候会无法获取导出数据，获得的值为null。可以使用 StringRedisTemplate 试试。 ## 1.2 操作StringRedisTemplate的工具类 RedisUtil.java ```java package com.liqiye.springbootdemo.utils; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cache.annotation.CachingConfigurerSupport; import org.springframework.data.redis.connection.DataType; import org.springframework.data.redis.core.Cursor; import org.springframework.data.redis.core.ScanOptions; import org.springframework.data.redis.core.StringRedisTemplate; import org.springframework.data.redis.core.ZSetOperations.TypedTuple; import org.springframework.stereotype.Component; import java.util.*; import java.util.concurrent.TimeUnit; @Component public class RedisUtil extends CachingConfigurerSupport { @Autowired private StringRedisTemplate stringRedisTemplate; public StringRedisTemplate getstringRedisTemplate() { return this.stringRedisTemplate; } /** -------------------key相关操作--------------------- */ /** * 删除key * * @param key */ public void delete(String key) { stringRedisTemplate.delete(key); } /** * 批量删除key * * @param keys */ public void delete(Collection&lt;String&gt; keys) { stringRedisTemplate.delete(keys); } /** * 序列化key * * @param key * @return */ public byte[] dump(String key) { return stringRedisTemplate.dump(key); } /** * 是否存在key * * @param key * @return */ public Boolean hasKey(String key) { return stringRedisTemplate.hasKey(key); } /** * 设置过期时间 * * @param key * @param timeout * @param unit * @return */ public Boolean expire(String key, long timeout, TimeUnit unit) { return stringRedisTemplate.expire(key, timeout, unit); } /** * 设置过期时间 * * @param key * @param date * @return */ public Boolean expireAt(String key, Date date) { return stringRedisTemplate.expireAt(key, date); } /** * 查找匹配的key * * @param pattern * @return */ public Set&lt;String&gt; keys(String pattern) { return stringRedisTemplate.keys(pattern); } /** * 将当前数据库的 key 移动到给定的数据库 db 当中 * * @param key * @param dbIndex * @return */ public Boolean move(String key, int dbIndex) { return stringRedisTemplate.move(key, dbIndex); } /** * 移除 key 的过期时间，key 将持久保持 * * @param key * @return */ public Boolean persist(String key) { return stringRedisTemplate.persist(key); } /** * 返回 key 的剩余的过期时间 * * @param key * @param unit * @return */ public Long getExpire(String key, TimeUnit unit) { return stringRedisTemplate.getExpire(key, unit); } /** * 返回 key 的剩余的过期时间 * * @param key * @return */ public Long getExpire(String key) { return stringRedisTemplate.getExpire(key); } /** * 从当前数据库中随机返回一个 key * * @return */ public String randomKey() { return stringRedisTemplate.randomKey(); } /** * 修改 key 的名称 * * @param oldKey * @param newKey */ public void rename(String oldKey, String newKey) { stringRedisTemplate.rename(oldKey, newKey); } /** * 仅当 newkey 不存在时，将 oldKey 改名为 newkey * * @param oldKey * @param newKey * @return */ public Boolean renameIfAbsent(String oldKey, String newKey) { return stringRedisTemplate.renameIfAbsent(oldKey, newKey); } /** * 返回 key 所储存的值的类型 * * @param key * @return */ public DataType type(String key) { return stringRedisTemplate.type(key); } /** -------------------string相关操作--------------------- */ /** * 设置指定 key 的值 * @param key * @param value */ public void set(String key, String value) { stringRedisTemplate.opsForValue().set(key, value); } /** * 获取指定 key 的值 * @param key * @return */ public String get(String key) { return stringRedisTemplate.opsForValue().get(key); } /** * 返回 key 中字符串值的子字符 * @param key * @param start * @param end * @return */ public String getRange(String key, long start, long end) { return stringRedisTemplate.opsForValue().get(key, start, end); } /** * 将给定 key 的值设为 value ，并返回 key 的旧值(old value) * * @param key * @param value * @return */ public String getAndSet(String key, String value) { return stringRedisTemplate.opsForValue().getAndSet(key, value); } /** * 对 key 所储存的字符串值，获取指定偏移量上的位(bit) * * @param key * @param offset * @return */ public Boolean getBit(String key, long offset) { return stringRedisTemplate.opsForValue().getBit(key, offset); } /** * 批量获取 * * @param keys * @return */ public List&lt;String&gt; multiGet(Collection&lt;String&gt; keys) { return stringRedisTemplate.opsForValue().multiGet(keys); } /** * 设置ASCII码, 字符串&#39;a&#39;的ASCII码是97, 转为二进制是&#39;01100001&#39;, 此方法是将二进制第offset位值变为value * * @param key * @param * @param value * 值,true为1, false为0 * @return */ public boolean setBit(String key, long offset, boolean value) { return stringRedisTemplate.opsForValue().setBit(key, offset, value); } /** * 将值 value 关联到 key ，并将 key 的过期时间设为 timeout * * @param key * @param value * @param timeout * 过期时间 * @param unit * 时间单位, 天:TimeUnit.DAYS 小时:TimeUnit.HOURS 分钟:TimeUnit.MINUTES * 秒:TimeUnit.SECONDS 毫秒:TimeUnit.MILLISECONDS */ public void setEx(String key, String value, long timeout, TimeUnit unit) { stringRedisTemplate.opsForValue().set(key, value, timeout, unit); } /** * 只有在 key 不存在时设置 key 的值 * * @param key * @param value * @return 之前已经存在返回false,不存在返回true */ public boolean setIfAbsent(String key, String value) { return stringRedisTemplate.opsForValue().setIfAbsent(key, value); } /** * 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始 * * @param key * @param value * @param offset * 从指定位置开始覆写 */ public void setRange(String key, String value, long offset) { stringRedisTemplate.opsForValue().set(key, value, offset); } /** * 获取字符串的长度 * * @param key * @return */ public Long size(String key) { return stringRedisTemplate.opsForValue().size(key); } /** * 批量添加 * * @param maps */ public void multiSet(Map&lt;String, String&gt; maps) { stringRedisTemplate.opsForValue().multiSet(maps); } /** * 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在 * * @param maps * @return 之前已经存在返回false,不存在返回true */ public boolean multiSetIfAbsent(Map&lt;String, String&gt; maps) { return stringRedisTemplate.opsForValue().multiSetIfAbsent(maps); } /** * 增加(自增长), 负数则为自减 * * @param key * @param * @return */ public Long incrBy(String key, long increment) { return stringRedisTemplate.opsForValue().increment(key, increment); } /** * * @param key * @param * @return */ public Double incrByFloat(String key, double increment) { return stringRedisTemplate.opsForValue().increment(key, increment); } /** * 追加到末尾 * * @param key * @param value * @return */ public Integer append(String key, String value) { return stringRedisTemplate.opsForValue().append(key, value); } /** -------------------hash相关操作------------------------- */ /** * 获取存储在哈希表中指定字段的值 * * @param key * @param field * @return */ public Object hGet(String key, String field) { return stringRedisTemplate.opsForHash().get(key, field); } /** * 获取所有给定字段的值 * * @param key * @return */ public Map&lt;Object, Object&gt; hGetAll(String key) { return stringRedisTemplate.opsForHash().entries(key); } /** * 获取所有给定字段的值 * * @param key * @param fields * @return */ public List&lt;Object&gt; hMultiGet(String key, Collection&lt;Object&gt; fields) { return stringRedisTemplate.opsForHash().multiGet(key, fields); } public void hPut(String key, String hashKey, String value) { stringRedisTemplate.opsForHash().put(key, hashKey, value); } public void hPutAll(String key, Map&lt;String, String&gt; maps) { stringRedisTemplate.opsForHash().putAll(key, maps); } /** * 仅当hashKey不存在时才设置 * * @param key * @param hashKey * @param value * @return */ public Boolean hPutIfAbsent(String key, String hashKey, String value) { return stringRedisTemplate.opsForHash().putIfAbsent(key, hashKey, value); } /** * 删除一个或多个哈希表字段 * * @param key * @param fields * @return */ public Long hDelete(String key, Object... fields) { return stringRedisTemplate.opsForHash().delete(key, fields); } /** * 查看哈希表 key 中，指定的字段是否存在 * * @param key * @param field * @return */ public boolean hExists(String key, String field) { return stringRedisTemplate.opsForHash().hasKey(key, field); } /** * 为哈希表 key 中的指定字段的整数值加上增量 increment * * @param key * @param field * @param increment * @return */ public Long hIncrBy(String key, Object field, long increment) { return stringRedisTemplate.opsForHash().increment(key, field, increment); } /** * 为哈希表 key 中的指定字段的整数值加上增量 increment * * @param key * @param field * @param delta * @return */ public Double hIncrByFloat(String key, Object field, double delta) { return stringRedisTemplate.opsForHash().increment(key, field, delta); } /** * 获取所有哈希表中的字段 * * @param key * @return */ public Set&lt;Object&gt; hKeys(String key) { return stringRedisTemplate.opsForHash().keys(key); } /** * 获取哈希表中字段的数量 * * @param key * @return */ public Long hSize(String key) { return stringRedisTemplate.opsForHash().size(key); } /** * 获取哈希表中所有值 * * @param key * @return */ public List&lt;Object&gt; hValues(String key) { return stringRedisTemplate.opsForHash().values(key); } /** * 迭代哈希表中的键值对 * * @param key * @param options * @return */ public Cursor&lt;Map.Entry&lt;Object, Object&gt;&gt; hScan(String key, ScanOptions options) { return stringRedisTemplate.opsForHash().scan(key, options); } /** ------------------------list相关操作---------------------------- */ /** * 通过索引获取列表中的元素 * * @param key * @param index * @return */ public String lIndex(String key, long index) { return stringRedisTemplate.opsForList().index(key, index); } /** * 获取列表指定范围内的元素 * * @param key * @param start * 开始位置, 0是开始位置 * @param end * 结束位置, -1返回所有 * @return */ public List&lt;String&gt; lRange(String key, long start, long end) { return stringRedisTemplate.opsForList().range(key, start, end); } /** * 存储在list头部 * * @param key * @param value * @return */ public Long lLeftPush(String key, String value) { return stringRedisTemplate.opsForList().leftPush(key, value); } /** * * @param key * @param value * @return */ public Long lLeftPushAll(String key, String... value) { return stringRedisTemplate.opsForList().leftPushAll(key, value); } /** * * @param key * @param value * @return */ public Long lLeftPushAll(String key, Collection&lt;String&gt; value) { return stringRedisTemplate.opsForList().leftPushAll(key, value); } /** * 当list存在的时候才加入 * * @param key * @param value * @return */ public Long lLeftPushIfPresent(String key, String value) { return stringRedisTemplate.opsForList().leftPushIfPresent(key, value); } /** * 如果pivot存在,再pivot前面添加 * * @param key * @param pivot * @param value * @return */ public Long lLeftPush(String key, String pivot, String value) { return stringRedisTemplate.opsForList().leftPush(key, pivot, value); } /** * * @param key * @param value * @return */ public Long lRightPush(String key, String value) { return stringRedisTemplate.opsForList().rightPush(key, value); } /** * * @param key * @param value * @return */ public Long lRightPushAll(String key, String... value) { return stringRedisTemplate.opsForList().rightPushAll(key, value); } /** * * @param key * @param value * @return */ public Long lRightPushAll(String key, Collection&lt;String&gt; value) { return stringRedisTemplate.opsForList().rightPushAll(key, value); } /** * 为已存在的列表添加值 * * @param key * @param value * @return */ public Long lRightPushIfPresent(String key, String value) { return stringRedisTemplate.opsForList().rightPushIfPresent(key, value); } /** * 在pivot元素的右边添加值 * * @param key * @param pivot * @param value * @return */ public Long lRightPush(String key, String pivot, String value) { return stringRedisTemplate.opsForList().rightPush(key, pivot, value); } /** * 通过索引设置列表元素的值 * * @param key * @param index * 位置 * @param value */ public void lSet(String key, long index, String value) { stringRedisTemplate.opsForList().set(key, index, value); } /** * 移出并获取列表的第一个元素 * * @param key * @return 删除的元素 */ public String lLeftPop(String key) { return stringRedisTemplate.opsForList().leftPop(key); } /** * 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 * * @param key * @param timeout * 等待时间 * @param unit * 时间单位 * @return */ public String lBLeftPop(String key, long timeout, TimeUnit unit) { return stringRedisTemplate.opsForList().leftPop(key, timeout, unit); } /** * 移除并获取列表最后一个元素 * * @param key * @return 删除的元素 */ public String lRightPop(String key) { return stringRedisTemplate.opsForList().rightPop(key); } /** * 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 * * @param key * @param timeout * 等待时间 * @param unit * 时间单位 * @return */ public String lBRightPop(String key, long timeout, TimeUnit unit) { return stringRedisTemplate.opsForList().rightPop(key, timeout, unit); } /** * 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 * * @param sourceKey * @param destinationKey * @return */ public String lRightPopAndLeftPush(String sourceKey, String destinationKey) { return stringRedisTemplate.opsForList().rightPopAndLeftPush(sourceKey, destinationKey); } /** * 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 * * @param sourceKey * @param destinationKey * @param timeout * @param unit * @return */ public String lBRightPopAndLeftPush(String sourceKey, String destinationKey, long timeout, TimeUnit unit) { return stringRedisTemplate.opsForList().rightPopAndLeftPush(sourceKey, destinationKey, timeout, unit); } /** * 删除集合中值等于value得元素 * * @param key * @param index * index=0, 删除所有值等于value的元素; index&gt;0, 从头部开始删除第一个值等于value的元素; * index&lt;0, 从尾部开始删除第一个值等于value的元素; * @param value * @return */ public Long lRemove(String key, long index, String value) { return stringRedisTemplate.opsForList().remove(key, index, value); } /** * 裁剪list * * @param key * @param start * @param end */ public void lTrim(String key, long start, long end) { stringRedisTemplate.opsForList().trim(key, start, end); } /** * 获取列表长度 * * @param key * @return */ public Long lLen(String key) { return stringRedisTemplate.opsForList().size(key); } /** --------------------set相关操作-------------------------- */ /** * set添加元素 * * @param key * @param values * @return */ public Long sAdd(String key, String... values) { return stringRedisTemplate.opsForSet().add(key, values); } /** * set移除元素 * * @param key * @param values * @return */ public Long sRemove(String key, Object... values) { return stringRedisTemplate.opsForSet().remove(key, values); } /** * 移除并返回集合的一个随机元素 * * @param key * @return */ public String sPop(String key) { return stringRedisTemplate.opsForSet().pop(key); } /** * 将元素value从一个集合移到另一个集合 * * @param key * @param value * @param destKey * @return */ public Boolean sMove(String key, String value, String destKey) { return stringRedisTemplate.opsForSet().move(key, value, destKey); } /** * 获取集合的大小 * * @param key * @return */ public Long sSize(String key) { return stringRedisTemplate.opsForSet().size(key); } /** * 判断集合是否包含value * * @param key * @param value * @return */ public Boolean sIsMember(String key, Object value) { return stringRedisTemplate.opsForSet().isMember(key, value); } /** * 获取两个集合的交集 * * @param key * @param otherKey * @return */ public Set&lt;String&gt; sIntersect(String key, String otherKey) { return stringRedisTemplate.opsForSet().intersect(key, otherKey); } /** * 获取key集合与多个集合的交集 * * @param key * @param otherKeys * @return */ public Set&lt;String&gt; sIntersect(String key, Collection&lt;String&gt; otherKeys) { return stringRedisTemplate.opsForSet().intersect(key, otherKeys); } /** * key集合与otherKey集合的交集存储到destKey集合中 * * @param key * @param otherKey * @param destKey * @return */ public Long sIntersectAndStore(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForSet().intersectAndStore(key, otherKey, destKey); } /** * key集合与多个集合的交集存储到destKey集合中 * * @param key * @param otherKeys * @param destKey * @return */ public Long sIntersectAndStore(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForSet().intersectAndStore(key, otherKeys, destKey); } /** * 获取两个集合的并集 * * @param key * @param otherKeys * @return */ public Set&lt;String&gt; sUnion(String key, String otherKeys) { return stringRedisTemplate.opsForSet().union(key, otherKeys); } /** * 获取key集合与多个集合的并集 * * @param key * @param otherKeys * @return */ public Set&lt;String&gt; sUnion(String key, Collection&lt;String&gt; otherKeys) { return stringRedisTemplate.opsForSet().union(key, otherKeys); } /** * key集合与otherKey集合的并集存储到destKey中 * * @param key * @param otherKey * @param destKey * @return */ public Long sUnionAndStore(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForSet().unionAndStore(key, otherKey, destKey); } /** * key集合与多个集合的并集存储到destKey中 * * @param key * @param otherKeys * @param destKey * @return */ public Long sUnionAndStore(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForSet().unionAndStore(key, otherKeys, destKey); } /** * 获取两个集合的差集 * * @param key * @param otherKey * @return */ public Set&lt;String&gt; sDifference(String key, String otherKey) { return stringRedisTemplate.opsForSet().difference(key, otherKey); } /** * 获取key集合与多个集合的差集 * * @param key * @param otherKeys * @return */ public Set&lt;String&gt; sDifference(String key, Collection&lt;String&gt; otherKeys) { return stringRedisTemplate.opsForSet().difference(key, otherKeys); } /** * key集合与otherKey集合的差集存储到destKey中 * * @param key * @param otherKey * @param destKey * @return */ public Long sDifference(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForSet().differenceAndStore(key, otherKey, destKey); } /** * key集合与多个集合的差集存储到destKey中 * * @param key * @param otherKeys * @param destKey * @return */ public Long sDifference(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForSet().differenceAndStore(key, otherKeys, destKey); } /** * 获取集合所有元素 * * @param key * @param * @param * @return */ public Set&lt;String&gt; setMembers(String key) { return stringRedisTemplate.opsForSet().members(key); } /** * 随机获取集合中的一个元素 * * @param key * @return */ public String sRandomMember(String key) { return stringRedisTemplate.opsForSet().randomMember(key); } /** * 随机获取集合中count个元素 * * @param key * @param count * @return */ public List&lt;String&gt; sRandomMembers(String key, long count) { return stringRedisTemplate.opsForSet().randomMembers(key, count); } /** * 随机获取集合中count个元素并且去除重复的 * * @param key * @param count * @return */ public Set&lt;String&gt; sDistinctRandomMembers(String key, long count) { return stringRedisTemplate.opsForSet().distinctRandomMembers(key, count); } /** * * @param key * @param options * @return */ public Cursor&lt;String&gt; sScan(String key, ScanOptions options) { return stringRedisTemplate.opsForSet().scan(key, options); } /**------------------zSet相关操作--------------------------------*/ /** * 添加元素,有序集合是按照元素的score值由小到大排列 * * @param key * @param value * @param score * @return */ public Boolean zAdd(String key, String value, double score) { return stringRedisTemplate.opsForZSet().add(key, value, score); } /** * * @param key * @param values * @return */ public Long zAdd(String key, Set&lt;TypedTuple&lt;String&gt;&gt; values) { return stringRedisTemplate.opsForZSet().add(key, values); } /** * * @param key * @param values * @return */ public Long zRemove(String key, Object... values) { return stringRedisTemplate.opsForZSet().remove(key, values); } /** * 增加元素的score值，并返回增加后的值 * * @param key * @param value * @param delta * @return */ public Double zIncrementScore(String key, String value, double delta) { return stringRedisTemplate.opsForZSet().incrementScore(key, value, delta); } /** * 返回元素在集合的排名,有序集合是按照元素的score值由小到大排列 * * @param key * @param value * @return 0表示第一位 */ public Long zRank(String key, Object value) { return stringRedisTemplate.opsForZSet().rank(key, value); } /** * 返回元素在集合的排名,按元素的score值由大到小排列 * * @param key * @param value * @return */ public Long zReverseRank(String key, Object value) { return stringRedisTemplate.opsForZSet().reverseRank(key, value); } /** * 获取集合的元素, 从小到大排序 * * @param key * @param start * 开始位置 * @param end * 结束位置, -1查询所有 * @return */ public Set&lt;String&gt; zRange(String key, long start, long end) { return stringRedisTemplate.opsForZSet().range(key, start, end); } /** * 获取集合元素, 并且把score值也获取 * * @param key * @param start * @param end * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zRangeWithScores(String key, long start, long end) { return stringRedisTemplate.opsForZSet().rangeWithScores(key, start, end); } /** * 根据Score值查询集合元素 * * @param key * @param min * 最小值 * @param max * 最大值 * @return */ public Set&lt;String&gt; zRangeByScore(String key, double min, double max) { return stringRedisTemplate.opsForZSet().rangeByScore(key, min, max); } /** * 根据Score值查询集合元素, 从小到大排序 * * @param key * @param min * 最小值 * @param max * 最大值 * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zRangeByScoreWithScores(String key, double min, double max) { return stringRedisTemplate.opsForZSet().rangeByScoreWithScores(key, min, max); } /** * * @param key * @param min * @param max * @param start * @param end * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zRangeByScoreWithScores(String key, double min, double max, long start, long end) { return stringRedisTemplate.opsForZSet().rangeByScoreWithScores(key, min, max, start, end); } /** * 获取集合的元素, 从大到小排序 * * @param key * @param start * @param end * @return */ public Set&lt;String&gt; zReverseRange(String key, long start, long end) { return stringRedisTemplate.opsForZSet().reverseRange(key, start, end); } /** * 获取集合的元素, 从大到小排序, 并返回score值 * * @param key * @param start * @param end * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zReverseRangeWithScores(String key, long start, long end) { return stringRedisTemplate.opsForZSet().reverseRangeWithScores(key, start, end); } /** * 根据Score值查询集合元素, 从大到小排序 * * @param key * @param min * @param max * @return */ public Set&lt;String&gt; zReverseRangeByScore(String key, double min, double max) { return stringRedisTemplate.opsForZSet().reverseRangeByScore(key, min, max); } /** * 根据Score值查询集合元素, 从大到小排序 * * @param key * @param min * @param max * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zReverseRangeByScoreWithScores( String key, double min, double max) { return stringRedisTemplate.opsForZSet().reverseRangeByScoreWithScores(key, min, max); } /** * * @param key * @param min * @param max * @param start * @param end * @return */ public Set&lt;String&gt; zReverseRangeByScore(String key, double min, double max, long start, long end) { return stringRedisTemplate.opsForZSet().reverseRangeByScore(key, min, max, start, end); } /** * 根据score值获取集合元素数量 * * @param key * @param min * @param max * @return */ public Long zCount(String key, double min, double max) { return stringRedisTemplate.opsForZSet().count(key, min, max); } /** * 获取集合大小 * * @param key * @return */ public Long zSize(String key) { return stringRedisTemplate.opsForZSet().size(key); } /** * 获取集合大小 * * @param key * @return */ public Long zZCard(String key) { return stringRedisTemplate.opsForZSet().zCard(key); } /** * 获取集合中value元素的score值 * * @param key * @param value * @return */ public Double zScore(String key, Object value) { return stringRedisTemplate.opsForZSet().score(key, value); } /** * 移除指定索引位置的成员 * * @param key * @param start * @param end * @return */ public Long zRemoveRange(String key, long start, long end) { return stringRedisTemplate.opsForZSet().removeRange(key, start, end); } /** * 根据指定的score值的范围来移除成员 * * @param key * @param min * @param max * @return */ public Long zRemoveRangeByScore(String key, double min, double max) { return stringRedisTemplate.opsForZSet().removeRangeByScore(key, min, max); } /** * 获取key和otherKey的并集并存储在destKey中 * * @param key * @param otherKey * @param destKey * @return */ public Long zUnionAndStore(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForZSet().unionAndStore(key, otherKey, destKey); } /** * * @param key * @param otherKeys * @param destKey * @return */ public Long zUnionAndStore(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForZSet() .unionAndStore(key, otherKeys, destKey); } /** * 交集 * * @param key * @param otherKey * @param destKey * @return */ public Long zIntersectAndStore(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForZSet().intersectAndStore(key, otherKey, destKey); } /** * 交集 * * @param key * @param otherKeys * @param destKey * @return */ public Long zIntersectAndStore(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForZSet().intersectAndStore(key, otherKeys, destKey); } /** * * @param key * @param options * @return */ public Cursor&lt;TypedTuple&lt;String&gt;&gt; zScan(String key, ScanOptions options) { return stringRedisTemplate.opsForZSet().scan(key, options); } } 1.3 操作RedisTemplate的工具类,以及配置类 配置Config 配置类，修改序列化方式，实体类需要实现 java.io.Serializable 接口```java@Configurationpublic class RedisConfig { @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); //配置序列化方式 Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper obm=new ObjectMapper(); // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和publi obm.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常 obm.activateDefaultTyping(LaissezFaireSubTypeValidator.instance,ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(obm); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); //key 采用String的序列化方式 template.setKeySerializer(stringRedisSerializer); //hash template.setHashKeySerializer(stringRedisSerializer); //value template.setValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; } } - 工具类 ```java /** * Redis工具类，使用之前请确保RedisTemplate成功注入 * * @author Lion Li * @version 2019-12-06 09:05:38 */ public class RedisUtils { private RedisUtils() { } @SuppressWarnings(&quot;unchecked&quot;) private static RedisTemplate&lt;String, Object&gt; redisTemplate = SpringUtils.getBean(RedisTemplate.class); /** * 设置有效时间 * * @param key Redis键 * @param timeout 超时时间 * @return true=设置成功；false=设置失败 */ public static boolean expire(final String key, final long timeout) { return expire(key, timeout, TimeUnit.SECONDS); } /** * 设置有效时间 * * @param key Redis键 * @param timeout 超时时间 * @param unit 时间单位 * @return true=设置成功；false=设置失败 */ public static boolean expire(final String key, final long timeout, final TimeUnit unit) { Boolean ret = redisTemplate.expire(key, timeout, unit); return ret != null &amp;&amp; ret; } /** * 删除单个key * * @param key 键 * @return true=删除成功；false=删除失败 */ public static boolean delKey(final String key) { Boolean ret = redisTemplate.delete(key); return ret != null &amp;&amp; ret; } /** * 删除多个key * * @param keys 键集合 * @return 成功删除的个数 */ public static long delKeys(final Collection&lt;String&gt; keys) { Long ret = redisTemplate.delete(keys); return ret == null ? 0 : ret; } /** * 存入普通对象 * * @param key Redis键 * @param value 值 */ public static void setValue(final String key, final Object value) { redisTemplate.opsForValue().set(key, value, 1, TimeUnit.MINUTES); } // 存储普通对象操作 /** * 存入普通对象 * * @param key 键 * @param value 值 * @param timeout 有效期，单位秒 */ public static void setValueTimeout(final String key, final Object value, final long timeout) { redisTemplate.opsForValue().set(key, value, timeout, TimeUnit.SECONDS); } /** * 获取普通对象 * * @param key 键 * @return 对象 */ public static Object getValue(final String key) { return redisTemplate.opsForValue().get(key); } // 存储Hash操作 /** * 确定哈希hashKey是否存在 * * @param key 键 * @param hkey hash键 * @return true=存在；false=不存在 */ public static boolean hasHashKey(final String key,String hkey) { Boolean ret = redisTemplate.opsForHash().hasKey(key,hkey); return ret != null &amp;&amp; ret; } /** * 往Hash中存入数据 * * @param key Redis键 * @param hKey Hash键 * @param value 值 */ public static void hashPut(final String key, final String hKey, final Object value) { redisTemplate.opsForHash().put(key, hKey, value); } /** * 往Hash中存入多个数据 * * @param key Redis键 * @param values Hash键值对 */ public static void hashPutAll(final String key, final Map&lt;String, Object&gt; values) { redisTemplate.opsForHash().putAll(key, values); } /** * 获取Hash中的数据 * * @param key Redis键 * @param hKey Hash键 * @return Hash中的对象 */ public static Object hashGet(final String key, final String hKey) { return redisTemplate.opsForHash().get(key, hKey); } /** * 获取Hash中的数据 * * @param key Redis键 * @return Hash对象 */ public static Map&lt;Object, Object&gt; hashGetAll(final String key) { return redisTemplate.opsForHash().entries(key); } /** * 获取多个Hash中的数据 * * @param key Redis键 * @param hKeys Hash键集合 * @return Hash对象集合 */ public static List&lt;Object&gt; hashMultiGet(final String key, final Collection&lt;Object&gt; hKeys) { return redisTemplate.opsForHash().multiGet(key, hKeys); } /** * 删除Hash中的数据 * * @param key Redis键 * @param hKeys Hash键集合 * @return Hash对象集合 */ public static long hashDeleteKeys(final String key, final Collection&lt;Object&gt; hKeys) { return redisTemplate.opsForHash().delete(key,hKeys); } // 存储Set相关操作 /** * 往Set中存入数据 * * @param key Redis键 * @param values 值 * @return 存入的个数 */ public static long setSet(final String key, final Object... values) { Long count = redisTemplate.opsForSet().add(key, values); return count == null ? 0 : count; } /** * 删除Set中的数据 * * @param key Redis键 * @param values 值 * @return 移除的个数 */ public static long setDel(final String key, final Object... values) { Long count = redisTemplate.opsForSet().remove(key, values); return count == null ? 0 : count; } /** * 获取set中的所有对象 * * @param key Redis键 * @return set集合 */ public static Set&lt;Object&gt; getSetAll(final String key) { return redisTemplate.opsForSet().members(key); } // 存储ZSet相关操作 /** * 往ZSet中存入数据 * * @param key Redis键 * @param values 值 * @return 存入的个数 */ public static long zsetSet(final String key, final Set&lt;ZSetOperations.TypedTuple&lt;Object&gt;&gt; values) { Long count = redisTemplate.opsForZSet().add(key, values); return count == null ? 0 : count; } /** * 删除ZSet中的数据 * * @param key Redis键 * @param values 值 * @return 移除的个数 */ public static long zsetDel(final String key, final Set&lt;ZSetOperations.TypedTuple&lt;Object&gt;&gt; values) { Long count = redisTemplate.opsForZSet().remove(key, values); return count == null ? 0 : count; } // 存储List相关操作 /** * 往List中存入数据 * * @param key Redis键 * @param value 数据 * @return 存入的个数 */ public static long listPush(final String key, final Object value) { Long count = redisTemplate.opsForList().rightPush(key, value); return count == null ? 0 : count; } /** * 往List中存入多个数据 * * @param key Redis键 * @param values 多个数据 * @return 存入的个数 */ public static long listPushAll(final String key, final Collection&lt;Object&gt; values) { Long count = redisTemplate.opsForList().rightPushAll(key, values); return count == null ? 0 : count; } /** * 往List中存入多个数据 * * @param key Redis键 * @param values 多个数据 * @return 存入的个数 */ public static long listPushAll(final String key, final Object... values) { Long count = redisTemplate.opsForList().rightPushAll(key, values); return count == null ? 0 : count; } /** * 从List中获取begin到end之间的元素 * * @param key Redis键 * @param start 开始位置 * @param end 结束位置（start=0，end=-1表示获取全部元素） * @return List对象 */ public static List&lt;Object&gt; listGet(final String key, final int start, final int end) { return redisTemplate.opsForList().range(key, start, end); } } 2. Jedis方式 pom文件引入```xml org.springframework.boot spring-boot-starter-data-redis redis.clients jedis 2.9.0 ``` 创建redis.properties配置文件 # Redis服务器地址 redis.host=127.0.0.1 # Redis服务器连接端口 redis.port=6379 # Redis服务器连接密码（默认为空） redis.password=null redis.timeout=30000 # 连接池最大连接数（使用负值表示没有限制） redis.maxTotal=30 # 连接池中的最大空闲连接 redis.maxIdle=10 redis.numTestsPerEvictionRun=1024 redis.timeBetweenEvictionRunsMillis=30000 redis.minEvictableIdleTimeMillis=1800000 redis.softMinEvictableIdleTimeMillis=10000 # 连接池最大阻塞等待时间（使用负值表示没有限制） redis.maxWaitMillis=1500 redis.testOnBorrow=true redis.testWhileIdle=true redis.blockWhenExhausted=false 创建RedisConfig配置类```javapackage com.wayne.config; import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig; /** redis配置类，用于读取redis地址、端口等基础参数 @author Wayne @date 2019/4/30 /@Configuration@PropertySource(“classpath:redis.properties”)public class RedisConfig { @Value(“${redis.host}”) private String host; @Value(“${redis.port}”) private int port; @Value(“${redis.timeout}”) private int timeout; @Value(“${redis.maxIdle}”) private int maxIdle; @Value(“${redis.maxWaitMillis}”) private int maxWaitMillis; @Value(“${redis.blockWhenExhausted}”) private Boolean blockWhenExhausted; @Value(“${redis.JmxEnabled}”) private Boolean JmxEnabled; @Bean public JedisPool jedisPoolFactory() { System.out.println(&quot;JedisPool注入开始...&quot;); JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxIdle(maxIdle); jedisPoolConfig.setMaxWaitMillis(maxWaitMillis); // 连接耗尽时是否阻塞, false报异常,true阻塞直到超时, 默认true jedisPoolConfig.setBlockWhenExhausted(blockWhenExhausted); // 是否启用pool的jmx管理功能, 默认tru jedisPoolConfig.setJmxEnabled(JmxEnabled); JedisPool jedisPool = new JedisPool(jedisPoolConfig, host, port, timeout); System.out.println(&quot;JedisPool注入成功...&quot;); return jedisPool; }}``` 创建RedisUtil工具类```javapackage com.wayne.utils; import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool; /** Redis工具类 @author Wayne @date 2019/4/30 /@Componentpublic class RedisUtil { @Autowired private JedisPool jedisPool; /** 向Redis中存值，永久有效 /public String set(String key, String value) { Jedis jedis = null; try { jedis = jedisPool.getResource(); return jedis.set(key, value); } catch (Exception e) { return &quot;0&quot;; } finally { returnResource(jedisPool, jedis); }} /** 根据传入Key获取指定Value /public String get(String key) { Jedis jedis = null; String value; try { jedis = jedisPool.getResource(); value = jedis.get(key); } catch (Exception e) { return &quot;0&quot;; } finally { returnResource(jedisPool, jedis); } return value;} /** 校验Key值是否存在 /public Boolean exists(String key) { Jedis jedis = null; try { jedis = jedisPool.getResource(); return jedis.exists(key); } catch (Exception e) { return false; } finally { returnResource(jedisPool, jedis); }} /** 删除指定Key-Value /public Long delete(String key) { Jedis jedis = null; try { jedis = jedisPool.getResource(); return jedis.del(key); } catch (Exception e) { return 0L; } finally { returnResource(jedisPool, jedis); }} // 以上为常用方法，更多方法自行百度 /** 释放连接 /private static void returnResource(JedisPool jedisPool, Jedis jedis) { if (jedis != null) { jedisPool.returnResource(jedis); }}}``` 使用:此处以注册发送短信验证码为例，验证码有效时间为2分钟```java@Autowiredprivate RedisUtil redisUtil; @Testpublic void sendMessage() { // 验证码为后台随机生成 final String CAPTCHA = “666666”; // 手机号为前端传入 final String MOBILE = “18888888888”; // 发送短信工具类 MessageUtils.sendMessage(CAPTCHA, MOBILE); // 将验证码存入Redis redisUtil.set(MOBILE, CAPTCHA); // 设置验证码过期时间为2分钟 redisUtil.expire(MOBILE, 60*2); System.out.println(&quot;验证码发送成功&quot;); } @Testpublic void validateCaptcha () { // 此验证码和手机号均为前端传入 String CAPTCHA = “666666”; String MOBILE = “18888888888”; // 校验验证码是否存在Redis中 if (!redisUtil.exists(MOBILE)) { System.out.println(&quot;验证码已过期&quot;); return; } // 获取Redis中的验证码 String tempCaptcha = redisUtil.get(MOBILE); // 校验验证码 if (!CAPTCHA.equals(tempCaptcha)) { System.out.println(&quot;验证码错误&quot;); return; } // 删除Redis中的验证码 redisUtil.delete(MOBILE); } # 3. @`Cacheable` 注解方式 ### 一、为什么使用注解来操作redis缓存 一般如果我们想把一个对象添加到redis缓存当中，都会写这样的一段代码 ```java @Autowired private RedisUtil redisUtil; redisInstance=redisUtil.get(&quot;test&quot;); if(redisInstance != null){ redisInstance=new String(); } redisUtil.add(&quot;test&quot;,redisInstance); 但是其实获取缓存的对象，判断对象是否为空，最后把对象放到缓存当中这样的操作对于不同的缓存操作都是一样的，那么通过使用注解的方式就可以把这么一段重复的代码抽离出来，减少重复代码。使用注解还有一个好处就是可拔插，不使用的时候，直接拿掉注解就可以了，不会影响原来的业务逻辑。更换使用的缓存方式也是，不需要替换缓存的实现方式。只需要把启用缓存注解的配置放到别的类型的缓存中即可。 二、使用缓存注解的具体方式 添加依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-cache&lt;/artifactId> &lt;/dependency> 设置启用缓存配置的设置 在redis的配置类RedisConfig.java里面添加 @EnableCaching 具体注解 主要的注解是，@Cacheable 、@CachePut、@CacheEvict@Cacheable就是用来替换我们原来的判空，查询缓存并返回的操作； 参数 解释 example value 缓存的名称，在 spring 配置文件中定义，必须指定至少一个 例如: @Cacheable(value=”mycache”) @Cacheable(value={”cache1”,”cache2”} key 缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 @Cacheable(value=”testcache”,key=”#userName”) condition 缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 @Cacheable(value=”testcache”,condition=”#userName.length()&gt;2”) @CachePut则是每次都会执行方法，其实只是有一个存入缓存的操作（只是“put”）； 参数 解释 example value 缓存的名称，在 spring 配置文件中定义，必须指定至少一个 @CachePut(value=”my cache”) key 缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 @CachePut(value=”testcache”,key=”#userName”) condition 缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 @CachePut(value=”testcache”,condition=”#userName.length()&gt;2”) @CacheEvict 是用来清空缓存的。 参数 解释 example value 缓存的名称，在 spring 配置文件中定义，必须指定至少一个 @CacheEvict(value=”my cache”) key 缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 @CacheEvict(value=”testcache”,key=”#userName”) condition 缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 @CacheEvict(value=”testcache”,condition=”#userName.length()&gt;2”) allEntries 是否清空所有缓存内容，缺省为 false，如果指定为 true，则方法调用后将立即清空所有缓存 @CachEvict(value=”testcache”,allEntries=true) beforeInvocation 是否在方法执行前就清空，缺省为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存 @CachEvict(value=”testcache”，beforeInvocation=true) 三个注解都可以用到方法上和类上面使用，看注解的定义就可以明白。 @CacheConfig(\"books\") public class BookRepositoryImpl implements BookRepository { @Cacheable public Book findBook(ISBN isbn) {...} } @CacheConfig所有的@Cacheable（）里面都有一个value＝“xxx”的属性，这显然如果方法多了，写起来也是挺累的，如果可以一次性声明完 那就省事了， 所以，有了@CacheConfig这个配置，一个类中可能会有多个缓存操作，而这些缓存操作可能是重复的。这个时候可以使用@CacheConfig。 新建RedisConfig.java```java@Configuration@EnableCachingpublic class RedisConfig { @Bean public CacheManager cacheManager(RedisConnectionFactory connectionFactory) { // 配置序列化（解决乱码的问题） RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ZERO) .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer)) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer)) .disableCachingNullValues(); RedisCacheManager cacheManager = RedisCacheManager.builder(factory) .cacheDefaults(config) .build(); return cacheManager; } @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) { RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); //序列化设置 ，这样为了存储操作对象时正常显示的数据，也能正常存储和获取 redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); return redisTemplate; } @Bean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory factory) { StringRedisTemplate stringRedisTemplate = new StringRedisTemplate(); stringRedisTemplate.setConnectionFactory(factory); return stringRedisTemplate; }} ### 三. 实例 ```java //@Cacheable(value=”accountCache”)，这个注释的意思是，当调用这个方法的时候，会从一个名叫 accountCache 的缓存中查询，如果没有，则执行实际的方法（即查询数据库）， //并将执行的结果存入缓存中，否则返回缓存中的对象。这里的缓存中的 key 就是参数 userName，value 就是 Account 对象。“accountCache”缓存是在 spring*.xml 中定义的名称。 @Cacheable(value=&quot;accountCache&quot;) public Account getAccountByName(String userName) { // 方法内部实现不考虑缓存逻辑，直接实现业务 System.out.println(&quot;real query account.&quot;+userName); return getFromDB(userName); } //@CachePut 注释，这个注释可以确保方法被执行，同时方法的返回值也被记录到缓存中，实现缓存与数据库的同步更新。 @CachePut(value=&quot;accountCache&quot;,key=&quot;#account.getName()&quot;)// 更新accountCache 缓存 public Account updateAccount(Account account) { return updateDB(account); } //@CacheEvict(value=&quot;accountCache&quot;,key=&quot;#account.getName()&quot;)// 清空accountCache 缓存 public void updateAccount(Account account) { updateDB(account); } //@CacheEvict(value=&quot;accountCache&quot;,allEntries=true)// 清空accountCache 缓存 public void reload() { reloadAll() } //@Cacheable(value=&quot;accountCache&quot;,condition=&quot;#userName.length() &lt;=4&quot;)// 缓存名叫 accountCache public Account getAccountByName(String userName) { // 方法内部实现不考虑缓存逻辑，直接实现业务 return getFromDB(userName); } 四. 条件缓存下面提供一些常用的条件缓存 //@Cacheable将在执行方法之前( #result还拿不到返回值)判断condition，如果返回true，则查缓存； @Cacheable(value = \"user\", key = \"#id\", condition = \"#id lt 10\") public User conditionFindById(final Long id) //@CachePut将在执行完方法后（#result就能拿到返回值了）判断condition，如果返回true，则放入缓存； @CachePut(value = \"user\", key = \"#id\", condition = \"#result.username ne 'zhang'\") public User conditionSave(final User user) //@CachePut将在执行完方法后（#result就能拿到返回值了）判断unless，如果返回false，则放入缓存；（即跟condition相反） @CachePut(value = \"user\", key = \"#user.id\", unless = \"#result.username eq 'zhang'\") public User conditionSave2(final User user) //@CacheEvict， beforeInvocation=false表示在方法执行之后调用（#result能拿到返回值了）；且判断condition，如果返回true，则移除缓存； @CacheEvict(value = \"user\", key = \"#user.id\", beforeInvocation = false, condition = \"#result.username ne 'zhang'\") public User conditionDelete(final User user) @Caching有时候我们可能组合多个Cache注解使用；比如用户新增成功后，我们要添加id–&gt;user；username—&gt;user；email—&gt;user的缓存；此时就需要@Caching组合多个注解标签了。 @Caching(put = { @CachePut(value = \"user\", key = \"#user.id\"), @CachePut(value = \"user\", key = \"#user.username\"), @CachePut(value = \"user\", key = \"#user.email\") }) public User save(User user) { }","categories":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/tags/springboot/"}],"author":"wst"},{"title":"【springboot】过滤器和拦截器用法及使用场景","slug":"spring boot/过滤器和拦截器用法及使用场景","date":"2022-01-23T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2022/0123[object Object].html","link":"","permalink":"https://409713427.github.io/2022/0123[object%20Object].html","excerpt":"","text":"拦截器与过滤器的区别： 过滤器和拦截器触发时机不一样，过滤器是在请求进入容器后，但请求进入servlet之前进行预处理的。请求结束返回也是，是在servlet处理完后，返回给前端之前。 如下图： 拦截器可以获取IOC容器中的各个bean，而过滤器就不行，因为拦截器是spring提供并管理的，spring的功能可以被拦截器使用，在拦截器里注入一个service，可以调用业务逻辑。而过滤器是JavaEE标准，只需依赖servlet api ，不需要依赖spring。 过滤器拦截器运行先后步骤： 其中第2步，SpringMVC的机制是由DispaterServlet来分发请求给不同的Controller，其实这一步是在Servlet的service()方法中执行的. 过滤器的实现基于回调函数。而拦截器（代理模式）的实现基于反射，代理分静态代理和动态代理，动态代理是拦截器的简单实现。 区别对比: 最简单明了的区别就是过滤器可以修改request，而拦截器不能 过滤器需要在servlet容器中实现，拦截器可以适用于javaEE，javaSE等各种环境 拦截器可以调用IOC容器中的各种依赖，而过滤器不能 过滤器只能在请求的前后使用，而拦截器可以详细到每个方法 过滤器就是筛选出你要的东西，比如requeset中你要的那部分拦截器在做安全方面用的比较多，比如终止一些流程 何时使用拦截器？何时使用过滤器？ 如果是非spring项目，那么拦截器不能用，只能使用过滤器。 如果是处理controller前后，既可以使用拦截器也可以使用过滤器。 如果是处理dispaterServlet前后，只能使用过滤器。 项目请求执行顺序 Filter -&gt;Interceptor.preHandle-&gt;Handler( Controller )-&gt;Interceptor.postHandle-&gt;Interceptor.afterCompletion-&gt;Filter spring boot 使用过滤器两种方式： 使用spring boot提供的FilterRegistrationBean注册Filter 使用原生servlet注解定义Filter 两种方式的本质都是一样的，都是去FilterRegistrationBean注册自定义Filter 方式一: 先定义Filter：```javapackage com.hwm.filter; import javax.servlet.*;import java.io.IOException; public class MyFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { // do something 处理request 或response System.out.println(&quot;filter1&quot;); // 调用filter链中的下一个filter filterChain.doFilter(servletRequest,servletResponse); } @Override public void destroy() { } } 2. 注册自定义Filter ```java @Configuration public class FilterConfig { @Bean public FilterRegistrationBean registrationBean() { FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new MyFilter()); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); return filterRegistrationBean; } } 方式二： （使用原生servlet注解定义Filter ) // 注入spring容器 @Component // 定义filterName 和过滤的url @WebFilter(filterName = \"my2Filter\" ,urlPatterns = \"/*\") public class My2Filter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { System.out.println(\"filter2\"); } @Override public void destroy() { } } 这里直接用@WebFilter就可以进行配置，同样，可以设置url匹配模式，过滤器名称等。这里需要注意一点的是@WebFilter这个注解是Servlet3.0的规范，并不是Spring boot提供的。除了这个注解以外，我们还需在启动类中加另外一个注解：@ServletComponetScan ，指定扫描的包。 Spring boot拦截器的使用： 实现拦截器可以通过继承 HandlerInterceptorAdapter类也可以通过实现HandlerInterceptor这个接口。另外，如果preHandle方法return true，则继续后续处理。首先我们实现拦截器类： public class MyInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"preHandle\"); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception { System.out.println(\"postHandle\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception { System.out.println(\"afterCompletion\"); } } 我们还需要实现HandlerInterceptor这个接口，这个接口包括三个方法，preHandle是请求执行前执行的，postHandler是请求结束执行的，但只有preHandle方法返回true的时候才会执行，afterCompletion是视图渲染完成后才执行，同样需要preHandle返回true，该方法通常用于清理资源等工作。除了实现上面的接口外，我们还需对其进行配置：配置拦截器: @Configuration public class InterceptorConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new MyInterceptor()).addPathPatterns(\"/**\");; } } 这里我们继承了WebMVCConfigurerAdapter，这里我们重写了addInterceptors这个方法，进行拦截器的配置，主要配置项就两个，一个是指定拦截器，第二个是指定拦截的URL。 拦截器不生效常见问题： 是否有加@Configuration 拦截路径是否有问题 ** 和 * 拦截器最后路径一定要 “/*”， 如果是目录的话则是 // 应用场景1. 拦截器应用场景拦截器本质上是面向切面编程（AOP），符合横切关注点的功能都可以放在拦截器中来实现，主要的应用场景包括： 登录验证，判断用户是否登录。 权限验证，判断用户是否有权限访问资源，如校验token 日志记录，记录请求操作日志（用户ip，访问时间等），以便统计请求访问量。 处理cookie、本地化、国际化、主题等。 性能监控，监控请求处理时长等。 通用行为：读取cookie得到用户信息并将用户对象放入请求，从而方便后续流程使用，还有如提取Locale、Theme信息等，只要是多个处理器都需要的即可使用拦截器实现）2. 过滤器应用场景 过滤敏感词汇（防止sql注入） 设置字符编码 URL级别的权限访问控制 压缩响应信息","categories":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/tags/springboot/"}],"author":"wst"},{"title":"【springcloud】Consul的基本使用","slug":"springcloud/Consul的基本使用","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1. 服务注册和发现1.1 注册服务 通过postman发送PUT请求到http://192.168.32.100:8500/v1/catalog/register地址可以完成服务注册。 { \"Datacenter\": \"dc1\", \"Node\": \"node01\", \"Address\": \"192.168.1.57\", \"Service\": { \"ID\": \"mysql-01\", \"Service\": \"mysql\", \"tags\": [ \"master\", \"v1\" ], \"Address\": \"192.168.1.57\", \"Port\": 3306 } } 1.2 服务查询 通过postman发送GET请求到http://192.168.32.100:8500/v1/catalog/services地址获取所有的服务列表。 通过postman发送GET请求到http://192.168.32.100:8500/v1/catalog/service/mysql获取具体的服务。 1.3 服务删除 通过postman发送PUT请求到http://192.168.32.100:8500/v1/catalog/deregister删除服务 2. Consul的KV存储 可以参照Consul提供的KV存储的API完成基于Consul的数据存储。| 含义 | 请求路径 | 请求方式 || — | — | — || 查看key | v1/kv/:key | GET || 保存或更新 | v1/kv/:key | put || 删除 | /v1/kv/:key | DELETE | key值中可以带/，可以看做是不同的目录结构。 value的值经过了base64编码，获取到数据后需要经过base64解码才能获取到原始值。数据不能大于521kb。 不同的数据中心的kv存储系统是独立的，使用dc=?参数指定。 3. 基于Consul的服务注册3**.1 案例目标** 准备一个商品微服务和订单微服务。 将商品微服务注册到Consul中。 订单微服务从consul中拉取所有的服务列表。 3**.2 案例准备**3**.2.1 sql脚本**```sqlSET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0; – Table structure for department DROP TABLE IF EXISTS department;CREATE TABLE department ( id int(11) NOT NULL AUTO_INCREMENT, name varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, PRIMARY KEY (id) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic; – Records of department INSERT INTO department VALUES (1, ‘开发部’);INSERT INTO department VALUES (2, ‘运维部’); – Table structure for employee DROP TABLE IF EXISTS employee;CREATE TABLE employee ( id int(11) NOT NULL AUTO_INCREMENT, name varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, gender varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, PRIMARY KEY (id) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic; – Records of employee INSERT INTO employee VALUES (1, ‘zhangsan’, ‘男’);INSERT INTO employee VALUES (2, ‘李四’, ‘女’); – Table structure for tb_order DROP TABLE IF EXISTS tb_order;CREATE TABLE tb_order ( id bigint(11) NOT NULL AUTO_INCREMENT, user_id int(11) NULL DEFAULT NULL COMMENT ‘用户id’, product_id int(11) NULL DEFAULT NULL COMMENT ‘商品id’, number int(11) NULL DEFAULT NULL COMMENT ‘数量’, price decimal(10, 2) NULL DEFAULT NULL COMMENT ‘单价’, amount decimal(10, 2) NULL DEFAULT NULL COMMENT ‘总额’, product_name varchar(40) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT ‘商品名’, username varchar(40) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT ‘用户名’, PRIMARY KEY (id) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; – Table structure for tb_product DROP TABLE IF EXISTS tb_product;CREATE TABLE tb_product ( id bigint(20) NOT NULL AUTO_INCREMENT, caption varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, inventory varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, price decimal(19, 2) NULL DEFAULT NULL, product_desc varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, product_name varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, status int(11) NULL DEFAULT NULL, PRIMARY KEY (id) USING BTREE) ENGINE = MyISAM AUTO_INCREMENT = 2 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic; – Records of tb_product INSERT INTO tb_product VALUES (1, ‘iPhone’, ‘1’, 5000.10, ‘苹果手机就是香’, ‘苹果哇’, 50); – Table structure for tb_user DROP TABLE IF EXISTS tb_user;CREATE TABLE tb_user ( id bigint(11) NOT NULL AUTO_INCREMENT, username varchar(40) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT ‘用户名’, password varchar(40) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT ‘密码’, age int(3) NULL DEFAULT NULL COMMENT ‘年龄’, balance decimal(10, 2) NULL DEFAULT NULL COMMENT ‘余额’, address varchar(80) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT ‘地址’, PRIMARY KEY (id) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; SET FOREIGN_KEY_CHECKS = 1; #### 3**.2.2 商品微服务** - pom.xml ```xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring_cloud_demo&lt;/artifactId&gt; &lt;groupId&gt;org.sunxiaping&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product_serivce-consul9003&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- 服务监控 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; application.yml```yamlserver:port: 9003 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ - Product.java ```java package com.sunxiaping.product.domain; import lombok.AllArgsConstructor; import lombok.Getter; import lombok.NoArgsConstructor; import lombok.Setter; import javax.persistence.*; import java.io.Serializable; import java.math.BigDecimal; @Setter @Getter @AllArgsConstructor @NoArgsConstructor @Entity @Table(name = &quot;tb_product&quot;) public class Product implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(name = &quot;product_name&quot;) private String productName; @Column(name = &quot;status&quot;) private Integer status; @Column(name = &quot;price&quot;) private BigDecimal price; @Column(name = &quot;product_desc&quot;) private String productDesc; @Column(name = &quot;caption&quot;) private String caption; @Column(name = &quot;inventory&quot;) private String inventory; } ProductRepository.java```javapackage com.sunxiaping.product.dao; import com.sunxiaping.product.domain.Product;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor;import org.springframework.stereotype.Repository; @Repositorypublic interface ProductRepository extends JpaRepository&lt;Product, Long&gt;, JpaSpecificationExecutor {} - ProductService.java ```java package com.sunxiaping.product.service; import com.sunxiaping.product.domain.Product; public interface ProductService { /** * 根据id查询 * * @param id * @return */ Product findById(Long id); /** * 保存 * * @param product */ void save(Product product); /** * 更新 * * @param product */ void update(Product product); /** * 删除 * * @param id */ void delete(Long id); } ProductServiceImpl.java```javapackage com.sunxiaping.product.service.impl; import com.sunxiaping.product.dao.ProductRepository;import com.sunxiaping.product.domain.Product;import com.sunxiaping.product.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service; import javax.transaction.Transactional; @Service@Transactionalpublic class ProductServiceImpl implements ProductService { @Autowired private ProductRepository productRepository; @Override public Product findById(Long id) { return productRepository.findById(id).orElse(new Product()); } @Override public void save(Product product) { productRepository.save(product); } @Override public void update(Product product) { productRepository.save(product); } @Override public void delete(Long id) { productRepository.deleteById(id); } } - ProductController.java ```java package com.sunxiaping.product.controller; import com.sunxiaping.product.domain.Product; import com.sunxiaping.product.service.ProductService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.*; @RestController @RequestMapping(value = &quot;/product&quot;) public class ProductController { @Autowired private ProductService productService; @PostMapping(value = &quot;/save&quot;) public String save(@RequestBody Product product) { productService.save(product); return &quot;新增成功&quot;; } @GetMapping(value = &quot;/findById/{id}&quot;) public Product findById(@PathVariable(value = &quot;id&quot;) Long id) { Product product = productService.findById(id); return product; } } 启动类：```javapackage com.sunxiaping.product; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplicationpublic class Product9003Application { public static void main(String[] args) { SpringApplication.run(Product9003Application.class, args); }} #### 3.2.3 订单微服务 - pom.xml ```xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring_cloud_demo&lt;/artifactId&gt; &lt;groupId&gt;org.sunxiaping&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;order-service-consul9004&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; application.yml```javaserver:port: 9004 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql jmx: unique-names: true 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ 开启日志debuglogging: level: root: info - SpringConfig.java ```java package com.sunxiaping.order.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class SpringConfig { @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } Product.java```javapackage com.sunxiaping.order.domain; import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter; import javax.persistence.*;import java.io.Serializable;import java.math.BigDecimal; @Setter@Getter@AllArgsConstructor@NoArgsConstructor@Entity@Table(name = “tb_product”)public class Product implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(name = &quot;product_name&quot;) private String productName; @Column(name = &quot;status&quot;) private Integer status; @Column(name = &quot;price&quot;) private BigDecimal price; @Column(name = &quot;product_desc&quot;) private String productDesc; @Column(name = &quot;caption&quot;) private String caption; @Column(name = &quot;inventory&quot;) private String inventory; } - OrderController.java ```java package com.sunxiaping.order.controller; import com.sunxiaping.order.domain.Product; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController @RequestMapping(value = &quot;/order&quot;) public class OrderController { @Autowired private RestTemplate restTemplate; @GetMapping(value = &quot;/buy/{id}&quot;) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { Product product = restTemplate.getForObject(&quot;http://localhost:9003/product/findById/&quot; + id, Product.class); return product; } } 启动类：```javapackage com.sunxiaping.order; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplicationpublic class Order9004Application { public static void main(String[] args) { SpringApplication.run(Order9004Application.class, args); }} ### 3**.3 服务注册** #### 3**.3.1 在商品微服务中添加SpringCloud基于Consul的依赖** - 修改部分： ```xml &lt;!-- SpringCloud提供的基于Consul的服务发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>product_serivce-consul9003&lt;/artifactId> &lt;dependencies> &lt;!-- 服务监控 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;!-- SpringCloud提供的基于Consul的服务发现 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-consul-discovery&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-jpa&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 3**.3.2 在商品微服务的application.yml中配置服务注册** 修改部分： spring: # 开始配置Consul的服务注册 cloud: consul: # ConsulServer的主机地址 host: 192.168.32.100 # ConsulServer端口 port: 8500 discovery: # 是否注册 register: true # 服务实例id 必须填写 也可以写成 {spring.application.name}:${spring.cloud.client.ip-address} instance-id: ${spring.application.name}-1 # 服务实例名称 service-name: ${spring.application.name} # 服务实例端口 port: ${server.port} # 健康检查路径 health-check-path: /actuator/health # 健康检查时间间隔 health-check-interval: 15s # 开启IP注册 prefer-ip-address: true # 实例的请求IP ip-address: ${spring.cloud.client.ip-address} 完整部分：```yamlserver:port: 9003 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 开始配置Consul的服务注册 cloud: consul: # ConsulServer的主机地址 host: 192.168.32.100 # ConsulServer端口 port: 8500 discovery: # 是否注册 register: true # 服务实例id 必须填写 也可以写成 {spring.application.name}:${spring.cloud.client.ip-address} instance-id: ${spring.application.name}-1 # 服务实例名称 service-name: ${spring.application.name} # 服务实例端口 port: ${server.port} # 健康检查路径 health-check-path: /actuator/health # 健康检查时间间隔 health-check-interval: 15s # 开启IP注册 prefer-ip-address: true # 实例的请求IP ip-address: ${spring.cloud.client.ip-address} 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ #### **3.3.3 启动类上加上@EnableDiscoveryClient注解** - 启动类: ```java package com.sunxiaping.product; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class Product9003Application { public static void main(String[] args) { SpringApplication.run(Product9003Application.class, args); } } 3**.4 服务发现**3**.4.1 在订单微服务中添加SpringCloud基于Consul的依赖** 修改部分: &lt;!-- 服务监控 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;!-- SpringCloud提供的基于Consul的服务发现 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-consul-discovery&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 order-service-consul9004 org.springframework.boot spring-boot-starter-data-jpa mysql mysql-connector-java org.springframework.boot spring-boot-starter-actuator org.springframework.cloud spring-cloud-starter-consul-discovery ``` #### 3.4.2 在订单微服务的application.yml中配置服务注册 修改部分: spring: # 开始配置Consul的服务注册 cloud: consul: # ConsulServer的主机地址 host: 192.168.32.100 # ConsulServer端口 port: 8500 discovery: # 是否注册 register: true # 服务实例id 必须填写 也可以写成 {spring.application.name}:${spring.cloud.client.ip-address} instance-id: ${spring.application.name}-1 # 服务实例名称 service-name: ${spring.application.name} # 服务实例端口 port: ${server.port} # 健康检查路径 health-check-path: /actuator/health # 健康检查时间间隔 health-check-interval: 15s # 开启IP注册 prefer-ip-address: true # 实例的请求IP ip-address: ${spring.cloud.client.ip-address} 完整部分:```yamlserver:port: 9004 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql jmx: unique-names: true 开始配置Consul的服务注册 cloud: consul: # ConsulServer的主机地址 host: 192.168.32.100 # ConsulServer端口 port: 8500 discovery: # 是否注册 register: true # 服务实例id 必须填写 也可以写成 {spring.application.name}:${spring.cloud.client.ip-address} instance-id: ${spring.application.name}-1 # 服务实例名称 service-name: ${spring.application.name} # 服务实例端口 port: ${server.port} # 健康检查路径 health-check-path: /actuator/health # 健康检查时间间隔 health-check-interval: 15s # 开启IP注册 prefer-ip-address: true # 实例的请求IP ip-address: ${spring.cloud.client.ip-address} 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ 开启日志debuglogging: level: root: info #### 3.4.3 在商品微服务的RestTemplate上面标注@LoadBalanced注解 - SpringConfig.java ```java package com.sunxiaping.order.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class SpringConfig { /** * SpringCloud对Consul进行了进一步的处理，向其中集成了Ribbon的支持 * * @return */ @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } 3.4.4 修改Controller OrderController.java```javapackage com.sunxiaping.order.controller; import com.sunxiaping.order.domain.Product;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate; @RestController@RequestMapping(value = “/order”)public class OrderController { @Autowired private RestTemplate restTemplate; @GetMapping(value = &quot;/buy/{id}&quot;) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { Product product = restTemplate.getForObject(&quot;http://service-product/product/findById/&quot; + id, Product.class); return product; } } #### 3**.4.5 启动类上加@EnableDiscoveryClient注解** - 启动类： ```java package com.sunxiaping.order; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class Order9004Application { public static void main(String[] args) { SpringApplication.run(Order9004Application.class, args); } } 4 Consul集群的搭建4.1 Consul的架构简介 图中的Server是Consul服务端高可用集群，Client是Consul的客户端。Consul客户端不保存数据，客户端将接收到的请求转发给响应的Server端。Server之间通过局域网或广域网通信实现数据一致性。每个Server或Client都是一个Consul agent。Consul集群间使用了gossip协议和raft一致性算法。 上图涉及到的相关术语： agent：agent是用来启动一个consul的守护进程。 client：是consul的代理，用来和consul server进行交互。一个微服务对应一个client，微服务和client部署到一台机器上。 server：一个server是一个具有一组扩展功能的代理，这些功能包括参与raft选举、维护集群状态、响应RPC查询，和其他数据中心交互以及转发查询给Leader或者远程数据中心等。简而言之。server就是真正干活的consul服务。一般推荐3~5个。 gossip协议：流言协议。所有的consul都会参与到gossip协议中。 raft协议：保证server集群的数据一致。 Leader：处理所有客户端交互、日志复制等，一般一次只有一个Leader。 Follower：类似选民，完全被动。 Candidate（候选人）：可以被选为一个新的领导人。 Leader全权负责所有客户端的请求，以及将数据同步到Follower中（同一时刻系统中只存在一个Leader）。 Follower被动响应请求RPC，从不主动发起RPC。 Candidate由Follower向Leader转换中间状态。 4.2 Consul集群搭建4**.2.1 概述** 首先一个正常的Consul集群，有Server，有Client。这里的服务器Server1、Server2和Server3上分别部署了Consul Server（这些服务器上最好只部署Consul程序，以尽量维护Consul Server的稳定）。 服务器Server4和Server5上通过Consul Client分别注册Service A、B、C，这里每个Service分别注册在了两个服务器上，这样可以避免Service的单点问题（一般而言微服务和Client绑定）。 在服务器Server6中Service D需要访问ServiceB，这个时候Service D首先访问本机Consul Client提供的HTTP API，本机Client会将请求转发到Consul Server，Consul Server查询到Service B当前的信息返回。4.2.2 准备环境| 服务器IP | Consul类型 | Node节点名称 | 序号 || — | — | — | — || 192.168.237.100 | Server | server-1 | s1 || 192.168.237.101 | Server | server-2 | s2 || 192.168.237.102 | Server | server-3 | s3 || 192.168.237.1 | Client | client-1 | s4 | 简而言之，就是通过VMWear新建3个CentOS7环境，然后每个CentOS7环境中的网络模式都是NAT。 agent以client模式启动的节点：在该模式下，该节点会采集相关信息，通过RPC的方式向server发送。client模式节点有无数个，官方建议搭配微服务配置。 agent以server模式启动的节点：一个数据中心至少包含1个server节点。不过官网建议使用3~5个server节点组成集群，以保证高可用且不失效率。server节点参与raft、维护微服务信息、注册服务、健康检查等功能。 4**.2.3 安装consul并启动** 关闭每个consul节点上（Linux机器）上的防火墙： systemctl stop firewalld systemctl disable firewalld 在每个consul节点上安装consul服务，下载安装过程和单节点一致： # 从官网下载最新版本的consul服务 wget https://releases.hashicorp.com/consul/1.8.4/consul_1.8.4_linux_amd64.zip # 使用unzip命令解压 unzip consul_1.8.4_linux_amd64.zip # 将解压好的consul可执行命令赋值到/usr/local/bin目录下 cp consul /usr/local/bin # 测试一下 consul 启动每个consul server节点: consul agent -server -bootstrap-expect 3 -data-dir=/etc/consul.d -node=server-1 -bind=192.168.237.100 -ui -client 0.0.0.0 & consul agent -server -bootstrap-expect 3 -data-dir=/etc/consul.d -node=server-2 -bind=192.168.237.101 -ui -client 0.0.0.0 & consul agent -server -bootstrap-expect 3 -data-dir=/etc/consul.d -node=server-3 -bind=192.168.237.102 -ui -client 0.0.0.0 & -server：以server身份启动 bootstrap-expect：集群要求的最少Server数量，当低于这个数量，集群将失效 data-dir：data存放的目录。 node：节点id，在同一集群中不能重复。 bind：监听的IP地址。 client：客户端的IP地址（0.0.0.0）表示不限制。&amp;：在后台运行，Linux脚本语法 在本地电脑中使用client形式启动consul： consul agent -data-dir /etc/consul.d -node=client-1 -bind=192.168.237.1 -client=0.0.0.0 4**.2.4 每个节点加入到集群中** 在s2（192.168.237.101），s3（192.168.237.102）和s4（192.168.237.1）服务行通过consul join命令加入s1中的consul集群中。 ## 加入到consul集群 consul join 192.168.237.100 4**.2.5 测试** 在任意一台服务器中输入consul members查看集群中的所有节点信息： # 查看consul集群节点信息 consul members 通过浏览器http://192.168.237.100:8500/ui/dc1/nodes查看： 4.3 微服务注册到Consul集群中4**.3.1 订单微服务注册到Consul集群中** application.yml```yamlserver:port: 9003 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.237.100:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 开始配置Consul的服务注册 cloud: consul: # Consul Client的地址 修改的地方 host: 192.168.237.1 # ConsulServer端口 port: 8500 discovery: # 是否注册 register: true # 服务实例id 必须填写 也可以写成 {spring.application.name}:${spring.cloud.client.ip-address} instance-id: ${spring.application.name}-1 # 服务实例名称 service-name: ${spring.application.name} # 服务实例端口 port: ${server.port} # 健康检查路径 health-check-path: /actuator/health # 健康检查时间间隔 health-check-interval: 15s # 开启IP注册 prefer-ip-address: true # 实例的请求IP ip-address: ${spring.cloud.client.ip-address} 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ #### **4.3.2 商品微服务注册到Consul集群中** - application.yml ```yaml server: port: 9004 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 datasource: url: jdbc:mysql://192.168.237.100:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql jmx: unique-names: true # 开始配置Consul的服务注册 cloud: consul: # Consul Client的地址 修改的地方 host: 192.168.237.1 # ConsulServer端口 port: 8500 discovery: # 是否注册 register: true # 服务实例id 必须填写 也可以写成 {spring.application.name}:${spring.cloud.client.ip-address} instance-id: ${spring.application.name}-1 # 服务实例名称 service-name: ${spring.application.name} # 服务实例端口 port: ${server.port} # 健康检查路径 health-check-path: /actuator/health # 健康检查时间间隔 health-check-interval: 15s # 开启IP注册 prefer-ip-address: true # 实例的请求IP ip-address: ${spring.cloud.client.ip-address} # 微服务info内容详细信息 info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ # 开启日志debug logging: level: root: info 4.4 Consul的常见问题4**.4.1 节点和服务注销** 当服务或者节点失效，Consul不会对注册的信息进行剔除处理，仅仅进行标记而已（并且服务不可以使用）。如果担心失效节点和失效服务过多影响监控。可以通过调用HTTP API的形式进行处理。 节注销任意节点和服务: # PUT请求 http://192.168.32.100:8500/v1/catalog/deregister 注销当前节点的服务： # PUT请求 http://192.168.32.100:8500/v1/agent/service/deregister/[service-id] 如果某个节点不继续使用，也可以在本机使用consul leave命令，或者在其他节点使用consul force-level 节点id。 4**.4.2 健康检查和故障转移** 在集群环境下，健康检查是由服务注册到的agent来处理的，如果这个agent挂掉了，那么此节点的健康检查就处于无人管理的状态了。 从实际应用看，节点上的服务可能既要被发现，又要发现别的服务，如果节点挂掉了，仅提供被发现的功能实际上服务还是不可用的。当然发现别的服务也可以不使用本机节点，可以通过访问一个Nginx实现的若干Consul节点的负载均衡来实现。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】Consul的安装(Eureka的替换方案 不推荐)","slug":"springcloud/Consul的安装(Eureka替换方案 不推荐)","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"Consul的下载和安装 Consul不同于Eureka需要单独安装，访问官网可以下载Consul的最新版本，目前使用的是Consul 1.8.4。根据不同的操作系统类型选择不同的安装包，Consul支持所有主流操作系统。 在linux中下载Consul# 从官网下载最新版本的consul服务 wget https://releases.hashicorp.com/consul/1.8.4/consul_1.8.4_linux_amd64.zip # 使用unzip命令解压 unzip consul_1.8.4_linux_amd64.zip # 将解压好的consul可执行命令赋值到/usr/local/bin目录下 cp consul /usr/local/bin # 测试一下 consul 启动Consul# 以开发者模式快速启动，-client指定客户端可以访问的IP地址 consul agent -dev -client=0.0.0.0 启动之后，返回http://localhost:8500，可以看到Consul的管理界面：","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】Spring Cloud Bus","slug":"springcloud/Spring Cloud Bus（不推荐）","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1 概述1.1 Spring Cloud Bus是什么？ Spring Cloud Bus配置Spring Cloud Config使用可以实现配置的动态刷新。 Spring Cloud Bus是用来分布式系统的节点和轻量级消息系统连接起来的框架，它整合了Java事件处理机制和消息中间件的功能。 Spring Cloud Bus目前支持RabbitMQ和Kafka。 1.2 Spring Cloud Bus能干嘛 Spring Cloud Bus能管理和传播分布式系统间的消息，就像一个分布式执行器，可用于广播状态更改、事件推送等，也可以当做微服务间的通信通道。 1.3 为什么称为总线？1.3.1 什么是总线 在微服务架构的系统中，通常会使用轻量级的消息代理来构建一个共用的消息主题，并让系统中所有微服务实例都连接上来。由于该主题中产生的消息会被所有实例监听和消费，所以称其为消息总线。 在总线上的各个实例，都可以方便的传播一些需要让其他连接在该主题上的实例都知道的消息。 1.3.2 基本原理 Config Client实例都监听MQ中的同一个Topic（默认是SpringCloudBus）。当一个服务刷新数据的时候，其他监听到这个主题的服务就会得到通知，然后去更新自身的配置。 2 Spring Cloud Bus动态刷新全局广播2.1 设计思想 根据上图我们可以看出Spring Cloud Bus做配置更新的步骤： 提交代码触发POST请求给bus/refresh。 server端接收到请求并发送给Spring Cloud Bus。 Spring Cloud Bus接收到消息并通知给其他客户端。 其他客户端接收到通知，请求Server端获取最新配置。 全部客户端获取到最新的配置。2.2 服务端修改2.2.1 导入相关依赖 修改部分: &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-bus-amqp&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 config_server9010 org.springframework.cloud spring-cloud-config-server org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.cloud spring-cloud-starter-bus-amqp org.springframework.boot spring-boot-starter-actuator ``` ### **2.2.2 修改配置文件** application.yml```yamlserver:port: 9010spring:application: name: config-server—-修改部分——配置rabbitmqrabbitmq: host: 192.168.1.57 port: 5672 username: guest password: guest—-修改部分——cloud: config:server: git: # git服务地址 uri: https://gitee.com/AncientFairy/config-repo.git # 配置git的用户名 username: # 配置git的密码 password: search-paths: - config-repo # 分支 label: master 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: config-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ —-修改部分——配置端点management: endpoints: web: exposure: include: ‘bus-refresh’ —-修改部分——### **2.2.3 启动类** ```java package com.sunxiaping.config; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.config.server.EnableConfigServer; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; /** * @author 许大仙 * @version 1.0 * @since 2020-10-09 16:48 */ @SpringBootApplication @EnableConfigServer //开启配置中心功能 @EnableEurekaClient public class ConfigServer9010Application { public static void main(String[] args) { SpringApplication.run(ConfigServer9010Application.class, args); } } 2.3 客户端修改2.3.1 导入相关依赖 修改部分: &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-bus-amqp&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 config_client9011 org.springframework.cloud spring-cloud-starter-bus-amqp org.springframework.cloud spring-cloud-starter-config org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-data-jpa mysql mysql-connector-java ``` ### **2.3.2 修改配置文件** bootstrap.yml：```yamlspring:—-修改部分——配置rabbitmqrabbitmq: host: 192.168.1.57 port: 5672 username: guest password: guest—-修改部分——cloud: config:name: product # 应用名称，需要对应git中配置文件名称的前半部分 profile: dev # 开发环境，需要对应git中配置文件名称的后半部分 label: master # 分支名称 # uri: http://localhost:9010 # config-server的请求地址 discovery: # 服务发现 service-id: config-server enabled: true # 从Eureka中获取配置信息 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product-dev:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ ### **2.3.3 启动类** ```java package com.sunxiaping.product; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient //开启Eureka Client public class ProductApplication { public static void main(String[] args) { SpringApplication.run(ProductApplication.class, args); } } 2.3.4 业务逻辑 Product.java```javapackage com.sunxiaping.product.domain; import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter; import javax.persistence.*;import java.io.Serializable;import java.math.BigDecimal; @Setter@Getter@AllArgsConstructor@NoArgsConstructor@Entity@Table(name = “tb_product”)public class Product implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(name = &quot;product_name&quot;) private String productName; @Column(name = &quot;status&quot;) private Integer status; @Column(name = &quot;price&quot;) private BigDecimal price; @Column(name = &quot;product_desc&quot;) private String productDesc; @Column(name = &quot;caption&quot;) private String caption; @Column(name = &quot;inventory&quot;) private String inventory; } - ProductRepository.java ```java package com.sunxiaping.product.dao; import com.sunxiaping.product.domain.Product; import org.springframework.data.jpa.repository.JpaRepository; import org.springframework.data.jpa.repository.JpaSpecificationExecutor; import org.springframework.stereotype.Repository; @Repository public interface ProductRepository extends JpaRepository&lt;Product, Long&gt;, JpaSpecificationExecutor&lt;Product&gt; { } ProductService.java```javapackage com.sunxiaping.product.service; import com.sunxiaping.product.domain.Product; public interface ProductService { /** * 根据id查询 * * @param id * @return */ Product findById(Long id); /** * 保存 * * @param product */ void save(Product product); /** * 更新 * * @param product */ void update(Product product); /** * 删除 * * @param id */ void delete(Long id); } - ProductServiceImpl.java ```java package com.sunxiaping.product.service.impl; import com.sunxiaping.product.dao.ProductRepository; import com.sunxiaping.product.domain.Product; import com.sunxiaping.product.service.ProductService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import javax.transaction.Transactional; @Service @Transactional public class ProductServiceImpl implements ProductService { @Autowired private ProductRepository productRepository; @Override public Product findById(Long id) { return this.productRepository.findById(id).orElse(new Product()); } @Override public void save(Product product) { this.productRepository.save(product); } @Override public void update(Product product) { this.productRepository.save(product); } @Override public void delete(Long id) { this.productRepository.deleteById(id); } } ProductController.java```javapackage com.sunxiaping.product.controller; import com.sunxiaping.product.domain.Product;import com.sunxiaping.product.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.*; @RestController@RequestMapping(value = “/product”)@RefreshScope //开启动态刷新public class ProductController { @Value(&quot;${server.port}&quot;) private String port; @Value(&quot;${spring.cloud.client.ip-address}&quot;) private String ip; @Autowired private ProductService productService; @PostMapping(value = &quot;/save&quot;) public String save(@RequestBody Product product) { this.productService.save(product); return &quot;新增成功&quot;; } @GetMapping(value = &quot;/findById/{id}&quot;) public Product findById(@PathVariable(value = &quot;id&quot;) Long id) { Product product = this.productService.findById(id); product.setProductName(&quot;访问的地址是：&quot; + this.ip + &quot;:&quot; + this.port); return product; } } ## **2.4 测试** - 通过postman发送POST请求到http://localhost:9010/actuator/bus-refresh或者在控制台执行`curl -X POST &quot;http://localhost:9010/actuator/bus-refresh&quot;`命令。 # **3 Spring Cloud Bus动态刷新定点通知** ## **3.1 概述** - 有的时候，不需要在刷新服务端的时候，将与之对应的所有客户端都动态刷新，而是只需要刷新具体的某个客户端即可。 ## **3.2 方法** - 发送POST请求到`http://localhost:配置中心的端口号/actuator/bus-refresh/{destination}`即可。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】Spring Cloud Config","slug":"springcloud/Spring Cloud Config（不推荐）","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1. Spring Cloud Config简介 Spring Cloud Config项目是一个解决分布式系统的配置解决方案。它包含了Client和Server两个部分，Server提供配置文件的存储，以接口的形式将配置文件的内容提供出去；Client通过接口获取数据，并依据此数据初始化自己的应用。 Spring Cloud Config为分布式系统的外部配置提供服务器和客户端支持。使用Config Server，您可以为所有环境中的应用程序管理其外部属性。它非常适合Spring应用，也可以使用在其他语言的应用上。随着应用程序通过从开发到测试和生产的部署流程，您可以管理这些环境之间的配置，并确定应用程序具有迁移时需要运行的一切。服务器存储后端的默认使用使用Git，因此他轻松的支持标签版本的配置环境以及可以访问用于管理内容的各种工具。 Spring Cloud Config服务端的特性： Http，为外部配置提供基于资源的API（键值对或者等价的YAML内容）。 属性值的加密和解密（对称加密和非对称加密）。 通过使用@EnableConfigServer在Spring Boot应用中非常简单的嵌入。 Spring Cloud Config客户端的 特性： 绑定Config服务端，并使用远程的属性源初始化Spring环境。 属性值的加密和解密（对称加密和非对称加密）。2. Spring Cloud Config入门2**.1 准备工作** Config Server是一个可横向扩展、集中式的配置服务器，它用于集中管理应用程序各个环境下的配置，默认使用Git存储配置文件内容，也可以使用SVN存储（但是又有谁使用SVN呢？）或者是本地文件存储。 在码云上创建仓库： 创建product-dev.yml和product-prod.yml文件上传到创建的仓库上。 product-dev.yml：```yamlserver:port: 9008 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product-dev:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ - product-prod.yml： ```yaml server: port: 9009 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product-prod:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 文件命名规则： {application}-{profile}.yml {application}-{profile}.properties application为应用名称，profile指的是开发环境（用于区分开发环境、测试环境和生产环境等） 2**.2 搭建服务端程序**2**.2.1 新建模块并导入相关依赖** 修改部分: &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-config-server&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 config_server9010 org.springframework.cloud spring-cloud-config-server org.springframework.cloud spring-cloud-starter-netflix-eureka-client ``` ### 2**.2.2 配置application.yml** ```yaml server: port: 9010 spring: application: name: config-server cloud: config: server: git: # git服务地址 uri: https://gitee.com/AncientFairy/config-repo.git # 配置git的用户名 username: # 配置git的密码 password: search-paths: - config-repo # 分支 label: master 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: config-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ ### 2**.2.3 配置启动类** ```java package com.sunxiaping.config; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.config.server.EnableConfigServer; /** * @author 许大仙 * @version 1.0 * @since 2020-10-09 16:48 */ @SpringBootApplication @EnableConfigServer //开启配置中心功能 public class ConfigServer9010Application { public static void main(String[] args) { SpringApplication.run(ConfigServer9010Application.class, args); } } 2**.2.4 测试** 启动微服务，可以在浏览器，通过访问http://localhost:9010/master/product-dev.yml请求访问到Git服务器上的文件。 配置读取规则（label：分支，name：服务名，profile：环境）： /label/{application}-{profile}.yml（推荐方式）： http://localhost:9010/master/product-dev.yml http://localhost:9010/master/product-prod.yml http://localhost:9010/dev/product-dev.yml http://localhost:9010/dev/product-prod.yml …… {application}-{profile}.yml（其实就是/master/{application}-{profile}.yml）： http://localhost:9010/product-dev.yml http://localhost:9010/product-prod.yml …… /{application}-{profile}[/{label}]： http://localhost:9010/product/dev/master http://localhost:9010/product/prod/master …… 2**.3 搭建客户端程序**2**.3.1 新建模块并导入相关依赖** 修改部分: &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-config&lt;/artifactId> &lt;/dependency> 完整部分: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>config_client9011&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-config&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-jpa&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 2**.3.2 配置bootstrap.yml** bootstrap.yml是系统级别的资源配置项，application.yml是用户级别的资源配置项。 Spring Cloud会创建一个“Boostrap Context”，作为Spring应用的“Application Context”的父上下文。初始化的时候，“Boostrap Context”负载从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的“Environment”。 “Boostrap”属性有高优先级，默认情况下，不会覆盖本地配置项。“Bootstrap Context”和“Application Context”有着不同的约定，所以新增了一个“bootstrap.yml”，保证“BootStrap Context”和“Application Context”配置的分离。 要将Client模块下的application.yml改为bootstrap.yml，很关键。因为bootstrap.yml比application.yml优先加载。 spring: cloud: config: name: product # 应用名称，需要对应git中配置文件名称的前半部分 profile: prod # 开发环境，需要对应git中配置文件名称的后半部分 label: master # 分支名称 uri: http://localhost:9010 # config-server的请求地址 2**.3.3 实体类**package com.sunxiaping.product.domain; import lombok.AllArgsConstructor; import lombok.Getter; import lombok.NoArgsConstructor; import lombok.Setter; import javax.persistence.*; import java.io.Serializable; import java.math.BigDecimal; @Setter @Getter @AllArgsConstructor @NoArgsConstructor @Entity @Table(name = \"tb_product\") public class Product implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(name = \"product_name\") private String productName; @Column(name = \"status\") private Integer status; @Column(name = \"price\") private BigDecimal price; @Column(name = \"product_desc\") private String productDesc; @Column(name = \"caption\") private String caption; @Column(name = \"inventory\") private String inventory; } 2**.3.4 Dao层**package com.sunxiaping.product.dao; import com.sunxiaping.product.domain.Product; import org.springframework.data.jpa.repository.JpaRepository; import org.springframework.data.jpa.repository.JpaSpecificationExecutor; import org.springframework.stereotype.Repository; @Repository public interface ProductRepository extends JpaRepository&lt;Product, Long>, JpaSpecificationExecutor&lt;Product> { } 2.3.5 Service层 ProductService.java```javapackage com.sunxiaping.product.service; import com.sunxiaping.product.domain.Product; public interface ProductService { /** * 根据id查询 * * @param id * @return */ Product findById(Long id); /** * 保存 * * @param product */ void save(Product product); /** * 更新 * * @param product */ void update(Product product); /** * 删除 * * @param id */ void delete(Long id); } - ProductServiceImpl.java ```java package com.sunxiaping.product.service.impl; import com.sunxiaping.product.dao.ProductRepository; import com.sunxiaping.product.domain.Product; import com.sunxiaping.product.service.ProductService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import javax.transaction.Transactional; @Service @Transactional public class ProductServiceImpl implements ProductService { @Autowired private ProductRepository productRepository; @Override public Product findById(Long id) { return this.productRepository.findById(id).orElse(new Product()); } @Override public void save(Product product) { this.productRepository.save(product); } @Override public void update(Product product) { this.productRepository.save(product); } @Override public void delete(Long id) { this.productRepository.deleteById(id); } } 2**.3.6 Controller层**package com.sunxiaping.product.controller; import com.sunxiaping.product.domain.Product; import com.sunxiaping.product.service.ProductService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.*; @RestController @RequestMapping(value = \"/product\") public class ProductController { @Value(\"${server.port}\") private String port; @Value(\"${spring.cloud.client.ip-address}\") private String ip; @Autowired private ProductService productService; @PostMapping(value = \"/save\") public String save(@RequestBody Product product) { this.productService.save(product); return \"新增成功\"; } @GetMapping(value = \"/findById/{id}\") public Product findById(@PathVariable(value = \"id\") Long id) { Product product = this.productService.findById(id); product.setProductName(\"访问的地址是：\" + this.ip + \":\" + this.port); return product; } } 2**.3.7 配置类**package com.sunxiaping.product; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient //开启Eureka Client public class ProductApplication { public static void main(String[] args) { SpringApplication.run(ProductApplication.class, args); } } 2**.4 手动刷新**2**.4.1 概述** 我们已经在客户端获取到了配置中心的值，但是当我们修改git中的值的时候，服务端（Config Server）能实时的获取到最新的值，但是客户端（Config Client）读取的是缓存，无法实时获取最新值。SpringCloud已经为我们解决了这个问题，那就是客户端使用POST去触发refresh，获取最新数据，需要依赖spring-boot-starter-actuator。 2**.4.2 应用示例** 导入依赖: &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> 在对应的Controller类中添加@RefreshScope注解：```javapackage com.sunxiaping.product.controller; import com.sunxiaping.product.domain.Product;import com.sunxiaping.product.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.*; @RestController@RequestMapping(value = “/product”)@RefreshScope //开启动态刷新public class ProductController { @Value(&quot;${server.port}&quot;) private String port; @Value(&quot;${spring.cloud.client.ip-address}&quot;) private String ip; @Autowired private ProductService productService; @PostMapping(value = &quot;/save&quot;) public String save(@RequestBody Product product) { this.productService.save(product); return &quot;新增成功&quot;; } @GetMapping(value = &quot;/findById/{id}&quot;) public Product findById(@PathVariable(value = &quot;id&quot;) Long id) { Product product = this.productService.findById(id); product.setProductName(&quot;访问的地址是：&quot; + this.ip + &quot;:&quot; + this.port); return product; } } - 在application.yml中开放端点配置： ```yaml spring: cloud: config: name: product # 应用名称，需要对应git中配置文件名称的前半部分 profile: dev # 开发环境，需要对应git中配置文件名称的后半部分 label: master # 分支名称 uri: http://localhost:9010 # config-server的请求地址 # 暴露监控端点 management: endpoints: web: exposure: include: &#39;*&#39; 测试：在Git服务器上修改配置之后，需要使用curl -X POST &quot;http://localhost:9008/actuator/refresh&quot;发送请求。 3. 配置中心的高可用3**.1 概述** 在之前的代码中，客户端都是直接调用配置中心的Server端来获取配置信息。这样就存在了一个问题，客户端和服务端的耦合性太高，如果Server要做集群，客户端只能通过原始的方式来路由，Server端改变IP地址的时候，客户端也需要修改配置，不符合Spring Cloud 服务治理的概念。 Spring Cloud提供了这样的解决方案，我们只需要将Server端当做一个服务注册到Eureka中，Client端去Eureka中去获取配置中心Server端的服务即可。 3**.2 服务端改造** 导入Eureka Client的依赖： &lt;!-- 导入Eureka Client对应的坐标 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> application.yml```yamlserver:port: 9010spring:application: name: config-servercloud: config: server: git: # git服务地址 uri: https://gitee.com/AncientFairy/config-repo.git # 配置git的用户名 username: # 配置git的密码 password: search-paths: - config-repo # 分支 label: master 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: config-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ ## **3.3 客户端改造** - bootstrap.yml： ```yaml spring: cloud: config: name: product # 应用名称，需要对应git中配置文件名称的前半部分 profile: dev # 开发环境，需要对应git中配置文件名称的后半部分 label: master # 分支名称 # uri: http://localhost:9010 # config-server的请求地址 discovery: # 服务发现 service-id: config-server enabled: true # 从Eureka中获取配置信息 # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product-dev:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ # 暴露监控端点 management: endpoints: web: exposure: include: &#39;*&#39;","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】Spring Cloud Stream","slug":"springcloud/Spring Cloud Stream","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1. 前言 在实际的企业开发中，消息中间件是至关重要的组件之一。消息中间件主要解决应用解耦、异步消息、流量削峰等问题，实现高性能、高可用、可伸缩和最终一致性的架构。不同的中间件其实现方式，内部结构是不一样的。如常见的RabbitMQ和Kafka，由于这两个消息中间件的架构上的不同，如RabbitMQ有Exchange，Kafka有Topic、Partitions，这些中间件的差异性导致我们实际项目开发会给我们造成了一定的困扰，我们如果用了两个消息中间件的其中一种，后面的业务需求，需要往另一种消息中间件迁移，这时候无疑就是一个灾难，一大堆东西需要重新推倒重做，因为它和我们系统耦合了，这时候Spring Cloud Stream给我们提供了一种解耦合的方式。 2. 概述 Spring Cloud Stream由一个中间件中立的Core组成。应用通过Spring Cloud Stream的input（相当于消费者consumer，它是从队列中接收消息的）和output（相当于生产者producer，它是从队列中发送消息的）通道和外界交流。通道通过指定中间件的Binder实现和外部代理连接。业务开发者不再关注具体消息中间件，只需要关注Binder对应用程序提供的抽象概念来使用消息中间件实现业务即可。 3. 核心概念3.1 绑定器 绑定器（Binder）是Spring Cloud Stream中的一个非常重要的概念。在没有绑定器这个概念的情况下，我们的SpringBoot应用要直接和消息中间件进行信息交互的时候，由于各个消息中间件构建的初衷不同，它们的实现细节上会有较大的差异性，这使得我们实现的消息交互逻辑就会非常笨重，因此对具体的中间件实现细节有太重的依赖，当中间件有较大的变动升级、或者更换中间件的时候，我们就需要付出非常大的代价来实施。 通过定义绑定器作为中间层，实现了应用程序和消息中间件细节之间的隔离。通过向应用程序暴露统一的Channel，使得应用程序不需要再考虑各种不同的消息中间件实现。当需要升级消息中间件或者更换其他的消息中间件产品时，我们需要做的就是更换对应的Binder绑定器而不需要修改任何应用逻辑，甚至可以任意的改变中间件的类型而不需要修改一行代码。 Spring Cloud Stream支持各种Binder实现，如下图所示： 通过配置把应用和Spring Cloud Stream的binder绑定在一起，之后我们只需要修改binder的配置来达到动态修改Topic、Exchange、type等一系列信息而不需要修改一行代码。 3.2 发布/订阅模型 在Spring Cloud Stream中的消息通信方式遵循了发布–订阅模式，当一条消息被投递到消息中间件之后，它会通过共享的Topic主题进行广播，消息消费者在订阅的主题中收到它并触发自身的业务逻辑处理。这里所提到的Topic主题是Spring Cloud Stream中的一个抽象概念，用来代表发布共享消息给消费者的地方。在不同的消息中间件中，Topic可能对应着不同的概念，如：在RabbitMQ中它对应了Exchange，在Kafka中对应了Topic。 4. Spring Cloud Stream标准流程套路 Middleware：中间件，目前只支持RabbitMQ和Kafka。 Binder：Binder是应用和消息中间件之间的封装，目前实现了Kafka和RabbitMQ的Binder，通过Binder可以很方便的连接中间件，可以动态的改变消息类型（对应于Kafka的Topic和RabbitMQ的Exchange），这些都是可以通过配置文件来实现。 @Input：注解标识输入通道，通过该输入通道接收到的消息进入应用程序。 @Output：注解标识输出通道，发布的消息将通过该通道离开应用程序。 @StreamListener：监听队列，用于消费者的队列的消息接收。 @EnableBinding：将通道Channel和Exchange绑定在一起。 Binder：很方便的连接中间件，屏蔽差异。 Channel：通道，是队列Queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过对Channel实现对队列进行配置。 Source和Sink：简单可以理解为参照对象就是Spring Cloud Stream本身，从Spring Cloud Stream发布消息就是输出，从Spring Cloud Stream接受消息就是输入。 5. 入门案例5.1 准备工作 采用RabbitMQ作为消息中间件，完成Spring Cloud Stream的案例，Docker安装方式如下： docker run -d --name rabbit -p 15672:15672 -p 5672:5672 rabbitmq:management 5.2 消息生产者 5.2.1 导入相关的依赖 修改部分： &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-stream-rabbit&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> 完整部分： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>stream_producer9005&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-stream-rabbit&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 5.2.2 修改配置文件 application.yml```yamlserver:port: 9005 spring: application: name: stream-producer rabbitmq:host: 192.168.32.100port: 5672username: guestpassword: guest cloud: stream: binders: # 配置绑定器 defaultRabbit: # 表示定义的名称，用于binding整合 type: rabbit # 消息组件类型 environment: # 设置RabbitMQ的相关的环境配置 spring: rabbitmq: host: 192.168.32.100 port: 5672 username: guest password: guest bindings: # 绑定通道 output: destination: rabbit-default # 指定消息发送的目的地。在RabbitMQ中，发送到一个名为rabbit-default的Exchange上。 contentType: application/json # 消息的类型 binder: defaultRabbit ### **5.2.3 配置启动类** - 启动类： ```java package com.sunxiaping.stream.producer; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * 发送消息，需要定义一个通道接口，通过接口中内置的Message Channel。 * Spring Cloud Stream中内置接口 Source * `@EnableBinding`注解：绑定对应通道 * 发送消息的话，通过MessageChannel发送消息 * * @author 许大仙 * @version 1.0 * @since 2020-10-08 20:48 */ @SpringBootApplication public class StreamProducer9005Application { public static void main(String[] args) { SpringApplication.run(StreamProducer9005Application.class, args); } } 5.2.4 编写业务逻辑 IMessageProvider.java```javapackage com.sunxiaping.stream.producer.service; /** @author 许大仙 @version 1.0 @since 2020-10-08 22:25 /public interface IMessageProvider { void send(); } - MessageProviderImpl.java ```java package com.sunxiaping.stream.producer.service.impl; import com.sunxiaping.stream.producer.service.IMessageProvider; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.cloud.stream.messaging.Source; import org.springframework.messaging.MessageChannel; import org.springframework.messaging.support.MessageBuilder; import java.util.UUID; /** * @author 许大仙 * @version 1.0 * @since 2020-10-08 22:25 */ @EnableBinding(Source.class) public class MessageProviderImpl implements IMessageProvider { @Autowired private MessageChannel output; @Override public void send() { //通过MessageBuilder帮助我们创建消息 this.output.send(MessageBuilder.withPayload(UUID.randomUUID().toString()).build()); } } SendMessageController.java```javapackage com.sunxiaping.stream.producer.controller; import com.sunxiaping.stream.producer.service.IMessageProvider;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; /** @author 许大仙 @version 1.0 @since 2020-10-08 22:33 /@RestControllerpublic class SendMessageController { @Resource private IMessageProvider messageProvider; @GetMapping(value = “/sendMessage”) public String sendMessage() { messageProvider.send(); return &quot;发送成功&quot;; } } ### **5.2.5 执行流程** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871867737-7aedf8d4-3809-4fba-abb9-afa677473999.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_54%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_937%2Climit_0#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=G0j0F&amp;margin=%5Bobject%20Object%5D&amp;originHeight=406&amp;originWidth=937&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## **5.3 消息消费者** ### **5.3.1 导入依赖** - 修改部分： ```xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 stream_consumer9006 org.springframework.cloud spring-cloud-starter-stream-rabbit org.springframework.boot spring-boot-starter-web ``` ### **5.3.2 修改配置文件** application.yml：```yamlserver:port: 9006 spring: application: name: stream-consumer rabbitmq:host: 192.168.32.100port: 5672username: guestpassword: guest cloud: stream: binders: # 配置绑定器 defaultRabbit: # 表示定义的名称，用于binding整合 type: rabbit # 消息组件类型 environment: # 设置RabbitMQ的相关的环境配置 spring: rabbitmq: host: 192.168.32.100 port: 5672 username: guest password: guest bindings: # 绑定通道 input: destination: rabbit-default # 指定消息获取的目的地。 contentType: application/json # 消息的类型 binder: defaultRabbit ### **5.3.3 配置启动类** - 启动类: ```java package com.sunxiaping.stream.consumer; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * @author 许大仙 * @version 1.0 * @since 2020-10-09 11:09 */ @SpringBootApplication public class StreamConsumer9006Application { public static void main(String[] args) { SpringApplication.run(StreamConsumer9006Application.class, args); } } 5.3.4 编写业务逻辑 MessageConsumer.java```javapackage com.sunxiaping.stream.consumer.listener; import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.messaging.Message; /** @author 许大仙 @version 1.0 @since 2020-10-09 11:12 /@EnableBinding(Sink.class)public class MessageConsumer { //监听binding中的消息 @StreamListener(Sink.INPUT) public void receive(Message message) { System.out.println(&quot;message = &quot; + message.getPayload()); }}``` 6. 自定义消息通道6.1 概述 Spring Cloud Stream内置类两种接口，分别定义了binding为“input”输入流和“output”输出流，而在我们实际使用中，往往需要定义各种输入输出流。使用方法也很简单。 6.2 自定义消息通道6.2.1 消息生产者 修改配置文件:```yamlserver:port: 9005 spring: application: name: stream-producer rabbitmq:host: 192.168.32.100port: 5672username: guestpassword: guest cloud: stream: binders: # 配置绑定器 defaultRabbit: # 表示定义的名称，用于binding整合 type: rabbit # 消息组件类型 environment: # 设置RabbitMQ的相关的环境配置 spring: rabbitmq: host: 192.168.32.100 port: 5672 username: guest password: guest bindings: # 绑定通道 output: destination: rabbit-default # 指定消息发送的目的地。在RabbitMQ中，发送到一个名为rabbit-default的Exchange上。 contentType: application/json # 消息的类型 binder: defaultRabbit # 自定义通道 customOutput: destination: rabbit-custom - CustomProcessor.java ```java package com.sunxiaping.stream.producer.channel; import org.springframework.cloud.stream.annotation.Input; import org.springframework.cloud.stream.annotation.Output; import org.springframework.cloud.stream.messaging.Sink; import org.springframework.cloud.stream.messaging.Source; import org.springframework.messaging.MessageChannel; import org.springframework.messaging.SubscribableChannel; /** * 自定义消息通道 * * @author 许大仙 * @version 1.0 * @since 2020-10-09 13:20 */ public interface CustomProcessor extends Source, Sink { /** * 自定义输出通道 */ String CUSTOM_OUTPUT = &quot;customOutput&quot;; /** * 自定义输入通道 */ String CUSTOM_INPUT = &quot;customInput&quot;; /** * 消息生产者的配置 * * @return */ @Output(CustomProcessor.CUSTOM_OUTPUT) MessageChannel customOutput(); /** * 消息消费者的配置 * * @return */ @Input(CustomProcessor.CUSTOM_INPUT) SubscribableChannel customInput(); } IMessageProvider.java```javapackage com.sunxiaping.stream.producer.service; /** @author 许大仙 @version 1.0 @since 2020-10-08 22:25 /public interface IMessageProvider { void send(); } - MessageProviderImpl.java ```java package com.sunxiaping.stream.producer.service.impl; import com.sunxiaping.stream.producer.channel.CustomProcessor; import com.sunxiaping.stream.producer.service.IMessageProvider; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.messaging.MessageChannel; import org.springframework.messaging.support.MessageBuilder; import java.util.UUID; /** * @author 许大仙 * @version 1.0 * @since 2020-10-08 22:25 */ @EnableBinding(CustomProcessor.class) public class MessageProviderImpl implements IMessageProvider { @Autowired @Qualifier(value = &quot;customOutput&quot;) private MessageChannel customOutput; @Override public void send() { //通过MessageBuilder帮助我们创建消息 this.customOutput.send(MessageBuilder.withPayload(UUID.randomUUID().toString()).build()); } } SendMessageController.java```javapackage com.sunxiaping.stream.producer.controller; import com.sunxiaping.stream.producer.service.IMessageProvider;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; /** @author 许大仙 @version 1.0 @since 2020-10-08 22:33 /@RestControllerpublic class SendMessageController { @Resource private IMessageProvider messageProvider; @GetMapping(value = “/sendMessage”) public String sendMessage() { messageProvider.send(); return &quot;发送成功&quot;; }}``` 6.2.2 消息消费者 修改配置文件:```yamlserver:port: 9006 spring: application: name: stream-consumer rabbitmq:host: 192.168.32.100port: 5672username: guestpassword: guest cloud: stream: binders: # 配置绑定器 defaultRabbit: # 表示定义的名称，用于binding整合 type: rabbit # 消息组件类型 environment: # 设置RabbitMQ的相关的环境配置 spring: rabbitmq: host: 192.168.32.100 port: 5672 username: guest password: guest bindings: # 绑定通道 input: destination: rabbit-default # 指定消息获取的目的地。 contentType: application/json # 消息的类型 binder: defaultRabbit # 自定义通道 customInput: destination: rabbit-custom - CustomProcessor.java ```java package com.sunxiaping.stream.consumer.channel; import org.springframework.cloud.stream.annotation.Input; import org.springframework.cloud.stream.annotation.Output; import org.springframework.cloud.stream.messaging.Sink; import org.springframework.cloud.stream.messaging.Source; import org.springframework.messaging.MessageChannel; import org.springframework.messaging.SubscribableChannel; /** * 自定义通道 * * @author 许大仙 * @version 1.0 * @since 2020-10-09 13:41 */ public interface CustomProcessor extends Source, Sink { /** * 自定义输出通道 */ String CUSTOM_OUTPUT = &quot;customOutput&quot;; /** * 自定义输入通道 */ String CUSTOM_INPUT = &quot;customInput&quot;; /** * 消息生产者的配置 * * @return */ @Output(CustomProcessor.CUSTOM_OUTPUT) MessageChannel customOutput(); /** * 消息消费者的配置 * * @return */ @Input(CustomProcessor.CUSTOM_INPUT) SubscribableChannel customInput(); } MessageConsumer.java```javapackage com.sunxiaping.stream.consumer.listener; import com.sunxiaping.stream.consumer.channel.CustomProcessor;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.messaging.Message; /** @author 许大仙 @version 1.0 @since 2020-10-09 11:12 /@EnableBinding(CustomProcessor.class)public class MessageConsumer { //监听binding中的消息 @StreamListener(CustomProcessor.CUSTOM_INPUT) public void receive(Message message) { System.out.println(&quot;message = &quot; + message.getPayload()); }}``` 7. 消息分组 通常在生产环境中，我们的每个服务都不会以单节点的方式，当同一个服务启动多个实例的时候，这些实例都会绑定到同一个消息通道的目标主题（Topic）上。默认情况下，当生产者发出一条消息到绑定通道上，这条消息会产生多个副本被每个消费者实例接收和处理，但是有些业务场景下，我们希望生产者的消息只被一个实例消费，这个时候我们需要为这些消费者设置消费组来实现这样的功能。 实现的方式很简单，我们只需要在服务消费端设置spring.cloud.stream.bindings.input.group属性即可，如下配置：```yamlserver:port: 9006 spring: application: name: stream-consumer rabbitmq:host: 192.168.32.100port: 5672username: guestpassword: guest cloud: stream: binders: # 配置绑定器 defaultRabbit: # 表示定义的名称，用于binding整合 type: rabbit # 消息组件类型 environment: # 设置RabbitMQ的相关的环境配置 spring: rabbitmq: host: 192.168.32.100 port: 5672 username: guest password: guest bindings: # 绑定通道 input: destination: rabbit-default # 指定消息获取的目的地。 contentType: application/json # 消息的类型 binder: defaultRabbit group: group1 # 设置消息的组名（同名组中的多个消息者，只有一个去消费消息） # 自定义通道 customInput: destination: rabbit-custom group: group2 # 设置消息的组名（同名组中的多个消息者，只有一个去消费消息） ```yaml server: port: 9007 spring: application: name: stream-consumer # rabbitmq: # host: 192.168.32.100 # port: 5672 # username: guest # password: guest cloud: stream: binders: # 配置绑定器 defaultRabbit: # 表示定义的名称，用于binding整合 type: rabbit # 消息组件类型 environment: # 设置RabbitMQ的相关的环境配置 spring: rabbitmq: host: 192.168.32.100 port: 5672 username: guest password: guest bindings: # 绑定通道 input: destination: rabbit-default # 指定消息获取的目的地。 contentType: application/json # 消息的类型 binder: defaultRabbit group: group1 # 设置消息的组名（同名组中的多个消息者，只有一个去消费消息） # 自定义通道 customInput: destination: rabbit-custom group: group2 # 设置消息的组名（同名组中的多个消息者，只有一个去消费消息） 在同一个group中的多个消费者只有一个可以获取到消息并消费。 8. 消息分区 有一些场景需要满足，同一特征的数据被同一个实例消费，比如同一个id的传感器监测数据必须被同一个实例统计计算分组，否则可能无法获取全部的数据。又比如部分异步任务，首次请求启动task，二次请求取消task，此场景就必须保证两次请求到同一个实例。 消息生产者配置：```yamlserver:port: 9005 spring: application: name: stream-producer rabbitmq:host: 192.168.32.100port: 5672username: guestpassword: guest cloud: stream: binders: # 配置绑定器 defaultRabbit: # 表示定义的名称，用于binding整合 type: rabbit # 消息组件类型 environment: # 设置RabbitMQ的相关的环境配置 spring: rabbitmq: host: 192.168.32.100 port: 5672 username: guest password: guest bindings: # 绑定通道 output: destination: rabbit-default # 指定消息发送的目的地。在RabbitMQ中，发送到一个名为rabbit-default的Exchange上。 contentType: application/json # 消息的类型 binder: defaultRabbit # 自定义通道 customOutput: destination: rabbit-custom producer: # ===========修改部分开始=========== partition-key-expression: payload #通过该参数指定了分组键的表达式规则，我们可以根据实际的输出消息规则来配置SPEL来生成合适的分区键 partition-count: 2 # 该参数指定了消息分区的数量 # ===========修改部分结束=========== - 消息消费者配置： ```yaml server: port: 9006 spring: application: name: stream-consumer # rabbitmq: # host: 192.168.32.100 # port: 5672 # username: guest # password: guest cloud: stream: # ===========修改部分开始=========== instance-count: 2 # 该参数指定了当前消费者实例的数量 instance-index: 0 # 该参数设置当前实例的索引号，从0开始，最大值为spring.stream.instance-count-1 # ===========修改部分结束=========== binders: # 配置绑定器 defaultRabbit: # 表示定义的名称，用于binding整合 type: rabbit # 消息组件类型 environment: # 设置RabbitMQ的相关的环境配置 spring: rabbitmq: host: 192.168.32.100 port: 5672 username: guest password: guest bindings: # 绑定通道 input: destination: rabbit-default # 指定消息获取的目的地。 contentType: application/json # 消息的类型 binder: defaultRabbit group: group1 # 设置消息的组名（同名组中的多个消息者，只有一个去消费消息） # 自定义通道 customInput: destination: rabbit-custom group: group2 # 设置消息的组名（同名组中的多个消息者，只有一个去消费消息） # ===========修改部分开始=========== consumer: partitioned: true # 开启消费者分区功能 # ===========修改部分结束=========== 9. 普通实现+延时消息+死信队列9.1 配置和代码示例9.1. 依赖&lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-stream-rabbit&lt;/artifactId> &lt;/dependency> 9.2. 配置spring: cloud: stream: #RabbitMQ服务器地址配置 binders: windrabbit: type: rabbit environment: spring: rabbitmq: addresses: localhost port: 15672 username: guest password: guest bindings: order-output: destination: order.exchange binder: windrabbit content-type: application/json group: order order-input: destination: order.exchange binder: windrabbit content-type: application/json group: order delay-output: destination: delay.exchange binder: windrabbit content-type: application/json group: delay-order producer: requiredGroups: delay-order delay-input: destination: delay.exchange binder: windrabbit content-type: application/json group: delay-order #这一部分是给上边声明的bindings添加配置的，例如队列的ttl，还有要不要给队列配置死信队列 rabbit: bindings: delay-output: producer: ttl: 120000#队列里的消息如果120000ms之后还没被消费，就会成为死信，这个参数生效的前提是spring.cloud.stream.bindings里边声明了requiredGroups autoBindDlq: true#这个参数为true的时候会自动为当前的队列创建一个死信队列，以dlq结尾 9.3. 新建一个Processor来映射上边配置的bindingsimport org.springframework.cloud.stream.annotation.Input; import org.springframework.cloud.stream.annotation.Output; import org.springframework.messaging.MessageChannel; import org.springframework.messaging.SubscribableChannel; import org.springframework.stereotype.Component; @Component public interface MQOrderProcessor { String INPUT=\"order-input\"; @Input(MQOrderProcessor.INPUT) SubscribableChannel orderInput(); // String DELAYINPUT=\"delay-input\"; // @Input(MQOrderProcessor.DELAYINPUT) // SubscribableChannel delayOrderInput(); String OUTPUT=\"order-output\"; @Output(MQOrderProcessor.OUTPUT) MessageChannel orderOutput(); String DELAYOUTPUT=\"delay-output\"; @Output(MQOrderProcessor.DELAYOUTPUT) MessageChannel delayOrderOutput(); } 9.4. 发送消息的代码import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.stream.annotation.EnableBinding; import com.wind.valley.mq.processor.MQOrderProcessor; import org.springframework.messaging.support.MessageBuilder; @EnableBinding(MQOrderProcessor.class) public class OrderMessageProvider { @Autowired private MQOrderProcessor processor; public boolean sendCancelOrderMessage(){ System.out.println(\"start send message to mq\"); return processor.delayOrderOutput().send(MessageBuilder.withPayload(\"{message:'cancel order'}\").build()); } } 9.5. 监听消息的代码import com.alibaba.fastjson.JSON; import com.wind.valley.mq.processor.MQOrderProcessor; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.cloud.stream.annotation.StreamListener; @EnableBinding(MQOrderProcessor.class) public class OrderMessageConsumer { @StreamListener(MQOrderProcessor.INPUT) public void process(Object obj) { System.out.println(\"get message\"+JSON.toJSONString(obj)); } // @StreamListener(MQOrderProcessor.DELAYINPUT) // public void delayProcess(Object obj) { // System.out.println(\"get delay message\"+JSON.toJSONString(obj)); // } } 9.2普通队列的实现步骤9.2.1 生产者 引入依赖 配置rabbitmq服务端spring.cloud.stream.binders 配置bindings spring.cloud.stream.bindings.xx-output 为bindings配置Processor（接口） public interface MQOrderProcessor { //对应bindings的名称 String OUTPUT=\"order-output\"; @Output(MQOrderProcessor.OUTPUT) MessageChannel orderOutput(); } 发送消息的示例代码 @EnableBinding(MQOrderProcessor.class) public class OrderMessageProvider { @Autowired private MQOrderProcessor processor; public boolean sendCancelOrderMessage(){ System.out.println(\"start send message to mq\"); return processor.delayOrderOutput().send(MessageBuilder.withPayload(\"{message:'cancel order'}\").build()); } } 9.2.2 消费者 引入依赖 配置rabbitmq服务端spring.cloud.stream.binders 配置bindings spring.cloud.stream.bindings.xx-input（destination指向生产者destination） 为bindings配置Processor（接口） public interface MQOrderProcessor { String INPUT=\"order-input\"; @Input(MQOrderProcessor.INPUT) SubscribableChannel orderInput(); } 监听Processor的input，这一步是添加具体实现，如果不做这一步，消息就会被Processor消费掉 @EnableBinding(MQOrderProcessor.class) public class OrderMessageConsumer { @StreamListener(MQOrderProcessor.INPUT) public void process(Object obj) { System.out.println(\"get message\"+JSON.toJSONString(obj)); } // @StreamListener(MQOrderProcessor.DELAYINPUT) // public void delayProcess(Object obj) { // System.out.println(\"get delay message\"+JSON.toJSONString(obj)); // } } 9.3 延迟队列与死信队列实现30分钟未支付，取消订单 在普通队列的基础上，配置延迟队列的关键属性spring.cloud.stream.rabbit.bindings.xx-output.producer.ttl，spring.cloud.stream.bindings.xx-output.producer.requiredGroups 为延迟队列添加属性spring.cloud.stream.rabbit.bindings.xx-output.producer.autoBindDlq=true，就会自动创建一个死信队列，延迟队列里的超时未消费的消息就会移动到这个死信队列里，自动添加的死信队列的名称为延迟队咧的destination+.dlq 写一个消费者消费死信队列里的消息就好了","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】Zookeeper(Eureka替换方案 不推荐)","slug":"springcloud/Zookeeper(Eureka替换方案 不推荐)","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1 Zookeeper简介 zookeeper的官网。 zookeeper由雅虎研究院开发，是Google Chubby的开源实现，后来托管到Apache，于2010年11月正式成为Apache的顶级项目。 大数据生态系统里的很多组件的命名都是某种动物或者昆虫，比如Hadoop就是，Hive就是。zookeeper即动物园管理者，顾名思义就是管理大数据生态系统各组件的管理员，如下图所示。 2 服务提供者注册到Zookeeper2.1 导入相关jar包的Maven坐标 修改部分： &lt;!-- SpringCloud整合zookeeper --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-zookeeper-discovery&lt;/artifactId> &lt;!--排除zk3.5.3--> &lt;exclusions> &lt;exclusion> &lt;groupId>org.apache.zookeeper&lt;/groupId> &lt;artifactId>zookeeper&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.zookeeper&lt;/groupId> &lt;artifactId>zookeeper&lt;/artifactId> &lt;version>3.4.10&lt;/version> &lt;exclusions> &lt;exclusion> &lt;groupId>org.slf4j&lt;/groupId> &lt;artifactId>slf4j-log4j12&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> 完整部分： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>product_service_zookeeper9001&lt;/artifactId> &lt;dependencies> &lt;!-- SpringCloud整合zookeeper --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-zookeeper-discovery&lt;/artifactId> &lt;!--排除zk3.5.3--> &lt;exclusions> &lt;exclusion> &lt;groupId>org.apache.zookeeper&lt;/groupId> &lt;artifactId>zookeeper&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.zookeeper&lt;/groupId> &lt;artifactId>zookeeper&lt;/artifactId> &lt;version>3.4.10&lt;/version> &lt;exclusions> &lt;exclusion> &lt;groupId>org.slf4j&lt;/groupId> &lt;artifactId>slf4j-log4j12&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-devtools&lt;/artifactId> &lt;scope>runtime&lt;/scope> &lt;optional>true&lt;/optional> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-jpa&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 2.2 application.yml 修改部分： spring: # SpringCloud cloud: zookeeper: connect-string: 192.168.237.100:2181 完整部分:```yamlserver:port: 9001 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.237.100:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql SpringCloud cloud: zookeeper: connect-string: 192.168.237.100:2181 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ ## 2.3 在启动类上标注@EnableDiscoveryClient注解 ```java package com.sunxiaping.product; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient //该注解用于向使用Consul或者zookeeper作为注册中心时注册服务 public class Product9001Application { public static void main(String[] args) { SpringApplication.run(Product9001Application.class, args); } } 2.4 ProductControllerpackage com.sunxiaping.product.controller; import com.sunxiaping.product.domain.Product; import com.sunxiaping.product.service.ProductService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.*; @RestController @RequestMapping(value = \"/product\") public class ProductController { @Value(\"${server.port}\") private String port; @Value(\"${spring.cloud.client.ip-address}\") private String ip; @Autowired private ProductService productService; @PostMapping(value = \"/save\") public String save(@RequestBody Product product) { productService.save(product); return \"新增成功\"; } @GetMapping(value = \"/findById/{id}\") public Product findById(@PathVariable(value = \"id\") Long id) { Product product = productService.findById(id); product.setProductName(\"访问的地址是：\" + ip + \":\" + port); return product; } } 3 服务消费者注册到Zookeeper3.1 导入相关jar包的Maven坐标 修改部分: &lt;!-- SpringCloud整合zookeeper --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-zookeeper-discovery&lt;/artifactId> &lt;!--排除zk3.5.3--> &lt;exclusions> &lt;exclusion> &lt;groupId>org.apache.zookeeper&lt;/groupId> &lt;artifactId>zookeeper&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.zookeeper&lt;/groupId> &lt;artifactId>zookeeper&lt;/artifactId> &lt;version>3.4.10&lt;/version> &lt;exclusions> &lt;exclusion> &lt;groupId>org.slf4j&lt;/groupId> &lt;artifactId>slf4j-log4j12&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 order_service_zookeeper8001 org.springframework.cloud spring-cloud-starter-zookeeper-discovery org.apache.zookeeper zookeeper org.apache.zookeeper zookeeper 3.4.10 org.slf4j slf4j-log4j12 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-devtools runtime true org.springframework.boot spring-boot-starter-test test org.springframework.boot spring-boot-starter-actuator ``` ## **3.2 application.yml** 修改部分: spring: # SpringCloud cloud: zookeeper: connect-string: 192.168.237.100:2181 完整部分:```yamlserver:port: 8001 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 SpringCloud cloud: zookeeper: connect-string: 192.168.237.100:2181 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ 开启日志debuglogging: level: root: info ## **3.3 在Spring容器中注入RestTemplate** - SpringConfig.java ```java package com.sunxiaping.order.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class SpringConfig { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } } 3.4 在启动类上标注@EnableDiscoveryClient注解package com.sunxiaping.order; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class Order8001Application { public static void main(String[] args) { SpringApplication.run(Order8001Application.class, args); } } 3.5 OrderControllerpackage com.sunxiaping.order.controller; import com.sunxiaping.order.domain.Product; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController @RequestMapping(value = \"/order\") public class OrderController { @Autowired private RestTemplate restTemplate; /** * 使用OrderCommand调用远程远程服务 * * @param id * @return */ @GetMapping(value = \"/buy/{id}\") public Product buy(@PathVariable(value = \"id\") Long id) { return restTemplate.getForObject(\"http://service-product/product/findById/\" + id, Product.class); } }","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】微服务的链路追踪Zipkin（不推荐）","slug":"springcloud/微服务的链路追踪Zipkin（不推荐）","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"SpringCloud-Alibaba+Sleuth.pdf 1. 链路追踪Sleuth入门1**.1 在网关层、订单微服务、商品微服务导入Sleuth的依赖** 修改部分 &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-sleuth&lt;/artifactId> &lt;/dependency> 网关层的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 api_gateway_server7007 org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.cloud spring-cloud-starter-sleuth ``` 订单微服务的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 order_service8003 org.springframework.cloud spring-cloud-starter-openfeign org.springframework.boot spring-boot-starter-web org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-actuator &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; ``` 商品微服务的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 product_service9004 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-data-jpa mysql mysql-connector-java org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-actuator org.springframework.cloud spring-cloud-starter-sleuth ``` ## 1**.2 修改网关层、订单微服务、商品微服务的配置文件** 修改部分: logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG 网关层的完整application.yml：```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: discovery: locator: enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 lower-case-service-id: true # 微服务名称以小写形式呈现 routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） # - Path=/product/** - Path=/product-service/** filters: # 配置路由过滤器 http://localhost:7007/product-service/product/findById/1 –&gt; http://localhost:7007/product/findById/1 - RewritePath=/product-service/(?.*), /${segment} # 路径重写的过滤器 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-gateway-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug - 订单微服务的完整application.yml： ```yaml server: port: 8003 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-order:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ feign: hystrix: # 开启Feign中的Hystrix enabled: true # 暴露所有端点 management: endpoints: web: exposure: include: &#39;*&#39; hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 3000 # 默认的连接超时时间为1秒，如果1秒没有返回数据，就自动触发降级逻辑 # 微服务info内容详细信息 info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug 商品微服务的完整application.yml：```yamlserver:port: 9004 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.217.100:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ ## 1**.3 重启网关层、订单微服务、商品微服务** - 重启之后，我们可以在控制台观察到Sleuth的日志输出。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871454303-614ae06e-943f-4055-af18-fba37d2af0b6.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_40%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=dwsN3&amp;margin=%5Bobject%20Object%5D&amp;originHeight=162&amp;originWidth=1417&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 其中，81a807d076c2a9f6是TraceId，后面跟着的是SpanId，依次调用有一个全局的TranceId，将调用链路串起来。仔细分析每个微服务的日志，不难看出请求的具体过程。 - 查看日志文件并不是一个很好的方法，当微服务越来越多日志文件也会越来越多，通过ZipKin可以将日志聚合，并进行可视化展示和全文检索。 # 2. **ZipKin概述** - Zipkin是Twitter的一个开源项目，它基于Google Dapper实现，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。我们可以使用它来收集各个服务器上请求链路的跟踪数据，并通过它提供的REST API接口来辅助我们查询跟踪以实现分布式系统的监控程序，从而及时的发现系统中出现的延迟升高的问题并找出系统性能瓶颈的根源。除了面向开发的API接口之外，它也提供了方便的UI组件来帮助我们直观的搜索跟踪信息和分析请求链路明细，比如：可以查询某段时间内各用户请求的处理时间等。Zipkin提供了可插拔数据存储方式：In-Memory、MySQL、Cassandra以及ElasticSearch。 ![](https://cdn.nlark.com/yuque/0/2020/jpeg/513185/1608871470696-3a4cf025-4bdf-40f0-9406-501ff13ee669.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_23%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=DSGsR&amp;margin=%5Bobject%20Object%5D&amp;originHeight=619&amp;originWidth=816&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 上图展示了Zipkin的基础架构，它主要由4个核心组件构成： - `Collector`：收集器组件，它主要用于处理从外部系统发送过来的跟踪信息，将这些信息转换为Zipkin内部处理的span格式，以支持后续的存储、分析、展示等功能。 - `Storage`：存储组件，它主要对处理收集器接收到的跟踪信息，默认会将这些信息存储在内存中，我们也可以修改此存储策略，将跟踪信息存储到数据库中。 - `Restful API`：API组件，它主要用来提供外部访问接口。比如给客户端展示跟踪信息，或者外接系统访问以实现监控等。 - `Web UI`：UI组件，基于API组件实现的上层应用。通过UI组件用户可以方便而直观的查询和分析跟踪信息。 - Zipkin分为两端，一个是Zipkin服务端，一个是Zipkin客户端，客户端也就是微服务的应用。客户端会配置服务端的URL地址，一旦发生服务间的调用时候，会被配置在微服务里面的Sleuth的监听器监听，并生成相应的Trace和Span信息发送给服务端。 - 发送的方式有两种：一种是HTTP报文的方式，另外一种是消息总线的方式如RabbitMQ。 - 不论哪种方式，我们都需要： - 一个Eureka服务注册中心。 - 一个Zipkin服务端。 - 多个微服务，这些微服务中配置了Zipkin客户端。 # **3. Zipkin Server的部署和配置** ## 3**.1 Zipkin Server下载** - 从SpringBoot2.0开始，官方就不再支持使用自建Zipkin Server的方式进行服务链路追踪，而是直接提供了编译好的jar包来给我们使用。可以从官方网站上下载[Zipkin的Web UI](https://repo1.maven.org/maven2/io/zipkin/java/zipkin-server/2.12.9/zipkin-server-2.12.9-exec.jar)。 ## 3**.2 启动** - 在命令行输入`java -jar zipkin-server-2.12.9-exec.jar`启动Zipkin Server。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871485265-693cb3be-3283-4858-b28d-9d8f93279153.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_27%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=ArUrx&amp;margin=%5Bobject%20Object%5D&amp;originHeight=480&amp;originWidth=960&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 默认Zipkin Server的请求端口是9411. - 在浏览器输入http://localhost:9411即可进入到Zipkin Server的管理后台。 ## 3**.3 使用Docker启动Zipkin Server** ```shell docker run -d -p 9411:9411 --name zipkin openzipkin/zipkin:2.12.9 4. 客户端Zipkin和Sleuth整合4**.1 概述** 通过查看日志分析微服务的调用链路并不是一个很直观的方案，结合Zipkin可以很直观的显示微服务之间的调用关系。 4.2 客户端Zipkin和Sleuth整合 4**.2.1 网关层、订单微服务和商品微服务添加Zipkin的依赖** 修改部分: &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-zipkin&lt;/artifactId> &lt;/dependency> 网关层的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 api_gateway_server7007 org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.cloud spring-cloud-starter-sleuth org.springframework.cloud spring-cloud-starter-zipkin ``` 订单微服务的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 order_service8003 org.springframework.cloud spring-cloud-starter-openfeign org.springframework.boot spring-boot-starter-web org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-actuator &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ``` 商品微服务的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 product_service9004 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-data-jpa mysql mysql-connector-java org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-actuator org.springframework.cloud spring-cloud-starter-sleuth org.springframework.cloud spring-cloud-starter-zipkin ``` ### 4**.2.2 网关层、订单微服务和商品微服务修改配置文件** 修改部分: spring: # zipkin zipkin: base-url: http://192.168.217.100:9411/ # Zipkin Server端的请求地址 sender: type: web # 数据的传输方式，以HTTP的形式向Zipkin Server端发送数据 sleuth: sampler: probability: 1 # 采样比 默认为0.1，即10%，这里配置1，是记录全部的sleuth信息，是为了收集到更多的数据（仅供测试使用） 网关层完整的application.yml：```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: discovery: locator: enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 lower-case-service-id: true # 微服务名称以小写形式呈现 routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） # - Path=/product/** - Path=/product-service/** filters: # 配置路由过滤器 http://localhost:7007/product-service/product/findById/1 –&gt; http://localhost:7007/product/findById/1 - RewritePath=/product-service/(?.*), /${segment} # 路径重写的过滤器 zipkin zipkin: base-url: http://192.168.217.100:9411/ # Zipkin Server端的请求地址 sender: type: web # 数据的传输方式，以HTTP的形式向Zipkin Server端发送数据 sleuth: sampler: probability: 1 # 采样比 默认为0.1，即10%，这里配置1，是记录全部的sleuth信息，是为了收集到更多的数据（仅供测试使用） 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-gateway-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug - 订单微服务完整的application.yml： ```yaml server: port: 8003 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 # zipkin zipkin: base-url: http://192.168.217.100:9411/ # Zipkin Server端的请求地址 sender: type: web # 数据的传输方式，以HTTP的形式向Zipkin Server端发送数据 sleuth: sampler: probability: 1 # 采样比 默认为0.1，即10%，这里配置1，是记录全部的sleuth信息，是为了收集到更多的数据（仅供测试使用） # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-order:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ feign: hystrix: # 开启Feign中的Hystrix enabled: true # 暴露所有端点 management: endpoints: web: exposure: include: &#39;*&#39; hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 3000 # 默认的连接超时时间为1秒，如果1秒没有返回数据，就自动触发降级逻辑 # 微服务info内容详细信息 info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug 商品微服务完整的application.yml：```yamlserver:port: 9004 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.217.100:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql zipkin zipkin: base-url: http://192.168.217.100:9411/ # Zipkin Server端的请求地址 sender: type: web # 数据的传输方式，以HTTP的形式向Zipkin Server端发送数据 sleuth: sampler: probability: 1 # 采样比 默认为0.1，即10%，这里配置1，是记录全部的sleuth信息，是为了收集到更多的数据（仅供测试使用） 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ ### **4.2.3 测试** - 分别重启网关层、订单微服务和商品微服务，通过浏览器发送一次微服务请求。打开Zipkin的Web UI控制台，我们可以根据条件追踪每次请求调用过程。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871535668-b11b8cf5-c6fe-4e5d-b050-c43b6b429371.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_54%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=j4AIm&amp;margin=%5Bobject%20Object%5D&amp;originHeight=752&amp;originWidth=1899&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 点击该trace可以看到请求的细节： ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871545845-414e0a72-82c4-4717-bc4b-0462d1a94339.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_54%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=c7YAy&amp;margin=%5Bobject%20Object%5D&amp;originHeight=482&amp;originWidth=1895&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) # 5. **分析Zipkin整合Sleuth的问题** ![](https://cdn.nlark.com/yuque/0/2020/jpeg/513185/1608871555829-a7ca6b2e-74ec-49b1-993a-e919ca32e18d.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_37%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=owdlk&amp;margin=%5Bobject%20Object%5D&amp;originHeight=733&amp;originWidth=1311&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 由上图可知： - 链路数据如何持久化保存（当前数据保存在Zipkin服务端的内存中，断电易丢失）。 - 如何优化数据采集过程（HTTP方式是同步阻塞方式，一旦出现网络波动等情况，可能会波及业务系统）。 # 6. **存储跟踪数据** ## 6**.1 概述** - Zipkin Server默认是将追踪数据信息保存到内存中，这种方式不适合生产环境。因为一旦Zipkin Server端关闭重启或者服务崩溃，就会导致历史数据消失。Zipkin支持将追踪数据持久化到MySQL数据库中或者存储到ElasticSearch中。 ## 6**.2 准备数据库** - 可以从官网中找到Zipkin Server持久化的MySQL数据库脚本： ```sql SET NAMES utf8mb4; SET FOREIGN_KEY_CHECKS = 0; -- ---------------------------- -- Table structure for zipkin_annotations -- ---------------------------- DROP TABLE IF EXISTS `zipkin_annotations`; CREATE TABLE `zipkin_annotations` ( `trace_id_high` bigint(20) NOT NULL DEFAULT 0 COMMENT &#39;If non zero, this means the trace uses 128 bit traceIds instead of 64 bit&#39;, `trace_id` bigint(20) NOT NULL COMMENT &#39;coincides with zipkin_spans.trace_id&#39;, `span_id` bigint(20) NOT NULL COMMENT &#39;coincides with zipkin_spans.id&#39;, `a_key` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT &#39;BinaryAnnotation.key or Annotation.value if type == -1&#39;, `a_value` blob NULL COMMENT &#39;BinaryAnnotation.value(), which must be smaller than 64KB&#39;, `a_type` int(11) NOT NULL COMMENT &#39;BinaryAnnotation.type() or -1 if Annotation&#39;, `a_timestamp` bigint(20) NULL DEFAULT NULL COMMENT &#39;Used to implement TTL; Annotation.timestamp or zipkin_spans.timestamp&#39;, `endpoint_ipv4` int(11) NULL DEFAULT NULL COMMENT &#39;Null when Binary/Annotation.endpoint is null&#39;, `endpoint_ipv6` binary(16) NULL DEFAULT NULL COMMENT &#39;Null when Binary/Annotation.endpoint is null, or no IPv6 address&#39;, `endpoint_port` smallint(6) NULL DEFAULT NULL COMMENT &#39;Null when Binary/Annotation.endpoint is null&#39;, `endpoint_service_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT &#39;Null when Binary/Annotation.endpoint is null&#39;, UNIQUE INDEX `trace_id_high`(`trace_id_high`, `trace_id`, `span_id`, `a_key`, `a_timestamp`) USING BTREE COMMENT &#39;Ignore insert on duplicate&#39;, INDEX `trace_id_high_2`(`trace_id_high`, `trace_id`, `span_id`) USING BTREE COMMENT &#39;for joining with zipkin_spans&#39;, INDEX `trace_id_high_3`(`trace_id_high`, `trace_id`) USING BTREE COMMENT &#39;for getTraces/ByIds&#39;, INDEX `endpoint_service_name`(`endpoint_service_name`) USING BTREE COMMENT &#39;for getTraces and getServiceNames&#39;, INDEX `a_type`(`a_type`) USING BTREE COMMENT &#39;for getTraces and autocomplete values&#39;, INDEX `a_key`(`a_key`) USING BTREE COMMENT &#39;for getTraces and autocomplete values&#39;, INDEX `trace_id`(`trace_id`, `span_id`, `a_key`) USING BTREE COMMENT &#39;for dependencies job&#39; ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compressed; -- ---------------------------- -- Table structure for zipkin_dependencies -- ---------------------------- DROP TABLE IF EXISTS `zipkin_dependencies`; CREATE TABLE `zipkin_dependencies` ( `day` date NOT NULL, `parent` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL, `child` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL, `call_count` bigint(20) NULL DEFAULT NULL, `error_count` bigint(20) NULL DEFAULT NULL, PRIMARY KEY (`day`, `parent`, `child`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compressed; -- ---------------------------- -- Table structure for zipkin_spans -- ---------------------------- DROP TABLE IF EXISTS `zipkin_spans`; CREATE TABLE `zipkin_spans` ( `trace_id_high` bigint(20) NOT NULL DEFAULT 0 COMMENT &#39;If non zero, this means the trace uses 128 bit traceIds instead of 64 bit&#39;, `trace_id` bigint(20) NOT NULL, `id` bigint(20) NOT NULL, `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL, `remote_service_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `parent_id` bigint(20) NULL DEFAULT NULL, `debug` bit(1) NULL DEFAULT NULL, `start_ts` bigint(20) NULL DEFAULT NULL COMMENT &#39;Span.timestamp(): epoch micros used for endTs query and to implement TTL&#39;, `duration` bigint(20) NULL DEFAULT NULL COMMENT &#39;Span.duration(): micros used for minDuration and maxDuration query&#39;, PRIMARY KEY (`trace_id_high`, `trace_id`, `id`) USING BTREE, INDEX `trace_id_high`(`trace_id_high`, `trace_id`) USING BTREE COMMENT &#39;for getTracesByIds&#39;, INDEX `name`(`name`) USING BTREE COMMENT &#39;for getTraces and getSpanNames&#39;, INDEX `remote_service_name`(`remote_service_name`) USING BTREE COMMENT &#39;for getTraces and getRemoteServiceNames&#39;, INDEX `start_ts`(`start_ts`) USING BTREE COMMENT &#39;for getTraces ordering and range&#39; ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compressed; SET FOREIGN_KEY_CHECKS = 1; 6**.3 命令行方式配置启动服务端**# STORAGE_TYPE 存储类型 # MYSQL_HOST MySQL主机地址 # MYSQL_TCP_PORT MySQL端口 # MYSQL_DB MySQL数据库名称 # MYSQL_USER MySQL用户名 # MYSQL_PASS MySQL地址 java -jar zipkin-server-2.12.9-exec.jar --STORAGE_TYPE=mysql --MYSQL_HOST=192.168.217.100 --MYSQL_TCP_PORT=3306 --MYSQL_DB=zipkin --MYSQL_USER=root --MYSQL_PASS=123456 6.4 Docker方式配置启动服务端docker run -d \\ -p 9411:9411 \\ --restart always \\ -v /etc/localtime:/etc/localtime:ro \\ -e MYSQL_USER=root \\ -e MYSQL_PASS=123456 \\ -e MYSQL_HOST=192.168.217.100 \\ -e STORAGE_TYPE=mysql \\ -e MYSQL_DB=zipkin \\ -e MYSQL_TCP_PORT=3306 \\ --name zipkin \\ openzipkin/zipkin:2.12.9 6**.5 测试** 配置好服务daunt之后，可以在浏览器中请求几次。回到数据库查看，会发现数据已经持久化到MySQL中了。 7. 基于消息中间件收集数据7**.1 概述** 在默认情况下，Zipkin客户端和Zipkin服务端之间是使用HTTP请求的方式进行通信（即同步的请求方式）。 在网络波动，Zipkin服务端异常等情况下，可能会存在信息收集不机制的问题。 Zipkin支持和RabbitMQ整合完整异步消息传输。 7**.2 步骤** 准备RabbitMQ中间件。 修改Zipkin客户端，将消息发送到MQ服务器。 修改Zipkin服务daunt，从MQ中拉取消息。7.3 RabbitMQ的安装和启动 以Docker形式安装和启动RabbitMQ： docker run -d --name rabbit -p 15672:15672 -p 5672:5672 rabbitmq:management 7**.4 命令行方式配置启动服务端**# STORAGE_TYPE 存储类型 # MYSQL_HOST MySQL主机地址 # MYSQL_TCP_PORT MySQL端口 # MYSQL_DB MySQL数据库名称 # MYSQL_USER MySQL用户名 # MYSQL_PASS MySQL地址 # RABBIT_ADDRESSES 指定Rabbitmq的地址 # RABBIT_USER 用户名（默认为guest） # RABBIT_PASSWORD 密码（默认为guest） java -jar zipkin-server-2.12.9-exec.jar --STORAGE_TYPE=mysql --MYSQL_HOST=192.168.217.100 --MYSQL_TCP_PORT=3306 --MYSQL_DB=zipkin --MYSQL_USER=root --MYSQL_PASS=123456 --RABBIT_ADDRESSES=192.168.217.100:5672 --RABBIT_USER=guest --RABBIT_PASSWORD=guest 7**.5 Docker方式启动配置启动服务端**```shelldocker run -d \\ p 9411:9411 \\ -restart always \\ v /etc/localtime:/etc/localtime:ro \\ e MYSQL_USER=root \\ e MYSQL_PASS=123456 \\ e MYSQL_HOST=192.168.217.100 \\ e STORAGE_TYPE=mysql \\ e MYSQL_DB=zipkin \\ e MYSQL_TCP_PORT=3306 \\ e RABBIT_ADDRESSES=192.168.217.100:5672 \\ e RABBIT_USER=guest \\ e RABBIT_PASSWORD=guest \\ -name zipkin openzipkin/zipkin:2.12.9``` 7**.6 客户端配置**7**.6.1 导入相关jar包的Maven坐标** 修改部分: &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-sleuth&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-zipkin&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-sleuth-zipkin&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-amqp&lt;/artifactId> &lt;/dependency> 网关层的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 api_gateway_server7007 org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.cloud spring-cloud-starter-sleuth org.springframework.cloud spring-cloud-starter-zipkin org.springframework.cloud spring-cloud-sleuth-zipkin org.springframework.boot spring-boot-starter-amqp ``` 订单微服务的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 order_service8003 org.springframework.cloud spring-cloud-starter-openfeign org.springframework.boot spring-boot-starter-web org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-actuator &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; ``` 商品微服务的完整pom：```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 product_service9004 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-data-jpa mysql mysql-connector-java org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-actuator org.springframework.cloud spring-cloud-starter-sleuth org.springframework.cloud spring-cloud-starter-zipkin org.springframework.cloud spring-cloud-sleuth-zipkin org.springframework.boot spring-boot-starter-amqp ``` ## 7**.6.2 配置消息中间件的地址** 修改部分 spring: # zipkin zipkin: # base-url: http://192.168.217.100:9411/ # Zipkin Server端的请求地址 sender: type: rabbit # type: web # 数据的传输方式，以HTTP的形式向Zipkin Server端发送数据 sleuth: sampler: probability: 1 # 采样比 默认为0.1，即10%，这里配置1，是记录全部的sleuth信息，是为了收集到更多的数据（仅供测试使用） rabbitmq: host: 192.168.217.100 port: 5672 username: guest password: guest # 重试机制 listener: direct: retry: enabled: true simple: retry: enabled: true 网关层的完整application.yml```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: discovery: locator: enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 lower-case-service-id: true # 微服务名称以小写形式呈现 routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） # - Path=/product/** - Path=/product-service/** filters: # 配置路由过滤器 http://localhost:7007/product-service/product/findById/1 –&gt; http://localhost:7007/product/findById/1 - RewritePath=/product-service/(?.*), /${segment} # 路径重写的过滤器 zipkin zipkin: # base-url: http://192.168.217.100:9411/ # Zipkin Server端的请求地址 sender: type: rabbit type: web # 数据的传输方式，以HTTP的形式向Zipkin Server端发送数据 sleuth: sampler: probability: 1 # 采样比 默认为0.1，即10%，这里配置1，是记录全部的sleuth信息，是为了收集到更多的数据（仅供测试使用） rabbitmq: host: 192.168.217.100 port: 5672 username: guest password: guest # 重试机制 listener: direct: retry: enabled: true simple: retry: enabled: true 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-gateway-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug - 订单微服务的application.yml ```yaml server: port: 8003 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 # zipkin zipkin: # base-url: http://192.168.217.100:9411/ # Zipkin Server端的请求地址 sender: type: rabbit # type: web # 数据的传输方式，以HTTP的形式向Zipkin Server端发送数据 sleuth: sampler: probability: 1 # 采样比 默认为0.1，即10%，这里配置1，是记录全部的sleuth信息，是为了收集到更多的数据（仅供测试使用） rabbitmq: host: 192.168.217.100 port: 5672 username: guest password: guest # 重试机制 listener: direct: retry: enabled: true simple: retry: enabled: true # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-order:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ feign: hystrix: # 开启Feign中的Hystrix enabled: true # 暴露所有端点 management: endpoints: web: exposure: include: &#39;*&#39; hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 3000 # 默认的连接超时时间为1秒，如果1秒没有返回数据，就自动触发降级逻辑 # 微服务info内容详细信息 info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug 商品微服务的完整application.yml```yamlserver:port: 9004 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.217.100:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql zipkin zipkin: # base-url: http://192.168.217.100:9411/ # Zipkin Server端的请求地址 sender: type: rabbit type: web # 数据的传输方式，以HTTP的形式向Zipkin Server端发送数据 sleuth: sampler: probability: 1 # 采样比 默认为0.1，即10%，这里配置1，是记录全部的sleuth信息，是为了收集到更多的数据（仅供测试使用） rabbitmq: host: 192.168.217.100 port: 5672 username: guest password: guest # 重试机制 listener: direct: retry: enabled: true simple: retry: enabled: true 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ logging: level: root: INFO org.springframework.web.servlet.DispatcherServlet: DEBUG org.springframework.cloud.sleuth: DEBUG org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ ## 7**.7 测试** - 关闭Zipkin Server，并随意发送请求。打开RabbitMQ管理后台可以看到，消费已经推送到了RabbitMQ中。 - 当Zipkin Server启动时，会自动从RabbitMQ获取消息并消费，展示追踪数据。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】服务注册和配置中心Nacos","slug":"springcloud/alibaba/服务注册和配置中心Nacos","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"SpringCloud-Nacos.pdf 1. 安装和运行1**.1 安装**1**.1.1 准备工作** 本地安装有JDK8和Maven3.x环境。 1**.1.2 下载** GitHub上的地址。 官网地址。 1**.2 运行** 解压缩安装包 直接在bin目录下，使用startup.cmd -m standalone命令启动Nacos。 命令运行成功后直接访问http://localhost:8848/nacos（默认用户名和密码为nacos/nacos）。 登录成功，结果页面： 2. Nacos作为服务注册中心2**.1 基于Nacos的服务提供者**2**.1.1 新建Module，并导入相关依赖** 父工程pom: &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-dependencies&lt;/artifactId> &lt;version>2.2.2.RELEASE&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>Hoxton.SR1&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-alibaba-dependencies&lt;/artifactId> &lt;version>2.1.0.RELEASE&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> 本模块pom修改部分： &lt;!-- Nacos --> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> 本模块pom完整部分： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>cloud_alibaba_provider9013&lt;/artifactId> &lt;dependencies> &lt;!-- Nacos --> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 2**.1.2 修改配置文件** application.yml```yamlserver:port: 9013 spring: application: name: cloud-alibaba-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 management: endpoints: web: exposure: include: ‘*’ ### 2**.1.3 启动类** ```java package com.sunxiaping.alibaba; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; /** * @author 许大仙 * @version 1.0 * @since 2020-10-11 10:54 */ @SpringBootApplication @EnableDiscoveryClient public class CloudAlibabaProvider9013Application { public static void main(String[] args) { SpringApplication.run(CloudAlibabaProvider9013Application.class, args); } } 2**.1.4 业务逻辑** PaymentController.java```javapackage com.sunxiaping.alibaba.controller; import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController; /** @author 许大仙 @version 1.0 @since 2020-10-11 10:57 /@RestControllerpublic class PaymentController { @Value(“${server.port}”) private String serverPort; @GetMapping(value = &quot;/payment/{id}&quot;) public String payment(@PathVariable(value = &quot;id&quot;) Integer id) { return &quot;Nacos的注册中心的端口是：&quot; + serverPort + &quot;,id是：&quot; + id; } } ## 2**.2 基于Nacos的服务消费者** ### 2**.2.1 新建Module，并导入相关依赖** - 父工程pom： ```xml &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 修改部分: &lt;!-- Nacos --> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 cloud_alibaba_provider9015 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-actuator ``` ### 2**.2.2 修改配置文件** application.yml```yamlserver:port: 9015 spring: application: name: cloud-alibaba-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 management: endpoints: web: exposure: include: ‘*’ ### 2**.2.3 启动类** ```java package com.sunxiaping.alibaba; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; /** * @author 许大仙 * @version 1.0 * @since 2020-10-11 11:34 */ @SpringBootApplication @EnableDiscoveryClient public class CloudAlibabaConsumer9015Application { public static void main(String[] args) { SpringApplication.run(CloudAlibabaConsumer9015Application.class, args); } } 2.2.4 业务逻辑 SpringConfig.java```javapackage com.sunxiaping.alibaba.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate; /** @author 许大仙 @version 1.0 @since 2020-10-11 11:35 /@Configurationpublic class SpringConfig { @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } - OrderController.java ```java package com.sunxiaping.alibaba.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; /** * @author 许大仙 * @version 1.0 * @since 2020-10-11 11:35 */ @RestController public class OrderController { @Autowired private RestTemplate restTemplate; @GetMapping(value = &quot;/order/{id}&quot;) public String order(@PathVariable(value = &quot;id&quot;) Integer id) { return restTemplate.getForObject(&quot;http://cloud-alibaba-provider&quot; + &quot;/payment/&quot; + id, String.class); } } 3. 各种服务注册中心对比3**.1 Nacos生态图** 3**.2 Nacos服务发现实例模型** 3**.3 Nacos和其他注册中心特性对比** 3**.4 Nacos支持AP和CP模式的切换**3**.4.1 概述** 如果不需要存储服务级别的信息且服务实例是通过Nacos Client注册，并能够保持心跳上报，那么就可以选择AP模式。当前主流的服务如Spring Cloud和Dubbo服务，都适用于AP模式，AP模式为了服务的可用性而减弱了一致性，因此AP模式下只支持临时实例。 如果需要在服务级别编辑或者存储配置信息，那么CP是必须，K8s服务和DNS服务则使用于CP模式。CP模式下支持注册服务化实例，此时则是以Raft协议为集群运行模式，该模式下注册实例之前必须先注册服务，如果服务不存在，则会返回错误。 3.4.2 模式切换 Nacos集群默认支持的CAP原则中的AP原则，但是也可以支持CP原则，切换命令如下： curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&value=CP' 同时微服务的bootstrap.properties需要配置如下选择指明注册为临时/永久实例（AP模式不支持数据一致性，所以只支持服务注册的临时实例，CP模式支持服务注册的永久实例）。 #false为永久实例，true表示临时实例开启，注册为临时实例 spring.cloud.nacos.discovery.ephemeral=false 4 Nacos作为服务配置中心的基础配置4.1 新建Modele，并导入相关依赖 修改部分: &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-config&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 cloud_alibaba_config_server3377 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-actuator ``` ## 4**.2 YML** Nacos和Spring Cloud Config一样，在项目初始化的时候，要保证先从配置中心进行配置拉取，拉取配置之后，才能保证项目的正常启动。 SpringBoot中配置文件的加载时存在优先级顺序的，bootstrap优先级高于application。 示例： bootstrap.yml```yamlspring:application: name: service-proudctprofiles: active: devcloud: nacos:discovery: server-addr: 127.0.0.1:8848 # 服务注册中心的地址 config: server-addr: 127.0.0.1:8848 # 配置中心的地址 file-extension: yml # 执行yaml格式的配置 management: endpoints: web: exposure: include: ‘*’ ## **4.3 向Nacos中添加配置信息** - Nacos中的dataId的组成格式和Spring Cloud中的配置文件的匹配规则。 - [官方地址](https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html)。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872385379-65effbf3-bdb5-4e08-a5cd-5028cbbb6c4a.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_27%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=gcFa8&amp;margin=%5Bobject%20Object%5D&amp;originHeight=314&amp;originWidth=934&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872395005-805a12c5-3015-47dc-a982-ec7d493c7c69.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_54%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=XzpCY&amp;margin=%5Bobject%20Object%5D&amp;originHeight=926&amp;originWidth=1898&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872403747-9914f2b0-c396-43bc-9740-e87eb87b771b.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_49%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=YLtgH&amp;margin=%5Bobject%20Object%5D&amp;originHeight=851&amp;originWidth=1721&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## 4**.4 启动类** ```java package com.sunxiaping; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class ProductApplication { public static void main(String[] args) { SpringApplication.run(ProductApplication.class, args); } } 4**.5 业务逻辑** Product.java```javapackage com.sunxiaping.domain; import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter; import javax.persistence.*;import java.io.Serializable;import java.math.BigDecimal; @Setter@Getter@AllArgsConstructor@NoArgsConstructor@Entity@Table(name = “tb_product”)public class Product implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(name = &quot;product_name&quot;) private String productName; @Column(name = &quot;status&quot;) private Integer status; @Column(name = &quot;price&quot;) private BigDecimal price; @Column(name = &quot;product_desc&quot;) private String productDesc; @Column(name = &quot;caption&quot;) private String caption; @Column(name = &quot;inventory&quot;) private String inventory; } - ProductRepository.java ```java package com.sunxiaping.dao; import com.sunxiaping.domain.Product; import org.springframework.data.jpa.repository.JpaRepository; import org.springframework.data.jpa.repository.JpaSpecificationExecutor; import org.springframework.stereotype.Repository; @Repository public interface ProductRepository extends JpaRepository&lt;Product, Long&gt;, JpaSpecificationExecutor&lt;Product&gt; { } ProductService.java```javapackage com.sunxiaping.service; import com.sunxiaping.domain.Product; public interface ProductService { /** * 根据id查询 * * @param id * @return */ Product findById(Long id); /** * 保存 * * @param product */ void save(Product product); /** * 更新 * * @param product */ void update(Product product); /** * 删除 * * @param id */ void delete(Long id); } - ProductServiceImpl.java ```java package com.sunxiaping.service.impl; import com.sunxiaping.dao.ProductRepository; import com.sunxiaping.domain.Product; import com.sunxiaping.service.ProductService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; @Service @Transactional public class ProductServiceImpl implements ProductService { @Autowired private ProductRepository productRepository; @Override public Product findById(Long id) { return this.productRepository.findById(id).orElse(new Product()); } @Override public void save(Product product) { this.productRepository.save(product); } @Override public void update(Product product) { this.productRepository.save(product); } @Override public void delete(Long id) { this.productRepository.deleteById(id); } } ProductController.java```javapackage com.sunxiaping.controller; import com.sunxiaping.domain.Product;import com.sunxiaping.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.*; @RestController@RequestMapping(value = “/product”)@RefreshScope //开启动态刷新public class ProductController { @Value(&quot;${server.port}&quot;) private String port; @Value(&quot;${spring.cloud.client.ip-address}&quot;) private String ip; @Autowired private ProductService productService; @PostMapping(value = &quot;/save&quot;) public String save(@RequestBody Product product) { this.productService.save(product); return &quot;新增成功&quot;; } @GetMapping(value = &quot;/findById/{id}&quot;) public Product findById(@PathVariable(value = &quot;id&quot;) Long id) { Product product = this.productService.findById(id); product.setProductName(&quot;访问的地址是：&quot; + this.ip + &quot;:&quot; + this.port); return product; } } # 5. **Nacos作为服务配置中心的分类配置** ## 5**.1 问题：多项目多环境问题** ### 5**.1.1 问题1** - 在实际开发中，通常一个系统会准备：dev开发环境，test测试环境，prod生产环境。如何保证指定环境启动时服务能正确读取到Nacos上相应环境的配置文件？ ### **5.1.2 问题2** - 一个大型分布式微服务会有很多微服务子项目，每个微服务服务又都会有相应的开发环境、测试环境、预发布环境、正式环境等等，如果对这些微服务配置进行管理？ ## 5**.2 Nacos图形化界面管理** ### 5**.2.1 配置列表** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872422267-b9e66328-7fce-4ff9-8bf6-d6191eaacd2a.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_54%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=scNrS&amp;margin=%5Bobject%20Object%5D&amp;originHeight=904&amp;originWidth=1900&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ### 5**.2.2 命名空间** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872430468-3ced52c1-d95b-4477-90a1-e4741807a674.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_54%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=qx36c&amp;margin=%5Bobject%20Object%5D&amp;originHeight=866&amp;originWidth=1892&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## 5**.3 Namespace+Group+DataId什么关系，为什么这么设计？** ### 5**.3.1 Namespace+Group+DataId是什么？** - Namespace+Group+DataId类似于Java里面的package（包名）和类名。 - 最外层的namespace是可以用于区分部署环境的，Group和DataId逻辑上区分两个目标对象。 ### **5.3.2 Namespace+Group+DataId的关系以及设计的意图** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872447017-7410b942-0914-46da-bc91-1b96f8a36ec5.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_22%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=DzWtd&amp;margin=%5Bobject%20Object%5D&amp;originHeight=412&amp;originWidth=759&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 默认情况下，Namespace=public、Group=DEFAULT_GROUP，默认Cluster是DEFAULT。 - Nacos的默认的命名空间是public，Namespace主要用来实现隔离。比如说，现在有三个环境：开发、测试和生产环境，我们就可以创建三个Namespace，不同的Namespace之间是隔离的。 - Group默认是DEFAULT_GROUP，Group可以把不同的微服务划分到同一个分组里面。 - Service就是微服务。一个Service可以包含多个Cluster（集群），Nacos默认Cluster就是DEFAULT，Cluster是对指定微服务的一个虚拟划分。比如说，为了容灾，将Service微服务分别部署在了杭州机房和广州机房，这时候就可以给杭州机房的Service微服务起一个集群名称（HZ），给广州机房的Service微服务起一个集群名称（GZ），还可以尽量让同一个机房的微服务互相调用，以提升性能。 - Instance，就是微服务的实例。 # 6. **Nacos集群和持久化配置** ## 6.1 官网说明 ### 6**.1.1 官网地址** - [官网地址](https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html)。 ### 6**.1.2 官网集群架构图** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872461649-6a33d827-b4a1-4056-8d17-e2f164af2edc.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_25%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=L0XKL&amp;margin=%5Bobject%20Object%5D&amp;originHeight=569&amp;originWidth=860&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ### 6**.1.3 Nacos集群架构图理解** ![](https://cdn.nlark.com/yuque/0/2020/jpeg/513185/1608872480492-c1f4929d-2457-4a12-a91a-2320c86b0718.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_22%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=N1pgZ&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1039&amp;originWidth=772&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ### 6**.1.4 说明** - [Nacos支持的三种部署模式](https://nacos.io/zh-cn/docs/deployment.html)。 ## 6**.2 单机版的Nacos持久化配置** - Nacos默认自带的是嵌入式数据库derby，不方便观察数据存储的基本情况，需要将数据源由derby切换到MySQL - derby切换到MySQL的步骤： - 安装MySQL数据库，版本要求5.6.5+。 - 初始化MySQL数据库，数据库的sql脚本在nacos/conf/nacos-mysql.sql文件中： ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872493106-ded70f4f-fc76-4dd9-91c0-3b5aa6b46c1e.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_25%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=kQVsY&amp;margin=%5Bobject%20Object%5D&amp;originHeight=333&amp;originWidth=885&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 修改conf/application.properites文件，增加支持MySQL数据源配置（目前只支持MySQL），添加MySQL的数据源的URL、用户和密码等。 ```properties spring.datasource.platform=mysql db.num=1 db.url.0=jdbc:mysql://localhost:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true db.user=root db.password=123456 6.3 Linux版Nacos+MySQL生产环境配置6**.3.1 准备工作** Nginx：1个。 Nacos Server：3个。 MySQL：1个（IP地址为192.168.32.100，端口是3306）。 Centos7：3个（IP地址分别为192.168.32.100、192.168.32.101和192.168.32.102）。 6**.3.2 逻辑架构图** 6**.3.3 在每个Centos7系统中下载Linux版本的Nacos**cd /opt wget https://github.91chifun.workers.dev//https://github.com/alibaba/nacos/releases/download/1.3.2/nacos-server-1.3.2.tar.gz tar -zxvf nacos-server-1.3.2.tar.gz 6**.3.4 将nacos-mysql.sql文件导入到MySQL数据库中** 6**.3.5 持久化配置** 在每个CentOS7系统上的Nacos的conf/application.properties文件中加入如下的配置：```properties 在最后一行添加spring.datasource.platform=mysql db.num=1db.url.0=jdbc:mysql://192.168.32.100:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=123456 ### 6**.3.6 集群配置** - 在每个CentOS7系统上的Nacos的conf目录，复制cluster.conf.example文件，并改名为cluster.conf： ```shell cp cluster.conf.example cluster.conf 修改每个CentOS7系统上的Nacos的conf/cluster.conf文件，并添加如下的配置：```shell 192.168.32.100:8848192.168.32.101:8848192.168.32.102:8848 - 分别启动各个Nacos服务。 ```shell /opt/nacos/bin ./startup.sh 6**.3.7 修改Nginx的配置文件并启动Nginx** nginx.conf```properties#user nobody;worker_processes 1; #error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024;} http { include mime.types; default_type application/octet-stream; #log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; # &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; # &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; # -----------修改----------------- upstream nacos { server 192.168.32.100:8848; server 192.168.32.101:8848; server 192.168.32.103:8848; } # -----------修改----------------- server { # -----------修改----------------- listen 8089; # -----------修改----------------- server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } # -----------修改----------------- location ^~ /nacos{ proxy_pass http://nacos; # nginx非80端口处理 proxy_set_header Host $host:$server_port; # 获取真实IP proxy_set_header X-Real-IP $remote_addr; # 获取代理者的真实ip proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 解决getScheme，isSecure，sendRedirect proxy_set_header X-Forwarded-Scheme $scheme; client_max_body_size 1000m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; } # -----------修改----------------- #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ /\\.ht { # deny all; #} } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} }","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】服务熔断Hystrix的替换方案Sentinel","slug":"springcloud/alibaba/服务熔断Hystrix的替换方案Sentinel","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"SpringCloud-Alibaba+Sentinel.pdf GitHub上的Sentinel仓库。 中文官网。 1. 安装和运行Sentinel Dashboard1**.1 Sentinel的组成** Sentinel 的组成可以分为两个部分: 核心库（Java 客户端）：不依赖任何框架/库，能够运行于 Java 7 及以上的版本的运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持（见 主流框架适配）。 控制台（Dashboard）：控制台主要负责管理推送规则、监控、集群限流分配管理、机器发现等。 1**.2 安装和运行步骤** 下载地址。 运行命令： # -Dserver.port=8080用于指定Sentinel控制台端口为8080 java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.0.jar Sentinel的登录界面（访问地址默认是http://localhost:8080/，用户名和密码为sentinel/sentinel）： 2. 初始化演示工程2**.1 启动Nacos服务注册中心和配置中心** 2**.2 新建Module**2.2.1 导入相关依赖jar包的Maven坐标 修改部分: &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-sentinel&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 cloud_alibaba_sentinel_service8401 com.alibaba.cloud spring-cloud-alibaba-nacos-discovery com.alibaba.csp sentinel-datasource-nacos com.alibaba.cloud spring-cloud-starter-alibaba-sentinel org.springframework.cloud spring-cloud-starter-openfeign org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-actuator ``` ### **2.2.2 配置application.yml** ```yaml server: port: 8401 spring: application: name: cloud-alibaba-sentinel-service cloud: nacos: discovery: # Nacos服务注册中心地址 server-addr: 127.0.0.1:8848 sentinel: transport: # 配置Sentinel Dashboard地址 dashboard: 127.0.0.1:8080 # 默认8719端口，假设被占用会自动从8719开始依次加1扫描，直到找到没有被占用的端口 port: 8719 # 取消懒加载 eager: true management: endpoints: web: exposure: include: ‘*’ ### **2.2.3 配置启动类** ```java package com.sunxiaping.sentinel; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; /** * @author 许大仙 * @version 1.0 * @since 2020-10-15 10:02 */ @EnableDiscoveryClient @SpringBootApplication public class Service8401Application { public static void main(String[] args) { SpringApplication.run(Service8401Application.class, args); } } 2**.2.4 编写业务逻辑** FlowLimitController.java```javapackage com.sunxiaping.sentinel.controller; import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController; /** @author 许大仙 @version 1.0 @since 2020-10-15 10:05 /@RestControllerpublic class FlowLimitController { @GetMapping(value = “/testA”) public String testA() { return &quot;-------testA--------&quot;; } @GetMapping(value = “/testB”) public String testB() { return &quot;~~~~~~~~testB~~~~~~~~&quot;; } } # 3. **流控规则** ## 3**.1 基本介绍** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872673174-21105501-6e79-4c5b-88d8-3f26b59edaff.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=g4AaL&amp;margin=%5Bobject%20Object%5D&amp;originHeight=532&amp;originWidth=717&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 资源名：唯一名称，默认请求路径。 - 针对来源：Sentinel可以针对调用者进行限流，填写微服务名，默认default（不区分来源）。 - 阈值类型/单机阈值： - QPS（每秒请求数量）：当调用该API的QPS达到阈值的时候，进行限流。 - 线程数：当调用该API的线程数达到阈值的时候，进行限流。 - 是否集群：不需要集群。 - 流控模式： - 直接：API达到限流条件时，直接限流。 - 关联：当关联的资源达到阈值的时候，就限流自己。 - 链路：只记录指定链路上的流量（指定资源从入口资源进来的流量，如果达到阈值，就进行限流）[API级别的针对来源]。 - 流控效果： - 快速失败：直接失败，抛异常。 - Warm Up：根据codeFactor（冷加载因子，默认为3）的值，从阈值/codeFactor，经过预热时长，才达到设置的QPS阈值。 - 排队等待：匀速排队，让请求以匀速的速度通过，阈值类型必须设置为QPS，否则无效。 ## 3**.2 流控模式之直接（默认直接–&gt;快速失败）** ### 3**.2.1 配置说明** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872685350-7d541728-9449-41f9-a6e2-9dfb3264a71f.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_19%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=nk7NC&amp;margin=%5Bobject%20Object%5D&amp;originHeight=510&amp;originWidth=679&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 表示1秒内查询1次就是OK，如果超过1次，就直接–&gt;快速失败，报默认错误。 ### 3**.2.2 测试** - 快速点击http://localhost:8401/testA。 - 结果显示： ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872712926-88e446da-bae5-489b-841b-2aa850171f10.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_23%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=UnV0o&amp;margin=%5Bobject%20Object%5D&amp;originHeight=381&amp;originWidth=798&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## 3**.3 流控模式之关联** ### 3**.3.1 是什么？** - 当和A关联的资源B达到阈值的时候，就限流A自己。 - 比如：电商系统中，下订单后面的流程就是支付，一旦支付超过阈值，就需要限制下订单。 ### 3**.3.2 配置说明** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872728078-b1bcfcd0-e2a9-4756-9bab-f5b7a3d988a9.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=zOyPx&amp;margin=%5Bobject%20Object%5D&amp;originHeight=568&amp;originWidth=705&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 当关联资源/testB的QPS的阈值超过1的时候，就限流A的访问。 ### 3**.3.3 测试** - 通过Postman并发测试http://localhost:8401/testB，然后通过浏览器访问http://localhost:8401/testA。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872735875-9e25a1de-c154-4760-b24a-c461684841bf.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_24%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=JviKO&amp;margin=%5Bobject%20Object%5D&amp;originHeight=254&amp;originWidth=844&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## **3.4 流控模式之链路** ### 3**.4.1 配置说明** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872750822-aab39347-1893-41b2-948c-42b9a1e25a33.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=b37vH&amp;margin=%5Bobject%20Object%5D&amp;originHeight=576&amp;originWidth=704&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 多个请求调用http://localhost:8401/testA，如果1秒内请求次数超过1次，就会触发限流。 ## 3**.5 流控效果之预热** ### 3**.5.1 概述** - Warm Up（RuleConstant.CONTROL_BEHAVIOR_WARM_UP）方式，即预热/冷启动方式。当系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过&quot;冷启动&quot;，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。详细文档可以参考 [流量控制 - Warm Up 文档](https://github.com/alibaba/Sentinel/wiki/%E9%99%90%E6%B5%81---%E5%86%B7%E5%90%AF%E5%8A%A8) ，具体的例子可以参见 [WarmUpFlowDemo](https://github.com/alibaba/Sentinel/blob/master/sentinel-demo/sentinel-demo-basic/src/main/java/com/alibaba/csp/sentinel/demo/flow/WarmUpFlowDemo.java)。 - 公式：阈值除以coldFactor(冷加载因子，默认为3)，经过预热后才会达到阈值。 ### 3**.5.2 配置说明** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872765611-1fc89e81-e911-45da-a063-71b4037d8d57.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=kdchk&amp;margin=%5Bobject%20Object%5D&amp;originHeight=553&amp;originWidth=696&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 系统初始化的的阈值是10/3约等于3，即阈值开始为3；经过5秒后阈值才慢慢升高恢复到10。 ## 3**.6 流控效果之排队等待** ### 3**.6.1 概述** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872780746-784cbfe8-3be1-45a2-9af8-bd249b25d176.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_27%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=x9AnC&amp;margin=%5Bobject%20Object%5D&amp;originHeight=500&amp;originWidth=944&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ### 3**.6.2 配置说明** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872789080-8ff1d72b-69f5-4ab5-821e-31ba17a2a61e.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=UrMLd&amp;margin=%5Bobject%20Object%5D&amp;originHeight=563&amp;originWidth=709&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - [http://localhost:8401/testA](http://localhost:8401/testA)每秒1次请求，超过的话就排队等待，等待的超时时间为20000毫秒。 # 4. **降级规则** ## 4**.1 基本介绍** - 除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。一个服务常常会调用别的模块，可能是另外的一个远程服务、数据库，或者第三方 API 等。例如，支付的时候，可能需要远程调用银联提供的 API；查询某个商品的价格，可能需要进行数据库查询。然而，这个被依赖服务的稳定性是不能保证的。如果依赖的服务出现了不稳定的情况，请求的响应时间变长，那么调用服务的方法的响应时间也会变长，线程会产生堆积，最终可能耗尽业务自身的线程池，服务本身也变得不可用。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872798526-09de1dc6-90b3-4a5e-a7c3-384e9614c2b0.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_32%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_937%2Climit_0#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=PCbX6&amp;margin=%5Bobject%20Object%5D&amp;originHeight=586&amp;originWidth=937&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 现代微服务架构都是分布式的，由非常多的服务组成。不同服务之间相互调用，组成复杂的调用链路。以上的问题在链路调用中会产生放大的效果。复杂链路上的某一环不稳定，就可能会层层级联，最终导致整个链路都不可用。因此我们需要对不稳定的**弱依赖服务调用**进行熔断降级，暂时切断不稳定调用，避免局部不稳定因素导致整体的雪崩。熔断降级作为保护自身的手段，通常在客户端（调用端）进行配置。 ## 4**.2 降级规则之慢调用比例** ### 4**.2.1 概述** - 慢调用比例 (SLOW_REQUEST_RATIO)：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。 ### 4**.2.2 代码** ```java package com.sunxiaping.sentinel.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; /** * @author 许大仙 * @version 1.0 * @since 2020-10-15 10:05 */ @RestController public class FlowLimitController { @GetMapping(value = &quot;/testA&quot;) public String testA() { try { //睡眠1秒 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;-------testA--------&quot;; } @GetMapping(value = &quot;/testB&quot;) public String testB() { return &quot;~~~~~~~~testB~~~~~~~~&quot;; } } 4**.2.3 配置** 最大RT（最大响应时间）设置为200ms，即请求的响应时间大于200ms则统计为慢调用。单位统计时长内请求的数量大于设置的最小请求数目（最小请求数设置为5），并且慢调用的比例大于阈值（阈值设置为0.0），则接下来的熔断时长内会自动被熔断（熔断时长设置为5s）。 4**.2.4 测试** 4**.2.5 结论** 按照上述配置，永远是1秒钟10个进程调用了testA，但是我们希望200ms内处理完本地任务，并且慢调动的比例大于了所设置的阈值0.0，所以一直处于熔断状态，当我们关闭Jmeter时，在未来时长5秒内，断路器一直处于打开状态，微服务不可用，直到5秒过去，微服务才恢复。 4**.3 降级规则之异常比例**4**.3.1 概述** 异常比例 (ERROR_RATIO)：当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 4**.3.2 代码**```javapackage com.sunxiaping.sentinel.controller; import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController; /** @author 许大仙 @version 1.0 @since 2020-10-15 10:05 /@RestControllerpublic class FlowLimitController { @GetMapping(value = “/testA”) public String testA() { //模拟异常 int num = 10 / 0; return &quot;-------testA--------&quot;; } @GetMapping(value = “/testB”) public String testB() { return &quot;~~~~~~~~testB~~~~~~~~&quot;; } } ### 4**.3.3 配置** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872840313-2b64b0f4-b526-4f8a-b3c9-b9a85e7d56e0.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_21%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=GlSxU&amp;margin=%5Bobject%20Object%5D&amp;originHeight=397&amp;originWidth=738&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 当单位统计时长内请求数量大于最小请求数目（设置为5），并且异常比例大于阈值（0.2），则接下来的熔断时间内请求自动会被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。 ### 4**.3.4 测试** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872846871-173c674e-fb5f-4981-b02f-977228bcc821.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_43%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=AHaR3&amp;margin=%5Bobject%20Object%5D&amp;originHeight=825&amp;originWidth=1520&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ### 4**.3.5 结论** - 按照上述配置，单独访问一次，必然访问一次，报错一次。开启Jmeter后，直接高并发发送请求，多次调用达到我们的配置条件了，断路器开启，微服务不可用了，不再报错而是服务降级了。 ## 4**.4 异常数** ### 4**.4.1 概述** - 当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。 ### 4**.4.2 代码** ```java package com.sunxiaping.sentinel.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; /** * @author 许大仙 * @version 1.0 * @since 2020-10-15 10:05 */ @RestController public class FlowLimitController { @GetMapping(value = &quot;/testA&quot;) public String testA() { //模拟异常 int num = 10 / 0; return &quot;-------testA--------&quot;; } @GetMapping(value = &quot;/testB&quot;) public String testB() { return &quot;~~~~~~~~testB~~~~~~~~&quot;; } } 4**.4.3 配置** 当单位统计时长内的异常数目超过阈值（2个）之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。 4**.4.4 测试** 5. 热点key限流5**.1 基本介绍** 何为热点？热点即经常访问的数据。很多时候我们希望统计某个热点数据中访问频次最高的 Top K 数据，并对其访问进行限制。比如： 商品 ID 为参数，统计一段时间内最常购买的商品 ID 并进行限制。 用户 ID 为参数，针对一段时间内频繁访问的用户 ID 进行限制。 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效。 Sentinel 利用 LRU 策略统计最近最常访问的热点参数，结合令牌桶算法来进行参数级别的流控。热点参数限流支持集群模式。 5**.2 @SentinelResource注解** 熔断降级方法分为系统默认和用户自定义两种，@SentinelResource注解和Hystrix的@HystrixCommand注解类似，都是用来配置用户自定义的熔断降级方法。 @SentinelResource注解和@HystrixCommand不同的是，只处理Sentinel控制台配置的违规情况，并不处理异常。 5**.3 应用示例**5**.3.1 代码**```javapackage com.sunxiaping.sentinel.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource;import com.alibaba.csp.sentinel.slots.block.BlockException;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController; /** @author 许大仙 @version 1.0 @since 2020-10-15 10:05 /@RestControllerpublic class FlowLimitController { @GetMapping(value = “/testA”) public String testA() { return &quot;-------testA--------&quot;; } @GetMapping(value = “/testB”) public String testB() { return &quot;~~~~~~~~testB~~~~~~~~&quot;; } @GetMapping(value = “/testHotKey”) //通过blockHandler指定熔断降级的方法，通过fallback指定触发异常执行的降级方法 @SentinelResource(value = “testHotKey”, blockHandler = “dealTestHotKey”) public String testHotKey( @RequestParam(value = &quot;p1&quot;, required = false) String p1, @RequestParam(value = &quot;p2&quot;, required = false) String p2) { return &quot;testHotKey&quot;; } /** * 熔断降级 * * @param p1 * @param p2 * @param exception * @return */ public String dealTestHotKey(String p1, String p2, BlockException exception) { return &quot;--------熔断降级-------&quot;; } } ### 5**.3.2 配置** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872897705-9324bb4e-a49a-4d97-9a70-196e7bf5613d.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_19%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=jVpLW&amp;margin=%5Bobject%20Object%5D&amp;originHeight=693&amp;originWidth=668&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 如果testHotKey的参数p1的值不是5，那么QPS是1；如果参数p1的值是5，那么QPS是2000。 ### 5**.3.2 测试** - 测试http://localhost:8401/testHotKey?p1=1请求，如果每秒请求1次，不会熔断降级，如果每次请求超过1次，会触发熔断降级。 - 测试http://localhost:8401/testHotKey?p1=5请求，只要每秒请求不超过2000次，就不会熔断降级。 # 6. **系统规则** ## 6**.1 基本介绍** - Sentinel 系统自适应限流从整体维度对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 ## 6**.2 背景** - 在开始之前，我们先了解一下系统保护的目的： - 保证系统不被拖垮 - 在系统稳定的前提下，保持系统的吞吐量 - 长期以来，系统保护的思路是根据硬指标，即系统的负载 (load1) 来做系统过载保护。当系统负载高于某个阈值，就禁止或者减少流量的进入；当 load 开始好转，则恢复流量的进入。这个思路给我们带来了不可避免的两个问题： - load 是一个“结果”，如果根据 load 的情况来调节流量的通过率，那么就始终有延迟性。也就意味着通过率的任何调整，都会过一段时间才能看到效果。当前通过率是使 load 恶化的一个动作，那么也至少要过 1 秒之后才能观测到；同理，如果当前通过率调整是让 load 好转的一个动作，也需要 1 秒之后才能继续调整，这样就浪费了系统的处理能力。所以我们看到的曲线，总是会有抖动。 - 恢复慢。想象一下这样的一个场景（真实），出现了这样一个问题，下游应用不可靠，导致应用 RT 很高，从而 load 到了一个很高的点。过了一段时间之后下游应用恢复了，应用 RT 也相应减少。这个时候，其实应该大幅度增大流量的通过率；但是由于这个时候 load 仍然很高，通过率的恢复仍然不高。 - [TCP BBR](https://en.wikipedia.org/wiki/TCP_congestion_control#TCP_BBR) 的思想给了我们一个很大的启发。我们应该根据系统能够处理的请求，和允许进来的请求，来做平衡，而不是根据一个间接的指标（系统 load）来做限流。最终我们追求的目标是 **在系统不被拖垮的情况下，提高系统的吞吐率，而不是 load 一定要到低于某个阈值**。如果我们还是按照固有的思维，超过特定的 load 就禁止流量进入，系统 load 恢复就放开流量，这样做的结果是无论我们怎么调参数，调比例，都是按照果来调节因，都无法取得良好的效果。 - Sentinel 在系统自适应保护的做法是，用 load1 作为启动自适应保护的因子，而允许通过的流量由处理请求的能力，即请求的响应时间以及当前系统正在处理的请求速率来决定。 ## 6**.3 系统规则** - 系统保护规则是从应用级别的入口流量进行控制，从单台机器的 load、CPU 使用率、平均 RT、入口 QPS 和并发线程数等几个维度监控应用指标，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 - 系统保护规则是应用整体维度的，而不是资源维度的，并且**仅对入口流量生效**。入口流量指的是进入应用的流量（EntryType.IN），比如 Web 服务或 Dubbo 服务端接收的请求，都属于入口流量。 - 系统规则支持以下的模式： - **Load 自适应**（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。 - **CPU usage**（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。 - **平均 RT**：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 - **并发线程数**：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 - **入口 QPS**：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 ## 6**.4 系统规则配置界面** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608872918949-6e6fbbc1-e3ea-4f7e-94a9-f91b495d5996.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_24%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=OJBTG&amp;margin=%5Bobject%20Object%5D&amp;originHeight=345&amp;originWidth=834&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) # 7. **Rest实现服务降级** ## 7**.1 准备工作** - 需要启动Nacos和Sentinel。 ## 7**.2 服务生产者** ### 7**.2.1 导入相关jar包的Maven坐标** - 修改部分: ```xml &lt;!-- Nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>cloud_alibaba_provider9013&lt;/artifactId> &lt;dependencies> &lt;!-- Nacos --> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 7**.2.2 修改配置文件** application.yml```yamlserver:port: 9013 spring: application: name: cloud-alibaba-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 management: endpoints: web: exposure: include: ‘*’ ### 7**.2.3 启动类** ```java package com.sunxiaping.alibaba; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; /** * @author 许大仙 * @version 1.0 * @since 2020-10-11 10:54 */ @SpringBootApplication @EnableDiscoveryClient public class CloudAlibabaProvider9013Application { public static void main(String[] args) { SpringApplication.run(CloudAlibabaProvider9013Application.class, args); } } 7**.2.4 业务逻辑** PaymentController.java```javapackage com.sunxiaping.alibaba.controller; import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController; /** @author 许大仙 @version 1.0 @since 2020-10-11 10:57 /@RestControllerpublic class PaymentController { @Value(“${server.port}”) private String serverPort; @GetMapping(value = &quot;/payment/{id}&quot;) public String payment(@PathVariable(value = &quot;id&quot;) Integer id) { return &quot;Nacos的注册中心的端口是：&quot; + serverPort + &quot;,id是：&quot; + id; } } ## 7**.3 服务消费者** ### 7**.3.1 导入相关jar包的Maven坐标** - 修改部分: ```xml &lt;!-- Nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 cloud_alibaba_consumer9015 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.cloud spring-cloud-starter-alibaba-sentinel org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-actuator ``` ### 7**.3.2 修改配置文件** application.yml```yamlserver:port: 9015 spring: application: name: cloud-alibaba-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 sentinel: transport: # 配置Sentinel Dashboard地址 dashboard: 127.0.0.1:8080 # 默认8719端口，假设被占用会自动从8719开始依次加1扫描，直到找到没有被占用的端口 port: 8719 # 取消懒加载 eager: true management: endpoints: web: exposure: include: ‘*’ ### **7.3.3 启动类** ```java package com.sunxiaping.alibaba; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; /** * @author 许大仙 * @version 1.0 * @since 2020-10-11 11:34 */ @SpringBootApplication @EnableDiscoveryClient public class CloudAlibabaConsumer9015Application { public static void main(String[] args) { SpringApplication.run(CloudAlibabaConsumer9015Application.class, args); } } 7**.3.4 业务逻辑** 异常工具类：```javapackage com.sunxiaping.alibaba.utils; import com.alibaba.csp.sentinel.slots.block.BlockException; /** @author 许大仙 @version 1.0 @since 2020-10-21 14:58 /public class ExceptionUtils { public static String handleBlock(Integer id, BlockException ex) { return &quot;熔断降级&quot;; } public static String handleFallback(Integer id, Throwable tx) { return &quot;异常降级&quot;; }}``` SpringConfig.java```javapackage com.sunxiaping.alibaba.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate; /** @author 许大仙 @version 1.0 @since 2020-10-11 11:35 /@Configurationpublic class SpringConfig { @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } - OrderController.java ```java package com.sunxiaping.alibaba.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource; import com.sunxiaping.alibaba.utils.ExceptionUtils; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; /** * @author 许大仙 * @version 1.0 * @since 2020-10-11 11:35 */ @RestController public class OrderController { @Autowired private RestTemplate restTemplate; @GetMapping(value = &quot;/order/{id}&quot;) @SentinelResource(blockHandlerClass = ExceptionUtils.class, blockHandler = &quot;handleBlock&quot;, fallbackClass = ExceptionUtils.class, fallback = &quot;handleFallback&quot;) public String order(@PathVariable(value = &quot;id&quot;) Integer id) { if (4 == id) { throw new IllegalArgumentException(&quot;非法参数异常&quot;); } return this.restTemplate.getForObject(&quot;http://cloud-alibaba-provider&quot; + &quot;/payment/&quot; + id, String.class); } } 8. Feign实现服务降级8**.1 准备工作** 需要启动Nacos和Sentinel。 8**.2 服务生产者**8**.2.1 导入相关jar包的Maven坐标** 修改部分: &lt;!-- Nacos --> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> 完整部分: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>cloud_alibaba_provider9013&lt;/artifactId> &lt;dependencies> &lt;!-- Nacos --> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 8**.2.2 修改配置文件** application.yml```yamlserver:port: 9013 spring: application: name: cloud-alibaba-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 management: endpoints: web: exposure: include: ‘*’ ### 8**.2.3 启动类** ```java package com.sunxiaping.alibaba; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; /** * @author 许大仙 * @version 1.0 * @since 2020-10-11 10:54 */ @SpringBootApplication @EnableDiscoveryClient public class CloudAlibabaProvider9013Application { public static void main(String[] args) { SpringApplication.run(CloudAlibabaProvider9013Application.class, args); } } 8**.2.4 业务逻辑** PaymentController.java```javapackage com.sunxiaping.alibaba.controller; import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController; /** @author 许大仙 @version 1.0 @since 2020-10-11 10:57 /@RestControllerpublic class PaymentController { @Value(“${server.port}”) private String serverPort; @GetMapping(value = &quot;/payment/{id}&quot;) public String payment(@PathVariable(value = &quot;id&quot;) Integer id) { return &quot;Nacos的注册中心的端口是：&quot; + serverPort + &quot;,id是：&quot; + id; } } ## 8**.3 服务消费者** ### 8**.3.1 导入相关jar包的Maven坐标** - 修改部分: ```xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 cloud_alibaba_consumer9015 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.cloud spring-cloud-starter-alibaba-sentinel org.springframework.cloud spring-cloud-starter-openfeign org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-actuator ``` ### 8**.3.2 修改配置文件** application.yml```yamlserver:port: 9015 spring: application: name: cloud-alibaba-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 sentinel: transport: # 配置Sentinel Dashboard地址 dashboard: 127.0.0.1:8080 # 默认8719端口，假设被占用会自动从8719开始依次加1扫描，直到找到没有被占用的端口 port: 8719 # 取消懒加载 eager: true 开启Feign对sentinel的支持feign: sentinel: enabled: true management: endpoints: web: exposure: include: ‘*’ ### 8**.3.3 启动类** ```java package com.sunxiaping.alibaba; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; /** * @author 许大仙 * @version 1.0 * @since 2020-10-11 11:34 */ @SpringBootApplication @EnableDiscoveryClient @EnableFeignClients public class CloudAlibabaConsumer9015Application { public static void main(String[] args) { SpringApplication.run(CloudAlibabaConsumer9015Application.class, args); } } 8**.3.4 业务逻辑** PaymentFeign.java```javapackage com.sunxiaping.alibaba.feign; import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable; /** @author 许大仙 @version 1.0 @since 2020-10-21 16:07 /@FeignClient(value = “cloud-alibaba-provider”, fallback = PaymentFeignCallback.class)public interface PaymentFeign { @GetMapping(value = “/payment/{id}”) String payment(@PathVariable(value = “id”) Integer id); } - PaymentFeignCallback.java ```java package com.sunxiaping.alibaba.feign; import org.springframework.stereotype.Component; /** * @author 许大仙 * @version 1.0 * @since 2020-10-21 16:09 */ @Component public class PaymentFeignCallback implements PaymentFeign { @Override public String payment(Integer id) { return &quot;熔断降级&quot;; } } OrderController.java```javapackage com.sunxiaping.alibaba.controller; import com.sunxiaping.alibaba.feign.PaymentFeign;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; /** @author 许大仙 @version 1.0 @since 2020-10-11 11:35 /@RestControllerpublic class OrderController { @Resource private PaymentFeign paymentFeign; @GetMapping(value = “/order/{id}”) public String order(@PathVariable(value = “id”) Integer id) { return this.paymentFeign.payment(id); } } # 9. Sentinel规则持久化 ## 9**.1 是什么？** - 一旦我们重启应用，Sentinel规则将消失，生产环境需要将配置规则进行持久化。 ## 9**.2 怎么玩？** - 将Sentinel中的规则持久化到Nacos保存，只要Nacos里面的配置不删除，那么Sentinel中的规则将持续有效。 ## 9**.3 步骤（修改服务消费者）** ### **9.3.1 导入相关jar包的Maven坐标** - 修改部分: ```xml &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>cloud_alibaba_consumer9015&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-datasource-nacos&lt;/artifactId> &lt;/dependency> &lt;!-- Nacos --> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-sentinel&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 9**.3.2 修改配置文件** application.yml```yamlserver:port: 9015 spring: application: name: cloud-alibaba-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 sentinel: transport: # 配置Sentinel Dashboard地址 dashboard: 127.0.0.1:8080 # 默认8719端口，假设被占用会自动从8719开始依次加1扫描，直到找到没有被占用的端口 port: 8719 # 将Sentinel的规则持久化到Nacos中 datasource: ds1: nacos: server-addr: 127.0.0.1:8848 dataId: ${spring.application.name} groupId: DEFAULT_GROUP data_type: json rule_type: flow # 取消懒加载 eager: true 开启Feign对sentinel的支持feign: sentinel: enabled: true management: endpoints: web: exposure: include: ‘*’ ### 9**.3.3 在Nacos中添加业务规则配置** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608873028661-bc597bfd-92bc-4948-84ab-b80c2bf7cccb.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_49%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=v0Awh&amp;margin=%5Bobject%20Object%5D&amp;originHeight=734&amp;originWidth=1729&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ```json [ { &quot;resource&quot;: &quot;/hello&quot;, &quot;limitApp&quot;: &quot;default&quot;, &quot;grade&quot;: 1, &quot;count&quot;: 5, &quot;strategy&quot;: 0, &quot;controlBehavior&quot;: 0, &quot;clusterMode&quot;: false } ] resource：资源名称。 limitApp：来源应用。 grade：阈值类型，0表示线程数，1表示QPS。 count：单机阈值。 strategy：流控模式，0表示直接，1表示关联，2表示链路。 controlBehavior：流控效果，0表示快速失败，1表示Warm up，2表示排队等待。 clusterMode：是否集群。 9**.3.4 启动微服务消费者，刷新Sentinel**","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】Netflex服务与注册中心(过时)","slug":"springcloud/netflex/Eureka服务注册与发现中心(过时)","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"一. 非集群 搭建Eureka Server。 创建工程（eureka_server）。 导入Eureka对应的坐标。 配置application.yml。 配置启动类。 将服务提供者注册到Eureka Server上。 服务消费者通过注册中心获取服务列表，并调用。 1. 搭建Eureka Server（注册中心）1.1 在pom.xml中导入相关jar包的坐标```java &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 eureka_service org.springframework.cloud spring-cloud-starter-netflix-eureka-server ``` ### 1.2 配置yml application.yml```yamlserver:port: 9000 #端口 #配置Eureka Servereureka: instance: # 主机地址名称 hostname: localhost client: register-with-eureka: false # 是否将自己注册到注册中心 fetch-registry: false # 是否从Eureka中获取服务列表 service-url: # 配置暴露给Eureka Client的请求地址 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ ### 1.3 配置启动类 - EurekaApplication.java ```java package com.sunxiaping.eureka; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; /** * @author 许威威 * @version 1.0 */ @SpringBootApplication @EnableEurekaServer //开启Eureka Server public class EurekaApplication { public static void main(String[] args) { SpringApplication.run(EurekaApplication.class, args); } } 1.4访问服务中心管理平台 打开浏览器访问http://localhost:9000/，即可进入Eureka Server内置的管理控制台，显示效果如下： 2. 服务提供者注册到Eureka注册中心2.1 在服务提供者微服务中引入Eureka Client的坐标&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>product_service&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-jpa&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;!-- 导入Eureka Client对应的坐标 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;version>2.2.2.RELEASE&lt;/version> &lt;configuration> &lt;fork>true&lt;/fork> &lt;/configuration> &lt;executions> &lt;execution> &lt;goals> &lt;goal>repackage&lt;/goal> &lt;/goals> &lt;/execution> &lt;/executions> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 2.2 修改yml配置文件 application.yml```yamlserver:port: 9001 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置 eurekaeureka: client: service-url: # Eureka Server的地址 defaultZone: http://localhost:9000/eureka/ ### 2**.3 配置启动类** - ProductApplication.java ```java package com.sunxiaping.product; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient //开启Eureka Client public class ProductApplication { public static void main(String[] args) { SpringApplication.run(ProductApplication.class, args); } } 2.4 测试 2**.5 actuator与注册微服务信息完善**2.5.1 主机名:服务名称修改 当前问题： 修改服务提供者的application.yml文件。 修改部分： # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:9001 client: service-url: # Eureka Server的地址 defaultZone: http://localhost:9000/eureka/ 完整部分```yamlserver:port: 9001 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:9001 client: service-url: # Eureka Server的地址 defaultZone: http://localhost:9000/eureka/ - 修改之后: ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608867432898-45f53701-ddb9-4772-908a-8a9c08fe9756.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_53%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=y9wH5&amp;margin=%5Bobject%20Object%5D&amp;originHeight=240&amp;originWidth=1869&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) #### **2.5.2 显示IP信息** - 当前问题： ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608867442423-41c26c3f-2784-407d-84ab-f1d77079b668.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_55%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=CCsiF&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1040&amp;originWidth=1920&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 修改服务提供者的application.yml文件。 - 修改部分： ```yaml # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:9001 # 显示IP信息 prefer-ip-address: true client: service-url: # Eureka Server的地址 defaultZone: http://localhost:9000/eureka/ 完整部分：```yamlserver:port: 9001 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:9001 # 显示IP信息 prefer-ip-address: true client: service-url: # Eureka Server的地址 defaultZone: http://localhost:9000/eureka/ - 修改之后: ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608867448902-c9b45382-6cba-40da-bd4e-8440bd564f0a.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_55%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=bIWaj&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1040&amp;originWidth=1920&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) #### 2**.5.3 微服务info内容详细信息** - 当前问题：点击超链接报告ErrorPage ![](https://cdn.nlark.com/yuque/0/2020/gif/513185/1608867466185-829179eb-4225-4224-b64c-eba776a3ea00.gif#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=V3JZR&amp;margin=%5Bobject%20Object%5D&amp;originHeight=787&amp;originWidth=949&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 修改服务提供者的pom.xml。 - 修改部分： ```xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>product_service&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-jpa&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;!-- 导入Eureka Client对应的坐标 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;version>2.2.2.RELEASE&lt;/version> &lt;configuration> &lt;fork>true&lt;/fork> &lt;/configuration> &lt;executions> &lt;execution> &lt;goals> &lt;goal>repackage&lt;/goal> &lt;/goals> &lt;/execution> &lt;/executions> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 在总工程添加build信息。 修改部分： &lt;build> &lt;finalName>spring_cloud_demo&lt;/finalName> &lt;resources> &lt;resource> &lt;directory>src/main/resources&lt;/directory> &lt;filtering>true&lt;/filtering> &lt;/resource> &lt;/resources> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-resources-plugin&lt;/artifactId> &lt;configuration> &lt;delimiters> &lt;delimit>$&lt;/delimit> &lt;/delimiters> &lt;/configuration> &lt;/plugin> &lt;/plugins> &lt;/build> 完整部分：```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; 4.0.0 pom product_service spring_cloud_common order_service eureka_service org.springframework.boot spring-boot-starter-parent 2.1.6.RELEASE &lt;groupId&gt;org.sunxiaping&lt;/groupId&gt; &lt;artifactId&gt;spring_cloud_demo&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.4&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Greenwich.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;http://repo.spring.io/libs-snapshot-local&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;http://repo.spring.io/libs-milestone-local&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-releases&lt;/id&gt; &lt;name&gt;Spring Releases&lt;/name&gt; &lt;url&gt;http://repo.spring.io/libs-release-local&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;http://repo.spring.io/libs-snapshot-local&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;http://repo.spring.io/libs-milestone-local&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;build&gt; &lt;finalName&gt;spring_cloud_demo&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;delimit&gt;$&lt;/delimit&gt; &lt;/delimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ``` 修改服务提供者的application.yml文件。 修改部分： # 微服务info内容详细信息 info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ 完整部分:```yamlserver:port: 9001 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:9001 # 显示IP信息 prefer-ip-address: true client: service-url: # Eureka Server的地址 defaultZone: http://localhost:9000/eureka/ 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ - 修改之后： ![](https://cdn.nlark.com/yuque/0/2020/gif/513185/1608867478808-061f9185-f748-4a97-a6cc-ca3b29d0f132.gif#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=oAri2&amp;margin=%5Bobject%20Object%5D&amp;originHeight=761&amp;originWidth=948&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## **3. 服务消费者通过注册中心获取服务列表，并调用** ### **3.1 在服务消费者微服务中引入Eureka Client的坐标** - 修改部分: ```xml &lt;!-- 导入Eureka Client对应的坐标 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分:```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 order_service org.springframework.boot spring-boot-starter-actuator org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-data-jpa mysql mysql-connector-java ``` ### **3.2 修改yml配置文件** application.yml```yamlserver:port: 9002 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置Eurekaeureka: instance: # 实例的名称 instance-id: service-order:9002 # 显示IP信息 prefer-ip-address: true client: service-url: # Eureka Server的地址 defaultZone: http://localhost:9000/eureka/ 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ ### 3**.3 修改Controller** - OrderController.java ```java package com.sunxiaping.order.controller; import com.sunxiaping.order.domain.Product; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import java.net.URI; import java.util.List; @RestController @RequestMapping(value = &quot;/order&quot;) public class OrderController { @Autowired private RestTemplate restTemplate; /** * SpringCloud提供的获取元数据的工具类 * 调用方法获取服务的元数据 */ @Autowired private DiscoveryClient discoveryClient; /** * 通过订单系统，调用商品微服务根据id查询商品信息 * * @param id * @return */ @GetMapping(value = &quot;/buy/{id}&quot;) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { List&lt;ServiceInstance&gt; instanceList = discoveryClient.getInstances(&quot;service-product&quot;); ServiceInstance serviceInstance = instanceList.get(0); URI uri = serviceInstance.getUri(); if (null != uri) { return restTemplate.getForObject(uri.toString() + &quot;/product/findById/&quot; + id, Product.class); } return null; } } 4. Eureka中的自我保护 微服务第一次注册成功后，每30秒会发送一次心跳将服务的实例信息注册到注册中心。通知Eureka Server该实例依然存在。如果超过90秒没有发送心跳，则服务器将从注册中心将此服务移除。 Eureka Server在运行期间，会统计心跳失败的比例在15分钟内是否低于85%，如果出现低于85%的情况（在单机调试的时候很容易满足，实际在生产环境上通常是由于网络不稳定导致），那么Eureka就会认为客户端和注册中心出现了网络故障，此时会做如下的处理： Eureka不再从注册列表中删除因为长时间没有收到心跳而应该过期的服务。 Eureka不再从注册列表中删除因为长时间没有收到心跳而应该过期的服务。 当网络稳定的时候，当前实例新的注册信息会被同步到其他节点中。 验证自我保护机制开启，并不会马上呈现在web后台上，而是默认需要等待5分钟（可以通过eureka.server.wait-time-in-ms-when-sync-empty配置），即5分钟后你就会看到如下所示的提示信息： 通过设置eureka.enableSelfPreservation=false来关闭自我保护机制。# eureka.instance.lease-renewal-interval-in-seconds 表示服务续约时间 eureka.instance.lease-renewal-interval-in-seconds = 30 # eureka.instance.lease-expiration-duration-in-seconds 表示服务时效时间 eureka.instance.lease-expiration-duration-in-seconds = 90 二. 搭建Eureka Server高可用集群1. 搭建Eureka Server高可用集群2、父项目依赖```xml 2.3.2.RELEASE org.springframework.boot spring-boot-dependencies ${spring.boot.version} pom import org.springframework.cloud spring-cloud-dependencies Hoxton.SR1 pom import ``` ## 3、三个服务注册中心子模块依赖 ```xml org.springframework.cloud spring-cloud-starter-netflix-eureka-server org.springframework.boot spring-boot-starter-web ``` ## 4、客户端服务提供者依赖 ```xml org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-web ``` ## 5、三个服务注册中心配置 修改 hosts 文件 由于只能在一台机器模拟三台服务器，此时必须要在主机的 hosts 文件中修改主机名，否则都默认为 localhost，则无法区分各个 Eureka 服务注册中心的实例。windows 目录：C:\\Windows\\System32\\drivers\\etc\\hosts，在末尾处添加如下映射配置。（修改主机名 hostname） 127.0.0.1 eureka8761 127.0.0.1 eureka8762 127.0.0.1 eureka8763 配置 application.properties 配置文件 8761```yamlserver:port: 8761 eureka: instance: hostname: eureka8761 # eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向本端注册中心注册自己。 fetch-registry: false # false 表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: # Eureka 实例之间互相注册，即把自己注册到另外两个服务注册中心实例中 defaultZone: http://eureka8762:8762/eureka/,http://eureka8763:8763/eureka/ - 8762 ```yaml server: port: 8761 eureka: instance: hostname: eureka8762 # eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向本端注册中心注册自己。 fetch-registry: false # false 表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: # Eureka 实例之间互相注册，即把自己注册到另外两个服务注册中心实例中 defaultZone: http://eureka8761:8761/eureka/,http://eureka8763:8763/eureka/ 8763```yamlserver:port: 8763 eureka: instance: hostname: eureka8761 # eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向本端注册中心注册自己。 fetch-registry: false # false 表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: # 有多台服务器时，用逗号隔开 # Eureka 实例之间互相注册，即把自己注册到另外两个服务注册中心实例中，以便于客户端的数据同步 defaultZone: http://eureka8761:8761/eureka/,http://eureka8762:8762/eureka/ 3. **Eureka 服务端注解 @EnableEurekaServer** &gt; 在 3 个服务端的子项目中的启动类上分别添加注解 @EnableEurekaServer ```java @EnableEurekaServer @SpringBootApplication public class ApplicationMain{ public static void main(String[] args) { SpringApplication.run(ApplicationMain.class, args); } } 6、启动服务集群 分别启动三个 Eureka 服务端项目。以 8761 节点为例： 在 hosts 文件中修改主机名后，我们可以用自定义的主机名进行访问（localhostname:8761）。如果不修改，只能用默认的 localhost:8761 进行访问。 7、将服务提供者注册到服务注册中心集群 配置 application.properties 配置文件```yamlserver:port: 8001 eureka: client: register-with-eureka: true # 是否向注册中心注册自己 fetchRegistry: true # 是否从注册中心抓取已有的注册信息，默认true，集群必须设置为true service-url: # 集群中各个服务注册中心的地址 defaultZone: http://eureka8761:8761/eureka,http://eureka8762:8762/eureka,http://eureka8763:8763/eureka instance: instance-id: servicer8001 # 服务实例Id prefer-ip-address: true #访问路径可以显示IP地址 &gt; 实际上，defaultZone 中只配置集群中任意一个服务注册中心的地址，集群中其他的节点都会相互复制服务实例。 2. **Eureka 客户端注解 @EnableEurekaClient** ```java @EnableEurekaClient @SpringBootApplication public class ApplicationMain{ public static void main(String[] args) { SpringApplication.run(ApplicationMain.class, args); } } 8、启动服务提供者注册到服务注册中心集群中 8761节点 8762节点 8763节点 9、服务注册与发现1、在客户端项目启动类添加 @EnableDiscoveryClient @EnableEurekaClient @EnableDiscoveryClient @SpringBootApplication public class ApplicationMain{ public static void main(String[] args) { SpringApplication.run(ApplicationMain.class, args); } } 2、查询使用注册的服务信息 要注入 DiscoveryClient 实例。 @RestController @RequestMapping(\"payment\") public class PaymentController { // 服务发现 @Resource private DiscoveryClient discoveryClient; @GetMapping(\"discovery\") public Object discovery() { List&lt;String> services = discoveryClient.getServices(); services.forEach(System.out::println); // 获得服务名下的实例列表 List&lt;ServiceInstance> instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); instances.forEach(instance -> { System.out.println(instance.getServiceId() + \"\\t\" + instance.getHost() + \"\\t\" + instance.getPort() + \"\\t\" + instance.getUri()); }); return this.discoveryClient; } } 3、@EnableDiscoveryClient 和 @EnableEurekaClient 共同点：都是能够让注册中心能够发现，扫描到该服务。 不同点：@EnableEurekaClient 只适用于 Eureka 作为注册中心，@EnableDiscoveryClient 可以用于所有注册中心（eureka，zookeeper，consul 和 nacos）。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】alibaba","slug":"springcloud/alibaba/Alibaba","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"SpringCloud Alibaba全解(第三版).pdf","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】Netflex","slug":"springcloud/netflex/Netflex","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"4、SpringCloud.pdf","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】服务熔断Hystrix（已过时）","slug":"springcloud/netflex/服务熔断Hystrix（已过时）","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1. Rest实现服务降级1**.1 引入Hystrix的依赖** 修改部分: &lt;!-- 引入Hystrix依赖 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 order_service_hystrix_rest9006 org.springframework.retry spring-retry org.springframework.boot spring-boot-starter-actuator org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.cloud spring-cloud-starter-netflix-hystrix ``` ## **1.2 在启动类上激活Hystrix** Order9006Application.java```javapackage com.sunxiaping; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker; @SpringBootApplication@EnableCircuitBreaker //激活Hystrixpublic class Order9006Application { public static void main(String[] args) { SpringApplication.run(Order9006Application.class, args); }} ## 1**.3 配置熔断处理的降级逻辑** - OrderController.java ```java package com.sunxiaping.controller; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import com.sunxiaping.domain.Product; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController @RequestMapping(value = &quot;/order&quot;) public class OrderController { @Autowired private RestTemplate restTemplate; /** * 使用注解配置熔断保护 * fallbackMethod：配置熔断之后的降级方法 * * @param id * @return */ @GetMapping(value = &quot;/buy/{id}&quot;) @HystrixCommand(fallbackMethod = &quot;orderFallBack&quot;) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { Product product = restTemplate.getForObject(&quot;http://service-product/product/findById/&quot; + id, Product.class); return product; } /** * 降级方法 * 和需要受到保护的方法的返回值一致 * 和需要受到保护的方法的参数列表一致 * * @param id * @return */ public Product orderFallBack(Long id) { Product product = new Product(); product.setId(-1L); product.setProductName(&quot;熔断:降级&quot;); return product; } } 1**.4 配置默认的降级逻辑** OrderController.java```javapackage com.sunxiaping.controller; import com.netflix.hystrix.contrib.javanica.annotation.DefaultProperties;import com.sunxiaping.domain.Product;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate; @RestController@RequestMapping(value = “/order”)@DefaultProperties(defaultFallback = “defaultFallBack”)public class OrderController { @Autowired private RestTemplate restTemplate; /** * 使用注解配置熔断保护 * fallbackMethod：配置熔断之后的降级方法 * * @param id * @return */ @GetMapping(value = &quot;/buy/{id}&quot;) // @HystrixCommand(fallbackMethod = “orderFallBack”) public Product buy(@PathVariable(value = “id”) Long id) { Product product = restTemplate.getForObject(&quot;http://service-product/product/findById/&quot; + id, Product.class); return product; } /** * 降级方法 * 和需要受到保护的方法的返回值一致 * 和需要受到保护的方法的参数列表一致 * * @param id * @return */ public Product orderFallBack(Long id) { Product product = new Product(); product.setId(-1L); product.setProductName(&quot;熔断:降级&quot;); return product; } /** * 指定统一的降级方法 * 参数：没有参数 * * @return */ public Product defaultFallBack() { Product product = new Product(); product.setProductName(&quot;触发统一的降级方法&quot;); return product; } } ## 1**.5 超时设置** - Hystrix的默认超时时间为1秒，我们可以通过如下的配置修改默认的超时设置： ```yaml hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 6000 # 默认的连接超时时间为1秒，如果1秒没有返回数据，就自动触发降级逻辑 当然，也可以在使用@HystrixCommand注解时配置超时设置：```javapackage com.sunxiaping.order.controller; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty;import com.sunxiaping.order.domain.Product;import lombok.var;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate; @RestController@RequestMapping(value = “/order”)public class OrderController { @Autowired private RestTemplate restTemplate; /** * 使用OrderCommand调用远程远程服务 * * @param id * @return */ @GetMapping(value = &quot;/buy/{id}&quot;) @HystrixCommand(fallbackMethod = &quot;orderFallback&quot;, commandProperties = { @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;3000&quot;) }) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { return restTemplate.getForObject(&quot;http://service-product/product/findById/&quot; + id, Product.class); } public Product orderFallback() { var product = new Product(); product.setId(Long.MAX_VALUE); product.setProductName(&quot;熔断降级啦&quot;); return product; } } # **2. Feign实现服务降级** &gt; Spring Cloud Feign默认已经为Feign整 合了Hystrix，所以添加Feign依赖后不用再添加Hystrix。feign中的hystrix默认是关闭的，需要在配置文件中开启。 ## 2**.1 引入OpenFeign的依赖** - 修改部分: ```xml &lt;!-- openfeign --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>order-service-hystrix_feign9007&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.retry&lt;/groupId> &lt;artifactId>spring-retry&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;!-- 导入Eureka Client对应的坐标 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;!-- openfeign --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 2**.2 修改application.yml在Feign中开启Hystrix** application.yml feign: hystrix: # 开启Feign中的Hystrix enabled: true 2**.3 自定义Feign接口的实现类，这个实现类就是熔断触发的降级逻辑** ProductFeignClientCallBack.java```javapackage com.sunxiaping.feign.impl; import com.sunxiaping.domain.Product;import com.sunxiaping.feign.ProductFeignClient;import org.springframework.stereotype.Component; /** 自定义Feign接口的实现类 /@Componentpublic class ProductFeignClientCallBack implements ProductFeignClient { @Override public Product findById(Long id) { Product product = new Product(); product.setProductName(&quot;熔断降级了&quot;); return product; }}```2**.4 修改Feign接口添加降级方法的支持** 原先的Feign接口：```javapackage com.sunxiaping.feign; import com.sunxiaping.domain.Product;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable; @FeignClient(value = “service-product”)public interface ProductFeignClient { @GetMapping(value = &quot;/product/findById/{id}&quot;) Product findById(@PathVariable(value = &quot;id&quot;) Long id); } - 修改Feign接口添加降级方法的支持： ```java package com.sunxiaping.feign; import com.sunxiaping.domain.Product; import com.sunxiaping.feign.impl.ProductFeignClientCallBack; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @FeignClient(value = &quot;service-product&quot;,fallback = ProductFeignClientCallBack.class) public interface ProductFeignClient { @GetMapping(value = &quot;/product/findById/{id}&quot;) Product findById(@PathVariable(value = &quot;id&quot;) Long id); } 3. Hystrix的监控平台3**.1 概述** 除了实现容错功能，Hystrix还提供了近乎实时的监控，HystrixCommand和HystrixObervableCommand在执行的时候，会生成执行结果和运行指标。比如每秒的请求数量、成功数量等待。这些状态会暴露在Actuator提供的/health端点中。 导入相关jar包的Maven坐标： &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;!-- openfeign --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> 在启动类上开启Hystrix：```javapackage com.sunxiaping; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication@EnableFeignClients //开启OpenFeign的支持@EnableCircuitBreaker //开启Hystrixpublic class Order9007Application { public static void main(String[] args) { SpringApplication.run(Order9007Application.class, args); }} - 在application.yml中将所有的端点打开： ```yaml # 配置hystrix hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 6000 # 默认的连接超时时间为1秒，如果1秒没有返回数据，就自动触发降级逻辑 feign: hystrix: # 开启Feign中的Hystrix enabled: true # 暴露所有端点 management: endpoints: web: exposure: include: &#39;*&#39; 重启项目，访问http://localhost:9007/actuator/hystrix.stream，即可以看到实时监控数据。 3**.2 搭建Hystrix DashBoard监控(不推荐)** Hystrix官方提供了基于图形化的DashBoard（仪表盘）监控平台，用来直观的展示系统的运行状态。Hystrix仪表盘可以显示每个断路器的状态。 导入依赖： &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId> &lt;/dependency> 在启动类上添加@EnableHystrixDashboard注解以激活仪表盘：```javapackage com.sunxiaping; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard;import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication@EnableFeignClients //开启OpenFeign的支持@EnableCircuitBreaker //开启Hystrix@EnableHystrixDashboard // 激活仪表盘public class Order9007Application { public static void main(String[] args) { SpringApplication.run(Order9007Application.class, args); }} - 重启项目，访问http://localhost:9007/hystrix，输入监控端点 （http://localhost:9007/actuator/hystrix.stream）展示监控的详细数据。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608870836984-58fc9be6-f3f9-4f72-b875-67f40d6dc309.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_55%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=VuuU1&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1040&amp;originWidth=1920&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## 3.3 **断路器聚合监控Turbine** ### 3**.3.1 概述** - 在微服务架构体系中，每个服务都需要配置Hystrix DashBoard监控。如果每次只能查看单个实例的监控数据，就需要不断切换监控地址，这显然很不方便。要想看整个系统的Hystrix DashBoard数据就需要用到Hystrix Turbine。Turbine是一个聚合Hystrix监控数据的工具，它可以将所有相关微服务的Hystrix监控数据聚合到一起，方便使用，引入Turbine后，整个监控系统架构如下： ![](https://cdn.nlark.com/yuque/0/2020/jpeg/513185/1608870851970-a1dfeedb-9bdf-47c2-a43b-090c368cb6ae.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_43%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=tKGu3&amp;margin=%5Bobject%20Object%5D&amp;originHeight=687&amp;originWidth=1494&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ### 3.**3.2 搭建Turbine Server** - 创建一个工程，并引入相关jar包的Maven坐标： - 修改部分： ```xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>hystrix_turbine7004&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-turbine&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 配置多个微服务的hystrix监控。 在application.yml的配置文件中开启turbine并进行相关配置：```yamlserver:port: 7004 spring: application: name: service-turbine # 微服务的名称 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-turbine:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ turbine: 要监控的微服务列表，多个用,隔开 app-config: service-order cluster-name-expression: “‘default’” - 配置启动类： ```java package com.sunxiaping.turbine; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard; import org.springframework.cloud.netflix.turbine.EnableTurbine; @SpringBootApplication @EnableHystrixDashboard @EnableTurbine public class Turbine7004Application { public static void main(String[] args) { SpringApplication.run(Turbine7004Application.class, args); } } 浏览器访问http://localhost:7004/hystrix展示Hystrix DashBoard，并在URL的位置输入http://localhost:7004/turbine.stream，可能会出现如下的错误： 需要在SpringBoot中配置HystrixMetricsStreamServlet：```javapackage com.sunxiaping.config; import com.netflix.hystrix.contrib.metrics.eventstream.HystrixMetricsStreamServlet;import org.springframework.boot.web.servlet.ServletRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration; @Configurationpublic class SpringConfig { @Bean public ServletRegistrationBean getServlet() { HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(“/hystrix.stream”); registrationBean.setName(“HystrixMetricsStreamServlet”); return registrationBean; }} # 4. **断路器的状态** ## 4.**1 概述** - Hystrix正常启动的时候，断路器的状态是CLOSED状态（所有的请求都可以正常访问）。 - 默认情况下，当请求次数大于20次，且存在50%的失败概率的时候，将自动触发熔断，断路器的状态变为OPEN状态（所有的请求都会进入到降级方法中）。 - 默认情况下，会维持OPEN状态一段时间（5s），进入到半打开状态（尝试释放一个请求到远程微服务发起调用）。如果释放的请求可以正常访问，就会关闭断路器（断路器的状态由HALF_OPEN状态变为CLOSED状态）。如果释放的请求不能访问，则将状态由HALF_OPEN状态变为OPEN状态。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608870884037-66d1508b-7cd8-498a-97ea-761ad16d8eba.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_26%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=g8x0Z&amp;margin=%5Bobject%20Object%5D&amp;originHeight=499&amp;originWidth=909&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## 4**.2 测试断路器的工作状态** ### 4**.2.1 环境准备** 1. 在订单系统中加入如下的逻辑： - 判断请求的id，如果id=1，正常执行（正常调用微服务）。 - 判断请求的id，如果id!=1，抛出异常。 2. 默认Hystrix有断路器状态转化的阈值。 - 触发熔断的最小请求次数为20次。 - 触发熔断的请求失败比例为50%。 3. 断路器开启的时长为5秒。 ### 4.2.2 修改订单系统的逻辑 - OrderController.java ```java package com.sunxiaping.order.controller; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty; import com.sunxiaping.order.domain.Product; import com.sunxiaping.order.feign.ProductFeignClient; import lombok.var; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController @RequestMapping(value = &quot;/order&quot;) public class OrderController { @Autowired private RestTemplate restTemplate; @Autowired private ProductFeignClient productFeignClient; @GetMapping(value = &quot;/buy/{id}&quot;) @HystrixCommand(fallbackMethod = &quot;orderFallback&quot;, commandProperties = { @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;3000&quot;), //默认的连接超时时间为1秒，如果1秒内没有返回数据，自动触发降级逻辑 }) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { if (1 != id) { throw new RuntimeException(&quot;服务器异常&quot;); } return restTemplate.getForObject(&quot;http://SERVICE-PRODUCT/product/findById/&quot; + id, Product.class); } public Product orderFallback(Long id) { var product = new Product(); product.setId(Long.MAX_VALUE); product.setProductName(&quot;******测试断路器的状态******&quot;); return product; } } 4**.2.3 修改Hystrix有断路器状态转化的阈值** 修改方式一：@HystrixCommand注解中配置```javapackage com.sunxiaping.order.controller; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty;import com.sunxiaping.order.domain.Product;import com.sunxiaping.order.feign.ProductFeignClient;import lombok.var;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate; @RestController@RequestMapping(value = “/order”)public class OrderController { @Autowired private RestTemplate restTemplate; @Autowired private ProductFeignClient productFeignClient; @GetMapping(value = &quot;/buy/{id}&quot;) @HystrixCommand(fallbackMethod = &quot;orderFallback&quot;, commandProperties = { @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;3000&quot;), //默认的连接超时时间为1秒，如果1秒内没有返回数据，自动触发降级逻辑 @HystrixProperty(name = &quot;circuitBreaker.enabled&quot;, value = &quot;true&quot;), //是否开启断路器 @HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;, value = &quot;5&quot;), //触发熔断的最小请求次数，默认为20/10秒 @HystrixProperty(name = &quot;circuitBreaker.sleepWindowInMilliseconds&quot;, value = &quot;10000&quot;), //熔断多少秒后去尝试请求，默认为10秒 @HystrixProperty(name = &quot;circuitBreaker.errorThresholdPercentage&quot;, value = &quot;50&quot;), //触发熔断的失败请求最小比例，默认为50% }) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { if (1 != id) { throw new RuntimeException(&quot;服务器异常&quot;); } return restTemplate.getForObject(&quot;http://SERVICE-PRODUCT/product/findById/&quot; + id, Product.class); } public Product orderFallback(Long id) { var product = new Product(); product.setId(Long.MAX_VALUE); product.setProductName(&quot;******测试断路器的状态******&quot;); return product; } } - 修改方式二：修改application.yml ```yaml hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 3000 # 默认的连接超时时间为1秒，如果1秒没有返回数据，就自动触发降级逻辑 circuitBreaker: requestVolumeThreshold: 5 #触发熔断的最小请求次数，默认20/10秒 sleepWindowInMilliseconds: 10000 #熔断多少秒后去尝试请求，默认为10秒 errorThresholdPercentage: 50 #触发熔断的失败请求最小占比，默认50% 5. 断路器的隔离策略 微服务使用Hystrix熔断器实现了服务的自动降级，让微服务具备自我保护的能力，提升了系统的稳定性，也较好的解决了雪崩效应。其使用方式目前支持两种策略： 线程池隔离策略：使用一个线程池来存储当前的请求，线程池对请求进行处理，设置任务返回处理超时时间，堆积的请求入线程池队列。这种方式需要为每个依赖的服务申请线程池队列，有一定的资源消耗，好处是可以应对突发流量（流量洪峰来临时，处理不玩可以将数据存储到线程池队列慢慢处理）。 信号量隔离策略：使用一个原子计数器（或信号量）来记录当前有多少个线程在运行，请求过来先判断计数器的数值，如果超过设置的最大线程个数则丢弃该类型的新请求，如果不超过设置的最大线程个数则将计数器+1，请求返回计数器-1。这种方式是严格控制线程且立即返回模式，无法应对突发流量（流量洪峰来临时，处理的线程超过数量，其他的请求会直接返回，不继续去请求依赖的服务）。| |线程池隔离 | 信号量隔离 || — | — | — || 线程 | 与调用线程非相同线程 | 与调用线程相同（jetty线程） || 开销 | 排队、调度、上下文开销等 | 无线程切换，开销低 || 异步 | 可以是异步，也可以是同步。看调用的方法 | 同步调用，不支持异步 || 并发支持 | 支持（最大线程池大小hystrix.threadpool.default.maximumSize） | 支持（最大信号量上限maxConcurrentRequests） || 是否超时 | 支持，可直接返回 | 不支持，如果阻塞，只能通过调用协议（如：socket超时才能返回） || 是否支持熔断 | 支持，当线程池到达maxSize后，再请求会触发fallback接口进行熔断 | 支持，当信号量达到maxConcurrentRequests后。再请求会触发fallback || 隔离原理 | 每个服务单独用线程池 | 通过信号量的计数器 || 资源开销 | 大，大量线程的上下文切换，容易造成机器负载高 | 小，只是个计数器 | 可以通过在application.yml中配置隔离策略：hystrix: command: default: execution: isolation: strategy: ExecutionIsolationStrategy.SEMAPHORE # 信号量隔离 maxConcurrentRequests： 5000 # 最大信号量上限 # strategy: ExecutionIsolationStrategy.THREAD # 线程池隔离","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】服务调用Feign","slug":"springcloud/netflex/服务调用Feign","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1. 基于Feign的服务调用1**.1 导入Feign的相关jar包的Maven坐标** 修改部分: &lt;!-- 导入openFeign的依赖 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> 完整部分: &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>spring_cloud_demo&lt;/artifactId> &lt;groupId>org.sunxiaping&lt;/groupId> &lt;version>1.0&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>order-service-feign9005&lt;/artifactId> &lt;dependencies> &lt;!-- 导入openFeign的依赖 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 1**.2 在启动类上添加Feign的支持** 启动类:```javapackage com.sunxiaping.order; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication@EnableFeignClients //添加对Feign的支持,@EnableFeignClients注解开启SpringCloudFeign的支持功能public class Order9005Application { public static void main(String[] args) { SpringApplication.run(Order9005Application.class, args); }} ## 1**.3 配置调用接口** - ProductClientFeign.java ```java package com.sunxiaping.order.feign; import com.sunxiaping.order.domain.Product; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; /** * 声明需要调用的微服务名称 * * @FeignClient name： 服务提供者的名称 */ @FeignClient(name = &quot;service-product&quot;) public interface ProductFeignClient { /** * 配置需要调用的微服务的接口 * * @param id * @return */ @GetMapping(value = &quot;/product/findById/{id}&quot;) Product findById(@PathVariable(value = &quot;id&quot;) Long id); } 1**.4 通过配置调用的接口调用远程微服务** OrderController.java```javapackage com.sunxiaping.order.controller; import com.sunxiaping.order.domain.Product;import com.sunxiaping.order.feign.ProductFeignClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController; @RestController@RequestMapping(value = “/order”)public class OrderController { @Autowired private ProductFeignClient productFeignClient; @GetMapping(value = &quot;/buy/{id}&quot;) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { Product product = productFeignClient.findById(id); return product; } } ## 1**.5 测试** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608870381041-2cdc0026-838b-4747-9193-6cff136502b0.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_40%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=xdvbq&amp;margin=%5Bobject%20Object%5D&amp;originHeight=499&amp;originWidth=1416&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) # 2. **负载均衡** - Feign本身已经集成了Ribbon的依赖和自动配置，因此我们不需要额外的引入依赖，也不需要再注册RestTemplate对象。我们可以通过ribbon.xx来进行全局配置，或者通过服务名.ribbon.xx来对指定的服务配置。 - 启动两个商品微服务，并将其注册到Eureka中，重新测试可以返现使用Ribbon的轮询策略进行负载均衡。 ![](https://cdn.nlark.com/yuque/0/2020/gif/513185/1608870389326-c0300a63-6f52-4152-8a28-b7cb809ea2ad.gif#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=v2T1S&amp;margin=%5Bobject%20Object%5D&amp;originHeight=784&amp;originWidth=950&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) # 3. **Feign的配置** - 从Spring Cloud Edeware开始，Feign支持使用属性自定义。对于一个指定名称的Feign Client（例如该Feign Client的名称是feignName），Feign支持如下的配置项。 ```yaml # 配置Feign feign: client: config: feignName: # 自定义FeignClient的名称 connectTimeout: 5000 # 建立连接的超时时间 readTimeout: 5000 # 读取的超时时间 # 配置Feign的日志级别 loggerLevel: full # Feign的错误解码器，相当于代码配置方式中的ErrorDecoder errorDecoder: feign.codec.ErrorDecoder.Default # 配置重试 retryer: feign.Retryer.Default # 配置请求拦截器 requestInterceptors: - BasicAuthRequestInterceptor - BaseRequestInterceptor # 配置熔断不处理404异常 decode404: false 如果需要改变所有的Feign Client，可使用默认的feign名称创建配置属性： feign: client: config: default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic 4. 请求压缩 Spring Cloud Feign支持对请求和响应进行Gzip压缩，以减少通信过程中的性能损耗。通过下面的参数可以开启请求和响应的压缩功能。 # 配置Feign feign: compression: request: enabled: true # 开启请求压缩 response: enabled: true # 开启响应压缩 同时，我们也可以对请求的数据类型以及触发压缩大小的下限进行设置: # 配置Feign feign: compression: request: enabled: true # 开启请求压缩 min-request-size: 2048 # 设置触发压缩的大小下限 mime-types: text/html,application/xml,application/json #设置压缩的数据类型 response: enabled: true # 开启响应压缩 5. 日志级别 在开发或者运行阶段的时候往往希望看到Feign请求过程的日志记录，默认情况下Feign的日志是没有开启的。如果想要属性配置方式来达到日志效果，只需要在application.yml中添加如下的内容即可：```yaml 配置Feignfeign:client: config: default: # key 为default时表示的是全局配置 loggerLevel: debug service-product: # 自定义FeignClient的名称 # 配置Feign的日志级别 loggerLevel: full logging: level: com.sunxiaping.order.feign.ProductFeignClient: debug # Feign日志只会对日志级别为debug做出响应 - `logging.level.xxx: debug`：Feign日志只会对日志级别的debug做出响应。 - `feign.client.config.service-product.loggerLevel`：默认Feign的日志级别有四种。 - NONE（性能最佳，适用于生产）：不记录任何日志（默认值）。 - BASIC（适用于生产环境追踪问题）：仅记录请求方法、URL、响应状态码以及执行时间。 - HEADERS：记录BASIC级别的基础上，记录请求和响应的header。 - FULL（比较适用于开发和测试环境定位问题）：记录请求和响应的header、body和元数据。 - 也可以使用配置Bean的方式开启所有的日志功能： ```java @Configuration public class FeignConfiguration { @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; } }","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】负载均衡Ribbon基础（此版本不过时，后面的版本推荐使用Spring Cloud Loadbalancer）","slug":"springcloud/netflex/负载均衡Ribbon基础（此版本不过时，后面的版本推荐使用Spring Cloud Loadbalancer）","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"不论是基于Eureka的注册中心还是基于Consul的注册中心，SpringCloud的Ribbon统一进行了封装，所以对于服务的调用，两者的方式是一样的。 在使用Eureka作为注册中心的时候，不需要再导入Ribbon的相关依赖，因为Eureka内部集成了Ribbon了。 1. 实现服务调用 在创建RestTemplate的时候，声明@LoadBalanced注解。 使用RestTemplate调用远程微服务的时候，不需要自己手动拼接远程微服务的URL，只需要用远程微服务的服务名替换IP地址即可。 消费者微服务：在创建RestTemplate的时候，声明@LoadBalanced注解```javapackage com.sunxiaping.order.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate; @Configurationpublic class SpringConfig { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } } - 消费者微服务: 使用RestTemplate调用远程微服务的时候，不需要自己手动拼接远程微服务的URL，只需要用远程微服务的服务名替换IP地址即可 ```java package com.sunxiaping.order.controller; import com.sunxiaping.order.domain.Product; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController @RequestMapping(value = &quot;/order&quot;) public class OrderController { @Autowired private RestTemplate restTemplate; /** * SpringCloud提供的获取元数据的工具类 * 调用方法获取服务的元数据 */ @Autowired private DiscoveryClient discoveryClient; /** * 基于Ribbon的形式调用远程的微服务 * * @param id * @return */ @GetMapping(value = &quot;/buy/{id}&quot;) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { Product product = restTemplate.getForObject(&quot;http://service-product/product/findById/&quot; + id, Product.class); return product; } } 代码测试：在浏览器请求http://192.168.31.198:9002/order/buy/1，查看展示效果如下，已经可以在订单微服务中通过服务名称的形式调用商品微服务获取数据了。 2. 实现负载均衡2.1 搭建环境 准备两个商品微服务（端口分别是9001和9011）让其注册到Eureka集群中。 商品微服务9001的application.yml：```yamlserver:port: 9001 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:9001 # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ - 商品微服务9011的application.yml： ```yaml server: port: 9011 # 微服务的端口号 spring: application: name: service-product # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: service-product:9011 # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ # 微服务info内容详细信息 info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ 商品微服务9001和9011的ProductController.java```javapackage com.sunxiaping.product.controller; import com.sunxiaping.product.domain.Product;import com.sunxiaping.product.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.*; @RestController@RequestMapping(value = “/product”)public class ProductController { @Autowired private ProductService productService; @Value(&quot;${server.port}&quot;) private String port; @Value(&quot;${spring.cloud.client.ip-address}&quot;) private String ip; @PostMapping(value = &quot;/save&quot;) public String save(@RequestBody Product product) { productService.save(product); return &quot;新增成功&quot;; } @GetMapping(value = &quot;/findById/{id}&quot;) public Product findById(@PathVariable(value = &quot;id&quot;) Long id) { Product product = productService.findById(id); product.setProductName(&quot;访问的地址是：&quot; + ip + &quot;:&quot; + port); return product; } } - 订单微服务的OrderController.java ```java package com.sunxiaping.order.controller; import com.sunxiaping.order.domain.Product; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController @RequestMapping(value = &quot;/order&quot;) public class OrderController { @Autowired private RestTemplate restTemplate; /** * SpringCloud提供的获取元数据的工具类 * 调用方法获取服务的元数据 */ @Autowired private DiscoveryClient discoveryClient; /** * 基于Ribbon的形式调用远程的微服务 * * @param id * @return */ @GetMapping(value = &quot;/buy/{id}&quot;) public Product buy(@PathVariable(value = &quot;id&quot;) Long id) { Product product = restTemplate.getForObject(&quot;http://service-product/product/findById/&quot; + id, Product.class); return product; } } 启动Eureka服务集群，将商品微服务启动并注册到Eureka服务集群中，然后通过http://localhost:9002/order/buy/1查看控制台效果。 2.2 Ribbon内置的负载均衡策略2.2.1 Ribbon内置的负载均衡策略的概述 Ribbon内置了多种负载均衡策略，内部负责复杂均衡的顶层接口为com.netflix.loadbalancer.IRule，实现方式如下： com.netflix.loadbalancer.RoundRobinRule：以轮询的方式进行负载均衡。 com.netflix.loadbalancer.RandomRule：随机策略。 com.netflix.loadbalancer.RetryRule：重试策略。 com.netflix.loadbalancer.WeightedResponseTimeRule：权重策略。会计算每个服务的权重，权重越高的被调用的可能性会越大。 com.netflix.loadbalancer.BestAvailableRule：最佳策略。遍历所有的服务实例，过滤掉故障实例，并将请求数量最小的实例返回。 com.netflix.loadbalancer.AvailabilityFilteringRule：可用过滤策略。过滤掉故障和请求数超过阈值的服务实例，再从剩下的实例中轮询调用。 2.2.2 Ribbon内置的负载均衡策略的使用一 在服务消费者的application.yml中修改负载均衡策略： # 修改ribbon的负载均衡策略 服务名 - ribbon - NFLoadBalancerRuleClassName ：负载均衡策略 service-product: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 修改ribbon的负载均衡策略为权重策略 消息者完整的application.yml：```yamlserver:port: 9002 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置Eurekaeureka: instance: # 实例的名称 instance-id: service-order:9002 # 显示IP信息 prefer-ip-address: true lease-renewal-interval-in-seconds: 5 # 发送心跳续约间隔（默认30秒） lease-expiration-duration-in-seconds: 10 # Eureka Client发送心跳给Eureka Server端后，续约到期时间（默认90秒） client: healthcheck: enabled: true service-url: # Eureka Server的地址 # defaultZone: http://localhost:9000/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 修改ribbon的负载均衡策略 服务名 - ribbon - NFLoadBalancerRuleClassName ：负载均衡策略service-product: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 修改ribbon的负载均衡策略为权重策略 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ ![](https://cdn.nlark.com/yuque/0/2020/gif/513185/1608870114773-5a6bdc95-e593-4480-9a99-1a0b97902a57.gif#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=PhMgJ&amp;margin=%5Bobject%20Object%5D&amp;originHeight=799&amp;originWidth=951&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ### **2.2.3 Ribbon内置的负载均衡策略的使用二** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608870127282-0f811585-887b-46bb-b87f-0215caae60b9.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_32%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=em4NM&amp;margin=%5Bobject%20Object%5D&amp;originHeight=625&amp;originWidth=1130&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 在启动类扫描不到的地方新建一个自定义的Rule配置类（比如启动类的包名是com.sunxiaping.order，而自定义Rule配置类的包名是com.sunxiaping.ribbon.rule）。 ```java package com.sunxiaping.ribbon.rule; import com.netflix.loadbalancer.IRule; import com.netflix.loadbalancer.RandomRule; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class SelfRule { /** * 替换Ribbon内置的负载均衡策略 * * @return */ @Bean public IRule iRule() { return new RandomRule(); } } 在启动类上标注@RibbonClient注解：```javapackage com.sunxiaping.order; import com.sunxiaping.ribbon.rule.SelfRule;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.netflix.ribbon.RibbonClient; @SpringBootApplication@EnableEurekaClient//在启动类上标注@RibbonClient注解，这样该微服务启动的时候就能去加载自定义的Ribbon配置类，从而使得配置生效@RibbonClient(name = “service-product”,configuration = SelfRule.class)public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); }} **2.2.4 Ribbon的策略选择** - 如果每个机器配置一样，建议不修改策略（推荐）。 - 如果部分机器配置强，则可以改为WeightedResponseTimeRule。 ## **2.3 请求重试机制** - 在实际生产环境中，Ribbon做客户端负载均衡的时候，Ribbon默认的负载均衡算法是轮询，一旦访问到的那台微服务提供者突然宕机了，此时就会出现404的情况，这时可以使用Ribbon的请求重试机制，Ribbon的请求重试机制基于Spring的retry（Spring的重试框架）。 - 使用： - 在微服务消费者导入spring-retry的Maven坐标： ```xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;/dependency&gt; 修改微服务消费者的application.yml： 修改部分： # Ribbon的重试机制 service-product: ribbon: # 修改ribbon的负载均衡策略 服务名 - ribbon - NFLoadBalancerRuleClassName ：负载均衡策略 # NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 修改ribbon的负载均衡策略为权重策略 # Ribbon的重试机制参数 ConnectTimeout: 250 # Ribbon的连接超时时间 ReadTimeout: 1000 # Ribbon的数据读取超时时间 OkToRetryOnAllOperations: true # 是否对所有操作都进行重试 MaxAutoRetriesNextServer: 2 # 切换实例的重试次数 MaxAutoRetries: 1 # 对当前实例的重试次数 完整部分:```yamlserver:port: 9002 # 微服务的端口号 spring: application: name: service-order # 微服务的名称 datasource: url: jdbc:mysql://192.168.1.57:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 jpa: generate-ddl: true show-sql: true open-in-view: true database: mysql 配置Eurekaeureka: instance: # 实例的名称 instance-id: service-order:9002 # 显示IP信息 prefer-ip-address: true lease-renewal-interval-in-seconds: 5 # 发送心跳续约间隔（默认30秒） lease-expiration-duration-in-seconds: 10 # Eureka Client发送心跳给Eureka Server端后，续约到期时间（默认90秒） client: healthcheck: enabled: true service-url: # Eureka Server的地址 # defaultZone: http://localhost:9000/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ Ribbon的重试机制service-product: ribbon: 修改ribbon的负载均衡策略 服务名 - ribbon - NFLoadBalancerRuleClassName ：负载均衡策略NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 修改ribbon的负载均衡策略为权重策略# Ribbon的重试机制参数 ConnectTimeout: 250 # Ribbon的连接超时时间 ReadTimeout: 1000 # Ribbon的数据读取超时时间 OkToRetryOnAllOperations: true # 是否对所有操作都进行重试 MaxAutoRetriesNextServer: 2 # 切换实例的重试次数 MaxAutoRetries: 1 # 对当前实例的重试次数 微服务info内容详细信息info: app.name: xxx company.name: xxx build.artifactId: $project.artifactId$ build.version: $project.version$ 开启日志debuglogging: level: root: debug","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】基于Nginx的网关实现","slug":"springcloud/网关/基于Nginx的网关实现","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1. Nginx介绍 Nginx是一个自由的、开源的、高性能的HTTP服务器和反向代理服务器，同时也是一个IMAP、POP3、SMTP代理服务器。 Nginx可以作为一个HTTP服务器进行网关的发布，同时Nginx也可以作为反向代理服务器实现负载均衡。 2. 正向代理和反向代理2.1 正向代理 正向代理：代理服务器代理客户端发出请求。 正向代理服务器是一个位于客户端和远程服务器之间的服务器，为了从远程服务器获取内容，客户端向代理服务器发送一个请求并且指定远程服务器，然后代理服务器向远程服务器转交请求并将获取的内容返回给客户端。 客户端必须要进行一些特别的设置才能使用正向代理（比如你需要自己搭建VPN服务器，或者买一些第三方的服务）。 2**.2 反向代理** 多个客户端给服务器发送请求，Nginx服务器收到请求之后，按照一定的规则分发给了后端的业务处理服务器进行处理。此时，请求的来源对于客户端是明确的，但是请求具体由那台服务器处理的并不明确，Nginx扮演的就是一个反向代理角色。客户端是无法感知代理的存在的，反向代理对外是透明的，访问者并不知道自己访问的是一个代理。因为客户端不需要任何配置就可以访问。 反向代理：代理的是服务端接收请求，主要用于服务器集群分布式部署的情况，反向代理隐藏了服务器的信息。 如果只是单纯的需要一个最基础的具备转发功能的网关，那么使用Nginx是一个不错的选择。 2.3 准备工作 准备商品微服务，单独请求地址：http://localhost:9004/。 准备订单微服务，单独请求地址：http://localhost:8003/。 准备Nginx软件。 2**.4 配置Nginx的请求转发** nginx.conf的修改部分:```propertieslocation /api-product{ proxy_pass http://localhost:9004/;} location /api-order{ proxy_pass http://localhost:8003/;} - nginx.conf的完整部分： ```properties #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; # &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; # &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } location /api-product{ proxy_pass http://localhost:9004/; } location /api-order{ proxy_pass http://localhost:8003/; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ /\\.ht { # deny all; #} } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} }","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】微服务网关Zuul（已过时）","slug":"springcloud/网关/微服务网关Zuul（已过时）","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1 Zuul简介 Zuul是Netflix开源的微服务网关，它可以和Eureka、Ribbon以及Hystrix等组件配合使用，Zuul组件的核心是一系列的过滤器，这些过滤器可以完成以下功能： 动态路由：动态将请求路由到不同后端集群。 压力测试：逐渐增加指向集群的流量，以了解性能。 负载分配：为每一种负载类型分配对应容量，并弃用超过限定值的请求。 静态响应处理：边缘位置进行响应，避免转发到内部集群。 身份认证和安全：识别每一个资源的验证要求，并拒绝那些不符合要求的请求。 SpringCloud对Zuul进行了整合和增强。 2 搭建Zuul网关服务器2.1 创建工程并导入相关依赖的Maven坐标 修改部分: &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-zuul&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 api_zuul_server7006 org.springframework.cloud spring-cloud-starter-netflix-zuul ``` ## **2.2 编写配置** 创建并配置application.yml：```yamlserver:port: 7006 spring: application: name: api-zuul-server ## **2.3 编写启动类** - 启动类: ```java package com.sunxiaping.zuul; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.zuul.EnableZuulProxy; @SpringBootApplication @EnableZuulProxy //开启Zuul网关功能 public class Zuul7006Application { public static void main(String[] args) { SpringApplication.run(Zuul7006Application.class, args); } } 3 Zuul中的路由转发3.1 概述 最直观的理解：“路由”是根据请求URL，将请求分配到对应的处理程序。 在微服务体系中，Zuul负责接收所有的请求。根据不同的URL匹配规则，将不同的请求转发到不同的微服务处理。 示例： 在application.yml中配置路由规则```yamlserver:port: 7006 spring: application: name: api-zuul-server 路由配置zuul: routes: # 以商品微服务为例 product-service: # 路由的id，随便写 path: /product-service/** # 这里是映射路径 url: http://localhost:9004 # 映射路径对应的实际URL地址 sensitiveHeaders: #默认zuul会屏蔽Cookie，Cookie不会传到下游服务器，这里设置为空则Cookie可以传递到下游的服务器 - 配置好Zuul路由之后启动服务，在浏览器中输入http://localhost:7006/product-service/product/findById/1，即可访问到商品微服务。 ## **3.2 面向服务的路由** ### **3.2.1 概述** - 微服务一般是由几十、上百个服务组成，对于一个URL请求，最终会确认一个服务实例来进行处理。如果对每个服务实例手动指定一个唯一的访问地址，然后根据URL去手动实现请求匹配，这样做显然不合理。 - Zuul支持和Eureka整合开发，根据serviceId自动的从注册中心获取服务地址并转发请求，这样做的好处不仅可以通过单个端点来访问应用的所有服务，而且在添加或移除服务实例的时候不用修改Zuul的路由配置。 ### **3.2.2 步骤** - 添加Eureka的依赖。 - 开启Eureka的客户端服务发现。 - 在Zuul网关服务中配置Eureka注册中心的相关配置。 - 修改路由中的映射配置。 ### **3.2.3 应用示例** - 添加Eureka的依赖： ```xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 开启Eureka的客户端服务发现：```javapackage com.sunxiaping.zuul; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.netflix.zuul.EnableZuulProxy; @SpringBootApplication@EnableZuulProxy //开启Zuul网关功能@EnableEurekaClient //开启Eureka的客户端服务发现public class Zuul7006Application { public static void main(String[] args) { SpringApplication.run(Zuul7006Application.class, args); }} - 在Zuul网关服务中配置Eureka注册中心的相关配置（application.yml）： ```yaml # 配置 eureka eureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-zuul-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 修改路由中的映射配置（application.yml）： # 路由配置 zuul: routes: # 以商品微服务为例 product-service: # 路由的id，随便写 path: /product-service/** # 这里是映射路径 serviceId: service-product # 配置转发的微服务名称 sensitiveHeaders: #默认zuul会屏蔽Cookie，Cookie不会传到下游服务器，这里设置为空则Cookie可以传递到下游的服务器 完整的application.yml：```yamlserver:port: 7006 spring: application: name: api-zuul-server 路由配置zuul: routes: # 以商品微服务为例 product-service: # 路由的id，随便写 path: /product-service/** # 这里是映射路径 serviceId: service-product # 配置转发的微服务名称 sensitiveHeaders: #默认zuul会屏蔽Cookie，Cookie不会传到下游服务器，这里设置为空则Cookie可以传递到下游的服务器 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-zuul-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ ## **3.3 简化的路由配置** - 在上面的配置中，我们的规则是这样的： ```yaml # 路由配置 zuul: routes: # 以商品微服务为例 product-service: # 路由的id，随便写 path: /product-service/** # 这里是映射路径 serviceId: service-product # 配置转发的微服务名称 sensitiveHeaders: #默认zuul会屏蔽Cookie，Cookie不会传到下游服务器，这里设置为空则Cookie可以传递到下游的服务器 使用zuul.routes.&lt;route&gt;.path=/xxx/**：来指定映射路径。是自定义的路由名。 使用zuul.routes.&lt;route&gt;.serviceId=xxx：来指定服务名。 但是绝大多数情况下，我们的&lt;route&gt;路由名往往和服务名是一样的。因此Zuul就提供了一种简化配置语法：zuul.routes.&lt;serviceId&gt;=path。 上面的配置可以简化： # 路由配置 zuul: routes: # 以商品微服务为例 # product-service: # 路由的id，随便写 # path: /product-service/** # 这里是映射路径 # serviceId: service-product # 配置转发的微服务名称 # sensitiveHeaders: #默认zuul会屏蔽Cookie，Cookie不会传到下游服务器，这里设置为空则Cookie可以传递到下游的服务器 service-product: /product-service/** # 如果路由id和对应微服务的serviceId一致，就可以使用简化的路由配置 3.4 默认的路由规则 在使用Zuul的过程中，简化的路由配置已经大大简化了我们手动配置。但是当服务较多的时候，配置也是比较繁琐的，因此Zuul就 指定了默认的路由规则。 默认情况下，一切服务的映射路径就是服务名本身。比如：服务名是service-product，则默认的映射路径就是：/service-product/**。 # 路由配置 zuul: routes: # 以商品微服务为例 # product-service: # 路由的id，随便写 # path: /product-service/** # 这里是映射路径 # serviceId: service-product # 配置转发的微服务名称 # sensitiveHeaders: #默认zuul会屏蔽Cookie，Cookie不会传到下游服务器，这里设置为空则Cookie可以传递到下游的服务器 service-product: /product-service/** # 如果路由id和对应微服务的serviceId一致，就可以使用简化的路由配置 # zuul中的默认路由规则，如果当前的微服务名是service-order，那么对应的映射路径就是/service-order/** 4 Zuul加入后的架构 5 Zuul中的过滤器5.1 概述 根据前面的知识，我们知道Zuul包含了两个核心功能：对请求的路由和过滤。其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础；而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验、服务聚合等功能的基础。其实，路由功能在真正运行时，它的路由映射和请求转发同样也由不同的过滤器完成的。所以，过滤器可以说是Zuul实现API网关功能最为核心的部件，每一个进入Zuul的HTTP请求都会经过一系列的过滤器处理链得到请求响应并返回给客户端。 5.2 ZuulFilter简介 Zuul中的过滤器和我们之前使用的javax.servlet.Filter不一样，javax.servlet.Filter只有一种类型，可以通过配置urlPatterns来拦截对应的请求。而Zuul中的过滤器总共有4种类型，且每种类型都有对应的使用场景。 PRE：这种过滤器在请求被路由之前调用。我们可以利用这种过滤器实现身份验证、在救你中选择请求的微服务、记录调试信息等。 ROUTING：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用Apache的HttpClient或Netflix的Ribbon请求微服务。 POST：这种过滤器在路由到微服务以后执行。这种过滤器可以用来响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等等。 ERROR：在其他阶段发生错误时执行该过滤器。 Zuul提供了自定义过滤器的功能实现也十分简单，只需要编写一个类去实现Zuul提供的接口。```javapublic abstract class ZuulFilter implements IZuulFilter, Comparable { //返回字符串，代表过滤器的类型。包含4种：pre、routing、post、error abstract public String filterType(); //通过返回的int值来定义过滤器的执行顺序，数字越小优先级越高 abstract public int filterOrder(); //返回一个boolean值，判断该过滤器是否需要执行。返回true执行，返回false不执行。 boolean shouldFilter(); //来自IZuulFilter //过滤器的具体业务逻辑。 Object run() throws ZuulException; //来自IZuulFilter } ## **5.3 生命周期** ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871110345-0dbed9fe-432c-4106-93d8-5d3be4a41387.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_18%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=C2Bks&amp;margin=%5Bobject%20Object%5D&amp;originHeight=480&amp;originWidth=640&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 正常流程： - 请求到达首先会经过pre类型过滤器，而后到达routing类型，进行路由，请求就到达真正的服务提供者，执行请求，返回结果后，会到达post过滤器，而后返回响应。 - 异常流程： - 整个过程中，pre或routing过滤器出现异常，都会直接进入error过滤器，error过滤器处理完毕后，会将请求交给post过滤器，最后返回给用户。 - 如果error过滤器自己出现异常，最终也会进入post过滤器，而后返回。 - 如果是post过滤器出现异常，会跳转到error过滤器，但是和pre以及routing不同的是，请求不会再到达post过滤器了。 - 不同过滤器的场景： - 请求鉴权：一般放在pre类型，如果发现没有访问权限，直接就拦截了。 - 异常处理：一般会在error类型和post类型过滤器中结合处理。 - 服务调用时长统计：pre和post结合使用。 - 所有内置的过滤器列表： ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871116117-0b4ac35f-4414-4555-af6d-73880070c979.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_25%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=qrAF9&amp;margin=%5Bobject%20Object%5D&amp;originHeight=468&amp;originWidth=881&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## **5.4 自定义过滤器** - 需求：如果请求中有access-token参数，则认为请求有效，放行。 ```java package com.sunxiaping.zuul.filter; import com.netflix.zuul.ZuulFilter; import com.netflix.zuul.context.RequestContext; import com.netflix.zuul.exception.ZuulException; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; import javax.servlet.http.HttpServletRequest; /** * 自定义身份认证过滤器 * * @author 许大仙 * @version 1.0 * @since 2020-10-05 13:24 */ @Component public class LoginFilter extends ZuulFilter { /** * 用来定义过滤器类型 * pre、routing、post、error * * @return 过滤器类型 */ @Override public String filterType() { return &quot;pre&quot;; } /** * 指定过滤器的执行顺序，值越小，执行顺序越高 * * @return */ @Override public int filterOrder() { return 1; } /** * 当前过滤器是否生效 * * @return 如果是true，此过滤器生效。如果是false，此过滤器不生效。 */ @Override public boolean shouldFilter() { return true; } /** * 执行过滤器中的业务逻辑 * 身份认证： * ①所有的请求需要携带一个参数:access-token * ②获取request请求 * ③通过request请求对象获取access-token * ④判断token是否为空 * 如果token == null，身份验证失败 * 如果token != null，执行后续操作 * 在Zuul网关中，通过RequestContext的上下文对象，可以获取对象request对象。 * * @return * @throws ZuulException */ @Override public Object run() throws ZuulException { RequestContext currentContext = RequestContext.getCurrentContext(); HttpServletRequest request = currentContext.getRequest(); String token = request.getHeader(&quot;access-token&quot;); //如果token为空，身份认证失败 if (StringUtils.isEmpty(token)) { currentContext.setSendZuulResponse(false); //拦截请求 currentContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); //设置响应的状态码 } //如果token不为空，执行后续操作 return null; } } 6 Zuul网关存在的问题 在实际使用中我们会发现直接使用Zuul存在诸多问题，包括： 性能问题：Zuul 1.x版本本质上就是一个同步的Servlet，采用多线程阻塞的模型进行请求转发。简单的讲，每一个请求，Servlet容器要为该请求分配一个线程专门负责处理这个请求，直到响应返回客户端这个线程才会被释放返回容器线程池。如果后台服务调用比较耗时，那么这个线程就会被阻塞，阻塞期间线程资源被占用，不能干其他事情。我们知道Servlet容器线程池的大小是由限制的，当前端请求量大，而后台慢服务比较多的时候，很容易耗尽容器线程池内的线程，造成容器无法接收新的请求。 不支持任何长连接，如WebSockt。 7 Zuul网关的替换方案 Zuul 2.x版本：SpringCloud目前还没有整合Zuul 2.x版本。 SpringCloud Gateway。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】微服务网关Gateway","slug":"springcloud/网关/微服务网关Gateway","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"5、SpringCloud-Gateway.pdfSpringCloud-Alibaba+Gateway.pdf 1. 入门案例1.1 创建工程并导入依赖 修改部分:```xml org.springframework.cloud spring-cloud-starter-gateway ``` ## **1.2 配置启动类** 启动类:```javapackage com.sunxiaping.gateway; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; /** @author 许大仙 @version 1.0 @since 2020-10-05 19:22 /@SpringBootApplicationpublic class Gateway7007Application { public static void main(String[] args) { SpringApplication.run(Gateway7007Application.class, args); }}```1.3 编写配置文件 application.yml```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Path=/product/** &gt; 上面配置的意思是，配置了一个id为product-service的路由规则，当访问网关请求地址以product开头时，会自动转发到http://localhost:9004这个地址。启动项目后，如果访问的路径是http://localhost:7007/product/findById/1，就会自动转发到http://localhost:9004/product/findById/1这个地址。 # **2 路由规则** - Spring Cloud Gateway的功能很强大，上面我们只是使用了predicates进行了简单的条件匹配，其实Spring Cloud Gateway帮准我们内置了很多Predicates功能。在Spring Cloud Gateway中Spring利用Predicate的特性实现了各种路由匹配规则，有通过header、请求参数等不同的条件来作为条件匹配到对应的路由。 ![](https://cdn.nlark.com/yuque/0/2020/jpeg/513185/1608871210769-63a6ebe8-b15a-4d66-a9b0-f31b69a19e83.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_28%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_937%2Climit_0#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=BWgsa&amp;margin=%5Bobject%20Object%5D&amp;originHeight=488&amp;originWidth=937&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 示例：在某个时间之前允许转发 ```yaml spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Before=2020-11-11T00:00:00+08:00[Asia/Shanghai] # 在2020-11-11T00:00:00之前允许访问 示例：在某个时间之后允许转发 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - After=2020-11-11T00:00:00+08:00[Asia/Shanghai] # 在2020-11-11T00:00:00之后允许访问 示例：在某个时间段内允许转发 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Between=2018-11-11T00:00:00+08:00[Asia/Shanghai],2020-11-11T00:00:00+08:00[Asia/Shanghai] 示例：通过Cookie匹配 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） # 如果cookie的名称是abc，cookie的值是根据下面的正则表达式匹配 - Cookie=abc,admin # Cookie的name,正则表达式 示例：通过Header属性匹配 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Header=X-Request-Id, \\d+ # Header头名称，正则表达式 示例：通过Host匹配 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Host=**.jd.com # http://surveys.jd.com/和http://passport.jd.com/等都可以匹配 示例：通过请求方式匹配 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Method=GET #GET请求匹配 示例：根据请求路径匹配```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Path=/foo/{segment} # http://localhost:7007/foo/a等都可匹配 - 示例：根据请求参数匹配 ```yaml server: port: 7007 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Query=smile # http://localhost:7007?simle=abc，只要请求中包含smile参数即可 server: port: 7007 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - Query=smile,abc # http://localhost:7007?simle=abc,请求中包含smile参数且smile的参数值是abc 示例：根据请求的IP地址进行匹配```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id uri: http://localhost:9004 # 路由到微服务的uri predicates: # 断言（判断条件） - RemoteAddr=192.168.1.1/24 # 3. 动态路由 ## 3.1 概述 - 和Zuul网关类似，在Spring Cloud Gateway中也支持动态路由：即自动从注册中心获取服务列表并访问。 ## **3.2 配置动态路由** - 添加Eureka-client的依赖： - 修改部分： ```xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 api_gateway_server7007 org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client ``` 配置启动类：```javapackage com.sunxiaping.gateway; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient; /** @author 许大仙 @version 1.0 @since 2020-10-05 19:22 /@SpringBootApplication@EnableEurekaClientpublic class Gateway7007Application { public static void main(String[] args) { SpringApplication.run(Gateway7007Application.class, args); }}``` 编写配置文件：```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） - Path=/product/** 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-gateway-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ # **4. 重写转发路径** - 在Spring Cloud Gateway中，路由转发是直接将匹配的路由Path直接拼接到映射路径URI之后，那么在微服务开发中往往并不方便。这里可以使用RewritePath机制来进行路径重写。 - 示例： - 修改application.yml，将匹配路径改为`/product-service/**` ```yaml server: port: 7007 spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） # - Path=/product/** - Path:/product-service/** 重启网关，我们在浏览器中访问http://localhost:7007/product-service/product/findById/1，会抛出404。这是因为路由转发规则默认转发的路径是http://localhost:9004/product-service/product/findById/1，商品微服务中没有对应的路径。 修改application.yml，添加RewritePath重写转发规则。spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） # - Path=/product/** - Path=/product-service/** filters: # 配置路由过滤器 http://localhost:7007/product-service/product/findById/1 --> http://localhost:7007/product/findById/1 - RewritePath=/product-service/(?&lt;segment>.*), /$\\{segment} # 路径重写的过滤器 此时我们访问http://localhost:7007/product-service/product/findById/1，会自动转发到http://localhost:9004/product/findById/1。 5. 微服务名称转发 Spring Cloud Gateway支持根据微服务名称进行自动转发。只需要修改application.yml配置文件即可（需要和Eureka整合）。 示例： 修改部分: spring: application: name: api-gateway-server # 配置 Spring Cloud Gateway cloud: gateway: discovery: locator: enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 lower-case-service-id: true # 微服务名称以小写形式呈现 完整部分：```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: discovery: locator: enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 lower-case-service-id: true # 微服务名称以小写形式呈现 routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） # - Path=/product/** - Path=/product-service/** filters: # 配置路由过滤器 http://localhost:7007/product-service/product/findById/1 –&gt; http://localhost:7007/product/findById/1 - RewritePath=/product-service/(?.*), /${segment} # 路径重写的过滤器 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-gateway-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ logging: level: org.springframework.cloud.gateway: trace org.springframework.http.server.reactive: debug org.springframework.web.reactive: debug reactor.ipc.netty: debug # 6. **过滤器** ## 6**.1 概述** - Spring Cloud Gateway除了具备请求路由功能之外，也支持对请求的过滤。和Zuul网关类似，也是通过过滤器的形式来实现的。 ## 6**.2 过滤器基础** ### 6**.2.1 过滤器的生命周期** - Spring Cloud Gateway的Filter的生命周期不像Zuul那么丰富，只有两个：&quot;pre&quot;和&quot;post&quot;。 - PRE：这种过滤器在请求被路由之前调用。我们可以利用这种过滤器实现身份认证、在集群中选择请求的微服务、记录调试信息等。 - POST：这种过滤器在路由到微服务以后执行。这种过滤器可以用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等等。 ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871241830-9aa213d0-24d1-47ff-806f-2bef487c3e07.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_58%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_937%2Climit_0#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=K4aEG&amp;margin=%5Bobject%20Object%5D&amp;originHeight=720&amp;originWidth=937&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ### 6**.2.2 过滤器的类型** - Spring Cloud Gateway的Filter从作用范围可以分为两种：GatewayFilter和GlobalFilter。 - GatewayFilter：应用到当个路由或者一个分组的路由上。 - GlobalFilter：应用到所有的路由上。 ## 6**.3 局部过滤器** - 局部过滤器（GatewayFilter），是针对单个路由的过滤器。可以对访问的URL过滤，进行切面处理。在Spring Cloud Gateway中通过GatewayFilter的形式内置了很多不同类型的局部过滤器。 | 过滤器工厂 | 作用 | 参数 | | --- | --- | --- | | AddRequestHeader | 为原始请求添加Header | Header的名称及值 | | AddRequestParameter | 为原始请求添加请求参数 | 参数名称及值 | | AddResponseHeader | 为原始响应添加Header | Header的名称及值 | | DedupeResponseHeader | 剔除响应头中重复的值 | 需要去重的Header名 称及去重策略 | | Hystrix | 为路由引入Hystrix的断路器保护 | HystrixCommand的名 称 | | FallbackHeaders | 为fallbackUri的请求头中添加具 体的异常信息 | Header的名称 | | PrefixPath | 为原始请求路径添加前缀 | 前缀路径 | | PreserveHostHeader | 为请求添加一个 preserveHostHeader=true的属 性，路由过滤器会检查该属性以 决定是否要发送原始的Host | 无 | | RequestRateLimiter | 用于对请求限流，限流算法为令 牌桶 | keyResolver、 rateLimiter、 statusCode、 denyEmptyKey、 emptyKeyStatus | | RedirectTo | 将原始请求重定向到指定的URL | http状态码及重定向的 url | | RemoveHopByHopHeadersFilter | 为原始请求删除IETF组织规定的 一系列Header | 默认就会启用，可以通 过配置指定仅删除哪些 Header | | RemoveRequestHeader | 为原始请求删除某个Header | Header名称 | | RemoveResponseHeader | 为原始响应删除某个Header | Header名称 | | RewritePath | 重写原始的请求路径 | 原始路径正则表达式以 及重写后路径的正则表 达式 | | RewriteResponseHeader | 重写原始响应中的某个Header | Header名称，值的正 则表达式，重写后的值 | | SaveSession | 在转发请求之前，强制执行 WebSession::save操作 | 无 | | secureHeaders | 为原始响应添加一系列起安全作 用的响应头 | 无，支持修改这些安全 响应头的值 | | SetPath | 修改原始的请求路径 | 修改后的路径 | | SetResponseHeader | 修改原始响应中某个Header的值 | Header名称，修改后 的值 | | SetStatus | 修改原始响应的状态码 | HTTP 状态码，可以是 数字，也可以是字符串 | | StripPrefix | 用于截断原始请求的路径 | 使用数字表示要截断的 路径的数量 | | Retry | 针对不同的响应进行重试 | retries、statuses、 methods、series | | RequestSize | 设置允许接收最大请求包的大 小。如果请求包大小超过设置的 值，则返回 413 Payload Too Large | 请求包大小，单位为字 节，默认值为5M | | ModifyRequestBody | 在转发请求之前修改原始请求体内容 | 修改后的请求体内容 | | ModifyResponseBody | 修改原始响应体的内容 | 修改后的响应体内容 | &gt; 每个过滤器工厂都对应一个实体类，并且这些类的名称必须以GatewayFilterFactory结尾，这是Spring Cloud Gateway的一个约定，例如AddRequestHeader对一个的实体类为AddRequestHeaderGatewayFilterFactory。 ## 6**.4 全局过滤器** - 全局过滤器（GlobalFilter）作用于所有路由，Spring Cloud Gateway定义了Global Filter接口，用户可以自定义实现自己的Global Filter。通过全局过滤器可以实现对权限的统一校验，安全性校验等功能，并且全局过滤器也是程序员使用比较多的过滤器。 - Spring Cloud Gateway内部也是通过一些列的内置全局过滤器对整个路由转发进行处理，如下图所示： ![](https://cdn.nlark.com/yuque/0/2020/png/513185/1608871259871-abd0feec-dd53-4df1-9b1c-ae30093bf361.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_28%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=ACVRt&amp;margin=%5Bobject%20Object%5D&amp;originHeight=493&amp;originWidth=996&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) # 7. **统一鉴权** ## 7**.1 概述** - 内置的过滤器已经可以完成大部分的功能，但是对于企业开发的一些业务功能处理，还是需要我们自己去编写过滤器来实现的，那么我们通过代码的形式自定义一个过滤器，去完成统一的权限校验。 ## 7**.2 鉴权逻辑** - 开发中的鉴权逻辑： - 当客户端第一次请求服务的时候，服务端对用户进行信息认证（登录）。 - 认证通过，将用户信息进行加密形成token，返回给客户端，作为登录凭证。 - 以后每次请求，客户端都携带认证的token。 - 服务daunt对token进行解密，判断是否有效。 ![](https://cdn.nlark.com/yuque/0/2020/jpeg/513185/1608871273694-5d96cbf1-f63e-44f4-996b-a6e137d04b9a.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_32%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=ZAPbT&amp;margin=%5Bobject%20Object%5D&amp;originHeight=718&amp;originWidth=1114&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 如上图所示，对于验证用户是否已经登录授权的过程可以在网关层统一校验。校验的标准就是请求中是否携带token凭证以及token的正确性。 ## 7**.3 代码实现** - LoginFilter.java ```java package com.sunxiaping.gateway.filter; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.Ordered; import org.springframework.http.HttpStatus; import org.springframework.http.server.reactive.ServerHttpRequest; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; /** * 自定义全局过滤器 * * @author 许大仙 * @version 1.0 * @since 2020-10-06 20:24 */ @Component public class LoginFilter implements GlobalFilter, Ordered { /** * 执行过滤器中的业务逻辑 * 对请求参数中的access-token进行判断，如果存在，则代表认证成功，否则，认证失败。 * * @param exchange 相当于请求和响应的上下文对象 * @param chain * @return */ @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { ServerHttpRequest request = exchange.getRequest(); String token = request.getHeaders().getFirst(&quot;access-token&quot;); if (StringUtils.isEmpty(token)) { //设置Http的状态码 exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); //请求结束 return exchange.getResponse().setComplete(); } //如果存在，继续执行 return chain.filter(exchange); } /** * 指定过滤器的执行顺序，返回值越小，优先级越高 * * @return */ @Override public int getOrder() { return 1; } } 8. 网关限流8**.1 常见的限流算法**8**.1.1 计数器** 计数器限流算法是最简单的一种限流实现方式。 其本质是通过维护一个单位时间内的计数器，每次请求计数器+1，当单位时间内计数器累加到大于设定的阈值，则之后的请求都被拒绝，直到单位时间已经过去，再将计数器重置为零。 8**.1.2 漏桶算法(适合秒杀,整点打卡等高并发场景,讲究的是容量,高并发时会丢弃较少的请求)** 漏桶算法可以很好的限制容量池的大小，从而防止流量暴增。 漏桶可以看作是一个带有常量服务时间的单服务器队列，如果漏桶（包缓存）溢出，那么数据包会被丢弃。 在网络中，漏桶算法可以控制端口的流量输出速率，平滑网络上的突发流量，实现流量整形，从而为网络提供一个稳定的流量。 为了更好的控制流量，漏桶算法需要通过两个变量进行控制：一个是桶的大小，支持流量突发增加时可以存多少水(burst)，另一个是桶漏洞的大小(rate)。 8**.1.3 令牌桶算法(平衡速率是关键,高并发时会丢弃较多的请求)** 令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程序的突发调用。 在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择等待可用的令牌或者直接拒绝。放令牌这个动作是持续不断的进行，如果桶中令牌数量达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置QPS为100，那么限流器初始化完成1秒后，桶中就已经有100个令牌了，这时服务可能还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定速率执行。 8**.2 基于Filter的限流**8.2.1 概述 Spring Cloud Gateway官方就提供了基于令牌桶的限流支持。基于其内置的过滤器工厂org.springframework.cloud.gateway.filter.factory.RequestRateLimiterGatewayFilterFactory实现。在过滤器工厂中是通过Redis和Lua脚本结合的方式进行流量控制。 8**.2.2 准备工作** Redis 8**.2.3 导入Redis的reactive依赖** 修改部分: &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis-reactive&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 api_gateway_server7007 org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-actuator org.springframework.boot spring-boot-starter-data-redis-reactive ``` ### **8.2.4 修改配置文件** application.yml```yamlserver:port: 7007 spring: application: name: api-gateway-server ———-修改部分———— redis: host: 192.168.1.57 port: 6379 database: 1 ———-修改部分————配置 Spring Cloud Gateway cloud: gateway: discovery: locator: enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 lower-case-service-id: true # 微服务名称以小写形式呈现 routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） # - Path=/product/** - Path=/product-service/** filters: # 配置路由过滤器 # ———-修改部分———— - name: RequestRateLimiter # 使用的限流过滤器是Spring Cloud Gateway提供的 args: # 使用SpEL从容器中获取对象 key-resolver: ‘#{@pathKeyResolver}’ # 令牌桶每秒填充平均速率 redis-rate-limiter.replenishRate: 1 # 令牌桶的上限 redis-rate-limiter.burstCapacity: 3 # ———-修改部分———— - RewritePath=/product-service/(?.*), /${segment} # 路径重写的过滤器 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-gateway-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ ### 8**.2.5 配置Redis中key的解析器** - keyResolverConfig.java ```java package com.sunxiaping.gateway.config; import org.springframework.cloud.gateway.filter.ratelimit.KeyResolver; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import reactor.core.publisher.Mono; /** * 配置Redis中Key的解析器 * * @author 许大仙 * @version 1.0 * @since 2020-10-22 09:53 */ @Configuration public class KeyResolverConfig { /** * 基于请求路径的限流 * * @return */ //@Bean public KeyResolver pathKeyResolver() { return exchange -&gt; Mono.just(exchange.getRequest().getPath().toString()); } /** * 基于请求参数的限流 * 请求/abc?userId=1 * * @return */ //@Bean public KeyResolver useKeyResolver() { return exchange -&gt; Mono.just(exchange.getRequest().getQueryParams().getFirst(&quot;userId&quot;)); } /** * 基于请求IP地址的限流 * * @return */ @Bean public KeyResolver ipKeyResolver() { return exchange -&gt; Mono.just(exchange.getRequest().getHeaders().getFirst(&quot;x-Forwarded-For&quot;)); } } 8.2.6 总结 Spring Cloud Gateway目前提供的限流还是比较简单的，在实际开发中我们的限流策略会有很多种情况，比如：对不同接口的限流，被限流后的友好提示，这些可以通过自定义RedisRateLimiter来实现自己的限流策略。 8**.3 基于Sentinel的限流**8**.3.1 概述** Sentinel 支持对 Spring Cloud Gateway、Zuul 等主流的 API Gateway 进行限流。 8**.3.2 导入相关jar包的Maven坐标** 修改部分: &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-spring-cloud-gateway-adapter&lt;/artifactId> &lt;/dependency> 完整部分:```xml &lt;project xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; spring_cloud_demo org.sunxiaping 1.0 4.0.0 api_gateway_server7007 org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.boot spring-boot-starter-actuator com.alibaba.csp sentinel-spring-cloud-gateway-adapter ``` ### 8**.3.3 修改配置文件** application.yml```yamlserver:port: 7007 spring: application: name: api-gateway-server 配置 Spring Cloud Gateway cloud: gateway: discovery: locator: enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 lower-case-service-id: true # 微服务名称以小写形式呈现 routes: # 配置路由： 路由id，路由到微服务的uri,断言（判断条件） - id: product-service # 路由id # uri: http://localhost:9004 uri: lb://service-product # 路由到微服务的uri。 lb://xxx，lb代表从注册中心获取服务列表，xxx代表需要转发的微服务的名称 predicates: # 断言（判断条件） # - Path=/product/** - Path=/product-service/** filters: # 配置路由过滤器 - RewritePath=/product-service/(?.*), /${segment} # 路径重写的过滤器 配置 eurekaeureka: instance: # 主机名称:服务名称修改，其实就是向eureka server中注册的实例id instance-id: api-gateway-server:${server.port} # 显示IP信息 prefer-ip-address: true client: service-url: # 此处修改为 Eureka Server的集群地址 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ ### 8**.3.4 配置Sentinel限流** - GatewayConfig.java ```java package com.sunxiaping.gateway.config; import com.alibaba.csp.sentinel.adapter.gateway.common.SentinelGatewayConstants; import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiDefinition; import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiPathPredicateItem; import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiPredicateItem; import com.alibaba.csp.sentinel.adapter.gateway.common.api.GatewayApiDefinitionManager; import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayFlowRule; import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayRuleManager; import com.alibaba.csp.sentinel.adapter.gateway.sc.SentinelGatewayFilter; import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.BlockRequestHandler; import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.GatewayCallbackManager; import com.alibaba.csp.sentinel.adapter.gateway.sc.exception.SentinelGatewayBlockExceptionHandler; import org.springframework.beans.factory.ObjectProvider; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.Ordered; import org.springframework.core.annotation.Order; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.codec.ServerCodecConfigurer; import org.springframework.web.reactive.function.BodyInserters; import org.springframework.web.reactive.function.server.ServerResponse; import org.springframework.web.reactive.result.view.ViewResolver; import javax.annotation.PostConstruct; import java.util.*; /** * Sentinel限流的配置 */ @Configuration public class GatewayConfig { private final List&lt;ViewResolver&gt; viewResolvers; private final ServerCodecConfigurer serverCodecConfigurer; public GatewayConfig(ObjectProvider&lt;List&lt;ViewResolver&gt;&gt; viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer) { this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList); this.serverCodecConfigurer = serverCodecConfigurer; } /** * 配置限流的异常处理器:SentinelGatewayBlockExceptionHandler */ @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() { return new SentinelGatewayBlockExceptionHandler(this.viewResolvers, this.serverCodecConfigurer); } /** * 配置限流过滤器 */ @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public GlobalFilter sentinelGatewayFilter() { return new SentinelGatewayFilter(); } /** * 配置初始化的限流参数 * 用于指定资源的限流规则： * 1.资源名称（路由id） * 2.配置统计时间窗口 * 3.配置限流阈值 */ @PostConstruct public void initGatewayRules() { Set&lt;GatewayFlowRule&gt; rules = new HashSet&lt;&gt;(); rules.add(new GatewayFlowRule(&quot;product-service&quot;) //资源名称 .setCount(1) // 限流阈值 .setIntervalSec(1) // 统计时间窗口，单位是秒，默认是 1 秒 ); //配置自定义API分组 rules.add(new GatewayFlowRule(&quot;product_api&quot;).setCount(1).setIntervalSec(1)); rules.add(new GatewayFlowRule(&quot;order_api&quot;).setCount(1).setIntervalSec(1)); GatewayRuleManager.loadRules(rules); } /** * 自定义异常提示 */ @PostConstruct public void initBlockHandlers() { BlockRequestHandler blockRequestHandler = (serverWebExchange, throwable) -&gt; { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;code&quot;, &quot;001&quot;); map.put(&quot;message&quot;, &quot;对不起,接口限流了&quot;); return ServerResponse .status(HttpStatus.OK) .contentType(MediaType.APPLICATION_JSON) .body(BodyInserters.fromValue(map)); }; GatewayCallbackManager.setBlockHandler(blockRequestHandler); } /** * 自定义API限流分组 * 1.定义分组 * 2.对小组配置限流规则 */ @PostConstruct private void initCustomizedApis() { Set&lt;ApiDefinition&gt; definitions = new HashSet&lt;&gt;(); ApiDefinition api1 = new ApiDefinition(&quot;product_api&quot;) .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;() {{ this.add(new ApiPathPredicateItem().setPattern(\"/product-service/product/**\"). setMatchStrategy(SentinelGatewayConstants.URL_MATCH_STRATEGY_PREFIX)); }}); ApiDefinition api2 = new ApiDefinition(&quot;order_api&quot;) .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;() {{ this.add(new ApiPathPredicateItem().setPattern(\"/order-service/order\")); }}); definitions.add(api1); definitions.add(api2); GatewayApiDefinitionManager.loadApiDefinitions(definitions); } } 9. 网关高可用 高可用HA是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。我们都知道，单点是系统高可用的大敌，单点往往是系统高可用的最大的风险和敌人，应该尽量在系统设计的过程中避免单点。 方法论上，高可用保证的原则是“集群化”，或者叫做“冗余”。只有一个单点，挂了服务会受影响；如果有冗余备份，挂了还有其他备份能够顶上。 我们实际使用Spring Cloud Gateway的方式如上图所示，不同的客户端使用不同的负载将请求分发到后端的Gateway，Gateway再通过HTTP调用后端服务，最后对外输出。因此为了保证Gateway的高可用性，前端可以同时启动多个Gateway实例进行负载，在Gateway的前端使用Nginx或者F5进行负载转发以达到高可用性。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】微服务链路追踪skywalking","slug":"springcloud/alibaba/微服务链路追踪skywalking","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1 Skywalking概述1.1 什么是APM系统？1.1.1 APM系统概述 APM（Application Performance Management）即应用性能管理系统，是对企业系统即时监控以实现对应用程序性能管理和故障管理的系统化的解决方案。应用性能管理，主要是指企业的关键业务进行监控、优化，提高企业应用的可靠性和质量，保证用户得到良好的服务，降低IT总的拥有成本。 APM系统是可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题。 1.1.2 分布式链路追踪 随着分布式系统和微服务架构的出现，一次用户的请求会经过多个系统，不同服务之间的调用关系十分复杂，任何一个系统的出错都可能影响整个请求的处理结果。以往的监控系统往往只能知道单个系统的健康状况、一次请求的成功和失败，无法快速定位失败的根本原因。 除此之外，复杂的分布式系统也面临这如下的问题： 性能分析：一个服务依赖很多服务，被依赖的服务也依赖了其他的服务。如果某个接口耗时突然很长，那未必是直接调用的下游服务慢了，也可能是下游的下游服务变慢造成的，如何快速快速定位耗时变长的根本原因？ 链路梳理：需求迭代很快，系统之间调用关系变化频繁，靠人工很难梳理出系统链路拓扑（系统之间的调用关系）。 为了解决这些问题，Google推出了一个分布式链路追踪系统Dapper，之后各个互联网公司都参照Dapper的思想推出了自己的分布式链路追踪系统，而这些系统就是分布式系统下的APM系统。 1.1.3 什么是OpenTracing？ 分布式链路追踪最先由Google在Dapper论文中提出的，而OpenTracing通过提供平台无关、厂商无关的API，使得开发人员能够方便的添加（或更换）追踪系统的实现。 下图是一个分布式调用的例子，客户端发起请求，请求首先到达负载均衡器，接着经过认证服务、订单服务，然后请求资源，最后返回结果。 虽然这种图对于看清各个组件的组合关系很有用，但是存在着如下的问题： 它不能很好的显示组件的调用时间，是串行调用还是并行调用，如果展现更复杂的调用关系，会更加复杂，甚至无法画出这样的图。 这种图也无法显示调用的时间间隔以及是否通过定时调用来启动调用。 一种有效的展现一个调用过程的图： 基于OpenTracing我们就可以很轻松的构建出如类似上面的图。 1.1.4 主流的开源APM产品 Pinpoint： Pinpoint是由一个韩国团队实现并开源，针对Java编写的大规模分布式系统设计，通过JavaAgent的机制做字节码的植入，实现加入tranceid和获取性能数据的目的，对应用代码零侵入。 官网： Skywalking： Skywalking是apache基金会下面的一个开源APM项目，为微服务架构和云原生架构系统设计。它通过探针自动收集所需的指标，并进行分布式追踪。通过这些调用链路以及指标，Skywalking APM会感知应用间的关系和服务间的关系，并进行相应的指标统计。 Skywalking支持链路追踪和监控应用组件基本涵盖主流框架和容器，如国产RPC Dubbo和motan等，国际化的SpringBoot、SpringCloud。 官网。 Zipkin： Zipkin是由Twitter开源，是分布式链路调用监控系统，聚合各业务系统调用延迟数据，达到链路调用监控跟踪。Zipkin基于Google的Dapper论文实现，主要完成数据的收集、存储、搜索和界面展示。 官网。 CAT： CAT是由大众点评开源的项目，基于Java开发的实时应用监控平台，包括实时应用监控、业务监控、可以提供几十张报表展示。 官网。1.2 什么是Skywalking？1.2.1 Skywalking概述 根据官方的解释，Skywalking是一个可观测分析平台（Observability Analysis Platform，简称OAP）和应用性能管理系统（Application Performance Management，简称APM）。 提供分布式链路追踪、服务网格（Service Mesh）遥测分析、度量（Metric）聚合和可视化一体化解决方案。 下面是Skywalking的几大特点： 多语言自动探针，Java、.NET、和NodeJS等。 多种监控手段、语言探针和Service Mesh。 轻量高效，不需要额外搭建大数据平台。 模块化架构，UI、存储、集群管理多种机制可选。 支持告警。 优秀的可视化效果。 Skywalking整体架构如下： Skywalking提供Tracing和Metric数据的获取和聚合。 Metric的特点是，它是可累加的：它们都是原子性的，每个都是一个逻辑计量单元，或者一个时间段内的柱状图。例如：队列的当前深度可以被定义为一个计量单元，在写入或读取时被更新统计；输入HTTP请求的数量可以被定义为一个计数器，用于简单累加；请求的执行时间可以被定义为一个柱状图，在指定的时间片上更新和统计汇总。Tracing的最大特点就是，它在单次请求的范围内，处理消息。任何的数据、元数据信息都被绑定到系统中的单个事务上。例如：一次调用远程服务的RPC执行过程，一次实际的SQL查询语句，一次HTTP请求的业务性ID。总结：Metric主要用来进行数据的统计，比如HTTP请求数的计算；Tracing主要包含了某一次请求的链路数据。 Skywalking的整体架构包含如下的三个组成部分： 探针（agent）：负责进行数据的收集，包含了Tracing和Metric的数据，agent会被安装到服务所在的服务器上，以方便数据的获取。 可观测性分析平台OAP：接收探针发送的数据，并在内存中使用分析引擎进行数据的整合运算，然后将数据存储到对应的存储介质上，比如ElasticSearch、MySQL数据库、H2数据库等，同时OAP还使用查询引擎提供HTTP查询接口。 Skywalking提供单独的UI进行数据的查看：此时UI会调用OAP提供的接口，获取对应的数据然后进行展示。1.2.2 Skywalking的优势 Skywalking相比较其他的分布式链路监控工具，具有以下的特点： 社区相当活跃。kywalking已经成为apache顶级项目，开发者是国人，可以直接和项目发起人交流进行问题的解决。 Skywalking支持Java、.NET和NodeJS语言。相对于其他平台，如Pinpoint支持Java和PHP，具有较大的优势。 探针无倾入性。对于CAT具有倾入性的探针，优势较大。不修改原有项目的一行代码就可以进行集成。 探针性能优秀。有网友对Pinpoint和Skywalking进行过测试，由于Pinpoint收集的数据过多，所以对性能损耗较大，而Skywalking探针性能十分出色。 支持组件较多。特别是对RPC框架的支持，这是其他框架所不具备的。Skywalking对Dubbo、gRpc等有原生的支持，甚至连小众的motan和sofarpc都支持。1.2.3 Skywalking的主要概念介绍 Skywalking的主要概念包括： 服务（Service）。 端点（Endpoint）。 实例（Instance）。 上图中，我们编写了用户服务，这是一个web项目，在生产中部署了两个节点：192.168.1.100和192.168.1.101。 用户服务就是Skywalking的服务（Service），用户服务其实就是一个独立的应用（Application），在6.0之后的Skywalking将应用更名为服务。 用户服务对外提供的HTTP接口就是一个端点，端点就是对外提供的接口。 192.168.1.100和192.168.1.101这两个相同服务部署的节点就是实例，实例指同一服务可以部署多个。 1.3 环境搭建1.3.1 概述及准备工作 我们在虚拟机中的CentOS7中搭建Skywalking的可观测性分析平台OAP环境。Skywalking默认使用H2内存数据库进行数据的存储，我们可以替换存储源为ElasticSearch保证其查询的高效和可用性。 本次使用的Skywalking的版本是8.3.0，下载地址 本次使用的ElasticSearch的版本是7.10.0，下载地址 网络不行，请点这里 创建skywalking目录： mkdir /usr/local/skywalking 建议将虚拟机内存设置为3G并且CPU设置为2核，防止资源不足。 进入skywalking目录，并下载Skywalking和ElasticSearch： cd /usr/local/skywalking wget https://ftp.wayne.edu/apache/skywalking/8.3.0/apache-skywalking-apm-es7-8.3.0.tar.gz wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.0-linux-x86_64.tar.gz 1.3.2 安装ElasticSearch 首先安装ElasticSearch，将压缩包解压： tar -zxvf elasticsearch-7.10.0-linux-x86_64.tar.gz 修改Linux系统的限制配置，将文件创建数改为65536个： vim /etc/security/limits.conf #新增如下内容在limits.conf文件中 es soft nofile 65536 es hard nofile 65536 es soft nproc 4096 es hard nproc 4096 修改系统中允许应用最多创建多少文件等的限制权限。Linux默认来说，一般限制应用最多创建的文件是65535个。但是ES最少需要65536的文件创建数的权限。 修改系统中允许用户启动的进程开启多少个线程。默认的Linux限制root用户开启的进程任意数量的线程，其他用户开启的进程最多1024个线程。必须修改限制树为4096+，因为ES至少需要4096的线程池预备。 修改系统控制权限，ElasticSearch需要开辟一个65536字节以上空间的虚拟内存。Linux默认不允许用户和应用程序直接开辟这么大的虚拟内存。 vim /etc/sysctl.conf #新增如下内容在sysctl.conf文件中，当前用户拥有的内存权限大小 vm.max_map_count=262144 vm.max_map_count=262144 #让系统控制权限配置生效 sysctl -p ES5之后不允许使用root用户启动，需要创建一个用户来启动ES： # 创建用户 useradd es # 修改上述用户的密码 passwd es # 修改es的目录的拥有者 chown -R es /usr/local/skywalking/elasticsearch-7.10.0 默认情况下，ES是不支持跨域访问的，所以需要修改ES的配置文件elasticsearch.yml，添加如下的参数： vim /usr/local/skywalking/elasticsearch-7.10.0/config/elasticsearch.yml node.name: node-1 cluster.initial_master_nodes: [\"node-1\"] network.host: 0.0.0.0 xpack.ml.enabled: false http.cors.enabled: true http.cors.allow-origin: /.*/ 启动ES: # 切换用户 su es cd /usr/local/skywalking/elasticsearch-7.10.0/bin # 后台启动 ./elasticsearch -d 测试: curl http://localhost:9200 1.3.3 安装Skywalking 安装Skywalking分为两个步骤： 安装Backend后端服务。 安装UI。 首先切回root用户，切换到skywalking目录下，解压skywalking： # 切换到root用户 su root # 切换到skywalking目录 cd /usr/local/skywalking # 解压skywalking tar -zxvf apache-skywalking-apm-es7-8.3.0.tar.gz 修改Skywalking的数据源配置： cd apache-skywalking-apm-bin-es7/config vim application.yml 我们可以发现默认是H2。 更改为ElasticSearch7： storage: selector: ${SW_STORAGE:elasticsearch7} elasticsearch7: nameSpace: ${SW_NAMESPACE:\"elasticsearch\"} 默认使用了localhost下的ES，所以我们不需要做任何处理，直接使用即可，启动OAP程序： cd /usr/local/skywalking/apache-skywalking-apm-bin-es7/bin ./oapService.sh 这样Backend后端服务就已经安装完毕了，接下来需要安装UI，先看下UI的配置文件： cd /usr/local/skywalking/apache-skywalking-apm-bin-es7/webapp cat webapp.yml 目前的默认配置不需要修改就可以使用，启动UI程序： cd /usr/local/skywalking/apache-skywalking-apm-bin-es7/bin ./webappService.sh 我们可以通过浏览器访问Skywalking的可视化页面，访问地址为：http://localhost:8080（假设虚拟机中CentOS7的IP是192.168.159.103，那么将lcoalhost改为192.168.159.103），如果出现下面的图，就代表安装成功了。 2 Skywalking基础2.1 agent的使用 agent探针可以让我们不修改代码的情况下，对Java应用上使用到的组件进行动态监控，获取运行数据发送到OAP上进行统计和存储。 agent探针在Java中是使用Java agent技术实现的，不需要更改任何代码，Java agent会通过虚拟机（JVM）接口来在运行期更改代码。 agent探针支持JDK1.6-12的版本，agent探针所有的文件在Skywalking的agent文件夹下，文件目录如下： 部分插件在使用上会影响整体的性能或者由于版权问题放置在可选插件包上，不会直接加载，如果需要使用，将可选插件中的jar包复制到plugins包下即可。 由于没有修改agent探针中的应用名，所以默认显示的是Your_ApplicationName，我们修改下应用名，让其显示更加准确。编辑agent的配置文件： cd /usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/config vim agent.config 找到如下的一行： agent.service_name=${SW_AGENT_NAME:Your_ApplicationName} 这里的配置含义是可以读取到SW_AGENT_NAME的配置属性，如果该属性没有指定，那么默认名称就是Your_ApplicationName。我们这里将Your_ApplicationName改为skywalking_boot。 2.2 Skywalking和Springboot的集成使用2.2.1 准备SpringBoot项目 pom.xml```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; 4.0.0 org.springframework.boot spring-boot-starter-parent 2.3.7.RELEASE com.example springboot2 1.0 springboot2 Demo project for Spring Boot 11 org.springframework.boot spring-boot-starter-web &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; org.springframework.boot spring-boot-maven-plugin ``` 启动类:```javapackage com.example.springboot2; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplicationpublic class Springboot2Application { public static void main(String[] args) { SpringApplication.run(Springboot2Application.class, args); } } - 业务类: ```java package com.example.springboot2.web; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * @author 许大仙 * @version 1.0 * @since 2021-01-12 09:18 */ @RestController public class HelloController { @RequestMapping(value = &quot;/hello&quot;) public String hello() { return &quot;你好啊&quot;; } @RequestMapping(value = &quot;/exception&quot;) public String exception(){ int i = 10 /0; return &quot;你怎么可以这个样子&quot;; } } 2.2.2 通过工具将SpringBoot项目打包，并上传至/usr/local/skywalking目录 略 2.2.3 使用命令启动SpringBoot项目 启动命令```shellcd /usr/local/skywalking java -javaagent:/usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar -Dserver.port=8082 -jar springboot2-1.0.jar &amp; &gt; - 使用jar包启动的项目如果需要集成Skywalking，需要添加-javaagent参数，参数值为agent的jar包的绝对路径。 &gt; - -Dserver.port参数用于指定端口号，防止和Skywalking端口冲突。 &gt; - 末尾添加&amp;后台运行模式启动SpringBoot项目。 ### **2.2.4 访问Skywalking的UI页面** - 通过访问http://192.168.159.103:8082/hello地址来进行访问，访问之后稍等片刻访问Skywalking的UI页面。 ![](https://cdn.nlark.com/yuque/0/2021/png/513185/1611193452922-6f798c98-6310-4bc1-b7d9-6396099c1467.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_54%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=onD2L&amp;margin=%5Bobject%20Object%5D&amp;originHeight=887&amp;originWidth=1887&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ## **2.3 Rocketbot的使用** ### **2.3.1 概述** - Skywalking的监控页面为Rocketbot，我们可以通过8080端口进行访问，由于8080端口很容易冲突，可以吸怪webapp/webapp.yaml来更改启动端口。 ```yaml server: port: 9010 # 修改为9010 我们修改为9010端口防止冲突。 2.3.2 仪表盘 2.3.3 拓扑图 Skywalking提供拓扑图，直观的查看服务之间的调用关系。 2.3.4 追踪 在Skywalking中，每一次用户发起一个请求，就可以视为一条追踪数据，每条追踪数据携带有一个ID值，追踪数据可以在追踪页面进行查询。 左侧是追踪列表，也可以通过上方的追踪ID来进行查询。点击追踪列表的某一条记录之后，右侧会显示出这条追踪的详细信息。有三种显示结果：列表、树结构和表格。 可以很好的展现这表追踪的调用链情况上的每个节点，可以通过左键点击节点，查看详细信息： 当前的接口是HTTP的GET请求，相对比较简单，如果出现异常情况或者数据库的访问，也会打印出异常信息、堆栈甚至详细的SQL语句。 2.3.5 告警 Skywalking中的告警功能相对比较简单，在到达告警阈值之后会生成一条告警记录，在告警页面上进行展示。 3 Skywalking高级3.1 MySQL调用监控3.1.1 前提条件 虚拟机中已经安装好了Docker（略）。 SpringBoot使用Spring Data JPA操作MySQL。 3.1.2 Docker命令启动MySQL Docker命令启动MySQL： docker run -id -p 3306:3306 --name mysql5.7 -v /var/mysql5.7/conf:/etc/mysql/conf.d -v /var/mysql5.7/logs:/logs -v /var/mysql5.7/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --restart=always mysql:5.7 --lower_case_table_names=1 3.1.3 sql脚本```sqlcreate database if not exists skywalking; DROP TABLE IF EXISTS user;CREATE TABLE user ( id int(11) NOT NULL AUTO_INCREMENT, name varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, PRIMARY KEY (id) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic; ```sql INSERT INTO `user` VALUES (1, &#39;张三&#39;); INSERT INTO `user` VALUES (2, &#39;李四&#39;); INSERT INTO `user` VALUES (3, &#39;王五&#39;); 3.1.4 Spring Data JPA访问MySQL 可以直接使用刚才创建的SpringBoot的项目，只需要导入MySQL和Spring Data JPA相关的依赖即可。 &lt;!-- 增加的依赖 --> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;scope>runtime&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-jpa&lt;/artifactId> &lt;/dependency> 在resources目录下新建application.yml文件： spring: # 配置数据源 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://192.168.159.103:3306/skywalking?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true&amp;nullCatalogMeansCurrent=true username: root password: 123456 # Hikari 连接池配置 hikari: # 最小空闲连接数量 minimum-idle: 5 # 空闲连接存活最大时间，默认600000（10分钟） idle-timeout: 180000 # 连接池最大连接数，默认是10 maximum-pool-size: 1000 # 此属性控制从池返回的连接的默认自动提交行为,默认值：true auto-commit: true # 连接池名称 pool-name: HikariCP # 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟 max-lifetime: 1800000 # 数据库连接超时时间,默认30秒，即30000 connection-timeout: 30000 connection-test-query: SELECT 1 data-source-properties: useInformationSchema: true 新建实体类：```javapackage com.example.springboot2.domain; import org.hibernate.annotations.DynamicInsert;import org.hibernate.annotations.DynamicUpdate; import javax.persistence.*;import java.io.Serializable;import java.util.Objects; /** @author 许大仙 @version 1.0 @since 2021-01-20 14:55 /@Entity@Table(name = “user“)@DynamicInsert@DynamicUpdatepublic class User implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; private String name; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; User user = (User) o; return Objects.equals(id, user.id) &amp;&amp; Objects.equals(name, user.name); } @Override public int hashCode() { return Objects.hash(id, name); } @Override public String toString() { return &quot;User{&quot; + &quot;id=&quot; + id + &quot;, name=&#39;&quot; + name + &#39;\\&#39;&#39; + &#39;}&#39;; } }``` 新建Dao:```javapackage com.example.springboot2.dao; import com.example.springboot2.domain.User;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor; /** @author 许大仙 @version 1.0 @since 2021-01-20 14:58 /public interface UserRepository extends JpaRepository&lt;User, Integer&gt;, JpaSpecificationExecutor { } - 新建Service： ```java package com.example.springboot2.service; import com.example.springboot2.dao.UserRepository; import com.example.springboot2.domain.User; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import javax.transaction.Transactional; import java.util.List; /** * @author 许大仙 * @version 1.0 * @since 2021-01-20 15:01 */ @Service @Transactional public class UserService { @Autowired private UserRepository userRepository; /** * 查询所有用户信息 * * @return */ public List&lt;User&gt; findAll() { return userRepository.findAll(); } } 新建Controller：```javapackage com.example.springboot2.web; import com.example.springboot2.domain.User;import com.example.springboot2.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController; import java.util.List; /** @author 许大仙 @version 1.0 @since 2021-01-20 15:03 /@RestController@RequestMapping(value = “/user”)public class UserController { @Autowired private UserService userService; @RequestMapping(value = &quot;/findAll&quot;) public List&lt;User&gt; findAll(){ return userService.findAll(); } } ### **3.1.5 部署方式** - 将SpringBoot项目打包，上传到/usr/local/skywalking的目录中（略）。 - 切换到/usr/local/skywalking，启动SpringBoot： ```shell cd /usr/local/skywalking java -javaagent:/usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar -Dserver.port=8082 -jar springboot2-1.0.jar & 3.1.6 调用接口 访问的地址是：http://192.168.159.103:8082/user/findAll。 3.1.7 打开skywalking查看mysql调用的监控情况 数据库仪表盘： 拓扑图: 追踪: 点击MySQL的调用，可以看到详细的SQL语句。 这样就可以很好的定位问题产生的原因，特别是在某些SQL语句执行慢的情况下。 3.2 配置覆盖3.2.1 概述 我们每次部署应用都需要到agent中修改服务名，如果部署多个应用，那么只能复制agent以便产生隔离，但是这样非常麻烦。我们可以用Skywalking提供的配置覆盖功能通过启动命令动态的指定服务名，这样agent就只需要部署一份即可。 Skywalking支持以下几种配置： 系统配置 探针配置 系统环境变量 配置文件中的值（上面的案例中我们就是这样使用）。3.2.2 系统配置（System Properties） 使用skywalking.+配置文件中的配置名作为系统配置项来进行覆盖。 例如：通过命令行启动的时候加上如下的参数可以进行agent.service_name的覆盖```shell Dskywalking.agent.service_name=skywalking_mysql``` 3.2.3 探针配置（Agent Options） 可以指定探针的时候加上参数，如果配置中包含分隔符（,或=），就必须使用引号（‘’）包裹起来。```shell javaagent:/usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar=[option]=[value],[option]=[value]``` 例如:```shell javaagent:/usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar=agent.service_name=skywalking_mysql``` 3.2.4 系统环境变量 案例： 由于agent.service_name配置项如下所示 agent.service_name=${SW_AGENT_NAME:Your_ApplicationName} 可以在环境变量中设置SW_AGENT_NAME的值来指定服务名。 3.2.5 覆盖的优先级 探针配置&gt;系统配置&gt;系统环境变量&gt;配置文件中的值。 简而言之，推荐使用探针方式或系统配置的方式。 3.3 获取追踪的ID3.3.1 概述 Skywalking提供了Trace工具包，用于在追踪链路的时候进行信息的打印或者获取对应的追踪ID。 3.3.2 应用示例 在pom.xml中增加Trace工具包的坐标： &lt;dependency> &lt;groupId>org.apache.skywalking&lt;/groupId> &lt;artifactId>apm-toolkit-trace&lt;/artifactId> &lt;version>8.3.0&lt;/version> &lt;/dependency> 修改Controller.java```javapackage com.example.springboot2.web; import org.apache.skywalking.apm.toolkit.trace.ActiveSpan;import org.apache.skywalking.apm.toolkit.trace.TraceContext;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController; /** @author 许大仙 @version 1.0 @since 2021-01-12 09:18 /@RestControllerpublic class HelloController { @RequestMapping(value = “/hello”) public String hello() { return &quot;你好啊&quot;; } /** TraceContext.traceId() 可以打印出当前追踪的ID，方便在Rocketbot中搜索 ActiveSpan提供了三个方法进行信息打印： error：会将本次调用转为失败状态，同时可以打印对应的堆栈信息和错误提示 info：打印info级别额信息 debug：打印debug级别的信息 @return /@RequestMapping(value = “/exception”)public String exception() { ActiveSpan.info(“打印info信息”); ActiveSpan.debug(“打印debug信息”); //使得当前的链路报错，并且提示报错信息 try { int i = 10 / 0; } catch (Exception e) { ActiveSpan.error(new RuntimeException(&quot;报错了&quot;)); //返回trace id return TraceContext.traceId(); } return “你怎么可以这个样子”;}}``` 将项目打包，部署，并使用如下的命令启动： java -javaagent:/usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar -Dserver.port=8082 -Dskywalking.agent.service_name=skywalking_mysql -jar springboot2-1.0.jar & 访问接口，获取追踪的ID： 可以看到追踪的ID已经打印出来了，此时我们在Rocketbot上进行搜索。 可以搜索到对应的追踪记录，但是显示调用是失败的，这是因为使用了ActiveSpan.error方法，点开追踪的详细信息。 3.4 过滤指定的端点3.4.1 概述 在开发的过程中，有一些端点（接口）并不需要去进行监控，比如Swagger相关的端点。这个时候我们使用Skywalking提供的过滤插件来进行过滤。 3.4.2 应用示例 在上面的SpringBoot项目中增加如下的控制器：```javapackage com.example.springboot2.web; import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController; /** @author 许大仙 @version 1.0 @since 2021-01-20 16:46 /@RestControllerpublic class FilterController { /** 此接口可以被追踪 @return /@GetMapping(value = “/include”)public String include() { return “include”;} /** 此接口不可以被追踪 @return /@GetMapping(value = “/exclude”)public String exclude() { return “exclude”;}}``` 将项目打包并上传到/usr/local/skywalking中。 将agent中的agent/optional-plugins/apm-trace-ignore-plugin-8.3.0.jar插件复制到plugins目录中。 cd /usr/local/skywalking/apache-skywalking-apm-bin-es7/agent cp optional-plugins/apm-trace-ignore-plugin-8.3.0.jar plugins/ 启动SpringBoot应用，并添加过滤参数。 java -javaagent:/usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar -Dserver.port=8082 -Dskywalking.agent.service_name=skywalking_mysql -Dskywalking.trace.ignore_path=/exclude -jar springboot2-1.0.jar & 这里添加-Dskywalking.trace.ignore_path参数来标识需要过滤那些请求，支持Ant Path表达式： /path/*，/path/**，/path/? ? 匹配任何单字符 *匹配0或者任意数量的字符 **匹配0或者更多的目录 调用接口，接口的地址为： http://192.168.159.103:8082/include。 http://192.168.159.103:8082/exclude。 会发现exclude接口已经被过滤了，只有include接口能被看到。 3.5 告警功能3.5.1 概述 Skywalking每隔一段时间根据收集到的链路追踪的数据和配置的告警规则（如服务响应时间、服务响应时间百分比）等，判断如果达到阈值则发送相应的告警信息。发送告警信息是通过调用webhook接口完成，具体的webhook接口可以由使用者自行定义，从而开发者可以在指定的webhook接口中编写各种告警方式，比如邮、短信等。告警的信息也可以在Rocketbot中查看到。 以下是默认的告警规则配置，位于Skywalking安装目录下的config文件下的alarm-settings.yml文件中。```yaml Sample alarm rules.rules: Rule unique name, must be ended with _rule.service_resp_time_rule: metrics-name: service_resp_time op: “&gt;” threshold: 1000 period: 10 count: 3 silence-period: 5 message: Response time of service {name} is more than 1000ms in 3 minutes of last 10 minutes.service_sla_rule: Metrics value need to be long, double or int metrics-name: service_sla op: “&lt;” threshold: 8000 The length of time to evaluate the metrics period: 10 How many times after the metrics match the condition, will trigger alarm count: 2 How many times of checks, the alarm keeps silence after alarm triggered, default as same as period. silence-period: 3 message: Successful rate of service {name} is lower than 80% in 2 minutes of last 10 minutesservice_resp_time_percentile_rule: Metrics value need to be long, double or int metrics-name: service_percentile op: “&gt;” threshold: 1000,1000,1000,1000,1000 period: 10 count: 3 silence-period: 5 message: Percentile response time of service {name} alarm in 3 minutes of last 10 minutes, due to more than one condition of p50 &gt; 1000, p75 &gt; 1000, p90 &gt; 1000, p95 &gt; 1000, p99 &gt; 1000service_instance_resp_time_rule: metrics-name: service_instance_resp_time op: “&gt;” threshold: 1000 period: 10 count: 2 silence-period: 5 message: Response time of service instance {name} is more than 1000ms in 2 minutes of last 10 minutesdatabase_access_resp_time_rule: metrics-name: database_access_resp_time threshold: 1000 op: “&gt;” period: 10 count: 2 message: Response time of database access {name} is more than 1000ms in 2 minutes of last 10 minutesendpoint_relation_resp_time_rule: metrics-name: endpoint_relation_resp_time threshold: 1000 op: “&gt;” period: 10 count: 2 message: Response time of endpoint relation {name} is more than 1000ms in 2 minutes of last 10 minutes Active endpoint related metrics alarm will cost more memory than service and service instance metrics alarm.Because the number of endpoint is much more than service and instance.endpoint_avg_rule:metrics-name: endpoint_avgop: “&gt;”threshold: 1000period: 10count: 2silence-period: 5message: Response time of endpoint {name} is more than 1000ms in 2 minutes of last 10 minutes webhooks: - http://127.0.0.1/notify/- http://127.0.0.1/go-wechat/ - 规则中的参数属性如下： | 属性 | 描述 | | --- | --- | | metrics-name | oal脚本中的度量名称 | | threshold | 阈值，与metrics-name和下面的比较符号相匹配，单位毫秒 | | op | 比较操作符，可以设定&gt;,&lt;,= | | period | 多久检查一次当前的指标数据是否符合告警规则，单位分钟 | | count | 达到多少次后，发送告警消息 | | silence-period | 在多久之内，忽略相同的告警消息，单位分钟 | | message | 告警消息内容 | | include-names | 本规则告警生效的服务列表 | - webhooks可以配置告警产生时的调用地址。 ### **3.5.2 告警功能测试** - 定义一个实体类用于封装接口告警信息： ```java package com.example.springboot2.domain; /** * @author 许大仙 * @version 1.0 * @since 2021-01-20 17:31 */ public class AlarmMessage { private Integer scopeId; private String name; private Integer id0; private Integer id1; private String alarmMessage; private long startTime; public Integer getScopeId() { return scopeId; } public void setScopeId(Integer scopeId) { this.scopeId = scopeId; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getId0() { return id0; } public void setId0(Integer id0) { this.id0 = id0; } public Integer getId1() { return id1; } public void setId1(Integer id1) { this.id1 = id1; } public String getAlarmMessage() { return alarmMessage; } public void setAlarmMessage(String alarmMessage) { this.alarmMessage = alarmMessage; } public long getStartTime() { return startTime; } public void setStartTime(long startTime) { this.startTime = startTime; } @Override public String toString() { return &quot;AlarmMessage{&quot; + &quot;scopeId=&quot; + scopeId + &quot;, name=&#39;&quot; + name + &#39;\\&#39;&#39; + &quot;, id0=&quot; + id0 + &quot;, id1=&quot; + id1 + &quot;, alarmMessage=&#39;&quot; + alarmMessage + &#39;\\&#39;&#39; + &quot;, startTime=&quot; + startTime + &#39;}&#39;; } } 定义告警Controller：```javapackage com.example.springboot2.web; import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController; /** 该接口主要用于模拟超时，多次调用之后就可以生成告警信息 @author 许大仙 @version 1.0 @since 2021-01-20 17:28 /@RestControllerpublic class AlarmController { /** 每次调用睡眠1.5秒，模拟超时的报警 @return /@GetMapping(value = “/timeout”)public String timeout() { try { Thread.sleep(1500); } catch (InterruptedException e) { e.printStackTrace(); } return “timeout”;} } - 定义WebHooks： ```java package com.example.springboot2.web; import com.example.springboot2.domain.AlarmMessage; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import java.util.ArrayList; import java.util.List; /** * 产生告警的时候会调用接口 * * @author 许大仙 * @version 1.0 * @since 2021-01-20 17:31 */ @RestController public class WebHooksController { private List&lt;AlarmMessage&gt; alarmMessageList = new ArrayList&lt;&gt;(); /** * 触发webhook * * @param alarmMessageList */ @PostMapping(value = &quot;/webhook&quot;) public void webhook(@RequestBody List&lt;AlarmMessage&gt; alarmMessageList) { this.alarmMessageList = alarmMessageList; } /** * 显示告警信息 * * @return */ @GetMapping(value = &quot;/show&quot;) public List&lt;AlarmMessage&gt; show() { return this.alarmMessageList; } } 3.5.3 部署测试 将项目打包并上传到/usr/local/skywalking中（略）。 修改告警规则配置文件，将webhook地址修改为： # 修改部分 webhooks: - http://127.0.0.1:8090/webhook # - http://127.0.0.1/go-wechat/ 重启Skywalking（略）。 启动SpringBoot应用： java -javaagent:/usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar -Dserver.port=8090 -Dskywalking.agent.service_name=skywalking_mysql -jar springboot2-1.0.jar & 不停的调用接口，接口地址为：http://192.168.159.103:8090/timeout。 直到出现告警。 查看告警信息： 从上图中可以看到，我们已经获取了告警相关的信息，在生产中使用可以在webhook接口中对接短信、邮件等平台，当告警出现的时候能迅速发送信息给对应的处理人员，提高故障处理的速度。 4 Skywalking的原理4.1 java agent的原理4.1.1 概述 我们知道，要使用Skywalking去监控服务，需要在其VM参数中添加“-javaagent:/usr/local/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar”，这里就使用到了java agent技术。 4.1.2 java agent是什么？ java agent是java命令的一个参数，参数javaagent可以用于指定一个jar包。 这个jar包的MANIFEST.MF文件必须指定Premain-Class项。 Premain-Class指定的那个类必须实现premain()方法。 当Java虚拟机启动时，在执行main函数之前，JVM会运行-javaagent所指定的jar包内Premain-Class这个类的premain方法。 4.1.3 如何使用java agent？ 定义一个MANIFEST.MF文件，必须包含Premain-Class选项，通常也会加入Can-Redefine-Classes和Can-Retransform-Classes选项。 创建一个Premain-Class指定的类，类中包含premain方法，方法逻辑由用户自己确定。 将premain类和MANIFEST.MF文件打成jar包。 使用参数-javaagent:jar包路径启动要代理的方法。 4.1.4 搭建java agent工程 使用Maven搭建java_agent总工程，其中java_agent_demo子工程是真正的逻辑实现，而java_agent_user子工程是测试。 在java_agent_demo的工程中引入maven-assembly-plugin插件，用于将java_agent_demo工程打成符合java agent标准的jar包： &lt;build> &lt;plugins> &lt;plugin> &lt;artifactId>maven-assembly-plugin&lt;/artifactId> &lt;configuration> &lt;appendAssemblyId>false&lt;/appendAssemblyId> &lt;descriptorRefs> &lt;descriptorRef>jar-with-dependencies&lt;/descriptorRef> &lt;/descriptorRefs> &lt;archive> &lt;!--自动添加META-INF/MANIFEST.MF --> &lt;manifest> &lt;addClasspath>true&lt;/addClasspath> &lt;/manifest> &lt;manifestEntries> &lt;Premain-Class>PreMainAgent&lt;/Premain-Class> &lt;Agent-Class>PreMainAgent&lt;/Agent-Class> &lt;Can-Redefine-Classes>true&lt;/Can-Redefine-Classes> &lt;Can-Retransform-Classes>true&lt;/Can-Retransform-Classes> &lt;/manifestEntries> &lt;/archive> &lt;/configuration> &lt;executions> &lt;execution> &lt;id>make-assembly&lt;/id> &lt;phase>package&lt;/phase> &lt;goals> &lt;goal>single&lt;/goal> &lt;/goals> &lt;/execution> &lt;/executions> &lt;/plugin> &lt;/plugins> &lt;/build> 在java_agent_demo工程创建PreMainAgent类。```javaimport java.lang.instrument.Instrumentation; public class PreMainAgent { /** * 在这个 premain 函数中，开发者可以进行对类的各种操作。 * 1、agentArgs 是 premain 函数得到的程序参数，随同 “– javaagent”一起传入。与 main 函数不同的是， * 这个参数是一个字符串而不是一个字符串数组，如果程序参数有多个，程序将自行解析这个字符串。 * 2、Inst 是一个 java.lang.instrument.Instrumentation 的实例，由 JVM 自动传入。* * java.lang.instrument.Instrumentation 是 instrument 包中定义的一个接口，也是这个包的核心部分， * 集中了其中几乎所有的功能方法，例如类定义的转换和操作等等。 * * @param agentArgs * @param inst */ public static void premain(String agentArgs, Instrumentation inst) { System.out.println(&quot;=========premain方法执行1========&quot;); System.out.println(agentArgs); } /** * 如果不存在 premain(String agentArgs, Instrumentation inst) * 则会执行 premain(String agentArgs) * * @param agentArgs */ public static void premain(String agentArgs) { System.out.println(&quot;=========premain方法执行2========&quot;); System.out.println(agentArgs); } } - 通过IDEA，进行打包。 ![](https://cdn.nlark.com/yuque/0/2021/png/513185/1611193683611-33d47471-e231-4caa-99a9-05ab64cf37bc.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_53%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fresize%2Cw_937%2Climit_0#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=oshv9&amp;margin=%5Bobject%20Object%5D&amp;originHeight=443&amp;originWidth=937&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - java_agent_user工程新建一个测试类。 ```java /** * @author 许大仙 * @version 1.0 * @since 2021-01-21 08:46 */ public class Main { public static void main(String[] args) { System.out.println(&quot;你好 世界&quot;); } } 先运行一次，然后点击编辑MAIN启动类： 在VM Options中添加代码：```shell javaagent:D:/project/java_agent/java_agent_demo/target/java_agent_demo-1.0.jar``` 启动的时候加载javaagent，指向java_agent_demo工程编译出来的javaagent的jar包地址。 4.1.5 统计方法的调用时间 Skywalking中对每个调用的时长都进行了统计，我们要使用ByteBuddy和java agent技术来统计方法的调用时长。 Byte Buddy是开源的、基于Apache2.0许可证的库，它致力于解决字节码操作和instrumentation API的复杂性。Byte Buddy所声称的目标是将显示的字节码操作隐藏在一个类型安全的领域特定语言背后，通过Byte Buddy，任何熟悉Java编程语言的人都有望非常容易的进行字节码的操作。Byte Buddy提供了额外的依赖API来生成java agent，可以轻松的增加我们已有的代码。 需要在java_agent_demo工程中添加如下的依赖： &lt;dependency> &lt;groupId>net.bytebuddy&lt;/groupId> &lt;artifactId>byte-buddy&lt;/artifactId> &lt;version>1.9.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>net.bytebuddy&lt;/groupId> &lt;artifactId>byte-buddy-agent&lt;/artifactId> &lt;version>1.9.2&lt;/version> &lt;/dependency> 新建一个MyInterceptor的类，用来统计调用的时长。```javaimport net.bytebuddy.implementation.bind.annotation.Origin;import net.bytebuddy.implementation.bind.annotation.RuntimeType;import net.bytebuddy.implementation.bind.annotation.SuperCall; import java.lang.reflect.Method;import java.util.concurrent.Callable; public class MyInterceptor { @RuntimeType public static Object intercept(@Origin Method method, @SuperCall Callable&lt;?&gt; callable) throws Exception { long start = System.currentTimeMillis(); try { //执行原方法 return callable.call(); } finally { //打印调用时长 System.out.println(method.getName() + “:” + (System.currentTimeMillis() - start) + “ms”); } }} - 修改PreMainAgent的代码： ```java import net.bytebuddy.agent.builder.AgentBuilder; import net.bytebuddy.description.method.MethodDescription; import net.bytebuddy.description.type.TypeDescription; import net.bytebuddy.dynamic.DynamicType; import net.bytebuddy.implementation.MethodDelegation; import net.bytebuddy.matcher.ElementMatchers; import net.bytebuddy.utility.JavaModule; import java.lang.instrument.Instrumentation; public class PreMainAgent { public static void premain(String agentArgs, Instrumentation inst) { //创建一个转换器，转换器可以修改类的实现 //ByteBuddy对java agent提供了转换器的实现，直接使用即可 AgentBuilder.Transformer transformer = new AgentBuilder.Transformer() { public DynamicType.Builder&lt;?&gt; transform(DynamicType.Builder&lt;?&gt; builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule javaModule) { return builder // 拦截任意方法 .method(ElementMatchers.&lt;MethodDescription&gt;any()) // 拦截到的方法委托给TimeInterceptor .intercept(MethodDelegation.to(MyInterceptor.class)); } }; new AgentBuilder // Byte Buddy专门有个AgentBuilder来处理Java Agent的场景 .Default() // 根据包名前缀拦截类 .type(ElementMatchers.nameStartsWith(&quot;com.agent&quot;)) // 拦截到的类由transformer处理 .transform(transformer) .installOn(inst); } } 对java_agent_demo工程重新打包。 将java_agent_user工程中的Main类方法com.agent包下，修改代码的内容为：```javapackage com.agent; /** @author 许大仙 @version 1.0 @since 2021-01-21 08:46 /public class Main { public static void main(String[] args) { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;你好 世界&quot;); }}``` 执行Main方法之后的显示结果为： 我们在没有修改代码的情况下，利用了java agent和Byte Buddy统计出了方法的时长，Skywalking的agent也是基于这些技术来实现统计时长的调用的。 4.2 Open Tracing介绍4.2.1 概述 Open Tracing通过提供平台无关、厂商无关的API，使得开发人员能够方便的添加（或更换）追踪系统的实现。Open Tracing最核心的概念就是Trace。 4.2.2 Trace 在广义上，一个trace代表了一个事务或者流程（在分布式）系统中的执行过程。在Open Tracing标准中，trace是多个span的一个有向无环图（DAG），每一个span代表trace中被命名并计时的连续性的执行片段。 例如客户端发起一次请求，就可以认为是一次Trace。将上面的图通过Open Tracing的语义修改完之后做可视化，得到下面的图： 图中的每一个色块其实就是一个span。 4.2.3 Span的概念 一个Span代表系统中具有开始时间和执行时长的逻辑运行单元。span之间通过嵌套或者顺序排列建立逻辑因果关系。 Span里面的信息包含：操作的名字，开始时间和结束时间，可以携带多个key:value构成的Tags（key必须是String，value可以是String、Boolean或者数字等），还可以携带Logs信息（不一定所有的实现都支持），也必须是key:value形式。 下面的例子是一个Trace，里面有8个Span： [Span A] ←←←(the root span) | +------+------+ | | [Span B] [Span C] ←←←(Span C 是 Span A 的孩子节点, ChildOf) | | [Span D] +---+-------+ | | [Span E] [Span F] >>> [Span G] >>> [Span H] ↑ ↑ ↑ (Span G 在 Span F 后被调用, FollowsFrom) 一个Span可以和一个或者多个Span间存在因果关系。Open Tracing定义了两种关系：ChildOf和FollowsFrom。这两种引用类型代表了子节点和父节点间的直接因果关系。未来，OpenTracing将支 持非因果关系的span引用关系。（例如：多个span被批量处理，span在同一个队列中，等等） ChildOf 很好理解，就是父亲 Span 依赖另一个孩子 Span。比如函数调用，被调者是调用者的孩子，比如说 RPC 调用，服务端那边的Span，就是 ChildOf 客户端的。很多并发的调用，然后将结果聚合起来的操作，就构成了 ChildOf 关系。 如果父亲 Span 并不依赖于孩子 Span 的返回结果，这时可以说它他构成 FollowsFrom 关系。 4.2.4 Log的概念 每个Span可以进行多次Logs操作，每一个Logs操作，都需要一个带时间戳的时间名称、以及可选的任意大小的存储结果。 如下图是一个异常的Log： 4.2.5 Tags的概念 每个Span可以有多个键值对（key:value）形式的Tags，Tags是没有时间戳的，支持简单的对Span进行注解和补充。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【springcloud】分布式事务Seata","slug":"springcloud/alibaba/分布式事务Seata","date":"2021-12-19T05:35:32.000Z","updated":"2022-07-06T14:46:33.312Z","comments":true,"path":"2021/1219[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1219[object%20Object].html","excerpt":"","text":"1 分布式事务基础1.1 事务 事务指的是一个操作单元，在这个操作单元中的所有操作最终要保持一致的行为，要么所有操作全部成功，要么所有操作全部被撤销。简而言之，事务提供一种“要么什么都不做，要么做全套”的机制。 1.2 本地事务 本地事务其实可以认为是数据库提供的事务机制，数据库事务中的四大特性： A：原子性（Atomicity），一个事务中的所有操作，要么全部成功，要么全部失败。 C：一致性（Consistency），在一个事务执行之前和执行之后数据库都必须处于一致性的状态。 I：隔离性（Isolation），在并发环境中，当不同的事务同时操作相同的数据时，事务之间互不影响。 D：持久性（Durability），指的是只要事务成功结束，它对数据库所做的更新就必须永久的保存下来。 数据库事务在实现的时候会将一次事务涉及到的所有操作全部纳入到一个不可分割的执行单元，该执行单元中的所有操作要么全部成功，要么全部事变，只要其中任一操作执行失败，都将导致整个事务的回滚。 1.3 分布式事务 分布式事务指的是事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。 简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。 本质上说，分布式事务就是为了保证不同数据库的数据一致性。 1.4 分布式事务的场景1.4.1 单体系统访问多个数据库 一个服务需要调用多个数据库实例完成数据的增删改操作。 1.4.2 多个微服务访问同一个数据库 多个微服务调用一个数据库实例完成数据的增删改操作。 1.4.3 多个微服务访问多个数据库 多个微服务访问多个数据库实例完成数据的增删改操作。 2 分布式事务解决方案2.1 全局事务（DTP模型） 全局事务基于DTP模式实现，DTP是由X/Open组织提出的一种分布式事务模型（X/Open Distributed Transaction Processing Reference Model）。它规定了要实现分布式事务，需要三种角色： AP：Application应用系统。 TM：Transaction Manager事务管理器。 RM：Resource Manager资源管理器。 整个事务分成两个阶段： 阶段一：表决阶段，所有参与者都将本事务执行预提交，并将能够成功的消息返回给协调者。 阶段二：执行阶段，协调者根据所有参与者的反馈，通知所有参与者，协调一致的执行提交或回滚。 优点：提高了数据一致性的概率，实现成本较低。 缺点： 单点问题：事务协调者宕机。 同步阻塞：延迟了提交时间，加长了资源阻塞时间。 数据不一致：提交第二阶段，依然存在commit结果未知的情况，有可能导致数据不一致。2.2 可靠消息服务 基于可靠消息服务的方案是通过消息中间件保证上、下游应用数据操作的一致性。假设有A和B两个系统，分别可以处理任务A和任务B，此时存在一个业务流程，需要将任务A和任务B在同一个事务中处理，就可以使用消息中间件来实现这种分布式事务。 第一步：消息由系统A投递到消息中间件。 在系统A处理任务A之前，首先向消息中间件发送一条消息。 消息中间件收到后将该条消息持久化，但不投递，持久化成功后，向A回复一个确认应答。 系统A收到确认应答后，则可以开始处理任务A。 任务A处理完成后，向消息中间件发送commit或者rollback的请求。该请求发送完成后，对系统A而言，该事务的处理过程就结束了。 如果消息中间件收到commit，则向B系统投递消息；如果收到rollback，则直接丢失消息。但是，如果消息中间件收不到commit或rollback的指令，那么就要依靠“超时询问机制”。 超时询问机制： 系统A除了实现正常的业务流程外，还需要提供一个事务询问的接口，供消息中间件调用。当消息中间件收到发布消息便开始计时，如果到了超时没收到确认指令，就会主动调用系统A提供的事务询问接口询问该系统目前的状态。 该接口会返回三种结果，中间件根据这三种结果做出不同的反应： 提交：将该消息投递给系统B。 回滚：直接将该消息丢弃。 处理中：继续等待。 第二步：消息中间件投递到系统B。 消息中间件向下游系统投递完消息后便进入阻塞等待的状态，下游系统便立即进行任务的处理，任务处理完成后便向消息中间件返回应答。 如果消息中间件收到确认应答后便认为该事务处理完毕。 如果消息中间件在等待确认应答超时之后就会重新投递，直到下游消费者返回消费成功响应为止。 一般消息中间件可以设置消息重试的次数和时间间隔，如果最终还是不能成功投递，则需要手动干预。之所以使用人工干预，而不是使用让A系统回滚，主要是考虑到整个系统设计的复杂度问题。 基于可靠消息服务的分布式事务，前半部分使用异步，注意性能；后半部分使用同步，注重开发成本。 2.3 最大努力通知 最大努力通知也被称为定期校对，其实是对第二种解决方案的进一步优化。它引入了本地消息表来记录错误消息，然后加入失败消息的定期校对功能，来进一步保证消息会被下游系统消费。 第一步：消息由系统A投递到消息中间件。 处理业务的同一事务中，向本地消息表中写入一条记录。 准备专门的消息发送者不断的发送本地消息表中的数据到消息中间件，如果发送失败则重试。 第二步：消息由消息中间件投递到系统B。 消息中间件收到消息后负责将该消息同步投递给相应的下游系统，并触发下游系统的任务执行。 当下游系统处理成功后，向消息中间件反馈确认应答，消息中间件便可以将该条消息删除，从而该事务完成。 对于投递失败的消息，利用重试机制进行重试，对于重试失败的，写入错误消息表。 消息中间件需要提供失败消息的查询接口，下游系统会定期查询失败消息，并将其消费。 优点：一种非常经典的实现，实现了最终一致性。 缺点：消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。 2.4 TCC事务 TCC即为Try Conﬁrm Cancel，它属于补偿型分布式事务。TCC实现分布式事务一共有三个步骤： Try：尝试待执行的业务：这个过程并未执行业务，只是完成所有业务的一致性检查，并预留好执行所需的全部资源 。 Conﬁrm：确认执行业务：确认执行业务操作，不做任何业务检查， 只使用Try阶段预留的业务资源。通常情况下，采用TCC 则认为 Conﬁrm阶段是不会出错的。即：只要Try成功，Conﬁrm一定成功。若Conﬁrm阶段真的 出错了，需引入重试机制或人工处理。 Cancel：取消待执行的业务：取消Try阶段预留的业务资源。通常情况下，采用TCC则认为Cancel阶段也是一定成功的。若 Cancel阶段真的出错了，需引入重试机制或人工处理。 TCC两阶段提交和XA两阶段提交的区别是： XA是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁。 TCC是业务层面的分布式事务，最终一致性，不会一直持有资源的锁。 优点：把数据库层的二阶段提交提高了应用层来实现，规避了数据库层的2PC性能低下的问题。 缺点：TCC的Try、Confirm和Cancel操作功能需要业务提供，开发成本高。 3 Seata（v 1.4.0）3.1 Seata介绍 2019年1月，阿里巴巴中间件团队发起了开源项目Fescar，其愿景是让分布式事务的使用像本地事务的使用一样，简单和高效，并逐步解决开发者遇到的分布式事务方面的所有难题，后来更名为Seata，是一套分布式事务的解决方案。 Seata的设计目标是对业务无侵入，因此从业务无侵入的2PC方案着手，在传统2PC的基础上演进，它把分布式事务理解成一个包含若干分支事务的全局事务，全局事务的职责是协调其管辖下的分支事务达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个关系数据库的本地事务。 Seata主要由三个重要组成组成： TC：Transaction Coordinator事务协调器，管理全局的分支事务的状态，用于全局性事务的提交和回滚。 TM：Transaction Manager事务管理器，用于开启全局、提交和回滚全局事务。 RM：Resource Manager资源管理器，用于分支事务上的资源管理，向TC注册分支事务，上报分支事务的状态，接受TC的命令以便提交或者回滚分支事务。 Seata的执行流程如下： A服务的TM向TC申请开启一个全局事务，TC就会创建一个全局事务并返回一个唯一的XID。 A服务的RM向TC注册分支事务，并将其纳入XID对应全局事务的管辖。 A服务执行分支事务，向数据库提交操作。 A服务开始远程调用B服务，此时XID会在微服务的调用链上传播。 B服务的RM注册分支事务，并将其纳入XID对应的全局事务的管辖。 B服务执行分支事务，向数据库提交操作。 全局事务调用链处理完毕，TM会根据有无异常向TC发起全局事务的提交或回滚。 TC协调其管辖之下的所有分支事务，决定是否回滚。 Seata实现2PC和传统2PC的差别： 架构层次方面，传统的2PC方案的RM实际上是在数据库层，RM本质上就是数据库本身，通过XA协议实现，而Seata的RM是以jar包的形式作为中间件层部署在应用程序这一层。 两阶段提交方面，传统2PC无论第二阶段的决议是commit还是rollback，事务性资源的锁都要保持到2Phase完成才释放，而Seata的做法是在1Phase就将本地事务提交，这样就省去了2Phase持锁的时间，整体提交了效率。3.2 Seata实现分布式事务控制 通过Seata中间件实现分布式事务，模拟电商中的下单和扣除库存的过程。 通过订单微服务执行下单操作，然后通过订单微服务调用商品微服务扣除库存。 3.3 准备环境3.3.1 数据库脚本 数据库脚本：```sqlCREATE DATABASE seata-order CHARACTER SET ‘utf8mb4’ COLLATE ‘utf8mb4_general_ci’; CREATE TABLE order_detail ( id int(11) NOT NULL AUTO_INCREMENT COMMENT ‘主键’, username varchar(255) DEFAULT NULL COMMENT ‘用户名’, product_id int(11) DEFAULT NULL COMMENT ‘商品的id’, number int(11) DEFAULT NULL COMMENT ‘数量’, product_name varchar(255) DEFAULT NULL COMMENT ‘商品的名称’, product_price decimal(10,2) DEFAULT NULL COMMENT ‘商品的价格’, PRIMARY KEY (id)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=’订单表’; CREATE DATABASE seata-product CHARACTER SET ‘utf8mb4’ COLLATE ‘utf8mb4_general_ci’; CREATE TABLE product ( id int(11) NOT NULL AUTO_INCREMENT COMMENT ‘主键’, name varchar(255) DEFAULT NULL COMMENT ‘名称’, num int(11) DEFAULT NULL COMMENT ‘库存’, PRIMARY KEY (id)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=’商品’; INSERT INTO product VALUES (1, ‘营养快线’, 5000);INSERT INTO product VALUES (2, ‘娃哈哈’, 5000);INSERT INTO product VALUES (3, ‘茅台’, 5000); ### 3.3.2 总工程的pom.xml - 总工程的pom.xml ```xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.xuweiwei&lt;/groupId&gt; &lt;artifactId&gt;seata&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;modules&gt; &lt;!-- 订单微服务 --&gt; &lt;module&gt;seata-order&lt;/module&gt; &lt;!-- 商品微服务 --&gt; &lt;module&gt;seata-product&lt;/module&gt; &lt;module&gt;seata-eureka&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt; &lt;maven-source.version&gt;1.8&lt;/maven-source.version&gt; &lt;maven-target.version&gt;1.8&lt;/maven-target.version&gt; &lt;spring-cloud-alibaba.version&gt;2.2.3.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;spring-cloud.version&gt;Hoxton.SR8&lt;/spring-cloud.version&gt; &lt;spring-boot.version&gt;2.3.2.RELEASE&lt;/spring-boot.version&gt; &lt;lombok.version&gt;1.18.16&lt;/lombok.version&gt; &lt;hutool-all.version&gt;5.5.1&lt;/hutool-all.version&gt; &lt;springfox-boot.version&gt;3.0.0&lt;/springfox-boot.version&gt; &lt;knife4j-boot.version&gt;3.0.2&lt;/knife4j-boot.version&gt; &lt;mapstruct.version&gt;1.4.1.Final&lt;/mapstruct.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;${lombok.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;${hutool-all.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Swagger --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;version&gt;${springfox-boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--整合Knife4j--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${knife4j-boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-jdk8&lt;/artifactId&gt; &lt;version&gt;${mapstruct.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct&lt;/artifactId&gt; &lt;version&gt;${mapstruct.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;${mapstruct.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;finalName&gt;${project.artifactId}&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 指定版本--&gt; &lt;configuration&gt; &lt;source&gt;${maven-source.version}&lt;/source&gt; &lt;target&gt;${maven-target.version}&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 3.3.3 商品微服务 pom.xml```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; seata com.xuweiwei 1.0 4.0.0 seata-product org.springframework.boot spring-boot-starter-web mysql mysql-connector-java org.springframework.boot spring-boot-starter-data-jpa org.springframework.cloud spring-cloud-starter-openfeign com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config ``` 启动类：```javapackage com.xuweiwei; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient; /** @author 许大仙 @version 1.0 @since 2021-02-07 09:37 /@EnableDiscoveryClient@SpringBootApplicationpublic class ProductApplication { public static void main(String[] args) { SpringApplication.run(ProductApplication.class, args); }}``` bootstrap.yml```yamlserver:port: 8001 spring: application: name: seata-order profiles: active: dev # 暂时没使用到 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata-order?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true&amp;nullCatalogMeansCurrent=true username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource # Hikari 连接池配置 hikari: # 最小空闲连接数量 minimum-idle: 5 # 空闲连接存活最大时间，默认600000（10分钟） idle-timeout: 180000 # 连接池最大连接数，默认是10 maximum-pool-size: 1000 # 此属性控制从池返回的连接的默认自动提交行为,默认值：true auto-commit: true # 连接池名称 pool-name: HikariCP # 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟 max-lifetime: 1800000 # 数据库连接超时时间,默认30秒，即30000 connection-timeout: 30000 connection-test-query: SELECT 1 data-source-properties: useInformationSchema: true cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 config: server-addr: 127.0.0.1:8848 # 配置中心的地址 file-extension: yml # 执行yaml格式的配置 JPA jpa: hibernate: ddl-auto: update # 第一次建表create 后面用update show-sql: true open-in-view: true devtools devtools: restart: # 热部署开关 enabled: true feign: 开启Feign对sentinel的支持 sentinel: enabled: true 客户端配置 client: config: default: connectTimeout: 3000 # 建立连接的超时时间 readTimeout: 5000 # 读取的超时时间 # 配置Feign的日志级别 loggerLevel: full # Feign的错误解码器，相当于代码配置方式中的ErrorDecoder errorDecoder: feign.codec.ErrorDecoder.Default # 配置重试 retryer: feign.Retryer.Default # 配置熔断不处理404异常 decode404: false 请求压缩 compression: request: # 开启请求压缩 enabled: true min-request-size: 2048 # 设置触发压缩的大小下限 mime-types: text/html,application/xml,application/json #设置压缩的数据类型 response: # 开启响应压缩 enabled: true - 实体类Product.java ```java package com.xuweiwei.biz.domain; import lombok.Getter; import lombok.Setter; import lombok.ToString; import javax.persistence.*; import java.io.Serializable; @Setter @Getter @ToString @Entity @Table(name = &quot;`product`&quot;) public class Product implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; @Column(name = &quot;name&quot;) private String name; @Column(name = &quot;num&quot;) private Integer num; } Dao层接口：```javapackage com.xuweiwei.biz.dao; import com.xuweiwei.biz.domain.Product;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor; /** @author 许大仙 @version 1.0 @since 2021-02-05 16:05 /public interface ProductRepository extends JpaRepository&lt;Product, Integer&gt;, JpaSpecificationExecutor { } - 业务层接口： ```java package com.xuweiwei.biz.service; import com.xuweiwei.biz.domain.Product; /** * @author 许大仙 * @version 1.0 * @since 2021-02-07 10:25 */ public interface ProductService { Product view(Integer id); void reduceInventory(Integer id, Integer num); } 业务层实现类：```javapackage com.xuweiwei.biz.service.impl; import com.xuweiwei.biz.dao.ProductRepository;import com.xuweiwei.biz.domain.Product;import com.xuweiwei.biz.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional; import java.util.Optional; /** @author 许大仙 @version 1.0 @since 2021-02-07 10:25 /@Service@Transactionalpublic class ProductServiceImpl implements ProductService { @Autowired private ProductRepository productRepository; @Override public Product view(Integer id) { return productRepository.findById(id).orElseGet(Product::new); } @Override public void reduceInventory(Integer id, Integer num) { Optional&lt;Product&gt; optional = productRepository.findById(id); if (optional.isPresent()) { Product product = optional.get(); int inventory = product.getNum() - num; product.setNum(inventory); productRepository.save(product); } }}``` 控制器ProductController.java```javapackage com.xuweiwei.biz.web; import com.xuweiwei.biz.domain.Product;import com.xuweiwei.biz.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*; /** @author 许大仙 @version 1.0 @since 2021-02-07 09:37 /@RestController@RequestMapping(value = “/product”)public class ProductController { @Autowired private ProductService productService; /** 查询商品信息 @param id @return /@GetMapping(value = “/view/{id}”)public Product view(@PathVariable(value = “id”) Integer id) { return productService.view(id);} /** 扣除库存 @param id @param num /@PostMapping(value = “/reduceInventory”)public void reduceInventory(@RequestParam(value = “id”) Integer id,@RequestParam(value = “num”) Integer num) { productService.reduceInventory(id,num);}}```3.3.4 订单微服务 pom.xml```xml &lt;project xmlns=”http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; seata com.xuweiwei 1.0 4.0.0 seata-order org.springframework.boot spring-boot-starter-web mysql mysql-connector-java org.springframework.boot spring-boot-starter-data-jpa org.springframework.cloud spring-cloud-starter-openfeign com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config ``` 启动类：```javapackage com.xuweiwei; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients; /** @author 许大仙 @version 1.0 @since 2021-02-07 09:51 /@EnableDiscoveryClient@SpringBootApplication@EnableFeignClientspublic class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); }}``` bootstrap.yml```yamlserver:port: 8002 spring: application: name: seata-product profiles: active: dev # 暂时没使用到 datasource: url: jdbc:mysql://127.0.0.1:3306/seata-product?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true&amp;nullCatalogMeansCurrent=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource # Hikari 连接池配置 hikari: # 最小空闲连接数量 minimum-idle: 5 # 空闲连接存活最大时间，默认600000（10分钟） idle-timeout: 180000 # 连接池最大连接数，默认是10 maximum-pool-size: 1000 # 此属性控制从池返回的连接的默认自动提交行为,默认值：true auto-commit: true # 连接池名称 pool-name: HikariCP # 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟 max-lifetime: 1800000 # 数据库连接超时时间,默认30秒，即30000 connection-timeout: 30000 connection-test-query: SELECT 1 data-source-properties: useInformationSchema: true cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 config: server-addr: 127.0.0.1:8848 # 配置中心的地址 file-extension: yml # 执行yaml格式的配置 JPA jpa: hibernate: ddl-auto: update # 第一次建表create 后面用update show-sql: true open-in-view: true devtools devtools: restart: # 热部署开关 enabled: true feign: 开启Feign对sentinel的支持 sentinel: enabled: true 客户端配置 client: config: default: connectTimeout: 3000 # 建立连接的超时时间 readTimeout: 5000 # 读取的超时时间 # 配置Feign的日志级别 loggerLevel: full # Feign的错误解码器，相当于代码配置方式中的ErrorDecoder errorDecoder: feign.codec.ErrorDecoder.Default # 配置重试 retryer: feign.Retryer.Default # 配置熔断不处理404异常 decode404: false 请求压缩 compression: request: # 开启请求压缩 enabled: true min-request-size: 2048 # 设置触发压缩的大小下限 mime-types: text/html,application/xml,application/json #设置压缩的数据类型 response: # 开启响应压缩 enabled: true - 实体类OrderDetail.java ```java package com.xuweiwei.biz.domain; import lombok.Getter; import lombok.Setter; import lombok.ToString; import javax.persistence.*; import java.io.Serializable; import java.math.BigDecimal; @Setter @Getter @ToString @Entity @Table(name=&quot;`order_detail`&quot;) public class OrderDetail implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; @Column(name = &quot;username&quot;) private String username; @Column(name = &quot;product_id&quot;) private Integer productId; @Column(name = &quot;number&quot;) private Integer number; @Column(name = &quot;product_name&quot;) private String productName; @Column(name = &quot;product_price&quot;) private BigDecimal productPrice; } Dao层接口：```javapackage com.xuweiwei.biz.dao; import com.xuweiwei.biz.domain.OrderDetail;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor; /** @author 许大仙 @version 1.0 @since 2021-02-05 16:05 /public interface OrderDetailRepository extends JpaRepository&lt;OrderDetail, Integer&gt;, JpaSpecificationExecutor {}``` 业务层接口：```javapackage com.xuweiwei.biz.service; import com.xuweiwei.biz.domain.OrderDetail; /** @author 许大仙 @version 1.0 @since 2021-02-07 10:10 /public interface OrderDetailService { /** 创建订单 @param pid @return /OrderDetail createOrder(Integer pid);}``` 业务层实现类：```javapackage com.xuweiwei.biz.service.impl; import cn.hutool.core.util.ObjectUtil;import cn.hutool.json.JSONUtil;import com.xuweiwei.api.ProductFeign;import com.xuweiwei.biz.dao.OrderDetailRepository;import com.xuweiwei.biz.domain.OrderDetail;import com.xuweiwei.biz.service.OrderDetailService;import com.xuweiwei.biz.utils.Product;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional; /** @author 许大仙 @version 1.0 @since 2021-02-07 10:10 /@Transactional@Service@Slf4jpublic class OrderDetailServiceImpl implements OrderDetailService { @Autowired private OrderDetailRepository orderDetailRepository; @Autowired private ProductFeign productFeign; @Override public OrderDetail createOrder(Integer pid) { Product product = productFeign.view(pid); log.info(&quot;查询到{}号商品的信息,内容是:{}&quot;, pid, JSONUtil.parseObj(product).toStringPretty()); if (ObjectUtil.isEmpty(product.getId())) { throw new RuntimeException(&quot;商品不存在&quot;); } //创建订单 OrderDetail orderDetail = new OrderDetail(); orderDetail.setUsername(&quot;测试用户&quot;); orderDetail.setProductId(pid); orderDetail.setNumber(1); orderDetail.setProductName(product.getName()); OrderDetail orderDetailDb = orderDetailRepository.save(orderDetail); log.info(&quot;创建订单成功,订单信息为{}&quot;, JSONUtil.parseObj(orderDetailDb).toStringPretty()); productFeign.reduceInventory(pid, orderDetail.getNumber()); return orderDetailDb; }}``` 数据传输对象：```javapackage com.xuweiwei.biz.utils; import lombok.Getter;import lombok.Setter; @Setter@Getterpublic class Product { private Integer id; private String name; private Integer num; } - 控制器OrderController.java ```java package com.xuweiwei.biz.web; import com.xuweiwei.biz.domain.OrderDetail; import com.xuweiwei.biz.service.OrderDetailService; import io.swagger.annotations.Api; import io.swagger.annotations.ApiOperation; import io.swagger.annotations.ApiParam; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * @author 许大仙 * @version 1.0 * @since 2021-02-07 09:51 */ @RestController @RequestMapping(value = &quot;/order&quot;) @Slf4j @Api(tags = &quot;订单&quot;) public class OrderController { @Autowired private OrderDetailService orderDetailService; @ApiOperation(value = &quot;新增订单&quot;, notes = &quot;新增订单&quot;, httpMethod = &quot;POST&quot;) @PostMapping(value = &quot;/order/buy/{pid}&quot;) public OrderDetail order(@PathVariable(&quot;pid&quot;) @ApiParam(value = &quot;pid&quot;, required = true) Integer pid) { log.info(&quot;接收到{}号商品的下单请求&quot;, pid); return orderDetailService.createOrder(pid); } } Swagger的配置类：```javapackage com.xuweiwei.biz.config; import com.github.xiaoymin.knife4j.spring.annotations.EnableKnife4j;import io.swagger.models.auth.In;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.builders.RequestParameterBuilder;import springfox.documentation.oas.annotations.EnableOpenApi;import springfox.documentation.service.*;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.contexts.SecurityContext;import springfox.documentation.spring.web.plugins.Docket; import java.util.Collections;import java.util.List; /** @author 许大仙 @version 1.0 @since 2020-11-17 10:56 /@Configuration@EnableOpenApi@EnableKnife4jpublic class SwaggerConfig { @Bean public Docket docket() { RequestParameter parameter = new RequestParameterBuilder() .name(&quot;Authorization&quot;) .description(&quot;请求头&quot;) .in(ParameterType.HEADER) .required(false) .build(); List&lt;RequestParameter&gt; parameters = Collections.singletonList(parameter); return new Docket(DocumentationType.OAS_30) .apiInfo(this.apiInfo()) .select() //指定扫描的包 .apis(RequestHandlerSelectors.basePackage(&quot;com.xuweiwei.biz.web&quot;)) .paths(PathSelectors.any()) .build() .globalRequestParameters(parameters) .securitySchemes(this.securitySchemes()) .securityContexts(this.securityContexts()) .enable(true); } /** 设置授权信息 /private List securitySchemes() { return Collections.singletonList(new ApiKey(“Authorization”, “token”, In.HEADER.toValue()));} /** 授权信息全局应用 /private List securityContexts() { return Collections.singletonList( SecurityContext.builder() .securityReferences(Collections.singletonList(new SecurityReference(&quot;Authorization&quot;, new AuthorizationScope[]{new AuthorizationScope(&quot;global&quot;, &quot;&quot;)}))) .build() );} private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(&quot;后端微服务架构&quot;) .description(&quot;订单微服务&quot;) .contact(new Contact(&quot;许大仙&quot;, &quot;&quot;, &quot;1900919313@qq.com&quot;)) .version(&quot;1.0&quot;) .build(); }}``` Feign接口：```javapackage com.xuweiwei.api; import com.xuweiwei.api.callback.ProductFeignCallBack;import com.xuweiwei.biz.utils.Product;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.stereotype.Component;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestParam; /** @author 许大仙 @version 1.0 @since 2021-02-07 10:11 /@Component@FeignClient(name = “seata-product”,fallback = ProductFeignCallBack.class)public interface ProductFeign { @GetMapping(value = “/product/view/{pid}”) Product view(@PathVariable(value = “pid”) Integer pid); @PostMapping(value = “/product/reduceInventory”) void reduceInventory(@RequestParam(value = “id”) Integer id,@RequestParam(value = “num”) Integer num);}``` Feign熔断处理类(暂时不会起作用，因为没有熔断组件)：```javapackage com.xuweiwei.api.callback; import com.xuweiwei.api.ProductFeign;import com.xuweiwei.biz.utils.Product;import org.springframework.stereotype.Component; /** @author 许大仙 @version 1.0 @since 2021-02-07 10:57 /@Componentpublic class ProductFeignCallBack implements ProductFeign { @Override public Product view(Integer pid) { return new Product(); } @Override public void reduceInventory(Integer id, Integer num) { }}``` 3.4 异常模式 在订单微服务的业务层实现类中模拟一个异常：商品微服务成功扣除库存，而订单微服务出现错误，引起本地事务回滚。```javapackage com.xuweiwei.biz.service.impl; import cn.hutool.core.util.ObjectUtil;import cn.hutool.json.JSONUtil;import com.xuweiwei.api.ProductFeign;import com.xuweiwei.biz.dao.OrderDetailRepository;import com.xuweiwei.biz.domain.OrderDetail;import com.xuweiwei.biz.service.OrderDetailService;import com.xuweiwei.biz.utils.Product;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional; /** @author 许大仙 @version 1.0 @since 2021-02-07 10:10 /@Transactional@Service@Slf4jpublic class OrderDetailServiceImpl implements OrderDetailService { @Autowired private OrderDetailRepository orderDetailRepository; @Autowired private ProductFeign productFeign; @Override public OrderDetail createOrder(Integer pid) { Product product = productFeign.view(pid); log.info(&quot;查询到{}号商品的信息,内容是:{}&quot;, pid, JSONUtil.parseObj(product).toStringPretty()); if (ObjectUtil.isEmpty(product.getId())) { throw new RuntimeException(&quot;商品不存在&quot;); } //创建订单 OrderDetail orderDetail = new OrderDetail(); orderDetail.setUsername(&quot;测试用户&quot;); orderDetail.setProductId(pid); orderDetail.setNumber(1); orderDetail.setProductName(product.getName()); OrderDetail orderDetailDb = orderDetailRepository.save(orderDetail); log.info(&quot;创建订单成功,订单信息为{}&quot;, JSONUtil.parseObj(orderDetailDb).toStringPretty()); productFeign.reduceInventory(pid, orderDetail.getNumber()); int i = 10 / 0; return orderDetailDb; }}``` 3.5 启动Seata3.5.1 Seata下载 Seata下载地址。 3.5.2 修改配置文件 将下载得到的压缩包进行解压，进入conf目录，修改下面的配置文件。 registry.conf```javaregistry { file 、nacos 、eureka、redis、zk、consul、etcd3、sofatype = “nacos”loadBalance = “RandomLoadBalance”loadBalanceVirtualNodes = 10 nacos { application = “seata-server” serverAddr = “127.0.0.1:8848” group = “SEATA_GROUP” namespace = “” cluster = “default” username = “nacos” password = “nacos”}} config { file、nacos 、apollo、zk、consul、etcd3 type = “nacos” nacos { serverAddr = “127.0.0.1:8848” namespace = “” group = “SEATA_GROUP” username = “nacos” password =”nacos” } } - 到GitHub的[Seata源码库](https://github.com/seata/seata/tree/develop/script/config-center)下载两个文件，`config.txt`和`nacos-config.sh`，其中`config.txt`复制到`seata`目录下，而`nacos-config.sh`复制到`seata/conf`目录下。 ![](https://cdn.nlark.com/yuque/0/2021/png/513185/1612732325240-2c665741-c7c4-498c-9520-8d3fbee1c196.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_23%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=vrnYY&amp;margin=%5Bobject%20Object%5D&amp;originHeight=336&amp;originWidth=822&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) ![](https://cdn.nlark.com/yuque/0/2021/png/513185/1612732333973-61041014-8a50-4aa1-b3b3-54d0e53f2d61.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_18%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;id=Lki9f&amp;margin=%5Bobject%20Object%5D&amp;originHeight=358&amp;originWidth=615&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=) - 修改config.txt： ```latex service.vgroupMapping.seata-product=default service.vgroupMapping.seata-order=default 语法为：service.vgroupMapping.定义的服务组名称=命名空间 3.5.3 初始化Seata到Nacos的配置 需要保证Nacos已经正常运行：cd conf nacos-config.sh 完整的命令：nacos-config.sh -h localhost -p 8848 -g SEATA_GROUP -t 命名空间的id - u nacos -w nacos 执行成功后，可以打开Nacos的控制台，在配置列表中，可以看到初始化了很多Group为SEATA_GROUP的配置。 3.5.4 启动Seata服务 启动Seata服务： cd bin seata-server.bat -p 8091 -m file 执行成功后，在Nacos的服务列表下面可以看到一个名为seata-server的服务。 3.6 使用Seata实现事务控制3.6.1 初始化数据库表 在我们的数据库中加入一张undo_log表，这是Seata记录事务日志要用到的表。 CREATE TABLE IF NOT EXISTS `undo_log` ( `branch_id` BIGINT(20) NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(100) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; 3.6.2 添加配置 在需要进行分布式控制的微服务中进行如下的配置。 添加依赖： &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-seata&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-config&lt;/artifactId> &lt;/dependency> 配置DataSourceProxyConfig：Seata是通过带来数据源实现事务控制的，所以需要配置io.seata.rm.datasource.DataSourceProxy的Bean，且是@Primary默认的数据源，否则事务不会回滚，无法实现分布式事务。```javapackage com.xuweiwei.biz.config; import com.zaxxer.hikari.HikariDataSource;import io.seata.rm.datasource.DataSourceProxy;import lombok.extern.slf4j.Slf4j;import org.springframework.boot.autoconfigure.jdbc.DataSourceProperties;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.jdbc.DataSourceBuilder;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary; import javax.sql.DataSource; /** @author 许大仙 @version 1.0 @since 2021-02-07 14:42 /@Configuration@Slf4jpublic class DataSourceProxyConfig { @Bean @ConfigurationProperties(prefix = “spring.datasource”) public DataSource dataSource(DataSourceProperties properties){ log.info(&quot;init data source：{}&quot;, properties); return DataSourceBuilder.create(properties.getClassLoader()) .type(HikariDataSource.class) .driverClassName(properties.determineDriverClassName()) .url(properties.determineUrl()) .username(properties.determineUsername()) .password(properties.determinePassword()) .build(); } @Bean @Primary public DataSourceProxy dataSourceProxy(DataSource dataSource){ return new DataSourceProxy(dataSource); } } - ![](https://gw.alipayobjects.com/os/lib/twemoji/11.2.0/2/svg/33-20e3.svg#crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;height=15&amp;id=BXsiI&amp;margin=%5Bobject%20Object%5D&amp;originHeight=150&amp;originWidth=150&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=&amp;width=15)修改bootstrap.yml文件： ```yaml # 修改部分 seata: enabled: true tx-service-group: ${spring.application.name} enable-auto-data-source-proxy: true config: type: nacos nacos: server-addr: ${spring.cloud.nacos.config.server-addr} group: SEATA_GROUP username: &quot;nacos&quot; password: &quot;nacos&quot; namespace: &quot;&quot; # 如果在nacos-config.sh将配置导入到Nacos中的时候加入了-t 参数，那么此处需要添加namespace的id registry: type: nacos nacos: application: seata-server server-addr: ${spring.cloud.nacos.config.server-addr} username: &quot;nacos&quot; password: &quot;nacos&quot; 完整的商品微服务的bootstrap.yml配置：```yamlserver:port: 8002 spring: application: name: seata-product profiles: active: dev # 暂时没使用到 datasource: url: jdbc:mysql://127.0.0.1:3306/seata-product?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true&amp;nullCatalogMeansCurrent=true driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource # Hikari 连接池配置 hikari: # 最小空闲连接数量 minimum-idle: 5 # 空闲连接存活最大时间，默认600000（10分钟） idle-timeout: 180000 # 连接池最大连接数，默认是10 maximum-pool-size: 1000 # 此属性控制从池返回的连接的默认自动提交行为,默认值：true auto-commit: true # 连接池名称 pool-name: HikariCP # 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟 max-lifetime: 1800000 # 数据库连接超时时间,默认30秒，即30000 connection-timeout: 30000 connection-test-query: SELECT 1 data-source-properties: useInformationSchema: true cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 config: server-addr: 127.0.0.1:8848 # 配置中心的地址 file-extension: yml # 执行yaml格式的配置 JPA jpa: hibernate: ddl-auto: update # 第一次建表create 后面用update show-sql: true open-in-view: true devtools devtools: restart: # 热部署开关 enabled: true seata: enabled: true tx-service-group: ${spring.application.name} enable-auto-data-source-proxy: true config: type: nacos nacos: server-addr: ${spring.cloud.nacos.config.server-addr} group: SEATA_GROUP username: “nacos” password: “nacos” namespace: “” # 如果在nacos-config.sh将配置导入到Nacos中的时候加入了-t 参数，那么此处需要添加namespace的id registry: type: nacos nacos: application: seata-server server-addr: ${spring.cloud.nacos.config.server-addr} username: “nacos” password: “nacos” feign: 开启Feign对sentinel的支持 sentinel: enabled: true 客户端配置 client: config: default: connectTimeout: 3000 # 建立连接的超时时间 readTimeout: 5000 # 读取的超时时间 # 配置Feign的日志级别 loggerLevel: full # Feign的错误解码器，相当于代码配置方式中的ErrorDecoder errorDecoder: feign.codec.ErrorDecoder.Default # 配置重试 retryer: feign.Retryer.Default # 配置熔断不处理404异常 decode404: false 请求压缩 compression: request: # 开启请求压缩 enabled: true min-request-size: 2048 # 设置触发压缩的大小下限 mime-types: text/html,application/xml,application/json #设置压缩的数据类型 response: # 开启响应压缩 enabled: true - 完成的订单微服务的bootstrap.yml配置： ```yaml server: port: 8001 spring: application: name: seata-order profiles: active: dev # 暂时没使用到 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/seata-order?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true&amp;nullCatalogMeansCurrent=true username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource # Hikari 连接池配置 hikari: # 最小空闲连接数量 minimum-idle: 5 # 空闲连接存活最大时间，默认600000（10分钟） idle-timeout: 180000 # 连接池最大连接数，默认是10 maximum-pool-size: 1000 # 此属性控制从池返回的连接的默认自动提交行为,默认值：true auto-commit: true # 连接池名称 pool-name: HikariCP # 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟 max-lifetime: 1800000 # 数据库连接超时时间,默认30秒，即30000 connection-timeout: 30000 connection-test-query: SELECT 1 data-source-properties: useInformationSchema: true cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # 配置Nacos的地址 config: server-addr: 127.0.0.1:8848 # 配置中心的地址 file-extension: yml # 执行yaml格式的配置 # JPA jpa: hibernate: ddl-auto: update # 第一次建表create 后面用update show-sql: true open-in-view: true # devtools devtools: restart: # 热部署开关 enabled: true seata: enabled: true tx-service-group: ${spring.application.name} enable-auto-data-source-proxy: true config: type: nacos nacos: server-addr: ${spring.cloud.nacos.config.server-addr} group: SEATA_GROUP username: &quot;nacos&quot; password: &quot;nacos&quot; namespace: &quot;&quot; # 如果在nacos-config.sh将配置导入到Nacos中的时候加入了-t 参数，那么此处需要添加namespace的id registry: type: nacos nacos: application: seata-server server-addr: ${spring.cloud.nacos.config.server-addr} username: &quot;nacos&quot; password: &quot;nacos&quot; feign: # 开启Feign对sentinel的支持 sentinel: enabled: true # 客户端配置 client: config: default: connectTimeout: 3000 # 建立连接的超时时间 readTimeout: 5000 # 读取的超时时间 # 配置Feign的日志级别 loggerLevel: full # Feign的错误解码器，相当于代码配置方式中的ErrorDecoder errorDecoder: feign.codec.ErrorDecoder.Default # 配置重试 retryer: feign.Retryer.Default # 配置熔断不处理404异常 decode404: false # 请求压缩 compression: request: # 开启请求压缩 enabled: true min-request-size: 2048 # 设置触发压缩的大小下限 mime-types: text/html,application/xml,application/json #设置压缩的数据类型 response: # 开启响应压缩 enabled: true 3.6.3 在订单微服务中开启全局事务 在订单微服务中开启全局事务：```javapackage com.xuweiwei.biz.service.impl; import cn.hutool.core.util.ObjectUtil;import cn.hutool.json.JSONUtil;import com.xuweiwei.api.ProductFeign;import com.xuweiwei.biz.dao.OrderDetailRepository;import com.xuweiwei.biz.domain.OrderDetail;import com.xuweiwei.biz.service.OrderDetailService;import com.xuweiwei.biz.utils.Product;import io.seata.spring.annotation.GlobalTransactional;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional; /** @author 许大仙 @version 1.0 @since 2021-02-07 10:10 /@Transactional@Service@Slf4jpublic class OrderDetailServiceImpl implements OrderDetailService { @Autowired private OrderDetailRepository orderDetailRepository; @Autowired private ProductFeign productFeign; @GlobalTransactional //开启全局事务控制 @Override public OrderDetail createOrder(Integer pid) { Product product = productFeign.view(pid); log.info(&quot;查询到{}号商品的信息,内容是:{}&quot;, pid, JSONUtil.parseObj(product).toStringPretty()); if (ObjectUtil.isEmpty(product.getId())) { throw new RuntimeException(&quot;商品不存在&quot;); } //创建订单 OrderDetail orderDetail = new OrderDetail(); orderDetail.setUsername(&quot;测试用户&quot;); orderDetail.setProductId(pid); orderDetail.setNumber(1); orderDetail.setProductName(product.getName()); OrderDetail orderDetailDb = orderDetailRepository.save(orderDetail); log.info(&quot;创建订单成功,订单信息为{}&quot;, JSONUtil.parseObj(orderDetailDb).toStringPretty()); productFeign.reduceInventory(pid, orderDetail.getNumber()); //模拟异常 int i = 10 / 0; return orderDetailDb; }}``` 3.7 Seata运行流程分析 要点说明： 1️⃣每个RM使用DataSourceProxy连接数据库，其目的是使用ConnectionProxy，使用数据源和数据连 接代理的目的就是在第一阶段将undo_log和业务数据放在一个本地事务提交，这样就保存了只要有业务 操作就一定有undo_log。 2️⃣在第一阶段undo_log中存放了数据修改前和修改后的值，为事务回滚作好准备，所以第一阶段完成 就已经将分支事务提交，也就释放了锁资源。 3️⃣TM开启全局事务开始，将XID全局事务id放在事务上下文中，通过feign调用也将XID传入下游分支 事务，每个分支事务将自己的Branch ID分支事务ID与XID关联。 4️⃣第二阶段全局事务提交，TC会通知各各分支参与者提交分支事务，在第一阶段就已经提交了分支事 务，这里各各参与者只需要删除undo_log即可，并且可以异步执行，第二阶段很快可以完成。 5️⃣第二阶段全局事务回滚，TC会通知各各分支参与者回滚分支事务，通过 XID 和 Branch ID 找到相应 的回滚日志，通过回滚日志生成反向的 SQL 并执行，以完成分支事务回滚到之前的状态，如果回滚失 败则会重试回滚操作。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"}],"author":"wst"},{"title":"【bug】在vue中使用axios请求数据  v-for渲染数据的时候结构没有出来的问题","slug":"bug/在vue中使用axios请求数据  v-for渲染数据的时候结构没有出来的问题","date":"2021-12-08T01:59:17.559Z","updated":"2022-03-18T09:13:25.801Z","comments":true,"path":"2021/120830546.html","link":"","permalink":"https://409713427.github.io/2021/120830546.html","excerpt":"","text":"在vue中使用axios请求数据 v-for渲染数据的时候结构没有出来的问题1.问题说明在使用axios向后台请求数据时，根据后台接口返回的数据，res.data.data 返回的是一个数组对象，并且将这个数组对象赋值给了在data定义的一个空数组，打印这个空数组，是真实存在的数据 res.data.data 使用v-for循环结构的时候，数据并没有出来以上都是常规操作，但是渲染的结构并没有出来 2.问题截图说明2.0.1 axios部分 没什么问题 正常打印 2.0.2 v-for部分 2.0.3 页面显示截图 数据能够正常打印 但是不挂载 3.问题分析3.1 我开始以为是this指向问题,但是我用的箭头函数应该会把this指向变成windows 3.2 然后看网上说可能是生命周期的问题,说是查询有延迟,但是初始化过早,所以数据不挂载,让加定时器什么的,由于本人vue目前只学习了基本用法,所以这种方法并没有尝试,后期会回来试一下 3.3 还有一部分人说我后台返回的是json格式,但是我前端定义的是数组,要用push,将数据push到数组当中,这个方案对于我这问题并没有什么用.但是其他人貌似有用这个办法解决的 4.解决办法在定义的空数组中加有个null, 最终页面也显示出来了,虽然解决了,但是具体什么原因还真不太清楚,等我弄明白再回来改QWQ","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"【bug】springboot+maven+多模块开发报错总结","slug":"bug/springboot+maven+多模块开发报错总结","date":"2021-11-18T08:37:15.942Z","updated":"2022-03-18T09:13:44.475Z","comments":true,"path":"2021/111845779.html","link":"","permalink":"https://409713427.github.io/2021/111845779.html","excerpt":"","text":"springboot+maven+多模块开发报错总结 1.找不到main 在我的父工程中build是这样的 &lt;build> &lt;plugins> &lt;plugin> &lt;!-- springboot打包方式 --> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;configuration> &lt;!-- &lt;skip>true&lt;/skip> 默认跳过单元测试--> &lt;excludes> &lt;exclude> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;/exclude> &lt;/excludes> &lt;/configuration> &lt;/plugin> &lt;/plugins> &lt;/build> 解决办法:只需要在父工程的build指定一下你的启动类在哪就行 &lt;configuration> &lt;mainClass>com.wst.ApiApplication&lt;/mainClass> &lt;/configuration> 2.找不到xxx.xxx.beans包 A项目依赖B项目，B项目中存在@service等注解，在本地eclipse中运行A项目时可以正常扫描B项目的注解创建对象。 但经过打包后，B项目和A项目的目录结构变成 +BOOT-INF +classes +lib +META-INF +org.springframework.boot.loader B项目本身又作为A项目BOOT-INF/lib下的jar包，A项目使用java -jar从入口启动类启动后无法扫描到B项目的注解， 且B项目中的lib也与A项目中的lib下jar包存在重复。 解决办法: 在父项目的pom中加入: &lt;configuration> &lt;classifier>exec&lt;/classifier> &lt;/configuration> spring-boot工程打包编译时，会生成两种jar包，一种是普通的jar，另一种是可执行jar。默认情况下，这两种jar的名称相同，在不做配置的情况下，普通的jar先生成，可执行jar后生成，所以可执行jar会覆盖普通的jar。","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"【bug】SpringBoot 打包异常：Unable to find main class","slug":"bug/SpringBoot 打包异常：Unable to find main class","date":"2021-11-17T14:13:28.415Z","updated":"2022-03-18T09:13:38.355Z","comments":true,"path":"2021/111740263.html","link":"","permalink":"https://409713427.github.io/2021/111740263.html","excerpt":"","text":"SpringBoot 打包异常：Unable to find main class正确解决方案是把parent的pom.xml的build给去掉,哪里需要build就写在哪个子项目的pom.xml上","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"【bug】springboot访问jsp页面时候却变成了下载文件","slug":"bug/springboot访问jsp页面时候却变成了下载文件","date":"2021-11-17T04:59:40.167Z","updated":"2022-03-18T09:13:48.675Z","comments":true,"path":"2021/111755763.html","link":"","permalink":"https://409713427.github.io/2021/111755763.html","excerpt":"","text":"springboot访问jsp页面时候却变成了下载文件前几天在本身写springboot项目的时候遇到个棘手 的问题，就是我访问项目url的时候原本应该跳转到jsp页面呢，然而却变成了下载文件 打开文件一看居然是我要访问的jsp页面内容。感到很奇怪，因而就仔细检查代码，检查是否加上了responseBodyspring 是否把路径写做了，配置文件里是否有错误问题，找了半天都没有发现问题，百度了一番，说是没有加入jsp的相关依赖。而后就尝试着加入下边的依赖 &lt;dependency> &lt;groupId>javax.servlet&lt;/groupId> &lt;artifactId>javax.servlet-api&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>javax.servlet&lt;/groupId> &lt;artifactId>jstl&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.tomcat.embed&lt;/groupId> &lt;artifactId>tomcat-embed-jasper&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.tomcat&lt;/groupId> &lt;artifactId>tomcat-jsp-api&lt;/artifactId> &lt;/dependency> 尝试从新启动一下，果真就行了","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"【bug】SpringBoot中注入StringRedisTemplate异常","slug":"bug/解决：SpringBoot中注入StringRedisTemplate异常","date":"2021-11-17T02:41:36.519Z","updated":"2022-03-18T09:13:18.599Z","comments":true,"path":"2021/111759353.html","link":"","permalink":"https://409713427.github.io/2021/111759353.html","excerpt":"","text":"解决：SpringBoot中注入StringRedisTemplate异常再学习springboot整合redis时,使用了StringRedisTemplate,结果测试启动时报错了： Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2021-11-17 10:38:14.394 ERROR 4756 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userServiceImpl': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanNotOfRequiredTypeException: Bean named 'redisTemplate' is expected to be of type 'org.springframework.data.redis.core.StringRedisTemplate' but was actually of type 'org.springframework.data.redis.core.RedisTemplate' at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:324) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:845) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:744) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:391) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:312) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1204) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE] at com.wst.SpringbootQf1Application.main(SpringbootQf1Application.java:12) ~[classes/:na] Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userServiceImpl': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanNotOfRequiredTypeException: Bean named 'redisTemplate' is expected to be of type 'org.springframework.data.redis.core.StringRedisTemplate' but was actually of type 'org.springframework.data.redis.core.RedisTemplate' at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:324) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1251) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1171) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:520) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:496) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:636) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:180) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:321) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] ... 17 common frames omitted Caused by: org.springframework.beans.factory.BeanNotOfRequiredTypeException: Bean named 'redisTemplate' is expected to be of type 'org.springframework.data.redis.core.StringRedisTemplate' but was actually of type 'org.springframework.data.redis.core.RedisTemplate' at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:392) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.resolveBeanByName(AbstractAutowireCapableBeanFactory.java:452) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:526) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:496) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:636) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:180) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:321) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] ... 33 common frames omitted 翻译如下： BeanCreationException：没有找到对应的bean，注入依赖资源项失败 ``BeanNotOfRequiredTypeException：名为“redisTemplate”的Bean应为“org.springframework.data.redis.core.StringRedisTemplate”类型，但实际为“org.springframework.data.redis.core.redisTemplate”类型。这个就很奇怪，我并没有用到redisTemplate的依赖，也不可能注入出错 后来我发现是这个Bean的名称问题，是因为名称问题导入注入失败？注入类型错误？ @Resource private StringRedisTemplate redisTemplate; 将redisTemplate改成stringRedisTemplate，好了，原因@Resource是默认取字段名进行按照名称注入，下面有具体介绍@Resource private StringRedisTemplate stringRedisTemplate; 关于@Autowired和@Resource注解两个注解都可以完成依赖注入功能。 1.@Autowired： @Autowired ：默认是以byType按类型自动注入。 @Autowired + @Qualifier(\"\"名称\"\")：将按照名称自动注入 2.@Resource： @Resource() 如果没有指定name属性，当注解写在字段上时，默认取字段名进行按照名称注入， 如果注解写在setter方法上默认取属性名进行注入。 当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。 @Resource(name=\"\"\"\") 将按照名称自动注入","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"【SSM】Spring和SpringMVC的整合","slug":"ssm整合/Spring 和 SpringMVC 的整合","date":"2021-11-15T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/1115[object Object].html","link":"","permalink":"https://409713427.github.io/2021/1115[object%20Object].html","excerpt":"","text":"第一章：本质 ContextLoaderListener：读取 spring-persist.xml。 DispatcherServlet：读取 springmvc.xml。 第二章：web.xml 配置 web.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"> &lt;!-- ContextLoaderListener --> &lt;!-- 通过 context-param 指定 Spring 框架的配置文件位置 --> &lt;context-param> &lt;param-name>contextConfigLocation&lt;/param-name> &lt;param-value>classpath:spring-persist.xml&lt;/param-value> &lt;/context-param> &lt;!-- 配置 ContextLoaderListener 监听器 --> &lt;listener> &lt;listener-class>org.springframework.web.context.ContextLoaderListener&lt;/listener-class> &lt;/listener> &lt;!-- DispatcherServlet --> &lt;servlet> &lt;servlet-name>dispatcherServlet&lt;/servlet-name> &lt;servlet-class>org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class> &lt;init-param> &lt;param-name>contextConfigLocation&lt;/param-name> &lt;param-value>classpath:springmvc.xml&lt;/param-value> &lt;/init-param> &lt;load-on-startup>1&lt;/load-on-startup> &lt;/servlet> &lt;servlet-mapping> &lt;servlet-name>dispatcherServlet&lt;/servlet-name> &lt;url-pattern>/&lt;/url-pattern> &lt;/servlet-mapping> &lt;!-- 需要注意两个 Filter 的顺序：字符集过滤器在前，转换请求方式过滤器在后 --> &lt;!-- CharacterEncodingFilter --> &lt;filter> &lt;filter-name>characterEncodingFilter&lt;/filter-name> &lt;filter-class>org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class> &lt;init-param> &lt;param-name>encoding&lt;/param-name> &lt;param-value>UTF-8&lt;/param-value> &lt;/init-param> &lt;init-param> &lt;param-name>forceRequestEncoding&lt;/param-name> &lt;param-value>true&lt;/param-value> &lt;/init-param> &lt;init-param> &lt;param-name>forceResponseEncoding&lt;/param-name> &lt;param-value>true&lt;/param-value> &lt;/init-param> &lt;/filter> &lt;filter-mapping> &lt;filter-name>characterEncodingFilter&lt;/filter-name> &lt;url-pattern>/*&lt;/url-pattern> &lt;/filter-mapping> &lt;!-- HiddenHttpMethodFilter --> &lt;filter> &lt;filter-name>hiddenHttpMethodFilter&lt;/filter-name> &lt;filter-class>org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class> &lt;/filter> &lt;filter-mapping> &lt;filter-name>hiddenHttpMethodFilter&lt;/filter-name> &lt;url-pattern>/*&lt;/url-pattern> &lt;/filter-mapping> &lt;/web-app> 第三章：SpringMVC 配置 springmvc.xml```xml &lt;beans xmlns=”http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=”com.github.fairy.era.handler”/&gt; mvc:annotation-driven/ mvc:default-servlet-handler/ &lt;mvc:view-controller path=”/“ view-name=”portal”/&gt; &lt;mvc:view-controller path=”/index.html” view-name=”portal”/&gt; ``` # **第四章：创建组件** EmployeeHandler.java```javapackage com.github.fairy.era.handler; import com.github.fairy.era.entity.Employee;import com.github.fairy.era.service.EmployeeService;import lombok.RequiredArgsConstructor;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping; import java.util.List; /** @author 许大仙 @version 1.0 @since 2021-11-22 13:48 /@Controller@RequiredArgsConstructorpublic class EmployeeHandler { private final EmployeeService employeeService; @GetMapping(“/get/all”) public String getAll(Model model) { // 1、查询数据 List&lt;Employee&gt; empList = employeeService.findAll(); // 2.存入模型 model.addAttribute(&quot;empList&quot;, empList); return &quot;emp-list&quot;; } } # **第五章：页面操作** ## **5.1 首页超链接** - portal.html ```html &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;a th:href=&quot;@{/get/all}&quot;&gt;显示全部数据&lt;/a&gt; &lt;/body&gt; &lt;/html&gt; 5.2 显示数据的页面 emp-list.html &lt;!DOCTYPE html> &lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"> &lt;head> &lt;meta charset=\"UTF-8\"> &lt;title>$Title$&lt;/title> &lt;/head> &lt;body> &lt;table> &lt;tr> &lt;th>id&lt;/th> &lt;th>lastName&lt;/th> &lt;th>gender&lt;/th> &lt;th>email&lt;/th> &lt;/tr> &lt;tbody th:if=\"${#lists.isEmpty(empList)}\"> &lt;tr> &lt;td colspan=\"3\">抱歉！没有查询到数据！&lt;/td> &lt;/tr> &lt;/tbody> &lt;tbody th:if=\"${not #lists.isEmpty(empList)}\"> &lt;tr th:each=\"emp : ${empList}\"> &lt;td th:text=\"${emp.id}\">这里显示员工ID&lt;/td> &lt;td th:text=\"${emp.lastName}\">这里显示员工lastName&lt;/td> &lt;td th:text=\"${emp.gender}\">这里显示员工gender&lt;/td> &lt;td th:text=\"${emp.email}\">这里显示员工email&lt;/td> &lt;/tr> &lt;/tbody> &lt;/table> &lt;a th:href=\"@{/}\">回首页&lt;/a> &lt;/body> &lt;/html>","categories":[{"name":"ssm","slug":"ssm","permalink":"https://409713427.github.io/categories/ssm/"}],"tags":[{"name":"ssm","slug":"ssm","permalink":"https://409713427.github.io/tags/ssm/"}],"author":"wst"},{"title":"【SSM】Spring和Mybatis的整合","slug":"ssm整合/Spring 和 Mybatis 的整合","date":"2021-11-15T05:35:32.000Z","updated":"2022-07-06T14:46:33.313Z","comments":true,"path":"2021/111536523.html","link":"","permalink":"https://409713427.github.io/2021/111536523.html","excerpt":"","text":"第一章：思路 第二章：Mybatis - Spring 技术 官网。 相关技术之间版本匹配说明： Mybatis-Spring 的依赖： &lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis-spring&lt;/artifactId> &lt;version>2.0.6&lt;/version> &lt;/dependency> 第三章：总体 SSM 整合所需依赖 pom.xml &lt;!-- Mybatis 整合 Spring --> &lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis-spring&lt;/artifactId> &lt;version>2.0.6&lt;/version> &lt;/dependency> &lt;!-- SpringMVC --> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-webmvc&lt;/artifactId> &lt;version>5.3.12&lt;/version> &lt;/dependency> &lt;!-- Spring 持久化层所需依赖 --> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-orm&lt;/artifactId> &lt;version>5.3.12&lt;/version> &lt;/dependency> &lt;!-- 日志 --> &lt;dependency> &lt;groupId>ch.qos.logback&lt;/groupId> &lt;artifactId>logback-classic&lt;/artifactId> &lt;version>1.2.7&lt;/version> &lt;/dependency> &lt;!-- ServletAPI --> &lt;dependency> &lt;groupId>javax.servlet&lt;/groupId> &lt;artifactId>javax.servlet-api&lt;/artifactId> &lt;version>4.0.1&lt;/version> &lt;scope>provided&lt;/scope> &lt;/dependency> &lt;!-- Spring5和Thymeleaf整合包 --> &lt;dependency> &lt;groupId>org.thymeleaf&lt;/groupId> &lt;artifactId>thymeleaf-spring5&lt;/artifactId> &lt;version>3.0.12.RELEASE&lt;/version> &lt;/dependency> &lt;!-- Mybatis核心 --> &lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis&lt;/artifactId> &lt;version>3.5.7&lt;/version> &lt;/dependency> &lt;!-- MySQL驱动 --> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>8.0.25&lt;/version> &lt;/dependency> &lt;!-- 数据源 --> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>druid&lt;/artifactId> &lt;version>1.2.8&lt;/version> &lt;/dependency> &lt;!-- junit5 --> &lt;dependency> &lt;groupId>org.junit.jupiter&lt;/groupId> &lt;artifactId>junit-jupiter-api&lt;/artifactId> &lt;version>5.8.1&lt;/version> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;!-- Spring 的测试功能 --> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-test&lt;/artifactId> &lt;version>5.3.12&lt;/version> &lt;/dependency> &lt;!-- Lombok --> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;version>1.18.22&lt;/version> &lt;scope>provided&lt;/scope> &lt;/dependency> 第四章：配置数据源4.1 创建 jdbc.properties jdbc.properties jdbc.user=root jdbc.password=123456 jdbc.url=jdbc:mysql://localhost:3306/ssm?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true&amp;allowMultiQueries=true jdbc.driver=com.mysql.cj.jdbc.Driver 4.2 加入日志配置文件 logback.xml```xml [%d{HH:mm:ss.SSS}] [%-5level] [%thread] [%logger] [%msg]%n UTF-8 ``` ## **4.3 创建 Spring 的配置文件** spring-persist.xml```xml &lt;beans xmlns=”http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=”classpath:jdbc.properties”&gt; ``` ## **4.3 创建 Junit 测试** ```java package com.github.fairy.era; import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.junit.jupiter.SpringJUnitConfig; import javax.sql.DataSource; /** @author 许大仙 @version 1.0 @since 2021-11-22 09:25 /@SpringJUnitConfig(locations = {“classpath:spring-persist.xml”})@Slf4jpublic class SpringTest { @Autowired private DataSource dataSource; @Test public void test() { log.info(&quot; dataSource = &quot; + dataSource); } } # **第五章：配置 SqlSessionFactoryBean** ## **5.1 创建 Mybatis 全局配置文件** - mybatis-config.xml ```xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt; &lt;configuration&gt; &lt;!-- Mybatis全局配置 --&gt; &lt;settings&gt; &lt;!-- 将数据库表字段映射到驼峰式命名的Java实体类属性中 --&gt; &lt;!-- 数据库表字段格式：单词_单词 --&gt; &lt;!-- Java实体类属性：首字母小写的驼峰式命名 --&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt; &lt;/configuration&gt; 5.2 数据库脚本SET NAMES utf8mb4; SET FOREIGN_KEY_CHECKS = 0; -- ---------------------------- -- 创建数据库 -- ---------------------------- CREATE DATABASE IF NOT EXISTS `ssm` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; -- ---------------------------- -- 创建表 -- ---------------------------- DROP TABLE IF EXISTS `employee`; CREATE TABLE `employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `last_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `gender` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `email` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE ) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic; -- ---------------------------- -- 插入数据 -- ---------------------------- INSERT INTO `employee` VALUES (1, 'jerry', '男', 'jerry@qq.com'); INSERT INTO `employee` VALUES (2, 'aa', '男', 'aa@11.com'); INSERT INTO `employee` VALUES (3, 'bb', '男', 'bb@11.com'); INSERT INTO `employee` VALUES (4, 'aa', '男', 'aa@11.com'); INSERT INTO `employee` VALUES (5, 'bb', '男', 'bb@11.com'); SET FOREIGN_KEY_CHECKS = 1; 5.3 创建实体类 Employee.java```javapackage com.github.fairy.era.entity; import lombok.Data; /** @author 许大仙 @version 1.0 @since 2021-11-22 09:42 /@Datapublic class Employee { private Integer id; private String lastName; private String gender; private String email;}``` 5.4 创建 Mapper 接口 EmployeeMapper.java```javapackage com.github.fairy.era.mapper; import com.github.fairy.era.entity.Employee; import java.util.List; /** @author 许大仙 @version 1.0 @since 2021-11-22 09:56 /public interface EmployeeMapper { List findAll();}``` 5.5 创建 Mapper 配置文件 EmployeeMapper.xml```xml &lt;select id=&quot;findAll&quot; resultType=&quot;com.github.fairy.era.entity.Employee&quot;&gt; SELECT id,last_name,gender,email FROM employee &lt;/select&gt; ``` ## **5.6 配置 sqlSessionFactoryBean** ### **5.6.1 保留 Mybatis 全局配置文件** spring-persist.xml &lt;!-- 配置 sessionFactoryBean --> &lt;bean id=\"sessionFactoryBean\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"> &lt;!-- 数据源 --> &lt;property name=\"dataSource\" ref=\"dataSource\"/> &lt;!-- 指定 Mybatis 全局配置文件位置 --> &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/> &lt;!-- 指定 Mapper 配置文件位置 --> &lt;property name=\"mapperLocations\" value=\"classpath*:com/github/fairy/era/mapper/*Mapper.xml\"/> &lt;/bean> 完整的 spring-persist.xml```xml &lt;beans xmlns=”http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=”classpath:jdbc.properties”&gt; ``` ### **5.6.2 彻底舍弃 Mybatis 全局配置文件** spring-persist.xml &lt;!-- 配置 sessionFactoryBean --> &lt;bean id=\"sessionFactoryBean\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"> &lt;!-- 数据源 --> &lt;property name=\"dataSource\" ref=\"dataSource\"/> &lt;!-- 舍弃 Mybatis 全局配置文件，使用 configuration 属性 --> &lt;property name=\"configuration\"> &lt;bean class=\"org.apache.ibatis.session.Configuration\"> &lt;property name=\"mapUnderscoreToCamelCase\" value=\"true\"/> &lt;/bean> &lt;/property> &lt;!-- 指定 Mapper 配置文件位置 --> &lt;property name=\"mapperLocations\" value=\"classpath*:com/github/fairy/era/mapper/*Mapper.xml\"/> &lt;/bean> 完整的 spring-persist.xml```xml &lt;beans xmlns=”http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=”classpath:jdbc.properties”&gt; ``` > 注意：上面两种方式如果并存，会抛出异常：java.lang.IllegalStateException: Property 'configuration' and 'configLocation' can not specified with together 5.7 配置 Mapper 接口的扫描器5.7.1 使用扫描器 spring-persist.xml &lt;!-- 配置 Mapper 接口 bean 的扫描器 --> &lt;bean id=\"mapperScannerConfigurer\" class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"> &lt;property name=\"basePackage\" value=\"com.github.fairy.era.mapper\"/> &lt;/bean> 完整的 spring-persist.xml```xml &lt;beans xmlns=”http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=”classpath:jdbc.properties”&gt; ``` ### **5.7.2 使用 mybatis-spring 名称空间** spring-persist.xml &lt;!-- 使用 mybatis-spring 名称空间 --> &lt;mybatis-spring:scan base-package=\"com.github.fairy.era.mapper\"/> 完整的 spring-persist.xml```xml &lt;beans xmlns=”http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mybatis-spring=&quot;http://mybatis.org/schema/mybatis-spring&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://mybatis.org/schema/mybatis-spring http://mybatis.org/schema/mybatis-spring.xsd&quot;&gt; &lt;context:property-placeholder location=”classpath:jdbc.properties”&gt; &lt;mybatis-spring:scan base-package=”com.github.fairy.era.mapper”/&gt; ``` > 注意：两种方式任选一种即可。 5.8 测试package com.github.fairy.era; import com.github.fairy.era.mapper.EmployeeMapper; import lombok.extern.slf4j.Slf4j; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.junit.jupiter.SpringJUnitConfig; /** * @author 许大仙 * @version 1.0 * @since 2021-11-22 09:25 */ @SpringJUnitConfig(locations = {\"classpath:spring-persist.xml\"}) @Slf4j public class SpringTest { @Autowired private EmployeeMapper employeeMapper; @Test public void test() { System.out.println(\"employeeMapper = \" + employeeMapper); } } 第六章：加入声明式事务6.1 配置事务管理器 spring-persist.xml &lt;!-- 配置事务管理器 --> &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"> &lt;property name=\"dataSource\" ref=\"dataSource\"/> &lt;/bean> &lt;!-- 开启基于注解的事务支持 --> &lt;tx:annotation-driven transaction-manager=\"transactionManager\"/> 完整的 spring-persist.xml```xml &lt;beans xmlns=”http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mybatis-spring=&quot;http://mybatis.org/schema/mybatis-spring&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://mybatis.org/schema/mybatis-spring http://mybatis.org/schema/mybatis-spring.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;context:property-placeholder location=”classpath:jdbc.properties”&gt; &lt;mybatis-spring:scan base-package=”com.github.fairy.era.mapper”/&gt; ``` ## **6.2 创建Service组件** EmployeeService.java```javapackage com.github.fairy.era.service; import com.github.fairy.era.entity.Employee; import java.util.List; /** @author 许大仙 @version 1.0 @since 2021-11-22 12:38 /public interface EmployeeService { List findAll();}``` EmployeeServiceImpl.java```javapackage com.github.fairy.era.service.impl; import com.github.fairy.era.entity.Employee;import com.github.fairy.era.mapper.EmployeeMapper;import com.github.fairy.era.service.EmployeeService;import lombok.RequiredArgsConstructor;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional; import java.util.List; /** @author 许大仙 @version 1.0 @since 2021-11-22 12:39 /@Service@Transactional(rollbackFor = Exception.class,readOnly = true)@RequiredArgsConstructorpublic class EmployeeServiceImpl implements EmployeeService { private final EmployeeMapper employeeMapper; @Override public List findAll() { return employeeMapper.findAll(); }}``` 6.3 配置自动扫描的包 spring-persist.xml &lt;!-- 配置自动扫描的包 --> &lt;context:component-scan base-package=\"com.github.fairy.era.service\"/> 完整的 spring-persist.xml```xml &lt;beans xmlns=”http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mybatis-spring=&quot;http://mybatis.org/schema/mybatis-spring&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://mybatis.org/schema/mybatis-spring http://mybatis.org/schema/mybatis-spring.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;context:property-placeholder location=”classpath:jdbc.properties”&gt; &lt;mybatis-spring:scan base-package=”com.github.fairy.era.mapper”/&gt; &lt;context:component-scan base-package=”com.github.fairy.era.service”/&gt; ``` ## **6.4 测试** ```java package com.github.fairy.era; import com.github.fairy.era.service.EmployeeService;import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.junit.jupiter.SpringJUnitConfig; /** @author 许大仙 @version 1.0 @since 2021-11-22 09:25 /@SpringJUnitConfig(locations = {“classpath:spring-persist.xml”})@Slf4jpublic class SpringTest { @Autowired private EmployeeService employeeService; @Test public void test() { employeeService.findAll().forEach(System.out::println); } }","categories":[{"name":"ssm","slug":"ssm","permalink":"https://409713427.github.io/categories/ssm/"}],"tags":[{"name":"ssm","slug":"ssm","permalink":"https://409713427.github.io/tags/ssm/"}],"author":"wst"},{"title":"【bug】SpringBoot配置thymeleaf 启动报错 org.thymeleaf.spring5.SpringTemplateEngine.setRenderHiddenMarkersBefore","slug":"bug/SpringBoot配置thymeleaf 启动报错 org.thymeleaf.spring5.SpringTemplateEngine.setRenderHiddenMarkersBefore","date":"2021-11-09T02:43:43.899Z","updated":"2022-03-18T09:13:53.098Z","comments":true,"path":"2021/110964583.html","link":"","permalink":"https://409713427.github.io/2021/110964583.html","excerpt":"","text":"SpringBoot配置thymeleaf 启动报错 org.thymeleaf.spring5.SpringTemplateEngine.setRenderHiddenMarkersBeforepom文件配置&lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;thymeleaf.version>3.0.9.RELEASE&lt;/thymeleaf.version> &lt;thymeleaf-layout-dialect.version>2.2.2&lt;/thymeleaf-layout-dialect.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-thymeleaf&lt;/artifactId> &lt;/dependency> &lt;/dependencies> 报错内容Description: An attempt was made to call a method that does not exist. The attempt was made from the following location: org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafDefaultConfiguration.templateEngine(ThymeleafAutoConfiguration.java:142) The following method did not exist: org.thymeleaf.spring5.SpringTemplateEngine.setRenderHiddenMarkersBeforeCheckboxes(Z)V The method's class, org.thymeleaf.spring5.SpringTemplateEngine, is available from the following locations: jar:file:/D:/repository/org/thymeleaf/thymeleaf-spring5/3.0.9.RELEASE/thymeleaf-spring5-3.0.9.RELEASE.jar!/org/thymeleaf/spring5/SpringTemplateEngine.class It was loaded from the following location: file:/D:/repository/org/thymeleaf/thymeleaf-spring5/3.0.9.RELEASE/thymeleaf-spring5-3.0.9.RELEASE.jar Action: Correct the classpath of your application so that it contains a single, compatible version of org.thymeleaf.spring5.SpringTemplateEngine Process finished with exit code 1 原因当前thymeleaf版本为&lt;thymeleaf.version&gt;3.0.11.RELEASE&lt;/thymeleaf.version&gt; &lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt;已经不适用 解决方法将&lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; 改为： &lt;thymeleaf.version>3.0.11.RELEASE&lt;/thymeleaf.version>","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"【bug】maven管理springboot项目可以不用写依赖的版本号","slug":"bug/学习springboot的时候发现maven的依赖是不用写版本号的，依然可以正常跑起来，这是为什么呢？","date":"2021-11-08T04:00:59.422Z","updated":"2022-03-18T09:13:21.867Z","comments":true,"path":"2021/110842044.html","link":"","permalink":"https://409713427.github.io/2021/110842044.html","excerpt":"","text":"maven管理springboot项目可以不用写依赖的版本号学习springboot的时候发现maven的依赖是不用写版本号的，依然可以正常跑起来，这是为什么呢？ 这是因为添加“parent”标签里的内容后，“spring-boot-starter-parent”会为开发者提供常用jar的版本管理，所以我们不需要指定版本，使用人家提供好的就可以了。当然，指定也是可以的，这会覆盖官方默认的版本，不推荐。 &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.5.6&lt;/version> &lt;relativePath/> &lt;!-- lookup parent from repository --> &lt;/parent> &lt;dependencies> &lt;dependency> &lt;groupId>org.mybatis.spring.boot&lt;/groupId> &lt;artifactId>mybatis-spring-boot-starter&lt;/artifactId> &lt;version>2.2.0&lt;/version> &lt;/dependency> &lt;!--下面两个没有版本号 使用springboot提供好的版本 --> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;scope>runtime&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;/dependencies>","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"【bug】spring整合MyBatis,maven工程中c3p0的jar包导入坐标","slug":"bug/maven工程的jar包导的c3p0问题","date":"2021-11-07T08:32:36.252Z","updated":"2022-03-18T09:13:34.618Z","comments":true,"path":"2021/110721021.html","link":"","permalink":"https://409713427.github.io/2021/110721021.html","excerpt":"","text":"Receiver class com.mchange.v2.c3p0.impl.NewProxyResultSet does not define or inherit an implementati最近做SSM框架整合测试的时候，spring整合MyBatis的时候，运行测试报错以下: 解决:面向百度一顿查,然后发现maven工程中c3p0的jar包导的有问题: 错误 &lt;dependency> &lt;groupId>c3p0&lt;/groupId> &lt;artifactId>c3p0&lt;/artifactId> &lt;version>0.9.1.2&lt;/version> &lt;type>jar&lt;/type> &lt;scope>compile&lt;/scope> &lt;/dependency> 正确 &lt;dependency> &lt;groupId>com.mchange&lt;/groupId> &lt;artifactId>c3p0&lt;/artifactId> &lt;version>0.9.5.2&lt;/version> &lt;type>jar&lt;/type> &lt;scope>compile&lt;/scope> &lt;/dependency>","categories":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"}],"author":"wst"},{"title":"【JS新特性系列】ES6新增属性Symbol详解","slug":"js新特性/ES6新增属性Symbol详解","date":"2021-10-27T08:25:32.000Z","updated":"2021-10-27T04:37:34.419Z","comments":true,"path":"2021/102719592.html","link":"","permalink":"https://409713427.github.io/2021/102719592.html","excerpt":"","text":"ES6新增属性Symbol详解1.什么Symbol?Symbol是ES6中新增的一种数据类型, 被划分到了基本数据类型中基本数据类型: 字符串、数值、布尔、undefined、null、Symbol引用数据类型: Object 2.Symbol的作用用来表示一个独一无二的值 3.如果生成一个独一无二的值?let xxx = Symbol(); 4.为什么需要Symbol?在企业开发中如果需要对一些第三方的插件、框架进行自定义的时候可能会因为添加了同名的属性或者方法, 将框架中原有的属性或者方法覆盖掉为了避免这种情况的发生, 框架的作者或者我们就可以使用Symbol作为属性或者方法的名称 5.如何区分Symbol?在通过Symbol生成独一无二的值时可以设置一个标记这个标记仅仅用于区分, 没有其它任何含义 let obj = { name: \"lnj\", say: function () { console.log(\"say\"); } } obj.name = \"it666\"; console.log(obj.name); //it666 原值被覆盖 obj.say = function () { console.log(\"test\"); } obj.say();//test 原方法被覆盖 //解决方案: 用symbol let name = Symbol(\"name\"); let say = Symbol(\"say\"); let obj = { // 注意点: 如果想使用变量作为对象属性的名称, 那么必须加上[] [name]: \"lnj\", [say]: function () { console.log(\"say\"); } } // obj.name = \"it666\"; obj[Symbol(\"name\")] = \"it666\"; console.log(obj); 6.symbol注意点通过Symbol生成独一无二值时需要在后面加上(), 但是前面不能加new, 因为它不是引用类型 let xxx = Symbol(); // 正确 let xxx = new Symbol(); // 错误 通过Symbol生成独一无二值时传入的字符串仅仅是一个标记, 方便我们阅读代码, 没有其它任何意义 let xxx = Symbol(\"name\"); 做类型转换的时候不能转换成数值 let xxx = Symbol(\"name\"); console.log(String(xxx)); console.log(Boolean(xxx)); console.log(Number(xxx)); 不能做任何运算 let xxx = Symbol(\"name\"); console.log(xxx + \"abc\"); //报错 console.log(xxx + 123); //报错 Symbol生成的值作为属性或方法名称时, 一定更要保存下来, 否则后续无法使用 let name = Symbol(\"name\"); let obj = { // [name]: \"lnj\" [Symbol(\"name\")]: \"it666\" } // console.log(obj[name]); console.log(obj[Symbol(\"name\")]); for循环无法遍历出Symbol的属性和方法 let name = Symbol(\"name\"); let say = Symbol(\"say\"); let obj = { // 注意点: 如果想使用变量作为对象属性的名称, 那么必须加上[] [name]: \"lnj\", [say]: function () { console.log(\"say\"); }, age: 34, gender: \"man\", hi: function () { console.log(\"hi\"); } } // for(let key in obj){ // console.log(key); // } console.log(Object.getOwnPropertySymbols(obj));","categories":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/categories/javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/tags/javascript/"}],"author":"wst"},{"title":"【JS新特性系列】Generator函数与async函数","slug":"js新特性/Generator函数与async函数","date":"2021-10-27T04:35:32.000Z","updated":"2021-10-27T04:37:34.425Z","comments":true,"path":"2021/102724586.html","link":"","permalink":"https://409713427.github.io/2021/102724586.html","excerpt":"","text":"Generator函数与async函数1.什么是Generator函数?Generator 函数是 ES6 提供的一种异步编程解决方案Generator 函数内部可以封装多个状态, 因此又可以理解为是一个状态机 2.如何定义Generator函数只需要在普通函数的function后面加上*即可 3.Generator函数和普通函数区别3.1调用Generator函数后, 无论函数有没有返回值, 都会返回一个迭代器对象,3.2调用Generator函数后, 函数中封装的代码不会立即被执行 4.真正让Generator具有价值的是yield关键字4.1在Generator函数内部使用yield关键字定义状态4.2并且yield关键字可以让 Generator内部的逻辑能够切割成多个部分。4.3通过调用迭代器对象的next方法执行一个部分代码,执行哪个部分就会返回哪个部分定义的状态 5.在调用next方法的时候可以传递一个参数, 这个参数会传递给上一个yieldfunction* gen() { console.log(\"123\"); let res = yield \"aaa\"; console.log(res); console.log(\"567\"); yield 1 + 1; console.log(\"789\"); yield true; } let it = gen(); // console.log(it); console.log(it.next()); console.log(it.next(\"it666\")); // console.log(it.next()); // console.log(it.next()); // 注意点: yield关键字只能在Generator函数中使用, 不能在普通函数中使用 // function say() { // yield \"abc\"; // } // say(); 应用场景1.让函数返回多个值 /* function calculate(a, b) { let sum = a + b; let sub = a - b; return [sum, sub]; } */ function* calculate(a, b) { yield a + b; yield a - b; } let it = calculate(10, 5); console.log(it.next().value); console.log(it.next().value); 2.用同步的流程来表示异步的操作 /* 回调地狱实现 function request(fn) { setTimeout(function () { fn(\"拿到的数据\"); }, 1000); } request(function (data) { console.log(\"1\", data); request(function (data) { console.log(\"2\", data); request(function (data) { console.log(\"3\", data); }); }); }); */ function request() { return new Promise(function (resolve, reject) { setTimeout(function () { resolve(\"拿到的数据\"); }, 1000); }); } /* promise实现 request().then(function (data) { console.log(data, 1); return request(); }).then(function (data) { console.log(data, 2); return request(); }).then(function (data) { console.log(data, 3); }); */ //Generator实现 function* gen() { yield request(); yield request(); yield request(); } let it = gen(); // console.log(it.next().value); it.next().value.then(function (data) { console.log(data, 1); return it.next().value; }).then(function (data) { console.log(data, 2); return it.next().value; }).then(function (data) { console.log(data, 3); }); 3.利用 Generator 函数，可以在任意对象上快速部署 Iterator 接口 /* Generator 函数特点 1.Generator 函数也是一个函数 2.Generator 函数会返回一个迭代器对象 3.迭代器对象有next方法 4.next方法每次执行都会返回一个对象{value: xxx, done: false} */ /* function* gen() { yield \"aaa\"; yield \"bbb\"; yield \"ccc\"; } let it = gen(); // console.log(it); console.log(it.next()); */ /* 1.必须有一个叫做[Symbol.iterator]的属性 2.[Symbol.iterator]的属性会返回一个函数 3.[Symbol.iterator]返回的函数执行之后会返回一个可迭代对象 4.[Symbol.iterator]函数返回的对象中又一个名称叫做next的方法 5.next方法每次执行都会返回一个对象{value: xxx, done: false} */ /* let obj = { name: \"lnj\", age: 34, gender: \"man\", [Symbol.iterator](){ let keys = Object.keys(this); // console.log(keys); let index = 0; let that = this; return { next(){ if(index &lt; keys.length){ return {value: that[keys[index++]], done: false}; }else{ return {value: undefined, done: true}; } } } } } // console.log(obj[Symbol.iterator]); // let it = obj[Symbol.iterator](); // console.log(it); // console.log(it.next()); // console.log(it.next()); // console.log(it.next()); // console.log(it.next()); for(let value of obj){ console.log(value); } */ let obj = { name: \"lnj\", age: 34, gender: \"man\" } function* gen(){ let keys = Object.keys(obj); for(let i = 0; i &lt; keys.length; i++){ yield obj[keys[i]]; } } obj[Symbol.iterator] = gen; // console.log(obj[Symbol.iterator]); let it = obj[Symbol.iterator](); // console.log(it); console.log(it.next()); console.log(it.next()); console.log(it.next()); console.log(it.next()); 6.async函数async函数是ES8中新增的一个函数, 用于定义一个异步函数async函数函数中的代码会自动从上至下的执行代码 7.await操作符await操作符只能在异步函数 async function 中使用await表达式会暂停当前 async function 的执行，等待 Promise 处理完成。若 Promise 正常处理(fulfilled)，其回调的resolve函数参数作为 await 表达式的值，然后继续执行 async function。 function request() { return new Promise(function (resolve, reject) { setTimeout(function () { resolve(\"拿到的数据\"); }, 1000); }); } /* function* gen() { yield request(); yield request(); yield request(); } let it = gen(); it.next().value.then(function (data) { console.log(data, 1); return it.next().value; }).then(function (data) { console.log(data, 2); return it.next().value; }).then(function (data) { console.log(data, 3); }); */ async function gen() { let res1 = await request(); console.log(res1, 1); let res2 = await request(); console.log(res2, 2); let res3 = await request(); console.log(res3, 3); } gen();","categories":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/categories/javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/tags/javascript/"}],"author":"wst"},{"title":"【JS新特性系列】ES6 Promise总结","slug":"js新特性/ES6中 Promise总结","date":"2021-10-27T04:25:32.000Z","updated":"2021-10-27T04:37:34.424Z","comments":true,"path":"2021/102715630.html","link":"","permalink":"https://409713427.github.io/2021/102715630.html","excerpt":"","text":"ES6中 Promise总结提示:如果你还不太懂js中的同步代码和异步代码 请参考此扩展阅读 1.什么是PromisePromise 是ES6中新增的异步编程解决方案，在代码中的表现是一个对象. // 需求: 从网络上加载3个资源, 要求加载完资源1才能加载资源2, 加载完资源2才能加载资源3 // 前面任何一个资源加载失败, 后续资源都不加载 function request(fn) { setTimeout(function () { fn(\"拿到的数据\"); }, 1000); } request(function (data) { console.log(data, 1); request(function (data) { console.log(data, 2); request(function (data) { console.log(data, 3); }); }); }); /* 2.promise作用 企业开发中为了保存异步代码的执行顺序, 那么就会出现回调函数层层嵌套 如果回调函数嵌套的层数太多, 就会导致代码的阅读性, 可维护性大大降低 promise对象可以将异步操作以同步流程来表示, 避免了回调函数层层嵌套(回调地狱) */ function request() { return new Promise(function (resolve, reject) { setTimeout(function () { resolve(\"拿到的数据\"); }, 1000); }); } request().then(function (data) { console.log(data, 1); return request(); }).then(function (data) { console.log(data, 2); return request(); }).then(function (data) { console.log(data, 3); }); 2.Promise的基本使用 什么是Promise? Promise是ES6中新增的一个对象,通过Promise就可以实现 用同步的流程来表示异步的操作通过Promise就可以 避免回调函数层层嵌套(回调地狱)问题 如何创建Promise对象? new Promise(function(resolve, reject){});promise对象不是异步的, 只要创建promise对象就会立即执行存放的代码 Promise是如何实现 通过同步的流程来表示异步的操作的? promise对象是通过状态的改变来实现的, 只要状态发生改变就会自动触发对应的函数 Promise对象三种状态 pending: 默认状态，只要没有告诉promise任务是成功还是失败就是pending状态fulfilled(resolved): 只要调用resolve函数, 状态就会变为fulfilled, 表示操作成功rejected: 只要调用rejected函数, 状态就会变为rejected, 表示操作失败注意点: 状态一旦改变既不可逆, 既从pending变为fulfilled, 那么永远都是fulfilled 即从pending变为rejected, 那么永远都是rejected 监听Promise状态改变 可以通过函数来监听状态的变化resolved –&gt; then()rejected –&gt; catch() let promise = new Promise(function (resolve, reject) { console.log(\"1\"); reject(); // resolve(); }); promise.then(function () { console.log(\"then\"); }); promise.catch(function () { console.log(\"catch\"); }); 3.then方法详解then方法接收两个参数,第一个参数是状态切换为成功时的回调,第二个参数是状态切换为失败时的回调 let promise = new Promise(function (resolve, reject) { // resolve(); // 将状态修改为成功 reject(); // 将状态修改为失败 }); promise.then(function () { console.log(\"成功\"); }, function () { console.log(\"失败\"); }); then方法在修改promise状态时, 可以传递参数给then方法中的回到函数 // resolve = success, reject = error; let promise = new Promise(function (resolve, reject) { // resolve(\"111\"); // 将状态修改为成功 success(\"111\"); reject(\"aaa\"); // 将状态修改为失败 error(\"aaa\"); }); // promise.then(function (data) { // console.log(\"成功\", data); // }, function (data) { // console.log(\"失败\", data); // }); function success(data) { console.log(data); } function error(data) { console.log(data); } promise.then(success, error); then方法同一个promise对象可以多次调用then方法,当该promise对象的状态时所有then方法都会被执行 let promise = new Promise(function (resolve, reject) { // resolve(); // 将状态修改为成功 reject(); // 将状态修改为失败 }); promise.then(function () { console.log(\"成功1\"); }, function () { console.log(\"失败1\"); }); promise.then(function () { console.log(\"成功2\"); }, function () { console.log(\"失败2\"); }); then方法then方法每次执行完毕后会返回一个新的promise对象 let promise = new Promise(function (resolve, reject) { resolve(); // 将状态修改为成功 // reject(); // 将状态修改为失败 }); let p2 = promise.then(function () { console.log(\"成功1\"); }, function () { console.log(\"失败1\"); }); console.log(p2); console.log(promise === p2);//false then方法可以通过上一个promise对象的then方法给下一个promise对象的then方法传递参数注意点:无论是在上一个promise对象成功的回调还是失败的回调传递的参数,都会传递给下一个promise对象成功的回调 let promise = new Promise(function (resolve, reject) { // resolve(\"111\"); // 将状态修改为成功 reject(\"aaa\"); // 将状态修改为失败 }); let p2 = promise.then(function (data) { console.log(\"成功1\", data); return \"222\"; }, function (data) { console.log(\"失败1\", data); return \"bbb\"; }); p2.then(function (data) { console.log(\"成功2\", data); }, function (data) { console.log(\"失败2\", data); }); then方法如果then方法返回的是一个Promise对象, 那么会将返回的Promise对象的执行结果中的值传递给下一个then方法 let promise = new Promise(function (resolve, reject) { resolve(\"111\"); // 将状态修改为成功 // reject(\"aaa\"); // 将状态修改为失败 }); let ppp = new Promise(function (resolve, reject) { // resolve(\"222\"); // 将状态修改为成功 reject(\"bbb\"); // 将状态修改为失败 }); let p2 = promise.then(function (data) { console.log(\"成功1\", data); return ppp; }, function (data) { console.log(\"失败1\", data); return \"bbb\"; }); p2.then(function (data) { console.log(\"成功2\", data); }, function (data) { console.log(\"失败2\", data); }); catch方法详解catch方法与then方法所讲的注意点基本一致,以下只说出catch独有的注意点 /* 0.catch方法 catch 其实是 then(undefined, () => {}) 的语法糖 * */ let promise = new Promise(function (resolve, reject) { // resolve(); // 将状态修改为成功 reject(); // 将状态修改为失败 }); promise.catch(function () { console.log(\"abc\"); }); /* 2.catch方法 注意点: 如果需要分开监听, 也就是通过then监听成功通过catch监听失败 那么必须使用链式编程, 否则会报错 * */ let promise = new Promise(function (resolve, reject) { // resolve(); // 将状态修改为成功 reject(); // 将状态修改为失败 }); promise.then(function () { console.log(\"成功\"); }).catch(function () { console.log(\"失败\"); }); /* 报错 promise.then(function () { console.log(\"成功\"); }); promise.catch(function () { console.log(\"失败\"); }); */ /* 3.catch方法 不使用链式编程的原因是 1.如果promise的状态是失败, 但是没有对应失败的监听就会报错 2.then方法会返回一个新的promise, 新的promise会继承原有promise的状态 3.如果新的promise状态是失败, 但是没有对应失败的监听也会报错 * */ let promise = new Promise(function (resolve, reject) { // resolve(); // 将状态修改为成功 reject(); // 将状态修改为失败 }); let p2 = promise.then(function () { console.log(\"成功\"); }); console.log(p2); promise.catch(function () { console.log(\"失败1\"); }); p2.catch(function () { console.log(\"失败2\"); }); /* 6.catch方法 和then方法第二个参数的区别在于, catch方法可以捕获上一个promise对象then方法中的异常 * */ let promise = new Promise(function (resolve, reject) { resolve(); }); // promise.then(function () { // console.log(\"成功\"); // xxx // }, function () { // console.log(\"失败\"); // }); promise.then(function () { console.log(\"成功\"); xxx }).catch(function (e) { console.log(\"失败\", e); }); promise应用场景练习/* 需求: 一次加载一张图片添加到body中. 前面图片加载失败后面图片不加载 */ let arr = [ \"http://www.xxx.com/picture_1.png\", \"http://www.xxx.com/picture_2.png\", \"http://wwww.xxx.com/files/picture_3.png\" ]; function loadImage(url) { return new Promise(function (resolve, reject) { let oImg = new Image(); oImg.src = url; oImg.onload = function () { resolve(oImg); } oImg.onerror = function () { reject(\"图片加载失败\"); } }); } loadImage(arr[0]).then(function (oImg) { // console.log(oImg); console.log(\"1\"); document.body.appendChild(oImg); return loadImage(arr[1]); }).then(function (oImg) { console.log(\"2\"); // console.log(oImg); document.body.appendChild(oImg); return loadImage(arr[2]); }).then(function (oImg) { console.log(\"3\"); // console.log(oImg); document.body.appendChild(oImg); }).catch(function (msg) { console.log(msg); }); promise-all方法Promise的all静态方法:1.all方法接收一个数组,2.如果数组中有多个Promise对象,只有都成功才会执行then方法,并且会按照添加的顺序, 将所有成功的结果重新打包到一个数组中返回给我们.3.如果数组中不是Promise对象, 那么会直接执行then方法 应用场景: 批量加载, 要么一起成功, 要么一起失败 练习: /* 需求: 无序加载图片, 只有所有图片都加载成功才添加, 有一张图片失败都不添加 */ let arr = [ \"http://www.xxx.com/picture_1.png\", \"http://www.xxx.com/picture_2.png\", \"http://wwww.xxx.com/files/picture_3.png\" ]; function loadImage(url) { return new Promise(function (resolve, reject) { let oImg = new Image(); let time = Math.random() * 1000; // console.log(time); setTimeout(function () { oImg.src = url; }, time); // oImg.src = url; oImg.onload = function () { resolve(oImg); } oImg.onerror = function () { reject(\"图片加载失败了\"); } }); } Promise.all([loadImage(arr[0]), loadImage(arr[1]),loadImage(arr[2])]) .then(function (result) { // console.log(result); result.forEach(function (oImg) { document.body.appendChild(oImg); }); }) .catch(function (e) { console.log(e); }); promise-race方法Promise的race静态方法:1.all方法接收一个数组,2.如果数组中有多个Promise对象, 谁先返回状态就听谁的, 后返回的会被抛弃3.如果数组中不是Promise对象, 那么会直接执行then方法 应用场景: 接口调试, 超时处理 场景模拟: let url = \"http://www.xxx.com/picture_1.png\"; function loadImage(url) { return new Promise(function (resolve, reject) { let oImg = new Image(); setTimeout(function () { oImg.src = url; }, 5000); oImg.onload = function () { resolve(oImg); } oImg.onerror = function () { reject(\"图片加载失败了\"); } }); } function timeout() { return new Promise(function (resolve, reject) { setTimeout(function () { reject(\"超时了\"); }, 3000); }); } Promise.race([loadImage(url), timeout()]).then(function (value) { console.log(\"成功\", value); }).catch(function (e) { console.log(\"失败\", e); });","categories":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/categories/javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/tags/javascript/"}],"author":"wst"},{"title":"【JS新特性系列】ajax,fetch,axios之间的详细区别以及优缺点","slug":"js新特性/ajax,fetch,axios之间的详细区别以及优缺点","date":"2021-10-26T02:25:32.000Z","updated":"2021-10-27T04:37:34.427Z","comments":true,"path":"2021/102634377.html","link":"","permalink":"https://409713427.github.io/2021/102634377.html","excerpt":"","text":"ajax,fetch,axios之间的详细区别以及优缺点将jQuery的ajax、axios和fetch做个简单的比较，所谓仁者见仁智者见智，最终使用哪个还是自行斟酌 1.jQuery ajax$.ajax({ type: 'POST', url: url, data: data, dataType: dataType, success: function () {}, error: function () {} }); 优缺点： 本身是针对MVC的编程,不符合现在前端MVVM的浪潮基于原生的XHR开发，XHR本身的架构不清晰，已经有了fetch的替代方案JQuery整个项目太大，单纯使用ajax却要引入整个JQuery非常的不合理（采取个性化打包的方案又不能享受CDN服务） 2.fetch和Ajax一样都是用于请求网络数据的fetch是ES6中新增的, 基于Promise的网络请求方法 fetch(\"http://127.0.0.1/jQuery/Ajax/xx.php\", { method: \"post\", body: JSON.stringify({teacher:\"hhh\", age:666}) }).then(function (res) { //res是response对象 // console.log(res.text()); //.text()返回promise对象 // return res.text(); return res.json(); }).then(function (data) { console.log(data); console.log(typeof data); }).catch(function (e) { console.log(e); }); 优缺点： 符合关注分离，没有将输入、输出和用事件来跟踪的状态混杂在一个对象里更好更方便的写法更加底层，提供的API丰富（request, response）脱离了XHR，是ES规范里新的实现方式1）fetchtch只对网络请求报错，对400，500都当做成功的请求，需要封装去处理2）fetch默认不会带cookie，需要添加配置项3）fetch不支持abort，不支持超时控制，使用setTimeout及Promise.reject的实现的超时控制并不能阻止请求过程继续在后台运行，造成了量的浪费4）fetch没有办法原生监测请求的进度，而XHR可以 3.axiosAxios 是一个基于 promise 的 HTTP 库网络请求插件. /* 3.全局的 axios 默认值 在企业开发中项目分为 :开发阶段和部署阶段, 这两个阶段项目存储的位置是不同的 项目上线前存储在企业内部测试服务器上, 项目上线后存储在企业正式服务器上 所以如果每次请求都将请求的地址写在请求中, 那么项目上线时需要大量修改请求地址 为了解决这个问题, 我们可以配置一个全局URL根地址, 项目上线时只需要修改根地址即可 例如: 上线前地址是: http://127.0.0.1/jQuery/Ajax/xx.php 上线后地址是: http://192.199.13.14/jQuery/Ajax/xx.php */ axios.defaults.timeout = 2000; axios.defaults.baseURL = \"http://127.0.0.1\"; axios.post(\"/jQuery/Ajax/xx.php\", { teacher: \"lnj\", age: 666 }) .then(function (res) { console.log(res.data); }) .catch(function (e) { console.log(e); }); 优缺点： 从 node.js 创建 http 请求 支持 Promise API 客户端支持防止CSRF 自动转换JSON数据 提供了一些并发请求的接口（重要，方便了很多的操作） 为什么要用axios?axios 是一个基于Promise 用于浏览器和 nodejs 的 HTTP 客户端，它本身具有以下特征： 从浏览器中创建 XMLHttpRequest从 node.js 发出 http 请求支持 Promise API拦截请求和响应转换请求和响应数据取消请求自动转换JSON数据客户端支持防止CSRF/XSRF","categories":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/categories/javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/tags/javascript/"}],"author":"wst"},{"title":"【JS新特性系列】H5新增存储方案有以及同源跨域访问请求","slug":"js新特性/同源与跨域访问请求","date":"2021-10-25T04:35:32.000Z","updated":"2021-10-27T04:37:34.428Z","comments":true,"path":"2021/102545839.html","link":"","permalink":"https://409713427.github.io/2021/102545839.html","excerpt":"","text":"JS新特性H5新增存储方案1.SessionStorage和LocalStorage简介 和Cookie一样, SessionStorage和LocalStorage也是用于存储网页中的数据的 2.Cookie、 SessionStorage、LocalStorage区别 2.1生命周期(同一浏览器下) Cookie生命周期: 默认是关闭浏览器后失效, 但是也可以设置过期时间 SessionStorage生命周期: 仅在当前会话(窗口)下有效，关闭窗口或浏览器后被清除, 不能设置过期时间 LocalStorage生命周期: 除非被清除，否则永久保存 ​ 2.2容量​ Cookie容量: 有大小(4KB左右)和个数(20~50)限制​ SessionStorage容量: 有大小限制(5M左右) 老外写的SessionStorage支撑测试​ LocalStorage容量: 有大小限制(5M左右) 老外写的LocalStorage支撑测试 ​ 2.3网络请求​ Cookie网络请求: 每次都会携带在HTTP头中，如果使用cookie保存过多数据会带来性能问题​ SessionStorage网络请求: 仅在浏览器中保存，不参与和服务器的通信​ LocalStorage网络请求: 仅在浏览器中保存，不参与和服务器的通信 3.Cookie、 SessionStorage、LocalStorage应用场景 Cookie: 判断用户是否登录 LocalStorage: 购物车 sessionStorage: 表单数据 4.注意点: 无论通过以上哪种方式存储的数据, 切记不能将敏感数据直接存储到本地 示例: // 存储cookie document.cookie = \"myName=hhh;path=/;domain=127.0.0.1;\"; //存储sessionStorage,删除sessionStorage,清空sessionStorage sessionStorage.setItem(\"age\", \"34\"); sessionStorage.removeItem(\"age\"); sessionStorage.clear(); //存储localStorage,删除localStorage,清空localStorage localStorage.setItem(\"name\", \"lnj\"); localStorage.removeItem(\"name\"); localStorage.clear(); 同源策略1.什么是同源策略? 同源策略（Same origin policy）是一种约定，它是浏览器最核心也最基本的安全功能 所谓同源是指: 协议，域名，端口都相同,就是同源, 否则就是跨域 ​ http://www.baidu.com:80/index.html​ 协议: http/https/…​ 一级域名: baidu.com/taobao.com​ 二级域名: www/study/edu/…​ 端口号: 80/3306/… // 协议+一级域名+二级域名+端口号都相同, 所以同源 http://www.it666.com:80/index.html http://www.it666.com:80/detail.html // 协议不同, 所以不同源, 是跨域 http://www.it666.com:80/index.html https://www.it666.com:80/index.html // 一级域名不同, 所以不同源, 是跨域 http://www.it666.com:80/index.html http://www.itzb.com:80/index.html // 二级域名不同, 所以不同源, 是跨域 http://www.it666.com:80/index.html http://edu.it666.com:80/index.html // 端口号不同, 所以不同源, 是跨域 http://www.it666.com:80/index.html http://www.it666.com:8090/index.html //ajax默认同源 $.ajax({ url:\"http://127.0.0.1:80/jQuery/Ajax/xxx.php\", success: function (msg) { console.log(msg); }, error: function () { console.log(\"请求失败\"); } }); 2.同源策略带来的影响 在同源策略下, 浏览器只允许Ajax请求同源的数据, 不允许请求不同源的数据 但在企业开发中, 一般情况下为了提升网页的性能, 网页和数据都是单独存储在不同服务器上的 这时如果再通过Ajax请求数据就会拿不到跨域数据 3.跨域解决方案(除第一种 剩下的基本不用了) jsonp document.domain+iframe location.hash + iframe window.name + iframe window.postMessage flash等第三方插件 JSONP 什么是JSONP?JSONP让网页从别的地址（跨域的地址）那获取资料，即跨域读取数据 JSONP实现跨域访问的原理2.1 在同一界面中可以定义多个script标签2.2 同一个界面中多个script标签中的数据可以相互访问2.3 可以通过script的src属性导入其它资源2.4 通过src属性导入其它资源的本质就是将资源拷贝到script标签中2.5 script的src属性不仅能导入本地资源, 还能导入远程资源2.6 由于script的src属性没有同源限制, 所以可以通过script的src属性来请求跨域数据 &lt;script src=\"http://libs.baidu.com/jquery/2.0.0/jquery.min.js\"> &lt;script src=\"http://127.0.0.1:80/jQuery/Ajax/xx.php\"> /* 当前网页的地址: http://127.0.0.1:63342/jQuery/Ajax/jsonp%E5%8E%9F%E7%90%86.html 远程资源的地址: http://127.0.0.1:80/jQuery/Ajax/jsonp.php */ /* 优化一 1.在企业开发中通过JSONP来获取跨域的数据, 一般情况下服务器返回的都不会是一个变量, 而是一个函数的调用 */ /* 优化二 2.当前服务器返回的函数调用名称写死了 例如服务前返回demo() ,那么本地就必须有一个 服务器返回函数叫什么名称, 我们本地就必须定义一个叫什么名称的函数 解决方案: 通过URL参数的方式来动态指定函数名称 例:http://127.0.0.1:80/jQuery/Ajax/20-jsonp.php?cb=test cb=test就是指定返回的函数调用名为test,后台获取到就可以定义一个test方法返回 */ /* 优化三 3.由于script标签默认是同步, 前面的script标签没有加载完数据, 后面的script标签就不会被执行 所以请求数据的script标签必须放到后面 解决方案: 通过JS动态创建script标签, 因为JS动态创建的script标签默认就是异步的, 不用等到前面的标签加载完就可以执行后面的script标签 */ let oScript = document.createElement(\"script\"); oScript.src = \"http://127.0.0.1:80/jQuery/Ajax/20-jsonp.php?cb=test\"; document.body.appendChild(oScript); jQuery中jsonp使用$.ajax({ url: \"http://127.0.0.1:80/jQuery/Ajax/jsonp.php\", data:{ \"name\": \"wst\", \"age\": 21 }, dataType: \"jsonp\", // 告诉jQuery需要请求跨域的数据 jsonp: \"cb\", // 告诉jQuery服务器在获取回调函数名称的时候需要用什么key来获取 jsonpCallback: \"wst\", // 告诉jQuery服务器在获取回调函数名称的时候回调函数的名称是什么 success: function (msg) { console.log(msg); } }); jQuery封装JSONP原理//自己封装的jsonp function obj2str(obj) { // 生成随机因子 obj.t = (Math.random() + \"\").replace(\".\", \"\"); let arr = []; for(let key in obj){ arr.push(key + \"=\" + encodeURI(obj[key])); } let str = arr.join(\"&amp;\"); // console.log(str); return str; } function myJSONP(options) { options = options || {}; // http://127.0.0.1/jQuery/Ajax/jsonp.php?cb=wst&amp;name=wst&amp;age=21&amp;_=1559735634387 // http://127.0.0.1/jQuery/Ajax/jsonp.php?cb=wst&amp;name=wst&amp;age=21&amp;t=08520581619221432 // 1.生成URL地址 let url = options.url; if(options.jsonp){ url += \"?\" + options.jsonp + \"=\"; }else{ url += \"?callback=\"; } let callbackName = (\"jQuery\" + Math.random()).replace(\".\", \"\"); if(options.jsonpCallback){ callbackName = options.jsonpCallback; url += options.jsonpCallback; }else{ // console.log(callbackName); url += callbackName; } if(options.data){ let str = obj2str(options.data); url += \"&amp;\" + str; } // console.log(url); // 2.获取跨域的数据 let oScript = document.createElement(\"script\"); oScript.src = url; document.body.appendChild(oScript); // 3.定义回调函数 window[callbackName] = function (data) { // 删除已经获取了数据的script标签 document.body.removeChild(oScript); // 将获取到的数据返回给外界 options.success(data); } } //调用自己定义的jsonp myJSONP({ url: \"http://127.0.0.1:80/jQuery/Ajax/jsonp.php\", data:{ \"name\": \"wst\", \"age\": 21 }, jsonp: \"cb\", // 告诉jQuery服务器在获取回调函数名称的时候需要用什么key来获取 jsonpCallback: \"wst\", // 告诉jQuery服务器在获取回调函数名称的时候回调函数的名称是什么 success: function (msg) { console.log(msg); } });","categories":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/categories/javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/tags/javascript/"}],"author":"wst"},{"title":"【Linux安装插件系列】Linux安装配置tomcat9.0","slug":"Linux服务器上安装tomcat","date":"2021-10-21T05:40:32.000Z","updated":"2021-10-21T05:54:07.928Z","comments":true,"path":"2021/102136523.html","link":"","permalink":"https://409713427.github.io/2021/102136523.html","excerpt":"","text":"Linux服务器上安装tomcat 安装软件 ： apache-tomcat-9.0.0.M1.tar.gz（下载地址http://tomcat.apache.org/） 步骤一 Tomcat是其中一个开源的且免费的java Web服务器，是Apache软件基金会的项目，所以安装Tomcat之前要安装java JDk，请参照Linux安装jdk1.8 步骤二 下载Tomcat9 ​ 将文件移动到apache-tomcat-9.0.0.M1.tar.gz移动到/usr/tomcat/下，并解压： 解压命令 : tar -xzvf apache-tomcat-10.0.12.tar.gz 并修改文件名 mv apache-tomcat-10.0.12 apache-tomcat-10.0.12-8082 再次解压apache-tomcat-10.0.12.tar.gz 文件，并修改解压后的文件价名为apache-tomcat-10.0.12-8082，得到 ​ 步骤三 修改端口，分别修改tomcat里面conf/server.xml server.xml文件中有三个端口设置 &lt;Server port=\"8005\" shutdown=\"SHUTDOWN\"> ：关闭时使用 &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /> ： 一般应用使用 &lt;Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" />：为AJP端口，即容器使用，如 APACHE能通过AJP协议访问Tomcat的8009端口 第一个80的tomcat的三个端口分别修改为：8005/80/8009 第二个8082的tomcat的三个端口分别修改为：7082/8082/9082 步骤四 启动tomcat，分别进入tomcat里面的bin目录 执行： ./startup.sh –&gt;启动tomcat 执行： ./shutdown.sh –&gt;关闭tomcat 浏览器中输入：http://ip:80 和http://ip:8082（ip指服务器的IP地址），即可访问不同的tomcat 步骤五 设置tomcat开机启动 1、找到/etc文件夹下的rc.local文件（有的是在/etc/rc.d文件夹下），在文件的最后添加以下java环境变量和启动tomcat命令： export JAVA_HOME=/home/wst/jdk1.8 export JRE_HOME=$JAVA_HOME/jre sh /home/wst/Documents/tomcat10/apache-tomcat-10.0.12-80/bin/startup.sh（启动命令，可以配置条） 保存退出 :wq 2、给rc.local文件添加执行权限 chmod +x rc.local 3、重启服务器，即可访问Tomcat reboot","categories":[{"name":"linux","slug":"linux","permalink":"https://409713427.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://409713427.github.io/tags/linux/"}],"author":"wst"},{"title":"【Linux安装插件系列】Linux安装配置jdk1.8","slug":"Linux安装jdk1.8","date":"2021-10-19T05:30:32.000Z","updated":"2021-10-21T05:54:06.762Z","comments":true,"path":"2021/101936523.html","link":"","permalink":"https://409713427.github.io/2021/101936523.html","excerpt":"","text":"Linux安装jdk1.8第一次再Linux安装jdk并且配置环境,为了以后查看,在这里记录一下. linux 下安装jdk和windows下的安装是一样的，之前在windows安装的时候是先下载压缩包，然后再配置环境变量。其实在linux下也是一样的。 第一步：创建jdk安装目录(该/usr/local/src 目录是空的,最好把我们自己下载的放到这,容易区分)命令： mkdir -p /usr/local/src/jdk 第二步：查看安装程序命令：rpm -qa | grep -i jdk 若之前安装过jdk，下次安装一定把之前的删除干净 第三步：下载jdk包需要联网，下载也需要点时间）此次使用的为后缀为tar.gz的文件（不需要安装），如jdk-8u131-linux-x64.tar.gz 安装指令: [root@master wst]# wget --no-check-certificate --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz 注意：如果上面wget命令不能用,报错：-bash: wget: command not found。执行一下该命令(安装依赖包) yum -y install wget 注意 : 记住需要加上：–no-check-certificate –no-cookies –header “Cookie: oraclelicense=accept-securebackup-cookie” 这段是为了避开用户验证用的 第四步：解压解压命令 : tar -zxvf jdk-8u131-linux-x64.tar.gz 系统会生成一个名为：jdk1.8.0_131 的文件夹。可以使用mv命令自定义文件名。 更改文件夹名称 : mv jdk1.8.0_131 jdk1.8 第五步：配置环境变量 编辑配置文件: vi /etc/profile 可以看到这个文件的内容，profile文件有点类似于windows系统里面的环境变量的配置， shift + g 定位到最后一行 这个时候按一下a或i键，进入编辑模式 export JAVA_HOME=/usr/local/src/jdk/jdk1.8 export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 第六步：退出文件，保存​ 按Esc键 输入:wq 保存并退出 第七步：让配置文件生效# source /etc/profile 第八步：查看是否配置成功[root@master wst]# java -version 若出现jdk版本号，则安装并配置环境变量成功 ​ 如果提示命令找不到的话，查看一下jdk的配置路径是否错误。","categories":[{"name":"linux","slug":"linux","permalink":"https://409713427.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://409713427.github.io/tags/linux/"}],"author":"wst"},{"title":"【Linux安装插件系列】Linux安装配置mysql8.0","slug":"Linux-CentOS7安装mysql8.0","date":"2021-10-15T05:35:32.000Z","updated":"2021-10-21T05:58:54.781Z","comments":true,"path":"2021/101536523.html","link":"","permalink":"https://409713427.github.io/2021/101536523.html","excerpt":"","text":"Linux-CentOS7安装mysql8.0密码策略： https://blog.csdn.net/Hello_World_QWP/article/details/79551789 CentOS7安装mysql8.0步骤1.1 安装前清理工作,第一次安装请忽略； 1.1.1 清理原有的mysql数据库； 使用以下命令查找出安装的mysql软件包和依赖包： rpm -pa | grep mysql 显示结果如下： mysql80-community-release-el7-1.noarch mysql-community-server-8.0.11-1.el7.x86_64 mysql-community-common-8.0.11-1.el7.x86_64 mysql-community-libs-8.0.11-1.el7.x86_64 mysql-community-client-8.0.11-1.el7.x86_64 使用以下命令依次删除上面的程序 yum remove mysql-xxx-xxx- 删除mysql的配置文件，卸载不会自动删除配置文件，首先使用如下命令查找出所用的配置文件； find / -name mysql 可能的显示结果如下： /etc/logrotate.d/mysql /etc/selinux/targeted/active/modules/100/mysql /etc/selinux/targeted/tmp/modules/100/mysql /var/lib/mysql /var/lib/mysql/mysql /usr/bin/mysql /usr/lib64/mysql /usr/local/mysql 根据需求使用以下命令 依次 对配置文件进行删除 rm -rf /var/lib/mysql 1.1.2 删除MariaDB的文件，由于MySQL在CentOS7中收费了，所以已经不支持MySQL了，取而代之在CentOS7内部集成了mariadb，而安装MySQL的话会和MariaDB的文件冲突，所以需要先卸载掉MariaDB. 使用rpm 命令查找出要删除的mariadb文件； rpm -pa | grep mariadb 可能的显示结果如下： mariadb-libs-5.5.56-2.el7.x86_64 rpm -e mariadb-libs-5.5.56-2.el7.x86_64 #删除上面的程序 可能出现错误提示如下： 依赖检测失败： libmysqlclient.so.18()(64bit) 被 (已安裝) postfix-2:2.10.1-6.el7.x86_64 需要 libmysqlclient.so.18(libmysqlclient_18)(64bit) 被 (已安裝) postfix-2:2.10.1-6.el7.x86_64 需要 libmysqlclient.so.18(libmysqlclient_18)(64bit) 被 (已安裝) postfix-2:2.10.1-6.el7.x86_64 需要 使用强制删除： rpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64 至此就将原来有的mysql 和mariadb数据库删除了； 1.2 安装mysql1.2.1 下面mysql官网提供的mysql repo源 centos的yum 源中默认是没有mysql的，所以我们需要先去官网下载mysql的repo源并安装； mysql官网下载链接：mysql repo下载地址 如下：https://dev.mysql.com/downloads/ 1.2.2 下载软件包rpm文件文件下载到home/wst/Documents/mysql8.0文件夹下； cd home/wst/Documents mkdir mysql8.0 cd mysql8.0 wget https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm 1.2.3 安装 yum repo文件并更新 yum 缓存；rpm -ivh mysql80-community-release-el7-1.noarch.rpm 执行结果： 会在/etc/yum.repos.d/目录下生成两个repo文件mysql-community.repo mysql-community-source.repo 更新 yum 命令 yum clean all yum makecache 1.2.4 使用 yum安装mysql当我们在使用yum安装mysql时，yum默认会从yum仓库中安装mysql最新的GA版本；如何选择自己的版本； 第一步： 查看mysql yum仓库中mysql版本，使用如下命令 yum repolist all | grep mysql 可以看到 MySQL 5.5 5.6 5.7为禁用状态 而MySQL 8.0为启用状态； 第二步 使用 yum-config-manager 命令修改相应的版本为启用状态最新版本为禁用状态，根据需要安装的版本修改 yum-config-manager --disable mysql80-community #关闭8.0版本 yum-config-manager --enable mysql57-community #开启5.7版本 或者可以编辑 mysql repo文件， cat /etc/yum.repos.d/mysql-community.repo 将相应版本下的enabled改成 1 即可； 1.2.5 安装mysql 命令如下：yum install mysql-community-server 1.2.6 开启mysql 服务systemctl start mysqld.service 1.2.7 获取初始密码登录mysqlmysql在安装后会创建一个root@locahost账户，并且把初始的密码放到了/var/log/mysqld.log文件中； cat /var/log/mysqld.log | grep password 使用初始密码登录mysql jKw)wB/&lt;X4?z mysql -u root -p #会提示输入密码 修改初始密码：ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!';#注意位数和种类至少大+写+小写+符号+数字 忘记密码重置密码[重置密码解决MySQL for Linux错误 ERROR 1045 (28000): Access denied for user ‘root‘@’localhost’ (using password: YES)] vim /etc/my.cnf #注：windows下修改的是my.ini skip-grant-tables# 在[mysqld]后面任意一行添加skip-grant-tables用来跳过密码验证的过程;设置完密码记得删除 systemctl restart mysqld.service #重启mysql ，就可以免密码登陆了，然后进行修改密码 1.2.8 在防火墙中开启3306端口CentOS7默认使用的是firewall作为防火墙，我这里改为习惯常用的iptables防火墙 第一步：开启firewall3306端口防火墙 firewall-cmd --zone=public --list-ports 查看所有打开的端口 firewall-cmd --zone=public --add-port=80/tcp --permanent 开启一个端口，添加--permanent永久生效，没有此参数重启后失效 firewall-cmd --permanent --add-port=80/tcp 开放端口80 firewall-cmd --permanent --remove-port=80/tcp 移除端口80 firewall-cmd --reload 重启防火墙，修改后重启防火墙生效 第五步： 重启防火墙 systemctl enable iptables.service systemctl start iptables.service 1.2.9 将mysql 服务加入开机启动项，并启动mysql进程 systemctl enable mysqld.service systemctl start mysqld.service 常用mysql服务命令： mysql -u username -p #登录mysql quit #退出mysql systemctl start mysqld.service #启动mysql systemctl stop mysqld.service #结束 systemctl restart mysqld.service #重启 systemctl enable mysqld.service #开机自启 select version(); #查看mysql版本 2.1 开启mysql远程服务：外网 Navicat 连接 Mysql 2.1.1 修改mysql数据库下的user表中host的值可能是你的帐号不允许从远程登陆，只能在localhost。这个时候只要在localhost的那台电脑，登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改称”%”登录mysql数据库 执行如下命令： mysql -u root -p use mysql; update user set host='%' where user='root'; 2.1.2 使用授权的方式赋予任何主机访问数据的权限 mysql> GRANT ALL PRIVILEGES ON *.* TO 'root'@'%'WITH GRANT OPTION; mysql>FLUSH PRIVILEGES 如果想myuser用户使用mypassword密码从任何主机连接到mysql服务器的话。 GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'%'IDENTIFIED BY 'mypassword' WITH GRANT OPTION; 如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器，并使用mypassword作为密码 GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'192.168.1.3'IDENTIFIED BY 'mypassword' WITH GRANT OPTION; 2.2 在使用 Navicat for Mysql连接mysql 8.0时会报如下错误：Authentication plugin ‘caching_sha2_password’ cannot be loaded: mysql8.0 引入了新特性 caching_sha2_password；这种密码加密方式客户端不支持；客户端支持的是mysql_native_password 这种加密方式； 我们可可以查看mysql 数据库中user表的 plugin字段； 可以使用命令将他修改成mysql_native_password加密模式： update user set plugin='mysql_native_password' where user='root'; 再用Navicat链接 就可以链接成功； 安装过程中涉及到的Linux命令学习； 3.1 rpm 3.2 putty 上传文件 pscp命令； 在window机上CD进入pttty安装目录： cd :\\program files (x86)\\Putty 将本地文件拷贝到Linux上：pscp 文件 用户名@LinuxIP:目录 pscp hello.txt root@192.168.145.135:/tmp/userfile/ 将本地文件夹 拷贝到Linux上：pscp -r 目录 用户名@LinuxIP:目录 pscp -r c:\\file root@10.43.65.98:/root/testFolder 将Linux上的文件\\root\\test.txt拷贝到本地C盘src文件夹，如下： pscp root@abc_pc:/root/test.txt C:\\src 3.3 修改防火墙文件/etc/sysconfig/iptables 3.4 systemctl命令 授权外网登陆 1。 改表法。 可能是你的帐号不允许从远程登陆，只能在localhost。这个时候只要在localhost的那台电脑，登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改成”%” Sql代码 1. mysql -u root -pvmwaremysql>use mysql; 2. mysql>update user set host = '%' where user = 'root'; 3. mysql>select host, user from user; 授权法。 例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。 Sql代码 GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'%' IDENTIFIED BY 'mypassword' WITH GRANT OPTION; FLUSH PRIVILEGES; 如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器的dk数据库，并使用mypassword作为密码 Sql代码 GRANT ALL PRIVILEGES ON dk.* TO 'myuser'@'192.168.1.3' IDENTIFIED BY 'mypassword' WITH GRANT OPTION; FLUSH PRIVILEGES; 注意授权后必须FLUSH PRIVILEGES;否则无法立即生效。 3 另外一种方法. 在安装mysql的机器上运行： 1、d:\\mysql\\bin\\>mysql -h localhost -u root //这样应该可以进入MySQL服务器 2、mysql>GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION //赋予任何主机访问数据的权限 3、mysql>FLUSH PRIVILEGES //修改生效 4、mysql>EXIT //退出MySQL服务器 这样就可以在其它任何的主机上以root身份登录啦！ 其它： mysql> grant all privileges on *.* to 'energy_pf'@'192.168.2.65' identified by 'energy_pf' with grant option; Query OK, 0 rows affected (0.00 sec) mysql> plush privileges; #立即生效 允许用户energy_pf从ip为192.168.2.65的主机连接到mysql服务器的任意数据库（*.*），并使用energy_pf作为密码","categories":[{"name":"linux","slug":"linux","permalink":"https://409713427.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://409713427.github.io/tags/linux/"}],"author":"wst"},{"title":"java基础【抽象类，接口、代码块、final、单例、枚举】","slug":"day02-抽象类，接口、代码块、final、单例、枚举","date":"2021-09-19T12:02:32.000Z","updated":"2021-10-21T05:33:56.009Z","comments":true,"path":"2021/091936523.html","link":"","permalink":"https://409713427.github.io/2021/091936523.html","excerpt":"","text":"java基础【抽象类，接口、代码块、final、单例、枚举】第一章 抽象类1.1 概述1.1.1 抽象类引入父类中的方法，被它的子类们重写，子类各自的实现都不尽相同。那么父类的方法声明和方法主体，只有声明还有意义，而方法主体则没有存在的意义了(因为子类对象会调用自己重写的方法)。换句话说，父类可能知道子类应该有哪个功能，但是功能具体怎么实现父类是不清楚的（由子类自己决定），父类完全只需要提供一个没有方法体的方法签名即可，具体实现交给子类自己去实现。我们把没有方法体的方法称为抽象方法。Java语法规定，包含抽象方法的类就是抽象类。 抽象方法 ： 没有方法体的方法。 抽象类：包含抽象方法的类。 1.2 abstract使用格式abstract是抽象的意思，用于修饰方法方法和类，修饰的方法是抽象方法，修饰的类是抽象类。 1.2.1 抽象方法使用abstract 关键字修饰方法，该方法就成了抽象方法，抽象方法只包含一个方法名，而没有方法体。 定义格式： 修饰符 abstract 返回值类型 方法名 (参数列表)； 代码举例： public abstract void run()； 1.2.2 抽象类如果一个类包含抽象方法，那么该类必须是抽象类。注意：抽象类不一定有抽象方法，但是有抽象方法的类必须定义成抽象类。 定义格式： abstract class 类名字 { } 代码举例： public abstract class Animal { public abstract void run()； } 1.2.3 抽象类的使用要求：继承抽象类的子类必须重写父类所有的抽象方法。否则，该子类也必须声明为抽象类。 代码举例： // 父类,抽象类 abstract class Employee { private String id; private String name; private double salary; public Employee() { } public Employee(String id, String name, double salary) { this.id = id; this.name = name; this.salary = salary; } // 抽象方法 // 抽象方法必须要放在抽象类中 abstract public void work(); } // 定义一个子类继承抽象类 class Manager extends Employee { public Manager() { } public Manager(String id, String name, double salary) { super(id, name, salary); } // 2.重写父类的抽象方法 @Override public void work() { System.out.println(\"管理其他人\"); } } // 定义一个子类继承抽象类 class Cook extends Employee { public Cook() { } public Cook(String id, String name, double salary) { super(id, name, salary); } @Override public void work() { System.out.println(\"厨师炒菜多加点盐...\"); } } // 测试类 public class Demo10 { public static void main(String[] args) { // 创建抽象类,抽象类不能创建对象 // 假设抽象类让我们创建对象,里面的抽象方法没有方法体,无法执行.所以不让我们创建对象 // Employee e = new Employee(); // e.work(); // 3.创建子类 Manager m = new Manager(); m.work(); Cook c = new Cook(\"ap002\", \"库克\", 1); c.work(); } } 此时的方法重写，是子类对父类抽象方法的完成实现，我们将这种方法重写的操作，也叫做实现方法。 1.3 抽象类的特征抽象类的特征总结起来可以说是 有得有失 有得：抽象类得到了拥有抽象方法的能力。 有失：抽象类失去了创建对象的能力。 其他成员（构造器，实例方法，静态方法等）抽象类都是具备的。 1.4 抽象类的注意事项关于抽象类的使用，以下为语法上要注意的细节，虽然条目较多，但若理解了抽象的本质，无需死记硬背。 抽象类不能创建对象，如果创建，编译无法通过而报错。只能创建其非抽象子类的对象。 理解：假设创建了抽象类的对象，调用抽象的方法，而抽象方法没有具体的方法体，没有意义。 抽象类中，可以有构造器，是供子类创建对象时，初始化父类成员使用的。 理解：子类的构造方法中，有默认的super()，需要访问父类构造方法。 抽象类中，不一定包含抽象方法，但是有抽象方法的类必定是抽象类。 理解：未包含抽象方法的抽象类，目的就是不想让调用者创建该类对象，通常用于某些特殊的类结构设计。 抽象类的子类，必须重写抽象父类中所有的抽象方法，否则子类也必须定义成抽象类，编译无法通过而报错。 理解：假设不重写所有抽象方法，则类中可能包含抽象方法。那么创建对象后，调用抽象的方法，没有意义。 抽象类存在的意义是为了被子类继承，抽象类体现的是模板思想。 理解：抽象类中已经实现的是模板中确定的成员，抽象类不确定如何实现的定义成抽象方法，交给具体的子类去实现。 1.5 抽象类存在的意义抽象类存在的意义是为了被子类继承，否则抽象类将毫无意义，抽象类体现的是模板思想，模板是通用的东西抽象类中已经是具体的实现（抽象类中可以有成员变量和实现方法），而模板中不能决定的东西定义成抽象方法，让使用模板（继承抽象类的类）的类去重写抽象方法实现需求，这是典型的模板思想。 1.6 第一个设计模式：模板模式我们现在使用抽象类设计一个模板模式的应用，例如在小学的时候，我们经常写作文，通常都是有模板可以套用的。假如我现在需要定义新司机和老司机类，新司机和老司机都有开车功能，开车的步骤都一样，只是驾驶时的姿势有点不同，新司机:开门,点火,双手紧握方向盘,刹车,熄火，老司机:开门,点火,右手握方向盘左手抽烟,刹车,熄火。我们可以将固定流程写到父类中，不同的地方就定义成抽象方法，让不同的子类去重写，代码如下: // 司机开车的模板类 public abstract class Driver { public void go() { System.out.println(\"开门\"); System.out.println(\"点火\"); // 开车姿势不确定?定义为抽象方法 ziShi(); System.out.println(\"刹车\"); System.out.println(\"熄火\"); } public abstract void ziShi(); } 现在定义两个使用模板的司机： public class NewDriver extends Driver { @Override public void ziShi() { System.out.println(\"新司机双手紧握方向盘\"); } } public class OldDriver extends Driver { @Override public void ziShi() { System.out.println(\"老司机右手握方向盘左手抽烟...\"); } } 编写测试类 public class Demo02 { public static void main(String[] args) { NewDriver nd = new NewDriver(); nd.go(); OldDriver od = new OldDriver(); od.go(); } } 可以看出，模板模式的优势是，模板已经定义了通用架构，使用者只需要关心自己需要实现的功能即可！非常的强大！ 第二章 接口2.1 概述我们已经学完了抽象类，抽象类中可以用抽象方法，也可以有普通方法，已经构造器，成员变量等。那么什么是接口呢？接口是更加彻底的抽象，接口中全部是抽象方法。（JDK8之前），接口同样是不能创建对象的。 2.2 定义格式//接口的定义格式： 修饰符 interface 接口名称{ // 抽象方法 } // 修饰符：public|缺省 // 接口的声明：interface // 接口名称：首字母大写，满足“驼峰模式” 2.3 接口成分的特点 在JDK8之前，接口中的成分包含：抽象方法和常量 2.3.1.抽象方法​ 注意：接口中的抽象方法默认会自动加上public abstract修饰程序员无需自己手写！！​ 按照规范：以后接口中的抽象方法建议不要写上public abstract。因为没有必要啊，默认会加上。 2.3.2 常量 在接口中定义的成员变量默认会加上： public static final修饰。也就是说在接口中定义的成员变量实际上是一个常量。这里是使用public static final修饰后，变量值就不可被修改，并且是静态化的变量可以直接用接口名访问，所以也叫常量。常量必须要给初始值。常量命名规范建议字母全部大写，多个单词用下划线连接。 2.3.3 案例演示public interface InterF { // 抽象方法！ // public abstract void run(); void run(); // public abstract String getName(); String getName(); // public abstract int add(int a , int b); int add(int a , int b); // 它的最终写法是： // public static final int AGE = 12 ; int AGE = 12; //常量 String SCHOOL_NAME = \"黑马程序员\"; } 2.4 基本的实现2.4.1 实现接口的概述类与接口的关系为实现关系，即类实现接口，该类可以称为接口的实现类，也可以称为接口的子类。实现的动作类似继承，格式相仿，只是关键字不同，实现使用 implements关键字。 2.4.2 实现接口的格式/**接口的实现： 在Java中接口是被实现的，实现接口的类称为实现类。 实现类的格式:*/ [修饰符] class 类名 implements 接口1,接口2,接口3...{ } 从上面格式可以看出，接口是可以被多实现的。大家可以想一想为什么呢？ 2.4.3 类实现接口的要求和意义 必须重写实现的全部接口中所有抽象方法。 如果一个类实现了接口，但是没有重写完全部接口的全部抽象方法，这个类也必须定义成抽象类。 意义：接口体现的是一种规范，接口对实现类是一种强制性的约束，要么全部完成接口申明的功能，要么自己也定义成抽象类。这正是一种强制性的规范。 2.4.4 类与接口基本实现案例假如我们定义一个运动员的接口（规范），代码如下： /** 接口：接口体现的是规范。 * */ public interface SportMan { void run(); // 抽象方法，跑步。 void law(); // 抽象方法，遵守法律。 String compittion(String project); // 抽象方法，比赛。 } 接下来定义一个乒乓球运动员类，实现接口，实现接口的实现类代码如下： package com.itheima._03接口的实现; /** * 接口的实现： * 在Java中接口是被实现的，实现接口的类称为实现类。 * 实现类的格式: * [修饰符] class 类名 implements 接口1,接口2,接口3...{ * * * } * */ public class PingPongMan implements SportMan { @Override public void run() { System.out.println(\"乒乓球运动员稍微跑一下！！\"); } @Override public void law() { System.out.println(\"乒乓球运动员守法！\"); } @Override public String compittion(String project) { return \"参加\"+project+\"得金牌！\"; } } 测试代码： public class TestMain { public static void main(String[] args) { // 创建实现类对象。 PingPongMan zjk = new PingPongMan(); zjk.run(); zjk.law(); System.out.println(zjk.compittion(\"全球乒乓球比赛\")); } } 1.4.5 类与接口的多实现案例类与接口之间的关系是多实现的，一个类可以同时实现多个接口。 首先我们先定义两个接口，代码如下： /** 法律规范：接口*/ public interface Law { void rule(); } /** 这一个运动员的规范：接口*/ public interface SportMan { void run(); } 然后定义一个实现类： /** * Java中接口是可以被多实现的： * 一个类可以实现多个接口: Law ,SportMan * * */ public class JumpMan implements Law ,SportMan { @Override public void rule() { System.out.println(\"尊长守法\"); } @Override public void run() { System.out.println(\"训练跑步！\"); } } 从上面可以看出类与接口之间是可以多实现的，我们可以理解成实现多个规范，这是合理的。 2.5 接口与接口的多继承Java中，接口与接口之间是可以多继承的：也就是一个接口可以同时继承多个接口。大家一定要注意： 类与接口是实现关系 接口与接口是继承关系 接口继承接口就是把其他接口的抽象方法与本接口进行了合并。 案例演示： public interface Abc { void go(); void test(); } /** 法律规范：接口*/ public interface Law { void rule(); void test(); } * * 总结： * 接口与类之间是多实现的。 * 接口与接口之间是多继承的。 * */ public interface SportMan extends Law , Abc { void run(); } 2.6 JDK 8之后的接口新增方法从JDK 8开始之后，接口不再纯洁了，接口中不再只是抽象方法，接口还可以有默认方法（也就是实例方法），和静态方法了，还包含了私有实例方法和私有静态方法 2.6.1 含有默认方法和静态方法默认方法：使用 default 修饰，不可省略，供子类调用或者子类重写。 静态方法：使用 static 修饰，供接口直接调用。 代码如下： public interface InterFaceName { public default void method() { // 执行语句 } public static void method2() { // 执行语句 } } 2.6.2 含有私有方法和私有静态方法私有方法：使用 private 修饰，供接口中的默认方法或者静态方法调用。 代码如下： public interface InterFaceName { private void method() { // 执行语句 } } 2.6.3 新增方法的使用默认方法和静态方法以及私有方法和私有静态方法，遵循面向对象的继承关系使用原则，实现类依然可以访问接口的非私有方法，对于接口中的非私有静态方法，可以直接通过接口名进行访问。 重写默认方法注意（了解）: 子接口重写默认方法时，default关键字可以保留。 实现类重写默认方法时，default关键字不可以保留。 2.7 实现多个接口使用注意事项2.7.1 多个接口同名静态方法如果实现了多个接口，多个接口中存在同名的静态方法并不会冲突，原因是只能通过各自接口名访问静态方法。 public interface A { public static void test(){ } } interface B { public static void test(){ } } class C implements A , B{ public static void main(String[] args) { People.test(); B.test(); // C.test(); // 编译出错 } } 2.7.2 优先级的问题当一个类，既继承一个父类，又实现若干个接口时，父类中的成员方法与接口中的默认方法重名，子类就近选择执行父类的成员方法。代码如下： 定义接口： interface A { public default void methodA(){ System.out.println(\"AAAAAAAAAAAA\"); } } 定义父类： class D { public void methodA(){ System.out.println(\"DDDDDDDDDDDD\"); } } 定义子类： class C extends D implements A { // 未重写methodA方法 } 定义测试类： public class Test { public static void main(String[] args) { C c = new C(); c.methodA(); } } 输出结果: DDDDDDDDDDDD 2.8 接口小结 接口中，无法定义成员变量，但是可以定义常量，其值不可以改变，默认使用public static final修饰。 接口中的方法全是抽象方法，默认会自动加上public abstract修饰 JDK 8开始，接口不再纯洁，支持静态方法，默认方法，私有方法。 接口中，没有构造器，不能创建对象。 类与接口是多实现的 接口与接口是多继承的 接口体现的规范。 第三章 代码块3.1 引入类的成分：​ 1.成员变量​ 2.构造器​ 3.成员方法​ 4.代码块​ 5.内部类 我们已经学完了成员变量，构造器，成员方法，接下来我们来介绍以下代码快，代码块按照有无static可以分为静态代码块和实例代码块。 3.2 静态代码块静态代码块​ 必须有static修饰，必须放在类下。与类一起加载执行。 格式 static{ // 执行代码 } 特点： 每次执行类，加载类的时候都会先执行静态代码块一次。 静态代码块是自动触发执行的，只要程序启动静态代码块就会先执行一次。 作用：在启动程序之前可以做资源的初始化，一般用于初始化静态资源。 案例演示 public class DaimaKuaiDemo01 { public static String sc_name ; // 1.静态代码块 static { // 初始化静态资源 sc_name = \"黑马程序员！\"; System.out.println(\"静态代码块执行！\"); } public static void main(String[] args) { System.out.println(\"main方法执行\"); System.out.println(sc_name); } } 3.3 实例代码块实例代码块​ 没有static修饰，必须放在类下。与对象初始化一起加载。 格式 { // 执行代码 } 特点： 无static修饰。属于对象，与对象的创建一起执行的。 每次调用构造器初始化对象，实例代码块都要自动触发执行一次。 实例代码块实际上是提取到每一个构造器中去执行的。 作用：实例代码块用于初始化对象的资源。 案例演示 public class DaimaKuaiDemo02 { private String name ; // 实例代码块。 无static修饰。 { System.out.println(\"实例代码块执行\"); name = \"dl\"; } // 构造器 public DaimaKuaiDemo02(){ //System.out.println(\"实例代码块执行\"); } // 有参数构造器 public DaimaKuaiDemo02(String name){ //System.out.println(\"实例代码块执行\"); } public static void main(String[] args) { // 匿名对象，创建出来没有给变量。 new DaimaKuaiDemo02(); new DaimaKuaiDemo02(); new DaimaKuaiDemo02(\"xulei\"); } } // 输出三次：实例代码块执行 常用API 第四章 final关键字4.1 概述学习了继承后，我们知道，子类可以在父类的基础上改写父类内容，比如，方法重写。那么我们能不能随意的继承API中提供的类，改写其内容呢？显然这是不合适的。为了避免这种随意改写的情况，Java提供了final 关键字，用于修饰不可改变内容。 final： 不可改变，最终的含义。可以用于修饰类、方法和变量。 类：被修饰的类，不能被继承。 方法：被修饰的方法，不能被重写。 变量：被修饰的变量，有且仅能被赋值一次。 4.2 使用方式4.2.1 修饰类final修饰的类，不能被继承。 格式如下： final class 类名 { } 代码: final class Fu { } // class Zi extends Fu {} // 报错,不能继承final的类 查询API发现像 public final class String 、public final class Math 、public final class Scanner 等，很多我们学习过的类，都是被final修饰的，目的就是供我们使用，而不让我们所以改变其内容。 4.2.2 修饰方法final修饰的方法，不能被重写。格式如下： 修饰符 final 返回值类型 方法名(参数列表){ //方法体 } 代码: class Fu2 { final public void show1() { System.out.println(\"Fu2 show1\"); } public void show2() { System.out.println(\"Fu2 show2\"); } } class Zi2 extends Fu2 { // @Override // public void show1() { // System.out.println(\"Zi2 show1\"); // } @Override public void show2() { System.out.println(\"Zi2 show2\"); } } 4.2.3 修饰变量-局部变量 局部变量——基本类型基本类型的局部变量，被final修饰后，只能赋值一次，不能再更改。代码如下： public class FinalDemo1 { public static void main(String[] args) { // 声明变量，使用final修饰 final int a; // 第一次赋值 a = 10; // 第二次赋值 a = 20; // 报错,不可重新赋值 // 声明变量，直接赋值，使用final修饰 final int b = 10; // 第二次赋值 b = 20; // 报错,不可重新赋值 } } 思考，如下两种写法，哪种可以通过编译？ 写法1： final int c = 0; for (int i = 0; i &lt; 10; i++) { c = i; System.out.println(c); } 写法2： for (int i = 0; i &lt; 10; i++) { final int c = i; System.out.println(c); } 根据 final 的定义，写法1报错！写法2，为什么通过编译呢？因为每次循环，都是一次新的变量c。这也是大家需要注意的地方。 4.2.4 修饰变量-实例成员变量成员变量涉及到初始化的问题，初始化方式有显示初始化和构造器初始化，只能选择其中一个： 显示初始化(在定义成员变量的时候立马赋值)； public class Student { final int num = 10; } 构造器初始化(在构造器中赋值一次)。 注意：每个构造器中都要赋值一次！ public class Student { final int num = 10; final int num2; public Student() { this.num2 = 20; // this.num2 = 20; } public Student(String name) { this.num2 = 20; // this.num2 = 20; } } 被final修饰的常量名称，一般都有书写规范，所有字母都大写。 第五章 单例设计模式正常情况下一个类可以创建多个对象 public static void main(String[] args) { // 正常情况下一个类可以创建多个对象 Person p1 = new Person(); Person p2 = new Person(); Person p3 = new Person(); } 5.1 单例设计模式的作用单例模式，是一种常用的软件设计模式。通过单例模式可以保证系统中，应用该模式的这个类只有一个实例。即一个类只有一个对象实例。 5.2 单例设计模式实现步骤 将构造方法私有化，使其不能在类的外部通过new关键字实例化该类对象。 在该类内部产生一个唯一的实例化对象，并且将其封装为private static类型的成员变量。 定义一个静态方法返回这个唯一对象。 5.3 单例设计模式的类型根据实例化对象的时机单例设计模式又分为以下两种: 饿汉单例设计模式 懒汉单例设计模式 5.4 饿汉单例设计模式饿汉单例设计模式就是使用类的时候已经将对象创建完毕，不管以后会不会使用到该实例化对象，先创建了再说。很着急的样子，故被称为“饿汉模式”。 代码如下： public class Singleton { // 1.将构造方法私有化，使其不能在类的外部通过new关键字实例化该类对象。 private Singleton() {} // 2.在该类内部产生一个唯一的实例化对象，并且将其封装为private static类型的成员变量。 private static final Singleton instance = new Singleton(); // 3.定义一个静态方法返回这个唯一对象。 public static Singleton getInstance() { return instance; } } 5.5 懒汉单例设计模式懒汉单例设计模式就是调用getInstance()方法时实例才被创建，先不急着实例化出对象，等要用的时候才例化出对象。不着急，故称为“懒汉模式”。 代码如下： public class Singleton { // 2.在该类内部产生一个唯一的实例化对象，并且将其封装为private static类型的成员变量。 private static Singleton instance; // 1.将构造方法私有化，使其不能在类的外部通过new关键字实例化该类对象。 private Singleton() {} // 3.定义一个静态方法返回这个唯一对象。要用的时候才例化出对象 public static Singleton getInstance() { if(instance == null) { instance = new Singleton(); } return instance; } } 注意：懒汉单例设计模式在多线程环境下可能会实例化出多个对象，不能保证单例的状态。我们在学习完多线程的时候还会再讲解如何解决这个问题。 5.6 小结单例模式可以保证系统中一个类只有一个对象实例。 实现单例模式的步骤： 将构造方法私有化，使其不能在类的外部通过new关键字实例化该类对象。 在该类内部产生一个唯一的实例化对象，并且将其封装为private static类型的成员变量。 定义一个静态方法返回这个唯一对象。 第六章 枚举6.1 不使用枚举存在的问题假设我们要定义一个人类，人类中包含姓名和性别。通常会将性别定义成字符串类型，效果如下： public class Person { private String name; private String sex; public Person() { } public Person(String name, String sex) { this.name = name; this.sex = sex; } // 省略get/set/toString方法 } public class Demo01 { public static void main(String[] args) { Person p1 = new Person(\"张三\", \"男\"); Person p2 = new Person(\"张三\", \"abc\"); // 因为性别是字符串,所以我们可以传入任意字符串 } } 不使用枚举存在的问题：可以给性别传入任意的字符串，导致性别是非法的数据，不安全。 6.2 枚举的作用与应用场景枚举的作用：一个方法接收的参数是固定范围之内的时候，那么即可使用枚举。 6.3 枚举的基本语法6.3.1 枚举的概念枚举是一种特殊类。枚举是有固定实例个数的类型，我们可以把枚举理解成有固定个数实例的多例模式。 6.3.2 定义枚举的格式enum 枚举名 { 第一行都是罗列枚举实例,这些枚举实例直接写大写名字即可。 } 6.3.3 入门案例 定义枚举：BOY表示男，GIRL表示女 enum Sex { BOY, GIRL; // 男，女 } Perosn中的性别有String类型改为Sex枚举类型 public class Person { private String name; private Sex sex; public Person() { } public Person(String name, Sex sex) { this.name = name; this.sex = sex; } // 省略get/set/toString方法 } 使用是只能传入枚举中的固定值 public class Demo02 { public static void main(String[] args) { Person p1 = new Person(\"张三\", Sex.BOY); Person p2 = new Person(\"张三\", Sex.GIRL); Person p3 = new Person(\"张三\", \"abc\"); } } 5.3.4 枚举的其他内容枚举的本质是一个类，我们刚才定义的Sex枚举最终效果如下： enum Sex { BOY, GIRL; // 男，女 } // 枚举的本质是一个类，我们刚才定义的Sex枚举相当于下面的类 final class SEX extends java.lang.Enum&lt;SEX> { public static final SEX BOY = new SEX(); public static final SEX GIRL = new SEX(); public static SEX[] values(); public static SEX valueOf(java.lang.String); static {}; } 枚举的本质是一个类，所以枚举中还可以有成员变量，成员方法等。 public enum Sex { BOY(18), GIRL(16); public int age; Sex(int age) { this.age = age; } public void showAge() { System.out.println(\"年龄是: \" + age); } } public class Demo03 { public static void main(String[] args) { Person p1 = new Person(\"张三\", Sex.BOY); Person p2 = new Person(\"张三\", Sex.GIRL); Sex.BOY.showAge(); Sex.GIRL.showAge(); } } 6.4 应用场景6.5 枚举的应用枚举的作用：枚举通常可以用于做信息的分类，如性别，方向，季度等。 枚举表示性别： public enum Sex { MAIL, FEMAIL; } 枚举表示方向： public enum Orientation { UP, RIGHT, DOWN, LEFT; } 枚举表示季度 public enum Season { SPRING, SUMMER, AUTUMN, WINTER; } 6.6 小结 枚举类在第一行罗列若干个枚举对象。（多例） 第一行都是常量，存储的是枚举类的对象。 枚举是不能在外部创建对象的，枚举的构造器默认是私有的。 枚举通常用于做信息的标志和分类。","categories":[{"name":"java","slug":"java","permalink":"https://409713427.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://409713427.github.io/tags/java/"}],"author":"wst"},{"title":"Java基础 【继承，引用类型使用】","slug":"Java基础 【继承，引用类型使用】","date":"2021-09-17T12:02:32.000Z","updated":"2021-09-19T04:12:24.015Z","comments":true,"path":"2021/091736523.html","link":"","permalink":"https://409713427.github.io/2021/091736523.html","excerpt":"","text":"Java基础 【继承，引用类型使用】第一章 继承1.1 定义​ 继承就是子类继承父类的属性和行为，使得子类对象可以直接具有与父类相同的属性、相同的行为。子类可以直接访问父类中的非私有的属性和行为 1.2 继承的好处 1. 提高**代码的复用性**（减少代码冗余，相同代码重复利用）。 2. 使类与类之间产生了关系。 1.3 子类不能继承的内容1.3.1 引入并不是父类的所有内容都可以给子类继承的： 子类不能继承父类的构造器，因为子类有自己的构造器。 值得注意的是子类可以继承父类的私有成员（成员变量，方法），只是子类无法直接访问而已，可以通过getter/setter方法访问父类的private成员变量。 1.3.2 演示代码public class Demo03 { public static void main(String[] args) { Zi z = new Zi(); System.out.println(z.num1); // System.out.println(z.num2); // 私有的子类无法使用 // 通过getter/setter方法访问父类的private成员变量 System.out.println(z.getNum2()); z.show1(); // z.show2(); // 私有的子类无法使用 } } class Fu { public int num1 = 10; private int num2 = 20; public void show1() { System.out.println(\"show1\"); } private void show2() { System.out.println(\"show2\"); } public int getNum2() { return num2; } public void setNum2(int num2) { this.num2 = num2; } } class Zi extends Fu { } 小贴士：父类中的成员变量是非私有的，子类中可以直接访问。若父类中的成员变量私有了，子类是不能直接访问的。通常编码时，我们遵循封装的原则，使用private修饰成员变量，那么如何访问父类的私有成员变量呢？对！可以在父类中提供公共的getXxx()方法和setXxx()方法。 1.4 方法重写1.4.1 概念方法重写 ：子类中出现与父类一模一样的方法时（返回值类型，方法名和参数列表都相同），会出现覆盖效果，也称为重写或者复写。声明不变，重新实现。 1.4.2使用场景与案例发生在子父类之间的关系。子类继承了父类的方法，但是子类觉得父类的这方法不足以满足自己的需求，子类重新写了一个与父类同名的方法，以便覆盖父类的该方 法。 例如：我们定义了一个动物类代码如下： public class Animal { public void run(){ System.out.println(\"动物跑的很快！\"); } public void cry(){ System.out.println(\"动物都可以叫~~~\"); } } 然后定义一个猫类，猫可能认为父类cry()方法不能满足自己的需求 代码如下： public class Cat extends Animal { public void cry(){ System.out.println(\"我们一起学猫叫，喵喵喵！喵的非常好听！\"); } } public class Test { public static void main(String[] args) { // 创建子类对象 Cat ddm = new Cat()； // 调用父类继承而来的方法 ddm.run(); // 调用子类重写的方法 ddm.cry(); } } 1.4.3 @Override重写注解 @Override:注解，重写注解校验！ 这个注解标记的方法，就说明这个方法必须是重写父类的方法，否则编译阶段报错。 建议重写都加上这个注解，一方面可以提高代码的可读性，一方面可以防止重写出错！ 加上后的子类代码形式如下： public class Cat extends Animal { // 声明不变，重新实现 // 方法名称与父类全部一样，只是方法体中的功能重写写了！ @Override public void cry(){ System.out.println(\"我们一起学猫叫，喵喵喵！喵的非常好听！\"); } } 1.4.4 注意事项 方法重写是发生在子父类之间的关系。 子类方法覆盖父类方法，必须要保证权限大于等于父类权限。 子类方法覆盖父类方法，返回值类型、函数名和参数列表都要一模一样。 1.5 this与super 子类的每个构造方法中均有默认的super()，调用父类的空参构造。手动调用父类构造会覆盖默认的super()。 super() 和 this() 都必须是在构造方法的第一行，所以不能同时出现。 super(..)和this(…)是根据参数去确定调用父类哪个构造器的。 super(..)可以调用父类构造器初始化继承自父类的成员变量的数据。 this(..)可以调用本类中的其他构造器。 第二章 引用类型使用总结实际的开发中，引用类型的使用非常重要，也是非常普遍的。我们可以在理解基本类型的使用方式基础上，进一步去掌握引用类型的使用方式。基本类型可以作为成员变量、作为方法的参数、作为方法的返回值，那么当然引用类型也是可以的。在这我们使用两个例子 , 来学习一下。 2.1 引用类型作为方法参数和返回值public class Person{ public void eat(){ System.out.println(\"吃饭\"); } } public class Test{ public static void main(String[] args){ method(new Person()); Person p = createPerson(); } //引用类型作为方法参数,在前面笔记本案例中我们也使用了接口类型作为方法参数 pubic static void method(Person p){ p.eat(); } //引用类型作为返回值 public static Person createPerson(){ return new Person(); } } 2.2 引用类型作为成员变量​ 我们每个人(Person)都有一个身份证(IDCard) , 为了表示这种关系 , 就需要在Person中定义一个IDCard的成员变量。定义Person类时，代码如下： class Person { String name;//姓名 int age;//年龄 } ​ 使用使用String 类型表示姓名 , int 类型表示年龄。其实，String本身就是引用类型，我们往往忽略了它是引用类型。如果我们继续丰富这个类的定义，给Person 增加身份证号 , 身份证签发机关等属性，我们将如何编写呢？这时候就需要编写一个IDCard类了 定义IDCard(身份证)类，添加身份证号 , 签发地等属性： class IDCard { String idNum;//身份证号 String authority;//签发地 //getter和setter方法 //... //toString方法 //... } 修改Person类： public class Person { String name;//姓名 int age;//年龄 IDCard idCard;//表示自己的身份证信息 //name和age的getter、setter方法 //... public IDCard getIdCard() { return idCard; } public void setIdCard(IDCard idCard) { this.idCard = idCard; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + \", idCard=\" + idCard + '}'; } } 测试类： public class TestDemo { public static void main(String[] args) { //创建IDCard对象 IDCard idCard = new IDCard(); //设置身份证号 idCard.setIdNum(\"110113201606066666\"); //设置签发地 idCard.setAuthority(\"北京市顺义区公安局\"); //创建Person对象 Person p = new Person(); //设置姓名 p.setName(\"小顺子\"); //设置年龄 p.setAge(2); //设置身份证信息 p.setIdCard(idCard); //打印小顺子的信息 System.out.println(p); } } 输出结果: Person{name='小顺子', age=2, idCard=IDCard{idNum='110113201606066666', authority='北京市顺义区公安局'}}","categories":[{"name":"java","slug":"java","permalink":"https://409713427.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://409713427.github.io/tags/java/"}],"author":"wst"},{"title":"我的第一篇博客文章","slug":"我的第一篇博客文章","date":"2021-09-16T05:22:43.000Z","updated":"2021-09-17T05:48:05.769Z","comments":true,"path":"2021/091615650.html","link":"","permalink":"https://409713427.github.io/2021/091615650.html","excerpt":"我的博客文章编写","text":"我的博客文章编写 标题使用标题时候需要写# 这是第一个段落 这是第二个段落 区块引用 这是一段高亮显示 超链接 百度 图片","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2021-09-15T11:20:52.891Z","updated":"2021-09-16T09:35:37.612Z","comments":true,"path":"2021/091516107.html","link":"","permalink":"https://409713427.github.io/2021/091516107.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Hello HexoCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"docker","slug":"docker","permalink":"https://409713427.github.io/categories/docker/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/categories/elasticsearch/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/categories/RabbitMQ/"},{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/categories/bug/"},{"name":"css","slug":"css","permalink":"https://409713427.github.io/categories/css/"},{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/categories/springboot/"},{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/categories/redis/"},{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/categories/springcloud/"},{"name":"ssm","slug":"ssm","permalink":"https://409713427.github.io/categories/ssm/"},{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/categories/javascript/"},{"name":"linux","slug":"linux","permalink":"https://409713427.github.io/categories/linux/"},{"name":"java","slug":"java","permalink":"https://409713427.github.io/categories/java/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://409713427.github.io/tags/docker/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://409713427.github.io/tags/elasticsearch/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://409713427.github.io/tags/RabbitMQ/"},{"name":"bug","slug":"bug","permalink":"https://409713427.github.io/tags/bug/"},{"name":"css","slug":"css","permalink":"https://409713427.github.io/tags/css/"},{"name":"redis","slug":"redis","permalink":"https://409713427.github.io/tags/redis/"},{"name":"springboot","slug":"springboot","permalink":"https://409713427.github.io/tags/springboot/"},{"name":"springcloud","slug":"springcloud","permalink":"https://409713427.github.io/tags/springcloud/"},{"name":"ssm","slug":"ssm","permalink":"https://409713427.github.io/tags/ssm/"},{"name":"javascript","slug":"javascript","permalink":"https://409713427.github.io/tags/javascript/"},{"name":"linux","slug":"linux","permalink":"https://409713427.github.io/tags/linux/"},{"name":"java","slug":"java","permalink":"https://409713427.github.io/tags/java/"}]}